<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Predicting first-episode homelessness among US Veterans using longitudinal EHR data: time-varying models and social risk factors</title>
      <link>https://arxiv.org/abs/2602.02731</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.02731</guid>
      <description>arXiv:2602.02731v1 Announce Type: new 
Abstract: Homelessness among US veterans remains a critical public health challenge, yet risk prediction offers a pathway for proactive intervention. In this retrospective prognostic study, we analyzed electronic health record (EHR) data from 4,276,403 Veterans...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, model, large language model, transformer, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 04 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>model</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes</title>
      <link>https://arxiv.org/abs/2602.00053</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00053</guid>
      <description>arXiv:2602.00053v1 Announce Type: new 
Abstract: Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing req...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, model, product, RAG, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 04 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>model</category>
      <category>product</category>
    </item>
    <item>
      <title>Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning</title>
      <link>https://arxiv.org/abs/2602.00298</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00298</guid>
      <description>arXiv:2602.00298v1 Announce Type: new 
Abstract: Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluatin...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; instruction, alignment, large language model, model, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 04 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>instruction</category>
      <category>alignment</category>
      <category>large language model</category>
    </item>
    <item>
      <title>SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?</title>
      <link>https://arxiv.org/abs/2602.00327</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00327</guid>
      <description>arXiv:2602.00327v1 Announce Type: new 
Abstract: We explore the use of large language models (LLMs) for next-utterance prediction in human dialogue. Despite recent advances in LLMs demonstrating their ability to engage in natural conversations with users, we show that even leading models surprisingl...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, large language model, research, multimodal, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 04 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>large language model</category>
      <category>research</category>
    </item>
    <item>
      <title>MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants</title>
      <link>https://arxiv.org/abs/2602.00353</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00353</guid>
      <description>arXiv:2602.00353v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly applied in mental health support systems, where reliable recognition of high-risk states such as suicidal ideation and self-harm is safety-critical. However, existing evaluations primarily rely on aggregat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, large language model, research, analysis, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 04 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>large language model</category>
      <category>research</category>
    </item>
    <item>
      <title>Augmenting Parameter-Efficient Pre-trained Language Models with Large Language Models</title>
      <link>https://arxiv.org/abs/2602.02501</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.02501</guid>
      <description>arXiv:2602.02501v1 Announce Type: new 
Abstract: Training AI models in cybersecurity with help of vast datasets offers significant opportunities to mimic real-world behaviors effectively. However, challenges like data drift and scarcity of labelled data lead to frequent updates of models and the ris...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, large language model, tool, fine-tuning, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 04 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>large language model</category>
      <category>tool</category>
    </item>
    <item>
      <title>Time-Critical Multimodal Medical Transportation: Organs, Patients, and Medical Supplies</title>
      <link>https://arxiv.org/abs/2602.02736</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.02736</guid>
      <description>arXiv:2602.02736v1 Announce Type: new 
Abstract: Timely transportation of organs, patients, and medical supplies is critical to modern healthcare, particularly in emergencies and transplant scenarios where even short delays can severely impact outcomes. Traditional ground-based vehicles such as ambu...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, model, ICL, RAG, multimodal | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 04 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>model</category>
      <category>ICL</category>
    </item>
    <item>
      <title>Sparse Adapter Fusion for Continual Learning in NLP</title>
      <link>https://arxiv.org/abs/2602.02502</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.02502</guid>
      <description>arXiv:2602.02502v1 Announce Type: new 
Abstract: Continual learning in natural language processing plays a crucial role in adapting to evolving data and preventing catastrophic forgetting. Despite significant progress, existing methods still face challenges, such as inefficient parameter reuse acros...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 04 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>WideSeek: Advancing Wide Research via Multi-Agent Scaling</title>
      <link>https://arxiv.org/abs/2602.02636</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.02636</guid>
      <description>arXiv:2602.02636v1 Announce Type: new 
Abstract: Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for retrieving and synthesizing comprehensive information under complex constraints in parallel. However, progress in this field is impeded by the lack of dedica...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, arxiv, research, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 04 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>arxiv</category>
      <category>research</category>
    </item>
  </channel>
</rss>