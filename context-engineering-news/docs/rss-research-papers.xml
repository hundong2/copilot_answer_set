<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>A Human-Centric Pipeline for Aligning Large Language Models with Chinese Medical Ethics</title>
      <link>https://arxiv.org/abs/2601.07954</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07954</guid>
      <description>arXiv:2601.07954v1 Announce Type: new 
Abstract: Recent advances in large language models have enabled their application to a range of healthcare tasks. However, aligning LLMs with the nuanced demands of medical ethics, especially under complex real world scenarios, remains underexplored. In this wo...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, framework, experiment, alignment, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>framework</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Knowing But Not Doing: Convergent Morality and Divergent Action in LLMs</title>
      <link>https://arxiv.org/abs/2601.07972</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07972</guid>
      <description>arXiv:2601.07972v1 Announce Type: new 
Abstract: Value alignment is central to the development of safe and socially compatible artificial intelligence. However, how Large Language Models (LLMs) represent and enact human values in real-world decision contexts remains under-explored. We present ValAct...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, alignment, context, large language model, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>alignment</category>
      <category>context</category>
    </item>
    <item>
      <title>Explaining Generalization of AI-Generated Text Detectors Through Linguistic Analysis</title>
      <link>https://arxiv.org/abs/2601.07974</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07974</guid>
      <description>arXiv:2601.07974v1 Announce Type: new 
Abstract: AI-text detectors achieve high accuracy on in-domain benchmarks, but often struggle to generalize across different generation conditions such as unseen prompts, model families, or domains. While prior work has reported these generalization gaps, there...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, analysis, large language model, study, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>analysis</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Multilingual, Multimodal Pipeline for Creating Authentic and Structured Fact-Checked Claim Dataset</title>
      <link>https://arxiv.org/abs/2601.07985</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07985</guid>
      <description>arXiv:2601.07985v1 Announce Type: new 
Abstract: The rapid proliferation of misinformation across online platforms underscores the urgent need for robust, up-to-date, explainable, and multilingual fact-checking resources. However, existing datasets are limited in scope, often lacking multimodal evid...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, research, platform, paper, multimodal | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>research</category>
      <category>platform</category>
    </item>
    <item>
      <title>Is Sentiment Banana-Shaped? Exploring the Geometry and Portability of Sentiment Concept Vectors</title>
      <link>https://arxiv.org/abs/2601.07995</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07995</guid>
      <description>arXiv:2601.07995v1 Announce Type: new 
Abstract: Use cases of sentiment analysis in the humanities often require contextualized, continuous scores. Concept Vector Projections (CVP) offer a recent solution: by modeling sentiment as a direction in embedding space, they produce continuous, multilingual...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; embedding, context, vector, model, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>embedding</category>
      <category>context</category>
      <category>vector</category>
    </item>
    <item>
      <title>Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms</title>
      <link>https://arxiv.org/abs/2601.08049</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.08049</guid>
      <description>arXiv:2601.08049v1 Announce Type: new 
Abstract: The increasing adoption of smart classroom technologies in higher education has mainly focused on automating attendance, with limited attention given to students&amp;#x27; emotional and cognitive engagement during lectures. This limits instructors&amp;#x27; ability to ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; attention, experiment, paper, model, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>attention</category>
      <category>experiment</category>
      <category>paper</category>
    </item>
    <item>
      <title>Semantic Gravity Wells: Why Negative Constraints Backfire</title>
      <link>https://arxiv.org/abs/2601.08070</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.08070</guid>
      <description>arXiv:2601.08070v1 Announce Type: new 
Abstract: Negative constraints (instructions of the form &amp;quot;do not use word X&amp;quot;) represent a fundamental test of instruction-following capability in large language models. Despite their apparent simplicity, these constraints fail with striking regularity, and the ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, instruction, large language model, model, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>instruction</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Affect and Effect: Limitations of regularisation-based continual learning in EEG-based emotion classification</title>
      <link>https://arxiv.org/abs/2601.07858</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07858</guid>
      <description>arXiv:2601.07858v1 Announce Type: new 
Abstract: Generalisation to unseen subjects in EEG-based emotion classification remains a challenge due to high inter-and intra-subject variability. Continual learning (CL) poses a promising solution by learning from a sequence of tasks while mitigating catastr...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; alignment, fine-tuning, study, model, memory | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>alignment</category>
      <category>fine-tuning</category>
      <category>study</category>
    </item>
    <item>
      <title>RewriteNets: End-to-End Trainable String-Rewriting for Generative Sequence Modeling</title>
      <link>https://arxiv.org/abs/2601.07868</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07868</guid>
      <description>arXiv:2601.07868v1 Announce Type: new 
Abstract: Dominant sequence models like the Transformer represent structure implicitly through dense attention weights, incurring quadratic complexity. We propose RewriteNets, a novel neural architecture built on an alternative paradigm: explicit, parallel stri...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; attention, transformer, study, model, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>attention</category>
      <category>transformer</category>
      <category>study</category>
    </item>
    <item>
      <title>Multiplicative Orthogonal Sequential Editing for Language Models</title>
      <link>https://arxiv.org/abs/2601.07873</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07873</guid>
      <description>arXiv:2601.07873v1 Announce Type: new 
Abstract: Knowledge editing aims to efficiently modify the internal knowledge of large language models (LLMs) without compromising their other capabilities. The prevailing editing paradigm, which appends an update matrix to the original parameter matrix, has be...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, LLM, experiment, large language model, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>LLM</category>
      <category>experiment</category>
    </item>
    <item>
      <title>E^2-LLM: Bridging Neural Signals and Interpretable Affective Analysis</title>
      <link>https://arxiv.org/abs/2601.07877</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07877</guid>
      <description>arXiv:2601.07877v1 Announce Type: new 
Abstract: Emotion recognition from electroencephalography (EEG) signals remains challenging due to high inter-subject variability, limited labeled data, and the lack of interpretable reasoning in existing approaches. While recent multimodal large language model...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, cross-modal, LLM, framework, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>cross-modal</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Executable Ontologies in Game Development: From Algorithmic Control to Semantic World Modeling</title>
      <link>https://arxiv.org/abs/2601.07964</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07964</guid>
      <description>arXiv:2601.07964v1 Announce Type: new 
Abstract: This paper examines the application of Executable Ontologies (EO), implemented through the boldsea framework, to game development. We argue that EO represents a paradigm shift: a transition from algorithmic behavior programming to semantic world model...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, LLM, paper, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>LLM</category>
      <category>paper</category>
    </item>
    <item>
      <title>Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms</title>
      <link>https://arxiv.org/abs/2601.08052</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.08052</guid>
      <description>arXiv:2601.08052v1 Announce Type: new 
Abstract: Dairy farming is an energy intensive sector that relies heavily on grid electricity. With increasing renewable energy integration, sustainable energy management has become essential for reducing grid dependence and supporting the United Nations Sustai...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, study, framework, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>study</category>
      <category>framework</category>
    </item>
    <item>
      <title>Bridging the Trust Gap: Clinician-Validated Hybrid Explainable AI for Maternal Health Risk Assessment in Bangladesh</title>
      <link>https://arxiv.org/abs/2601.07866</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07866</guid>
      <description>arXiv:2601.07866v1 Announce Type: new 
Abstract: While machine learning shows promise for maternal health risk prediction, clinical adoption in resource-constrained settings faces a critical barrier: lack of explainability and trust. This study presents a hybrid explainable AI (XAI) framework combin...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, study, analysis, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>study</category>
      <category>analysis</category>
    </item>
    <item>
      <title>HOSC: A Periodic Activation with Saturation Control for High-Fidelity Implicit Neural Representations</title>
      <link>https://arxiv.org/abs/2601.07870</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07870</guid>
      <description>arXiv:2601.07870v1 Announce Type: new 
Abstract: Periodic activations such as sine preserve high-frequency information in implicit neural representations (INRs) through their oscillatory structure, but often suffer from gradient instability and limited control over multi-scale behavior. We introduce...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, image, study, audio, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>image</category>
      <category>study</category>
    </item>
    <item>
      <title>Internal Deployment Gaps in AI Regulation</title>
      <link>https://arxiv.org/abs/2601.08005</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.08005</guid>
      <description>arXiv:2601.08005v1 Announce Type: new 
Abstract: Frontier AI regulations primarily focus on systems deployed to external users, where deployment is more visible and subject to outside scrutiny. However, high-stakes applications can occur internally when companies deploy highly capable systems within...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>A New Strategy for Verifying Reach-Avoid Specifications in Neural Feedback Systems</title>
      <link>https://arxiv.org/abs/2601.08065</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.08065</guid>
      <description>arXiv:2601.08065v1 Announce Type: new 
Abstract: Forward reachability analysis is the predominant approach for verifying reach-avoid properties in neural feedback systems (dynamical systems controlled by neural networks). This dominance stems from the limited scalability of existing backward reachab...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, framework, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>framework</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>NOVAK: Unified adaptive optimizer for deep neural networks</title>
      <link>https://arxiv.org/abs/2601.07876</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.07876</guid>
      <description>arXiv:2601.07876v1 Announce Type: new 
Abstract: This work introduces NOVAK, a modular gradient-based optimization algorithm that integrates adaptive moment estimation, rectified learning-rate scheduling, decoupled weight regularization, multiple variants of Nesterov momentum, and lookahead synchron...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; product, framework, image, analysis, memory | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 14 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>product</category>
      <category>framework</category>
      <category>image</category>
    </item>
  </channel>
</rss>