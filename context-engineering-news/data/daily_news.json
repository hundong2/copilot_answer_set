{
  "generated_at": "2025-08-13T20:05:48.085011",
  "total_items": 45,
  "items": [
    {
      "title": "Argument Quality Annotation and Gender Bias Detection in Financial Communication through Large Language Models",
      "url": "https://arxiv.org/abs/2508.08262",
      "description": "arXiv:2508.08262v1 Announce Type: new \nAbstract: Financial arguments play a critical role in shaping investment decisions and public trust in financial institutions. Nevertheless, assessing their quality remains poorly studied in the literature. In this paper, we examine the capabilities of three st...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "large language model",
        "research",
        "experiment",
        "alignment",
        "model",
        "API",
        "LLM",
        "analysis",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "TurQUaz at CheckThat! 2025: Debating Large Language Models for Scientific Web Discourse Detection",
      "url": "https://arxiv.org/abs/2508.08265",
      "description": "arXiv:2508.08265v1 Announce Type: new \nAbstract: In this paper, we present our work developed for the scientific web discourse detection task (Task 4a) of CheckThat! 2025. We propose a novel council debate method that simulates structured academic discussions among multiple large language models (LL...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "large language model",
        "study",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Heartificial Intelligence: Exploring Empathy in Language Models",
      "url": "https://arxiv.org/abs/2508.08271",
      "description": "arXiv:2508.08271v1 Announce Type: new \nAbstract: Large language models have become increasingly common, used by millions of people worldwide in both professional and personal contexts. As these models continue to advance, they are frequently serving as virtual assistants and companions. In human int...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "large language model",
        "study",
        "model",
        "API",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "TT-XAI: Trustworthy Clinical Text Explanations via Keyword Distillation and LLM Reasoning",
      "url": "https://arxiv.org/abs/2508.08273",
      "description": "arXiv:2508.08273v1 Announce Type: new \nAbstract: Clinical language models often struggle to provide trustworthy predictions and explanations when applied to lengthy, unstructured electronic health records (EHRs). This work introduces TT-XAI, a lightweight and effective framework that improves both c...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "augmented",
        "arxiv",
        "chain-of-thought",
        "large language model",
        "reasoning",
        "study",
        "model",
        "prompt",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Distilling Knowledge from Large Language Models: A Concept Bottleneck Model for Hate and Counter Speech Recognition",
      "url": "https://arxiv.org/abs/2508.08274",
      "description": "arXiv:2508.08274v1 Announce Type: new \nAbstract: The rapid increase in hate speech on social media has exposed an unprecedented impact on society, making automated methods for detecting such content important. Unlike prior black-box models, we propose a novel transparent method for automated hate an...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "large language model",
        "model",
        "transformer",
        "RAG",
        "LLM",
        "API",
        "embedding",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis",
      "url": "https://arxiv.org/abs/2508.08275",
      "description": "arXiv:2508.08275v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) rely on continual instruction tuning to adapt to the evolving demands of real-world applications. However, progress in this area is hindered by the lack of rigorous and systematic benchmarks. To address this ga...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "fine-tuning",
        "multimodal",
        "arxiv",
        "chain-of-thought",
        "large language model",
        "reasoning",
        "CoT",
        "model",
        "LLM",
        "analysis",
        "instruction"
      ],
      "score": 1.0
    },
    {
      "title": "Evaluating Contrast Localizer for Identifying Causal Unitsin Social & Mathematical Tasks in Language Models",
      "url": "https://arxiv.org/abs/2508.08276",
      "description": "arXiv:2508.08276v1 Announce Type: new \nAbstract: This work adapts a neuroscientific contrast localizer to pinpoint causally relevant units for Theory of Mind (ToM) and mathematical reasoning tasks in large language models (LLMs) and vision-language models (VLMs). Across 11 LLMs and 5 VLMs ranging in...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "reasoning",
        "large language model",
        "model",
        "LLM",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "Objective Metrics for Evaluating Large Language Models Using External Data Sources",
      "url": "https://arxiv.org/abs/2508.08277",
      "description": "arXiv:2508.08277v1 Announce Type: new \nAbstract: Evaluating the performance of Large Language Models (LLMs) is a critical yet challenging task, particularly when aiming to avoid subjective assessments. This paper proposes a framework for leveraging subjective metrics derived from the class textual m...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "large language model",
        "model",
        "alignment",
        "RAG",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "MinionsLLM: a Task-adaptive Framework For The Training and Control of Multi-Agent Systems Through Natural Language",
      "url": "https://arxiv.org/abs/2508.08283",
      "description": "arXiv:2508.08283v1 Announce Type: new \nAbstract: This paper presents MinionsLLM, a novel framework that integrates Large Language Models (LLMs) with Behavior Trees (BTs) and Formal Grammars to enable natural language control of multi-agent systems within arbitrary, user-defined environments. Minions...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "paper",
        "release",
        "arxiv",
        "large language model",
        "research",
        "experiment",
        "model",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Topos Theory for Generative AI and LLMs",
      "url": "https://arxiv.org/abs/2508.08293",
      "description": "arXiv:2508.08293v1 Announce Type: new \nAbstract: We propose the design of novel categorical generative AI architectures (GAIAs) using topos theory, a type of category that is ``set-like\": a topos has all (co)limits, is Cartesian closed, and has a subobject classifier. Previous theoretical results on...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "large language model",
        "model",
        "transformer",
        "LLM",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models",
      "url": "https://arxiv.org/abs/2508.08300",
      "description": "arXiv:2508.08300v1 Announce Type: new \nAbstract: A significant barrier to the widespread adoption of Bayesian inference is the specification of prior distributions and likelihoods, which often requires specialized statistical expertise. This paper investigates the feasibility of using a Large Langua...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "large language model",
        "experiment",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "First Ask Then Answer: A Framework Design for AI Dialogue Based on Supplementary Questioning with Large Language Models",
      "url": "https://arxiv.org/abs/2508.08308",
      "description": "arXiv:2508.08308v1 Announce Type: new \nAbstract: Large Language Models (LLMs) often struggle to deliver accurate and actionable answers when user-provided information is incomplete or ill-specified. We propose a new interaction paradigm, First Ask Then Answer (FATA), in which, through prompt words, ...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "reasoning",
        "large language model",
        "experiment",
        "model",
        "prompt",
        "LLM",
        "framework",
        "prompting",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge",
      "url": "https://arxiv.org/abs/2508.08344",
      "description": "arXiv:2508.08344v1 Announce Type: new \nAbstract: Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) is an increasingly explored approach for combining the reasoning capabilities of large language models with the structured evidence of knowledge graphs. However, current evaluation practice...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "arxiv",
        "reasoning",
        "large language model",
        "model",
        "retrieval",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "UrzaGPT: LoRA-Tuned Large Language Models for Card Selection in Collectible Card Games",
      "url": "https://arxiv.org/abs/2508.08382",
      "description": "arXiv:2508.08382v1 Announce Type: new \nAbstract: Collectible card games (CCGs) are a difficult genre for AI due to their partial observability, long-term decision-making, and evolving card sets. Due to this, current AI models perform vastly worse than human players at CCG tasks such as deckbuilding ...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "fine-tuning",
        "zero-shot",
        "arxiv",
        "large language model",
        "model",
        "RAG",
        "LLM",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "OverFill: Two-Stage Models for Efficient Language Model Decoding",
      "url": "https://arxiv.org/abs/2508.08446",
      "description": "arXiv:2508.08446v1 Announce Type: new \nAbstract: Large language models (LLMs) excel across diverse tasks but face significant deployment challenges due to high inference costs. LLM inference comprises prefill (compute-bound) and decode (memory-bound) stages, with decode dominating latency particular...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "large language model",
        "model",
        "memory",
        "RAG",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Benchmarking Large Language Models for Geolocating Colonial Virginia Land Grants",
      "url": "https://arxiv.org/abs/2508.08266",
      "description": "arXiv:2508.08266v1 Announce Type: new \nAbstract: Virginia's seventeenth- and eighteenth-century land patents survive primarily as narrative metes-and-bounds descriptions, limiting spatial analysis. This study systematically evaluates current-generation large language models (LLMs) in converting thes...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "augmented",
        "release",
        "arxiv",
        "chain-of-thought",
        "large language model",
        "study",
        "model",
        "tool",
        "API",
        "LLM",
        "analysis",
        "context",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Doctor Sun: A Bilingual Multimodal Large Language Model for Biomedical AI",
      "url": "https://arxiv.org/abs/2508.08270",
      "description": "arXiv:2508.08270v1 Announce Type: new \nAbstract: Large multimodal models (LMMs) have demonstrated significant potential in providing innovative solutions for various biomedical tasks, including pathology analysis, radiology report generation, and biomedical assistance. However, the existing multimod...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "release",
        "multimodal",
        "arxiv",
        "large language model",
        "image",
        "research",
        "model",
        "alignment",
        "LLM",
        "vision",
        "analysis",
        "instruction"
      ],
      "score": 1.0
    },
    {
      "title": "XFMNet: Decoding Cross-Site and Nonstationary Water Patterns via Stepwise Multimodal Fusion for Long-Term Water Quality Forecasting",
      "url": "https://arxiv.org/abs/2508.08279",
      "description": "arXiv:2508.08279v1 Announce Type: new \nAbstract: Long-term time-series forecasting is critical for environmental monitoring, yet water quality prediction remains challenging due to complex periodicity, nonstationarity, and abrupt fluctuations induced by ecological factors. These challenges are furth...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "multimodal",
        "arxiv",
        "image",
        "experiment",
        "model",
        "attention",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Understanding Transformers through the Lens of Pavlovian Conditioning",
      "url": "https://arxiv.org/abs/2508.08289",
      "description": "arXiv:2508.08289v1 Announce Type: new \nAbstract: Transformer architectures have revolutionized artificial intelligence (AI) through their attention mechanisms, yet the computational principles underlying their success remain opaque. We present a novel theoretical framework that reinterprets the core...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "arxiv",
        "model",
        "memory",
        "transformer",
        "retrieval",
        "framework",
        "analysis",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "Probabilistic Emissivity Retrieval from Hyperspectral Data via Physics-Guided Variational Inference",
      "url": "https://arxiv.org/abs/2508.08291",
      "description": "arXiv:2508.08291v1 Announce Type: new \nAbstract: Recent research has proven neural networks to be a powerful tool for performing hyperspectral imaging (HSI) target identification. However, many deep learning frameworks deliver a single material class prediction and operate on a per-pixel basis; such...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "research",
        "model",
        "tool",
        "retrieval",
        "RAG",
        "framework",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Comparative study of machine learning and statistical methods for automatic identification and quantification in {\\gamma}-ray spectrometry",
      "url": "https://arxiv.org/abs/2508.08306",
      "description": "arXiv:2508.08306v1 Announce Type: new \nAbstract: During the last decade, a large number of different numerical methods have been proposed to tackle the automatic identification and quantification in {\\gamma}-ray spectrometry. However, the lack of common benchmarks, including datasets, code and compa...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "experiment",
        "model",
        "analysis",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "context window",
        "prompt engineering",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "CoT",
        "framework",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "LLM",
        "attention",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "reasoning",
        "knowledge base",
        "model",
        "vector",
        "retrieval",
        "RAG",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "fine-tuning",
        "LLM",
        "tool",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "retrieval",
        "RAG",
        "API",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "prompt",
        "LLM",
        "framework",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "framework",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Towards Heterogeneity-Aware and Energy-Efficient Topology Optimization for Decentralized Federated Learning in Edge Environment",
      "url": "https://arxiv.org/abs/2508.08278",
      "description": "arXiv:2508.08278v1 Announce Type: new \nAbstract: Federated learning (FL) has emerged as a promising paradigm within edge computing (EC) systems, enabling numerous edge devices to collaboratively train artificial intelligence (AI) models while maintaining data privacy. To overcome the communication b...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "model",
        "RAG",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "Multi-grained spatial-temporal feature complementarity for accurate online cellular traffic prediction",
      "url": "https://arxiv.org/abs/2508.08281",
      "description": "arXiv:2508.08281v1 Announce Type: new \nAbstract: Knowledge discovered from telecom data can facilitate proactive understanding of network dynamics and user behaviors, which in turn empowers service providers to optimize cellular traffic scheduling and resource allocation. Nevertheless, the telecom i...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "arxiv",
        "attention",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "model",
        "tool",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "MoSSDA: A Semi-Supervised Domain Adaptation Framework for Multivariate Time-Series Classification using Momentum Encoder",
      "url": "https://arxiv.org/abs/2508.08280",
      "description": "arXiv:2508.08280v1 Announce Type: new \nAbstract: Deep learning has emerged as the most promising approach in various fields; however, when the distributions of training and test data are different (domain shift), the performance of deep learning models can degrade. Semi-supervised domain adaptation ...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "experiment",
        "model",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "paper",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Topos Causal Models",
      "url": "https://arxiv.org/abs/2508.08295",
      "description": "arXiv:2508.08295v1 Announce Type: new \nAbstract: We propose topos causal models (TCMs), a novel class of causal models that exploit the key properties of a topos category: they are (co)complete, meaning all (co)limits exist, they admit a subobject classifier, and allow exponential objects. The main ...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "reasoning",
        "model",
        "example"
      ],
      "score": 0.4
    },
    {
      "title": "Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning",
      "url": "https://arxiv.org/abs/2508.08385",
      "description": "arXiv:2508.08385v1 Announce Type: new \nAbstract: We study an efficient implementation of Multi-Armed Bandit (MAB)-based Monte-Carlo Tree Search (MCTS) for classical planning. One weakness of MCTS is that it spends a significant time deciding which node to expand next. While selecting a node from an ...",
      "published_date": "2025-08-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study"
      ],
      "score": 0.4
    },
    {
      "title": "TextQuests: How Good are LLMs at Text-Based Video Games?",
      "url": "https://huggingface.co/blog/textquests",
      "description": "...",
      "published_date": "2025-08-12T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "ðŸ‡µðŸ‡­ FilBench - Can LLMs Understand and Generate Filipino?",
      "url": "https://huggingface.co/blog/filbench",
      "description": "...",
      "published_date": "2025-08-12T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}