{
  "generated_at": "2025-12-11T20:06:22.635944",
  "total_items": 45,
  "items": [
    {
      "title": "Noise-Robust Abstractive Compression in Retrieval-Augmented Language Models",
      "url": "https://arxiv.org/abs/2512.08943",
      "description": "arXiv:2512.08943v1 Announce Type: new \nAbstract: Abstractive compression utilizes smaller langauge models to condense query-relevant context, reducing computational costs in retrieval-augmented generation (RAG). However, retrieved documents often include information that is either irrelevant to answ...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "augmented",
        "compression",
        "experiment",
        "model",
        "retrieval",
        "RAG",
        "attention",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing Reliability across Short and Long-Form QA via Reinforcement Learning",
      "url": "https://arxiv.org/abs/2512.08944",
      "description": "arXiv:2512.08944v1 Announce Type: new \nAbstract: While reinforcement learning has unlocked unprecedented complex reasoning in large language models, it has also amplified their propensity for hallucination, creating a critical trade-off between capability and reliability. This work confronts this ch...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "reasoning",
        "experiment",
        "model",
        "research",
        "framework",
        "RAG",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "The Linguistic Architecture of Reflective Thought: Evaluation of a Large Language Model as a Tool to Isolate the Formal Structure of Mentalization",
      "url": "https://arxiv.org/abs/2512.08945",
      "description": "arXiv:2512.08945v1 Announce Type: new \nAbstract: Background: Mentalization integrates cognitive, affective, and intersubjective components. Large Language Models (LLMs) display an increasing ability to generate reflective texts, raising questions regarding the relationship between linguistic form an...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "study",
        "model",
        "large language model",
        "LLM",
        "tool",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Luxical: High-Speed Lexical-Dense Text Embeddings",
      "url": "https://arxiv.org/abs/2512.09015",
      "description": "arXiv:2512.09015v1 Announce Type: new \nAbstract: Frontier language model quality increasingly hinges on our ability to organize web-scale text corpora for training. Today's dominant tools trade off speed and flexibility: lexical classifiers (e.g., FastText) are fast but limited to producing classifi...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "model",
        "embedding",
        "retrieval",
        "transformer",
        "tool",
        "library",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Knowledge-Guided Large Language Model for Automatic Pediatric Dental Record Understanding and Safe Antibiotic Recommendation",
      "url": "https://arxiv.org/abs/2512.09127",
      "description": "arXiv:2512.09127v1 Announce Type: new \nAbstract: Accurate interpretation of pediatric dental clinical records and safe antibiotic prescribing remain persistent challenges in dental informatics. Traditional rule-based clinical decision support systems struggle with unstructured dental narratives, inc...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "study",
        "experiment",
        "model",
        "framework",
        "retrieval",
        "RAG",
        "large language model",
        "LLM",
        "arxiv",
        "summarization"
      ],
      "score": 1.0
    },
    {
      "title": "Detecting Hallucinations in Graph Retrieval-Augmented Generation via Attention Patterns and Semantic Alignment",
      "url": "https://arxiv.org/abs/2512.09148",
      "description": "arXiv:2512.09148v1 Announce Type: new \nAbstract: Graph-based Retrieval-Augmented Generation (GraphRAG) enhances Large Language Models (LLMs) by incorporating external knowledge from linearized subgraphs retrieved from knowledge graphs. However, LLMs struggle to interpret the relational and topologic...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "alignment",
        "augmented",
        "model",
        "retrieval",
        "analysis",
        "RAG",
        "attention",
        "large language model",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "MindShift: Analyzing Language Models' Reactions to Psychological Prompts",
      "url": "https://arxiv.org/abs/2512.09149",
      "description": "arXiv:2512.09149v1 Announce Type: new \nAbstract: Large language models (LLMs) hold the potential to absorb and reflect personality traits and attitudes specified by users. In our study, we investigated this potential using robust psychometric measures. We adapted the most studied test in psychologic...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "alignment",
        "study",
        "model",
        "prompt",
        "large language model",
        "LLM",
        "ICL",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Targeting Misalignment: A Conflict-Aware Framework for Reward-Model-based LLM Alignment",
      "url": "https://arxiv.org/abs/2512.09212",
      "description": "arXiv:2512.09212v1 Announce Type: new \nAbstract: Reward-model-based fine-tuning is a central paradigm in aligning Large Language Models with human preferences. However, such approaches critically rely on the assumption that proxy reward models accurately reflect intended supervision, a condition oft...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "alignment",
        "experiment",
        "model",
        "fine-tuning",
        "paper",
        "framework",
        "RAG",
        "large language model",
        "LLM",
        "vision",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "CORE: A Conceptual Reasoning Layer for Large Language Models",
      "url": "https://arxiv.org/abs/2512.09222",
      "description": "arXiv:2512.09222v1 Announce Type: new \nAbstract: Large language models handle single-turn generation well, but multi-turn interactions still require the model to reconstruct user intent and task state from an expanding token history because internal representations do not persist across turns. This ...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "reasoning",
        "model",
        "prompt",
        "large language model",
        "instruction",
        "library"
      ],
      "score": 1.0
    },
    {
      "title": "Training-free Context-adaptive Attention for Efficient Long Context Modeling",
      "url": "https://arxiv.org/abs/2512.09238",
      "description": "arXiv:2512.09238v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of natural language processing tasks. These capabilities stem primarily from the self-attention mechanism, which enables modeling of long-range dependencies. Ho...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "compression",
        "experiment",
        "paper",
        "model",
        "analysis",
        "memory",
        "attention",
        "large language model",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Calibrated Trust in Dealing with LLM Hallucinations: A Qualitative Study",
      "url": "https://arxiv.org/abs/2512.09088",
      "description": "arXiv:2512.09088v1 Announce Type: new \nAbstract: Hallucinations are outputs by Large Language Models (LLMs) that are factually incorrect yet appear plausible [1]. This paper investigates how such hallucinations influence users' trust in LLMs and users' interaction with LLMs. To explore this in every...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "study",
        "model",
        "paper",
        "large language model",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "A Categorical Analysis of Large Language Models and Why LLMs Circumvent the Symbol Grounding Problem",
      "url": "https://arxiv.org/abs/2512.09117",
      "description": "arXiv:2512.09117v1 Announce Type: new \nAbstract: This paper presents a formal, categorical framework for analysing how humans and large language models (LLMs) transform content into truth-evaluated propositions about a state space of possible worlds W , in order to argue that LLMs do not solve but c...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "paper",
        "framework",
        "analysis",
        "large language model",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "SDialog: A Python Toolkit for End-to-End Agent Building, User Simulation, Dialog Generation, and Evaluation",
      "url": "https://arxiv.org/abs/2512.09142",
      "description": "arXiv:2512.09142v1 Announce Type: new \nAbstract: We present SDialog, an MIT-licensed open-source Python toolkit that unifies dialog generation, evaluation and mechanistic interpretability into a single end-to-end framework for building and analyzing LLM-based conversational agents. Built around a st...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "experiment",
        "model",
        "audio",
        "research",
        "framework",
        "LLM",
        "API",
        "tool",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration",
      "url": "https://arxiv.org/abs/2512.09340",
      "description": "arXiv:2512.09340v1 Announce Type: new \nAbstract: Understanding how humans and AI systems interpret ambiguous visual stimuli offers critical insight into the nature of perception, reasoning, and decision-making. This paper examines image labeling performance across human participants and deep neural ...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "alignment",
        "reasoning",
        "model",
        "paper",
        "framework",
        "analysis",
        "attention",
        "image",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search",
      "url": "https://arxiv.org/abs/2512.09566",
      "description": "arXiv:2512.09566v1 Announce Type: new \nAbstract: Drug discovery is a time-consuming and expensive process, with traditional high-throughput and docking-based virtual screening hampered by low success rates and limited scalability. Recent advances in generative modelling, including autoregressive, di...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "alignment",
        "context",
        "experiment",
        "model",
        "framework",
        "RAG",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "An End-to-end Planning Framework with Agentic LLMs and PDDL",
      "url": "https://arxiv.org/abs/2512.09629",
      "description": "arXiv:2512.09629v1 Announce Type: new \nAbstract: We present an end-to-end framework for planning supported by verifiers. An orchestrator receives a human specification written in natural language and converts it into a PDDL (Planning Domain Definition Language) model, where the domain and problem ar...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "framework",
        "large language model",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "An Electrocardiogram Multi-task Benchmark with Comprehensive Evaluations and Insightful Findings",
      "url": "https://arxiv.org/abs/2512.08954",
      "description": "arXiv:2512.08954v1 Announce Type: new \nAbstract: In the process of patient diagnosis, non-invasive measurements are widely used due to their low risks and quick results. Electrocardiogram (ECG), as a non-invasive method to collect heart activities, is used to diagnose cardiac conditions. Analyzing t...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "experiment",
        "model",
        "research",
        "analysis",
        "RAG",
        "ICL",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "LLM4XCE: Large Language Models for Extremely Large-Scale Massive MIMO Channel Estimation",
      "url": "https://arxiv.org/abs/2512.08955",
      "description": "arXiv:2512.08955v1 Announce Type: new \nAbstract: Extremely large-scale massive multiple-input multiple-output (XL-MIMO) is a key enabler for sixth-generation (6G) networks, offering massive spatial degrees of freedom. Despite these advantages, the coexistence of near-field and far-field effects in h...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "embedding",
        "fine-tuning",
        "framework",
        "RAG",
        "attention",
        "large language model",
        "LLM",
        "transformer",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "LUMOS: Large User MOdels for User Behavior Prediction",
      "url": "https://arxiv.org/abs/2512.08957",
      "description": "arXiv:2512.08957v1 Announce Type: new \nAbstract: User behavior prediction at scale remains a critical challenge for online B2C platforms. Traditional approaches rely heavily on task-specific models and domain-specific feature engineering. This is time-consuming, computationally expensive, and requir...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "context",
        "product",
        "experiment",
        "model",
        "embedding",
        "RAG",
        "attention",
        "transformer",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "SEA: Spectral Edge Attacks on Graph Neural Networks",
      "url": "https://arxiv.org/abs/2512.08964",
      "description": "arXiv:2512.08964v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) achieve strong performance on graph-structured data, but are notoriously vulnerable to small, carefully crafted perturbations of the graph structure. Most existing structure-based attacks rely on gradient-based heuristics ...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "model",
        "embedding",
        "paper",
        "RAG",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Financial Instruction Following Evaluation (FIFE)",
      "url": "https://arxiv.org/abs/2512.08965",
      "description": "arXiv:2512.08965v1 Announce Type: new \nAbstract: Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruction-following c...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "zero-shot",
        "release",
        "model",
        "research",
        "prompt",
        "analysis",
        "instruction",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "context window",
        "prompt engineering",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "CoT",
        "audio",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "model",
        "prompt",
        "LLM",
        "API",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "context",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "reasoning",
        "model",
        "framework",
        "retrieval",
        "RAG",
        "knowledge base",
        "LLM",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "retrieval",
        "RAG",
        "API",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "framework",
        "LLM",
        "platform",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Learning When to Ask: Simulation-Trained Humanoids for Mental-Health Diagnosis",
      "url": "https://arxiv.org/abs/2512.08952",
      "description": "arXiv:2512.08952v1 Announce Type: new \nAbstract: Testing humanoid robots with users is slow, causes wear, and limits iteration and diversity. Yet screening agents must master conversational timing, prosody, backchannels, and what to attend to in faces and speech for Depression and PTSD. Most simulat...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "RAG",
        "arxiv",
        "prompt"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "model",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Analyzing Planner Design Trade-offs for MAPF under Realistic Simulation",
      "url": "https://arxiv.org/abs/2512.09736",
      "description": "arXiv:2512.09736v1 Announce Type: new \nAbstract: Multi-Agent Path Finding (MAPF) algorithms are increasingly deployed in industrial warehouses and automated manufacturing facilities, where robots must operate reliably under real-world physical constraints. However, existing MAPF evaluation framework...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "platform",
        "study",
        "model",
        "research",
        "framework",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "DW-KNN: A Transparent Local Classifier Integrating Distance Consistency and Neighbor Reliability",
      "url": "https://arxiv.org/abs/2512.08956",
      "description": "arXiv:2512.08956v1 Announce Type: new \nAbstract: K-Nearest Neighbors (KNN) is one of the most used ML classifiers. However, if we observe closely, standard distance-weighted KNN and relative variants assume all 'k' neighbors are equally reliable. In heterogeneous feature space, this becomes a limita...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Resolving Conflicts in Lifelong Learning via Aligning Updates in Subspaces",
      "url": "https://arxiv.org/abs/2512.08960",
      "description": "arXiv:2512.08960v1 Announce Type: new \nAbstract: Low-Rank Adaptation (LoRA) enables efficient Continual Learning but often suffers from catastrophic forgetting due to destructive interference between tasks. Our analysis reveals that this degradation is primarily driven by antagonistic directional up...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "framework",
        "analysis",
        "vision",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "EEG-Bench: A Benchmark for EEG Foundation Models in Clinical Applications",
      "url": "https://arxiv.org/abs/2512.08959",
      "description": "arXiv:2512.08959v1 Announce Type: new \nAbstract: We introduce a unified benchmarking framework focused on evaluating EEG-based foundation models in clinical applications. The benchmark spans 11 well-defined diagnostic tasks across 14 publicly available EEG datasets, including epilepsy, schizophrenia...",
      "published_date": "2025-12-11T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "release",
        "model",
        "framework",
        "ICL",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "New in llama.cpp: Model Management",
      "url": "https://huggingface.co/blog/ggml-org/model-management-in-llamacpp",
      "description": "...",
      "published_date": "2025-12-11T15:47:44",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model"
      ],
      "score": 0.2
    },
    {
      "title": "Codex is Open Sourcing AI models",
      "url": "https://huggingface.co/blog/hf-skills-training-codex",
      "description": "...",
      "published_date": "2025-12-11T00:00:00",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model"
      ],
      "score": 0.2
    },
    {
      "title": "Apriel-1.6-15b-Thinker: Cost-efficient Frontier Multimodal Performance",
      "url": "https://huggingface.co/blog/ServiceNow-AI/apriel-1p6-15b-thinker",
      "description": "...",
      "published_date": "2025-12-09T20:06:56",
      "source": "Hugging Face Blog",
      "category": "multimodal_context",
      "keywords": [
        "multimodal"
      ],
      "score": 0.2
    }
  ]
}