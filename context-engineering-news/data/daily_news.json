{
  "generated_at": "2025-08-28T20:06:10.381227",
  "total_items": 45,
  "items": [
    {
      "title": "MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts",
      "url": "https://arxiv.org/abs/2508.19268",
      "description": "arXiv:2508.19268v1 Announce Type: new \nAbstract: Despite LLMs' excellent code creation capabilities, multilingual code generation remains extremely challenging. To address this, we intent to improve the multi-programming-lingual (MultiPL) performance of the base LLMs while retaining the most popular...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "large language model",
        "model",
        "experiment",
        "context",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English",
      "url": "https://arxiv.org/abs/2508.19270",
      "description": "arXiv:2508.19270v1 Announce Type: new \nAbstract: Cross-lingual phoneme recognition has emerged as a significant challenge for accurate automatic speech recognition (ASR) when mixing Vietnamese and English pronunciations. Unlike many languages, Vietnamese relies on tonal variations to distinguish wor...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "experiment",
        "alignment",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT",
      "url": "https://arxiv.org/abs/2508.19271",
      "description": "arXiv:2508.19271v1 Announce Type: new \nAbstract: Prompt-based reasoning strategies such as Chain-of-Thought (CoT) and In-Context Learning (ICL) have become widely used for eliciting reasoning capabilities in large language models (LLMs). However, these methods rely on fragile, implicit mechanisms of...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "prompt",
        "arxiv",
        "RAG",
        "reasoning",
        "large language model",
        "model",
        "ICL",
        "context",
        "in-context",
        "memory",
        "chain-of-thought",
        "LLM",
        "prompting",
        "retrieval",
        "CoT",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "RAGAPHENE: A RAG Annotation Platform with Human Enhancements and Edits",
      "url": "https://arxiv.org/abs/2508.19272",
      "description": "arXiv:2508.19272v1 Announce Type: new \nAbstract: Retrieval Augmented Generation (RAG) is an important aspect of conversing with Large Language Models (LLMs) when factually correct information is important. LLMs may provide answers that appear correct, but could contain hallucinated information. Thus...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "RAG",
        "large language model",
        "model",
        "platform",
        "LLM",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis",
      "url": "https://arxiv.org/abs/2508.19274",
      "description": "arXiv:2508.19274v1 Announce Type: new \nAbstract: In countries without civil registration and vital statistics, verbal autopsy (VA) is a critical tool for estimating cause of death (COD) and inform policy priorities. In VA, interviewers ask proximal informants for details on the circumstances precedi...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "analysis",
        "RAG",
        "model",
        "fine-tuning",
        "tool",
        "framework",
        "multimodal",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "FLAIRR-TS -- Forecasting LLM-Agents with Iterative Refinement and Retrieval for Time Series",
      "url": "https://arxiv.org/abs/2508.19279",
      "description": "arXiv:2508.19279v1 Announce Type: new \nAbstract: Time series Forecasting with large languagemodels (LLMs) requires bridging numericalpatterns and natural language. Effective fore-casting on LLM often relies on extensive pre-processing and fine-tuning.Recent studiesshow that a frozen LLM can rival sp...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "arxiv",
        "model",
        "experiment",
        "template",
        "fine-tuning",
        "LLM",
        "prompting",
        "retrieval",
        "framework",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning",
      "url": "https://arxiv.org/abs/2508.19282",
      "description": "arXiv:2508.19282v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance the timeliness of knowledge and the factual accuracy of responses in Large Language Models (LLMs). However, the inclusion of excessive retrieved documents substantiall...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "RAG",
        "large language model",
        "release",
        "compression",
        "model",
        "experiment",
        "context",
        "in-context",
        "LLM",
        "retrieval",
        "framework",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains",
      "url": "https://arxiv.org/abs/2508.19357",
      "description": "arXiv:2508.19357v1 Announce Type: new \nAbstract: Large Language Models (LLMs) excel in language tasks but are prone to hallucinations and outdated knowledge. Retrieval-Augmented Generation (RAG) mitigates these by grounding LLMs in external knowledge. However, in complex domains involving multiple, ...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "RAG",
        "large language model",
        "compression",
        "model",
        "experiment",
        "context",
        "LLM",
        "retrieval",
        "framework",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction",
      "url": "https://arxiv.org/abs/2508.19359",
      "description": "arXiv:2508.19359v1 Announce Type: new \nAbstract: Event Extraction (EE) involves automatically identifying and extracting structured information about events from unstructured text, including triggers, event types, and arguments. Traditional discriminative models demonstrate high precision but often ...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "instruction",
        "RAG",
        "large language model",
        "model",
        "experiment",
        "fine-tuning",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "LongReasonArena: A Long Reasoning Benchmark for Large Language Models",
      "url": "https://arxiv.org/abs/2508.19363",
      "description": "arXiv:2508.19363v1 Announce Type: new \nAbstract: Existing long-context benchmarks for Large Language Models (LLMs) focus on evaluating comprehension of long inputs, while overlooking the evaluation of long reasoning abilities. To address this gap, we introduce LongReasonArena, a benchmark specifical...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "reasoning",
        "large language model",
        "model",
        "context",
        "LLM",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Sycophancy as compositions of Atomic Psychometric Traits",
      "url": "https://arxiv.org/abs/2508.19316",
      "description": "arXiv:2508.19316v1 Announce Type: new \nAbstract: Sycophancy is a key behavioral risk in LLMs, yet is often treated as an isolated failure mode that occurs via a single causal mechanism. We instead propose modeling it as geometric and causal compositions of psychometric traits such as emotionality, o...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "vector",
        "model",
        "study",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science",
      "url": "https://arxiv.org/abs/2508.19383",
      "description": "arXiv:2508.19383v1 Announce Type: new \nAbstract: Modern plant science increasingly relies on large, heterogeneous datasets, but challenges in experimental design, data preprocessing, and reproducibility hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent system that integr...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "research",
        "model",
        "experiment",
        "memory",
        "study",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs",
      "url": "https://arxiv.org/abs/2508.19432",
      "description": "arXiv:2508.19432v1 Announce Type: new \nAbstract: Quantization enables efficient deployment of large language models (LLMs) in resource-constrained environments by significantly reducing memory and computation costs. While quantized LLMs often maintain performance on perplexity and zero-shot tasks, t...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "arxiv",
        "reasoning",
        "large language model",
        "model",
        "zero-shot",
        "memory",
        "LLM",
        "alignment",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Reliable Weak-to-Strong Monitoring of LLM Agents",
      "url": "https://arxiv.org/abs/2508.19461",
      "description": "arXiv:2508.19461v1 Announce Type: new \nAbstract: We stress test monitoring systems for detecting covert misbehavior in autonomous LLM agents (e.g., secretly sharing private information). To this end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1) varying levels of agent a...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "prompt",
        "arxiv",
        "company",
        "release",
        "research",
        "model",
        "tool",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "SLIM: Subtrajectory-Level Elimination for More Effective Reasoning",
      "url": "https://arxiv.org/abs/2508.19502",
      "description": "arXiv:2508.19502v1 Announce Type: new \nAbstract: In recent months, substantial progress has been made in complex reasoning of Large Language Models, particularly through the application of test-time scaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When responding to a query, these ...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "reasoning",
        "example",
        "large language model",
        "model",
        "experiment",
        "study",
        "fine-tuning",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Caught in the Act: a mechanistic approach to detecting deception",
      "url": "https://arxiv.org/abs/2508.19505",
      "description": "arXiv:2508.19505v1 Announce Type: new \nAbstract: Sophisticated instrumentation for AI systems might have indicators that signal misalignment from human values, not unlike a \"check engine\" light in cars. One such indicator of misalignment is deceptiveness in generated responses. Future AI instrumenta...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "reasoning",
        "model",
        "LLM",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities",
      "url": "https://arxiv.org/abs/2508.19562",
      "description": "arXiv:2508.19562v1 Announce Type: new \nAbstract: This paper introduces Democracy-in-Silico, an agent-based simulation where societies of advanced AI agents, imbued with complex psychological personas, govern themselves under different institutional frameworks. We explore what it means to be human in...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "large language model",
        "model",
        "paper",
        "LLM",
        "alignment",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding",
      "url": "https://arxiv.org/abs/2508.19576",
      "description": "arXiv:2508.19576v1 Announce Type: new \nAbstract: With respect to improving the reasoning accuracy of LLMs, the representative reinforcement learning (RL) method GRPO faces failure due to insignificant reward variance, while verification methods based on process reward models (PRMs) suffer from diffi...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "reasoning",
        "model",
        "experiment",
        "paper",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties",
      "url": "https://arxiv.org/abs/2508.19611",
      "description": "arXiv:2508.19611v1 Announce Type: new \nAbstract: Preparing high-quality instructional materials remains a labor-intensive process that often requires extensive coordination among teaching faculty, instructional designers, and teaching assistants. In this work, we present Instructional Agents, a mult...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "instruction",
        "large language model",
        "model",
        "tool",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats",
      "url": "https://arxiv.org/abs/2508.19263",
      "description": "arXiv:2508.19263v1 Announce Type: new \nAbstract: As deep learning models grow and deployment becomes more widespread, reducing the storage and transmission costs of neural network weights has become increasingly important. While prior work such as ZipNN has shown that lossless compression methods - ...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "arxiv",
        "RAG",
        "large language model",
        "compression",
        "model",
        "memory",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization",
      "url": "https://arxiv.org/abs/2508.19277",
      "description": "arXiv:2508.19277v1 Announce Type: new \nAbstract: Recent advances in Chain-of-Thought (CoT) prompting have substantially enhanced the reasoning capabilities of large language models (LLMs), enabling sophisticated problem-solving through explicit multi-step reasoning traces. However, these enhanced re...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "arxiv",
        "reasoning",
        "large language model",
        "model",
        "experiment",
        "chain-of-thought",
        "template",
        "LLM",
        "prompting",
        "retrieval",
        "CoT",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Re:Frame -- Retrieving Experience From Associative Memory",
      "url": "https://arxiv.org/abs/2508.19344",
      "description": "arXiv:2508.19344v1 Announce Type: new \nAbstract: Offline reinforcement learning (RL) often deals with suboptimal data when collecting large expert datasets is unavailable or impractical. This limitation makes it difficult for agents to generalize and achieve high performance, as they must learn prim...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "arxiv",
        "RAG",
        "memory",
        "demonstration",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "Efficient Multi-Source Knowledge Transfer by Model Merging",
      "url": "https://arxiv.org/abs/2508.19353",
      "description": "arXiv:2508.19353v1 Announce Type: new \nAbstract: While transfer learning is an advantageous strategy, it overlooks the opportunity to leverage knowledge from numerous available models online. Addressing this multi-source transfer learning problem is a promising path to boost adaptability and cut re-...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "RAG",
        "model",
        "fine-tuning",
        "knowledge base",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs",
      "url": "https://arxiv.org/abs/2508.19366",
      "description": "arXiv:2508.19366v1 Announce Type: new \nAbstract: Hallucinations in large language models (LLMs) remain a fundamental obstacle to trustworthy AI, particularly in high-stakes multimodal domains such as medicine, law, and finance. Existing evaluation techniques are largely heuristic -- anchored in qual...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "prompt",
        "arxiv",
        "RAG",
        "large language model",
        "model",
        "LLM",
        "multimodal",
        "embedding",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "context window",
        "prompt engineering",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "audio",
        "chain-of-thought",
        "CoT",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "model",
        "context",
        "API",
        "tool",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "RAG",
        "reasoning",
        "model",
        "LLM",
        "retrieval",
        "knowledge base",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "fine-tuning",
        "tool",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "API",
        "retrieval",
        "product",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "vector",
        "platform",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "framework",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "tool",
        "context",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "model",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Skill-based Explanations for Serendipitous Course Recommendation",
      "url": "https://arxiv.org/abs/2508.19569",
      "description": "arXiv:2508.19569v1 Announce Type: new \nAbstract: Academic choice is crucial in U.S. undergraduate education, allowing students significant freedom in course selection. However, navigating the complex academic environment is challenging due to limited information, guidance, and an overwhelming number...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "paper",
        "study",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "(DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems",
      "url": "https://arxiv.org/abs/2508.19318",
      "description": "arXiv:2508.19318v1 Announce Type: new \nAbstract: Deep Reinforcement Learning (DRL) has emerged as an efficient approach to resource allocation due to its strong capability in handling complex decision-making tasks. However, only limited research has explored the training of DRL models with real-worl...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "research",
        "paper",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Physics-Informed Regression: Parameter Estimation in Parameter-Linear Nonlinear Dynamic Models",
      "url": "https://arxiv.org/abs/2508.19249",
      "description": "arXiv:2508.19249v1 Announce Type: new \nAbstract: We present a new efficient hybrid parameter estimation method based on the idea, that if nonlinear dynamic models are stated in terms of a system of equations that is linear in terms of the parameters, then regularized ordinary least squares can be us...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "example",
        "study",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Atrial Fibrillation Prediction Using a Lightweight Temporal Convolutional and Selective State Space Architecture",
      "url": "https://arxiv.org/abs/2508.19361",
      "description": "arXiv:2508.19361v1 Announce Type: new \nAbstract: Atrial fibrillation (AF) is the most common arrhythmia, increasing the risk of stroke, heart failure, and other cardiovascular complications. While AF detection algorithms perform well in identifying persistent AF, early-stage progression, such as par...",
      "published_date": "2025-08-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "API",
        "study",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}