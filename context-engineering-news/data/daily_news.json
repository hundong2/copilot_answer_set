{
  "generated_at": "2025-10-06T20:05:40.074091",
  "total_items": 47,
  "items": [
    {
      "title": "Hallucination reduction with CASAL: Contrastive Activation Steering For Amortized Learning",
      "url": "https://arxiv.org/abs/2510.02324",
      "description": "arXiv:2510.02324v1 Announce Type: new \nAbstract: Large Language Models (LLMs) exhibit impressive capabilities but often hallucinate, confidently providing incorrect answers instead of admitting ignorance. Prior work has shown that models encode linear representations of their own knowledge and that ...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "large language model",
        "arxiv",
        "vision",
        "transformer",
        "product",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval",
      "url": "https://arxiv.org/abs/2510.02326",
      "description": "arXiv:2510.02326v1 Announce Type: new \nAbstract: Large language models accelerate literature synthesis but can hallucinate and mis-cite, limiting their usefulness in expert workflows. We present RA-FSM (Research Assistant - Finite State Machine), a modular GPT-based research assistant that wraps gen...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "vector",
        "analysis",
        "arxiv",
        "GPT",
        "retrieval",
        "RAG",
        "reasoning",
        "API",
        "research",
        "model",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "KAME: Tandem Architecture for Enhancing Knowledge in Real-Time Speech-to-Speech Conversational AI",
      "url": "https://arxiv.org/abs/2510.02327",
      "description": "arXiv:2510.02327v1 Announce Type: new \nAbstract: Real-time speech-to-speech (S2S) models excel at generating natural, low-latency conversational responses but often lack deep knowledge and semantic understanding. Conversely, cascaded systems combining automatic speech recognition, a text-based Large...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "framework",
        "arxiv",
        "transformer",
        "paper",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering",
      "url": "https://arxiv.org/abs/2510.02328",
      "description": "arXiv:2510.02328v1 Announce Type: new \nAbstract: Medical Multimodal Large Language Models (Med-MLLMs) have shown great promise in medical visual question answering (Med-VQA). However, when deployed in low-resource settings where abundant labeled data are unavailable, existing Med-MLLMs commonly fail...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "image",
        "zero-shot",
        "few-shot",
        "framework",
        "arxiv",
        "retrieval",
        "reasoning",
        "experiment",
        "multimodal",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "EntropyLong: Effective Long-Context Training via Predictive Uncertainty",
      "url": "https://arxiv.org/abs/2510.02330",
      "description": "arXiv:2510.02330v1 Announce Type: new \nAbstract: Training long-context language models to capture long-range dependencies requires specialized data construction. Current approaches, such as generic text concatenation or heuristic-based variants, frequently fail to guarantee genuine long-range depend...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "RAG",
        "context",
        "fine-tuning",
        "instruction",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Human Mobility Datasets Enriched With Contextual and Social Dimensions",
      "url": "https://arxiv.org/abs/2510.02333",
      "description": "arXiv:2510.02333v1 Announce Type: new \nAbstract: In this resource paper, we present two publicly available datasets of semantically enriched human trajectories, together with the pipeline to build them. The trajectories are publicly available GPS traces retrieved from OpenStreetMap. Each dataset inc...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "analysis",
        "framework",
        "arxiv",
        "reasoning",
        "context",
        "ICL",
        "multimodal",
        "research",
        "paper",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Where Did It Go Wrong? Attributing Undesirable LLM Behaviors via Representation Gradient Tracing",
      "url": "https://arxiv.org/abs/2510.02334",
      "description": "arXiv:2510.02334v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities, yet their deployment is frequently undermined by undesirable behaviors such as generating harmful content, factual inaccuracies, and societal biases. Diagnosing the root causes of...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "large language model",
        "analysis",
        "framework",
        "arxiv",
        "tool",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "RefineShot: Rethinking Cinematography Understanding with Foundational Skill Evaluation",
      "url": "https://arxiv.org/abs/2510.02423",
      "description": "arXiv:2510.02423v1 Announce Type: new \nAbstract: Cinematography understanding refers to the ability to recognize not only the visual content of a scene but also the cinematic techniques that shape narrative meaning. This capability is attracting increasing attention, as it enhances multimodal unders...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "reasoning",
        "multimodal",
        "attention",
        "instruction",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Safe and Efficient In-Context Learning via Risk Control",
      "url": "https://arxiv.org/abs/2510.02480",
      "description": "arXiv:2510.02480v1 Announce Type: new \nAbstract: Large language models (LLMs) demonstrate a remarkable ability to learn new tasks from a few in-context examples. However, this flexibility introduces safety concerns: LLMs can be influenced by incorrect or malicious demonstrations -- for example, if a...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "large language model",
        "example",
        "zero-shot",
        "in-context",
        "arxiv",
        "RAG",
        "context",
        "demonstration",
        "attention",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Multimodal Function Vectors for Spatial Relations",
      "url": "https://arxiv.org/abs/2510.02528",
      "description": "arXiv:2510.02528v1 Announce Type: new \nAbstract: Large Multimodal Models (LMMs) demonstrate impressive in-context learning abilities from limited multimodal demonstrations, yet the internal mechanisms supporting such task learning remain opaque. Building on prior work of large language models, we sh...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "large language model",
        "image",
        "in-context",
        "zero-shot",
        "vector",
        "analysis",
        "arxiv",
        "reasoning",
        "context",
        "vision",
        "multimodal",
        "demonstration",
        "attention",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Orchestrating Human-AI Teams: The Manager Agent as a Unifying Research Challenge",
      "url": "https://arxiv.org/abs/2510.02557",
      "description": "arXiv:2510.02557v1 Announce Type: new \nAbstract: While agentic AI has advanced in automating individual tasks, managing complex multi-agent workflows remains a challenging problem. This paper presents a research vision for autonomous agentic systems that orchestrate collaboration within dynamic huma...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "GPT",
        "vision",
        "reasoning",
        "release",
        "research",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Agentic Additive Manufacturing Alloy Discovery",
      "url": "https://arxiv.org/abs/2510.02567",
      "description": "arXiv:2510.02567v1 Announce Type: new \nAbstract: Agentic systems enable the intelligent use of research tooling, augmenting a researcher's ability to investigate and propose novel solutions to existing problems. Within Additive Manufacturing (AM), alloy discovery remains a complex challenge, often r...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "analysis",
        "experiment",
        "arxiv",
        "LLM",
        "context",
        "tool",
        "research",
        "prompt",
        "model",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "Multimodal Large Language Model Framework for Safe and Interpretable Grid-Integrated EVs",
      "url": "https://arxiv.org/abs/2510.02592",
      "description": "arXiv:2510.02592v1 Announce Type: new \nAbstract: The integration of electric vehicles (EVs) into smart grids presents unique opportunities to enhance both transportation systems and energy networks. However, ensuring safe and interpretable interactions between drivers, vehicles, and the surrounding ...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "large language model",
        "framework",
        "arxiv",
        "context",
        "ICL",
        "multimodal",
        "tool",
        "prompt engineering",
        "paper",
        "prompt",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Mitigating Modal Imbalance in Multimodal Reasoning",
      "url": "https://arxiv.org/abs/2510.02608",
      "description": "arXiv:2510.02608v1 Announce Type: new \nAbstract: Foundation models (FMs) deployed in real-world tasks such as computer-use agents must integrate diverse modalities. How good are FMs at performing joint reasoning, simultaneously reasoning over multiple modalities, especially when the modalities inter...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "cross-modal",
        "example",
        "study",
        "experiment",
        "arxiv",
        "reasoning",
        "context",
        "vision",
        "multimodal",
        "attention",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "On the Role of Temperature Sampling in Test-Time Scaling",
      "url": "https://arxiv.org/abs/2510.02611",
      "description": "arXiv:2510.02611v1 Announce Type: new \nAbstract: Large language models (LLMs) can improve reasoning at inference time through test-time scaling (TTS), where multiple reasoning traces are generated and the best one is selected. Prior work shows that increasing the number of samples K steadily improve...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "analysis",
        "arxiv",
        "RAG",
        "reasoning",
        "paper",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "OpenTSLM: Time-Series Language Models for Reasoning over Multivariate Medical Text- and Time-Series Data",
      "url": "https://arxiv.org/abs/2510.02410",
      "description": "arXiv:2510.02410v1 Announce Type: new \nAbstract: LLMs have emerged as powerful tools for interpreting multimodal data. In medicine, they hold particular promise for synthesizing large volumes of clinical information into actionable insights and digital health applications. Yet, a major limitation re...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "prompting",
        "chain-of-thought",
        "CoT",
        "memory",
        "arxiv",
        "GPT",
        "reasoning",
        "multimodal",
        "attention",
        "tool",
        "research",
        "prompt",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "RainSeer: Fine-Grained Rainfall Reconstruction via Physics-Guided Modeling",
      "url": "https://arxiv.org/abs/2510.02414",
      "description": "arXiv:2510.02414v1 Announce Type: new \nAbstract: Reconstructing high-resolution rainfall fields is essential for flood forecasting, hydrological modeling, and climate analysis. However, existing spatial interpolation methods-whether based on automatic weather station (AWS) measurements or enhanced w...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "framework",
        "arxiv",
        "alignment",
        "attention",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "How to Train Your Advisor: Steering Black-Box LLMs with Advisor Models",
      "url": "https://arxiv.org/abs/2510.02453",
      "description": "arXiv:2510.02453v1 Announce Type: new \nAbstract: Foundation models are increasingly deployed as black-box services, where model weights cannot be modified and customization is limited to prompting. While static prompt optimization has shown promise, it produces a single fixed prompt that fails to ad...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompting",
        "instruction",
        "in-context",
        "memory",
        "framework",
        "arxiv",
        "reasoning",
        "context",
        "API",
        "prompt",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Uncertainty-Guided Model Selection for Tabular Foundation Models in Biomolecule Efficacy Prediction",
      "url": "https://arxiv.org/abs/2510.02476",
      "description": "arXiv:2510.02476v1 Announce Type: new \nAbstract: In-context learners like TabPFN are promising for biomolecule efficacy prediction, where established molecular feature sets and relevant experimental results can serve as powerful contextual examples. However, their performance is highly sensitive to ...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "example",
        "in-context",
        "study",
        "experiment",
        "arxiv",
        "RAG",
        "context",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Litespark Technical Report: High-Throughput, Energy-Efficient LLM Training Framework",
      "url": "https://arxiv.org/abs/2510.02483",
      "description": "arXiv:2510.02483v1 Announce Type: new \nAbstract: Training Large Language Models (LLMs) is plagued by long training times and massive energy consumption, with modern models requiring months of computation and gigawatt-hours of electricity. In light of these challenges,we introduce Litespark, a novel ...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "large language model",
        "framework",
        "arxiv",
        "fine-tuning",
        "transformer",
        "attention",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt",
        "context",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "CoT",
        "framework",
        "reasoning",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "tool",
        "prompt",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "framework",
        "RAG",
        "reasoning",
        "retrieval",
        "knowledge base",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "fine-tuning",
        "tool",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "API",
        "product",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "framework",
        "platform",
        "prompt",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "SelfJudge: Faster Speculative Decoding via Self-Supervised Judge Verification",
      "url": "https://arxiv.org/abs/2510.02329",
      "description": "arXiv:2510.02329v1 Announce Type: new \nAbstract: Speculative decoding accelerates LLM inference by verifying candidate tokens from a draft model against a larger target model. Recent judge decoding boosts this process by relaxing verification criteria by accepting draft tokens that may exhibit minor...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "vision",
        "model",
        "LLM"
      ],
      "score": 0.8
    },
    {
      "title": "Synthetic Dialogue Generation for Interactive Conversational Elicitation & Recommendation (ICER)",
      "url": "https://arxiv.org/abs/2510.02331",
      "description": "arXiv:2510.02331v1 Announce Type: new \nAbstract: While language models (LMs) offer great potential for conversational recommender systems (CRSs), the paucity of public CRS data makes fine-tuning LMs for CRSs challenging. In response, LMs as user simulators qua data generators can be used to train LM...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompting",
        "example",
        "arxiv",
        "fine-tuning",
        "prompt",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "A High-Capacity and Secure Disambiguation Algorithm for Neural Linguistic Steganography",
      "url": "https://arxiv.org/abs/2510.02332",
      "description": "arXiv:2510.02332v1 Announce Type: new \nAbstract: Neural linguistic steganography aims to embed information\n  into natural text while preserving statistical undetectability. A fundamental challenge in this ffeld stems from tokenization ambiguity in modern tokenizers, which can lead to catastrophic de...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "embedding"
      ],
      "score": 0.8
    },
    {
      "title": "BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks",
      "url": "https://arxiv.org/abs/2510.02418",
      "description": "arXiv:2510.02418v1 Announce Type: new \nAbstract: LLM web agents now browse and take actions on the open web, yet current agent evaluations are constrained to sandboxed environments or artificial tasks. We introduce BrowserArena, a live open-web agent evaluation platform that collects user-submitted ...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "example",
        "study",
        "arxiv",
        "platform",
        "model",
        "LLM"
      ],
      "score": 0.8
    },
    {
      "title": "A Benchmark Study of Deep Reinforcement Learning Algorithms for the Container Stowage Planning Problem",
      "url": "https://arxiv.org/abs/2510.02589",
      "description": "arXiv:2510.02589v1 Announce Type: new \nAbstract: Container stowage planning (CSPP) is a critical component of maritime transportation and terminal operations, directly affecting supply chain efficiency. Owing to its complexity, CSPP has traditionally relied on human expertise. While reinforcement le...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "framework",
        "arxiv",
        "research",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "Assessing the Potential for Catastrophic Failure in Dynamic Post-Training Quantization",
      "url": "https://arxiv.org/abs/2510.02457",
      "description": "arXiv:2510.02457v1 Announce Type: new \nAbstract: Post-training quantization (PTQ) has recently emerged as an effective tool for reducing the computational complexity and memory usage of a neural network by representing its weights and activations with lower precision. While this paradigm has shown g...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "memory",
        "experiment",
        "arxiv",
        "RAG",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "SAGE: Streaming Agreement-Driven Gradient Sketches for Representative Subset Selection",
      "url": "https://arxiv.org/abs/2510.02470",
      "description": "arXiv:2510.02470v1 Announce Type: new \nAbstract: Training modern neural networks on large datasets is computationally and energy intensive. We present SAGE, a streaming data-subset selection method that maintains a compact Frequent Directions (FD) sketch of gradient geometry in $O(\\ell D)$ memory an...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "example",
        "memory",
        "arxiv",
        "RAG",
        "compression",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "API",
        "tool",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Market-Based Data Subset Selection -- Principled Aggregation of Multi-Criteria Example Utility",
      "url": "https://arxiv.org/abs/2510.02456",
      "description": "arXiv:2510.02456v1 Announce Type: new \nAbstract: Selecting a small yet useful subset of training data is hard because signals of example utility (uncertainty, rarity, diversity, etc.) are heterogeneous and typically combined with ad hoc weights. We propose a market-based selector that prices each ex...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "example",
        "framework",
        "arxiv",
        "RAG",
        "reasoning",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "From Pixels to Factors: Learning Independently Controllable State Variables for Reinforcement Learning",
      "url": "https://arxiv.org/abs/2510.02484",
      "description": "arXiv:2510.02484v1 Announce Type: new \nAbstract: Algorithms that exploit factored Markov decision processes are far more sample-efficient than factor-agnostic methods, yet they assume a factored representation is known a priori -- a requirement that breaks down when the agent sees only high-dimensio...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "RAG"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Extreme value forecasting using relevance-based data augmentation with deep learning models",
      "url": "https://arxiv.org/abs/2510.02407",
      "description": "arXiv:2510.02407v1 Announce Type: new \nAbstract: Data augmentation with generative adversarial networks (GANs) has been popular for class imbalance problems, mainly for pattern classification and computer vision-related applications. Extreme value forecasting is a challenging field that has various ...",
      "published_date": "2025-10-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "memory",
        "framework",
        "arxiv",
        "vision",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}