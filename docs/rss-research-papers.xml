<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Benchmarking Open-Source Large Language Models for Persian in Zero-Shot and Few-Shot Learning</title>
      <link>https://arxiv.org/abs/2510.12807</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.12807</guid>
      <description>arXiv:2510.12807v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous languages; however, their effectiveness in low-resource languages like Persian requires thorough investigation. This paper presents a comprehensive benchmark of sev...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, zero-shot, research, paper, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>zero-shot</category>
      <category>research</category>
    </item>
    <item>
      <title>Cancer Diagnosis Categorization in Electronic Health Records Using Large Language Models and BioBERT: Model Performance Evaluation Study</title>
      <link>https://arxiv.org/abs/2510.12813</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.12813</guid>
      <description>arXiv:2510.12813v1 Announce Type: new 
Abstract: Electronic health records contain inconsistently structured or free-text data, requiring efficient preprocessing to enable predictive health care models. Although artificial intelligence-driven natural language processing tools show promise for automa...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, research, large language model, tool, GPT | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>research</category>
      <category>large language model</category>
    </item>
    <item>
      <title>From Noise to Signal to Selbstzweck: Reframing Human Label Variation in the Era of Post-training in NLP</title>
      <link>https://arxiv.org/abs/2510.12817</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.12817</guid>
      <description>arXiv:2510.12817v1 Announce Type: new 
Abstract: Human Label Variation (HLV) refers to legitimate disagreement in annotation that reflects the genuine diversity of human perspectives rather than mere error. For decades, HLV in NLP was dismissed as noise to be discarded, and only slowly over the last...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, paper, large language model, alignment, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>paper</category>
      <category>large language model</category>
    </item>
    <item>
      <title>MEDEQUALQA: Evaluating Biases in LLMs with Counterfactual Reasoning</title>
      <link>https://arxiv.org/abs/2510.12818</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.12818</guid>
      <description>arXiv:2510.12818v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly deployed in clinical decision support, yet subtle demographic cues can influence their reasoning. Prior work has documented disparities in outputs across patient groups, but little is known about how inter...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, large language model, analysis, reasoning, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>large language model</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Mathematics with large language models as provers and verifiers</title>
      <link>https://arxiv.org/abs/2510.12829</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.12829</guid>
      <description>arXiv:2510.12829v1 Announce Type: new 
Abstract: During 2024 and 2025 the discussion about the theorem-proving capabilities of large language models started reporting interesting success stories, mostly to do with difficult exercises (such as problems from the International Mathematical Olympiad), b...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, paper, large language model, GPT, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>paper</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Repurposing Annotation Guidelines to Instruct LLM Annotators: A Case Study</title>
      <link>https://arxiv.org/abs/2510.12835</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.12835</guid>
      <description>arXiv:2510.12835v1 Announce Type: new 
Abstract: This study investigates how existing annotation guidelines can be repurposed to instruct large language model (LLM) annotators for text annotation tasks. Traditional guidelines are written for human annotators who internalize training, while LLMs requ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, large language model, instruction, LLM, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>large language model</category>
      <category>instruction</category>
    </item>
    <item>
      <title>SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents</title>
      <link>https://arxiv.org/abs/2510.12985</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.12985</guid>
      <description>arXiv:2510.12985v1 Announce Type: new 
Abstract: We present Sentinel, the first framework for formally evaluating the physical safety of Large Language Model(LLM-based) embodied agents across the semantic, plan, and trajectory levels. Unlike prior methods that rely on heuristic rules or subjective L...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, large language model, framework, alignment, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>large language model</category>
      <category>framework</category>
    </item>
    <item>
      <title>From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers&amp;#x27; Hazardous Actions in Crashes Using Large Language Model</title>
      <link>https://arxiv.org/abs/2510.13002</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.13002</guid>
      <description>arXiv:2510.13002v1 Announce Type: new 
Abstract: Vehicle crashes involve complex interactions between road users, split-second decisions, and challenging environmental conditions. Among these, two-vehicle crashes are the most prevalent, accounting for approximately 70% of roadway crashes and posing ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, RAG, large language model, ICL, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>RAG</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Toward Reasoning-Centric Time-Series Analysis</title>
      <link>https://arxiv.org/abs/2510.13029</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.13029</guid>
      <description>arXiv:2510.13029v1 Announce Type: new 
Abstract: Traditional time series analysis has long relied on pattern recognition, trained on static and well-established benchmarks. However, in real-world settings -- where policies shift, human behavior adapts, and unexpected events unfold -- effective analy...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, paper, large language model, analysis, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>paper</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation</title>
      <link>https://arxiv.org/abs/2510.13195</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.13195</guid>
      <description>arXiv:2510.13195v1 Announce Type: new 
Abstract: The advent of large language models (LLMs) has enabled agents to represent virtual humans in societal simulations, facilitating diverse interactions within complex social systems. However, existing LLM-based agents exhibit severe limitations in affect...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; embedding, arxiv, paper, large language model, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>embedding</category>
      <category>arxiv</category>
      <category>paper</category>
    </item>
    <item>
      <title>Personalized Learning Path Planning with Goal-Driven Learner State Modeling</title>
      <link>https://arxiv.org/abs/2510.13215</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.13215</guid>
      <description>arXiv:2510.13215v1 Announce Type: new 
Abstract: Personalized Learning Path Planning (PLPP) aims to design adaptive learning paths that align with individual goals. While large language models (LLMs) show potential in personalizing learning experiences, existing approaches often lack mechanisms for ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, research, release, fine-tuning, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>research</category>
      <category>release</category>
    </item>
    <item>
      <title>Think as a Doctor: An Interpretable AI Approach for ICU Mortality Prediction</title>
      <link>https://arxiv.org/abs/2510.11745</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.11745</guid>
      <description>arXiv:2510.11745v1 Announce Type: new 
Abstract: Intensive Care Unit (ICU) mortality prediction, which estimates a patient&amp;#x27;s mortality status at discharge using EHRs collected early in an ICU admission, is vital in critical care. For this task, predictive accuracy alone is insufficient; interpretabi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, research, framework, reasoning, attention | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>research</category>
      <category>framework</category>
    </item>
    <item>
      <title>GAR: Generative Adversarial Reinforcement Learning for Formal Theorem Proving</title>
      <link>https://arxiv.org/abs/2510.11769</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.11769</guid>
      <description>arXiv:2510.11769v1 Announce Type: new 
Abstract: Solving math problems through verifiable languages such as Lean has significantly impacted both the mathematics and computer science communities. Current state-of-the-art models are often trained with expensive online Reinforcement Learning (RL) or ex...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, RAG, framework, experiment, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>RAG</category>
      <category>framework</category>
    </item>
    <item>
      <title>Schr\&amp;quot;odinger bridge for generative AI: Soft-constrained formulation and convergence analysis</title>
      <link>https://arxiv.org/abs/2510.11829</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.11829</guid>
      <description>arXiv:2510.11829v1 Announce Type: new 
Abstract: Generative AI can be framed as the problem of learning a model that maps simple reference measures into complex data distributions, and it has recently found a strong connection to the classical theory of the Schr\&amp;quot;odinger bridge problems (SBPs) due p...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, fine-tuning, model, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>fine-tuning</category>
      <category>model</category>
    </item>
    <item>
      <title>Z0-Inf: Zeroth Order Approximation for Data Influence</title>
      <link>https://arxiv.org/abs/2510.11832</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.11832</guid>
      <description>arXiv:2510.11832v1 Announce Type: new 
Abstract: A critical aspect of analyzing and improving modern machine learning systems lies in understanding how individual training examples influence a model&amp;#x27;s predictive behavior. Estimating this influence enables critical applications, including data select...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, large language model, example, analysis, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>large language model</category>
      <category>example</category>
    </item>
    <item>
      <title>MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training</title>
      <link>https://arxiv.org/abs/2510.12831</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.12831</guid>
      <description>arXiv:2510.12831v1 Announce Type: new 
Abstract: Multi-turn Text-to-SQL aims to translate a user&amp;#x27;s conversational utterances into executable SQL while preserving dialogue coherence and grounding to the target schema. However, most existing systems only regard this task as a simple text translation t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, research, release, framework, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>research</category>
      <category>release</category>
    </item>
    <item>
      <title>Balancing Synthetic Data and Replay for Enhancing Task-Specific Capabilities</title>
      <link>https://arxiv.org/abs/2510.11842</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.11842</guid>
      <description>arXiv:2510.11842v1 Announce Type: new 
Abstract: Adapting language models to new tasks through continued pretraining faces a fundamental trade-off: models must learn new capabilities while avoiding catastrophic forgetting of existing knowledge. While prior work has studied synthetic data generation ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, reasoning, study, experiment, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>reasoning</category>
      <category>study</category>
    </item>
    <item>
      <title>Actor-Enriched Time Series Forecasting of Process Performance</title>
      <link>https://arxiv.org/abs/2510.11856</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.11856</guid>
      <description>arXiv:2510.11856v1 Announce Type: new 
Abstract: Predictive Process Monitoring (PPM) is a key task in Process Mining that aims to predict future behavior, outcomes, or performance indicators. Accurate prediction of the latter is critical for proactive decision-making. Given that processes are often ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, study, research, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 16 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>study</category>
      <category>research</category>
    </item>
  </channel>
</rss>