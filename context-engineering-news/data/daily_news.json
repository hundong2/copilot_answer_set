{
  "generated_at": "2025-11-05T20:06:05.325013",
  "total_items": 46,
  "items": [
    {
      "title": "Multi-Personality Generation of LLMs at Decoding-time",
      "url": "https://arxiv.org/abs/2511.01891",
      "description": "arXiv:2511.01891v1 Announce Type: new \nAbstract: Multi-personality generation for LLMs, enabling simultaneous embodiment of multiple personalization attributes, is a fundamental challenge. Existing retraining-based approaches are costly and poorly scalable, while decoding-time methods often rely on ...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "framework",
        "paper",
        "LLM",
        "RAG",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Rethinking LLM Human Simulation: When a Graph is What You Need",
      "url": "https://arxiv.org/abs/2511.02135",
      "description": "arXiv:2511.02135v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly used to simulate humans, with applications ranging from survey prediction to decision-making. However, are LLMs strictly necessary, or can smaller, domain-grounded models suffice? We identify a large class...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "LLM",
        "RAG",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "IG-Pruning: Input-Guided Block Pruning for Large Language Models",
      "url": "https://arxiv.org/abs/2511.02213",
      "description": "arXiv:2511.02213v1 Announce Type: new \nAbstract: With the growing computational demands of large language models (LLMs), efficient inference has become increasingly critical for practical deployment. Depth pruning has emerged as a promising approach for reducing the computational costs of large lang...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "transformer",
        "paper",
        "LLM",
        "experiment",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Demo: Statistically Significant Results On Biases and Errors of LLMs Do Not Guarantee Generalizable Results",
      "url": "https://arxiv.org/abs/2511.02246",
      "description": "arXiv:2511.02246v1 Announce Type: new \nAbstract: Recent research has shown that hallucinations, omissions, and biases are prevalent in everyday use-cases of LLMs. However, chatbots used in medical contexts must provide consistent advice in situations where non-medical factors are involved, such as w...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "study",
        "LLM",
        "prompt",
        "RAG",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LTD-Bench: Evaluating Large Language Models by Letting Them Draw",
      "url": "https://arxiv.org/abs/2511.02347",
      "description": "arXiv:2511.02347v1 Announce Type: new \nAbstract: Current evaluation paradigms for large language models (LLMs) represent a critical blind spot in AI research--relying on opaque numerical metrics that conceal fundamental limitations in spatial reasoning while providing no intuitive understanding of m...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "LLM",
        "reasoning",
        "analysis",
        "experiment",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation",
      "url": "https://arxiv.org/abs/2511.02358",
      "description": "arXiv:2511.02358v1 Announce Type: new \nAbstract: Query augmentation makes queries more meaningful by appending further information to the queries to find relevant documents. Current studies have proposed Large Language Model (LLM)-based embedders, which learn representation for embedding and generat...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "LLM",
        "multimodal",
        "RAG",
        "experiment",
        "model",
        "embedding",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context",
      "url": "https://arxiv.org/abs/2511.02366",
      "description": "arXiv:2511.02366v1 Announce Type: new \nAbstract: In this work, we propose LiveSecBench, a dynamic and continuously updated safety benchmark specifically for Chinese-language LLM application scenarios. LiveSecBench evaluates models across six critical dimensions (Legality, Ethics, Factuality, Privacy...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "vector",
        "arxiv",
        "framework",
        "LLM",
        "reasoning",
        "model",
        "ICL",
        "image",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda",
      "url": "https://arxiv.org/abs/2511.02374",
      "description": "arXiv:2511.02374v1 Announce Type: new \nAbstract: Current large language models excel at broad, general-purpose tasks, but consistently underperform when exposed to highly specialized domains that require deep cultural, linguistic, and subject-matter expertise. In particular, traditional medical syst...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "LLM",
        "reasoning",
        "model",
        "vision",
        "instruction",
        "large language model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models",
      "url": "https://arxiv.org/abs/2511.02376",
      "description": "arXiv:2511.02376v1 Announce Type: new \nAbstract: Large Language Models (LLMs) remain vulnerable to jailbreaking attacks where adversarial prompts elicit harmful outputs, yet most evaluations focus on single-turn interactions while real-world attacks unfold through adaptive multi-turn conversations. ...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "framework",
        "LLM",
        "prompting",
        "prompt",
        "alignment",
        "model",
        "GPT",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Merging Continual Pretraining Models for Domain-Specialized LLMs: A Case Study in Finance",
      "url": "https://arxiv.org/abs/2511.02451",
      "description": "arXiv:2511.02451v1 Announce Type: new \nAbstract: While LLMs excel at general tasks, they struggle in specialized domains like finance, requiring diverse skills in domain knowledge, mathematical reasoning, and multilingual processing. Merging domain-specific Continual Pre-training (CPT) \"experts\" off...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "framework",
        "LLM",
        "reasoning",
        "fine-tuning",
        "analysis",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Graph-Attentive MAPPO for Dynamic Retail Pricing",
      "url": "https://arxiv.org/abs/2511.00039",
      "description": "arXiv:2511.00039v1 Announce Type: new \nAbstract: Dynamic pricing in retail requires policies that adapt to shifting demand while coordinating decisions across related products. We present a systematic empirical study of multi-agent reinforcement learning for retail price optimization, comparing a st...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "attention",
        "arxiv",
        "study",
        "RAG",
        "product",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "QuantumBench: A Benchmark for Quantum Problem Solving",
      "url": "https://arxiv.org/abs/2511.00092",
      "description": "arXiv:2511.00092v1 Announce Type: new \nAbstract: Large language models are now integrated into many scientific workflows, accelerating data analysis, hypothesis generation, and design space exploration. In parallel with this growth, there is a growing need to carefully evaluate whether models accura...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "study",
        "LLM",
        "analysis",
        "model",
        "ICL",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Engineering.ai: A Platform for Teams of AI Engineers in Computational Design",
      "url": "https://arxiv.org/abs/2511.00122",
      "description": "arXiv:2511.00122v1 Announce Type: new \nAbstract: In modern engineering practice, human engineers collaborate in specialized teams to design complex products, with each expert completing their respective tasks while communicating and exchanging results and data with one another. While this division o...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "platform",
        "framework",
        "arxiv",
        "memory",
        "LLM",
        "analysis",
        "product",
        "augmented",
        "GPT",
        "vision",
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Advancing Cognitive Science with LLMs",
      "url": "https://arxiv.org/abs/2511.00206",
      "description": "arXiv:2511.00206v1 Announce Type: new \nAbstract: Cognitive science faces ongoing challenges in knowledge synthesis and conceptual clarity, in part due to its multifaceted and interdisciplinary nature. Recent advances in artificial intelligence, particularly the development of large language models (...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "tool",
        "framework",
        "LLM",
        "model",
        "large language model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Better Call CLAUSE: A Discrepancy Benchmark for Auditing LLMs Legal Reasoning Capabilities",
      "url": "https://arxiv.org/abs/2511.00340",
      "description": "arXiv:2511.00340v1 Announce Type: new \nAbstract: The rapid integration of large language models (LLMs) into high-stakes legal work has exposed a critical gap: no benchmark exists to systematically stress-test their reliability against the nuanced, adversarial, and often subtle flaws present in real-...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "study",
        "LLM",
        "reasoning",
        "API",
        "analysis",
        "RAG",
        "model",
        "augmented",
        "retrieval",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "CudaForge: An Agent Framework with Hardware Feedback for CUDA Kernel Optimization",
      "url": "https://arxiv.org/abs/2511.01884",
      "description": "arXiv:2511.01884v1 Announce Type: new \nAbstract: Developing efficient CUDA kernels is increasingly critical for AI applications such as large-scale LLM training. However, manual kernel design is both costly and time-consuming, motivating automatic approaches that leverage LLMs for code generation. E...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "framework",
        "LLM",
        "API",
        "RAG",
        "model",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Retrieval-Augmented Multimodal Depression Detection",
      "url": "https://arxiv.org/abs/2511.01892",
      "description": "arXiv:2511.01892v1 Announce Type: new \nAbstract: Multimodal deep learning has shown promise in depression detection by integrating text, audio, and video signals. Recent work leverages sentiment analysis to enhance emotional understanding, yet suffers from high computational cost, domain mismatch, a...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "framework",
        "LLM",
        "multimodal",
        "analysis",
        "prompt",
        "RAG",
        "audio",
        "experiment",
        "model",
        "augmented",
        "retrieval",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Superpositional Gradient Descent: Harnessing Quantum Principles for Model Training",
      "url": "https://arxiv.org/abs/2511.01918",
      "description": "arXiv:2511.01918v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly trained with classical optimization techniques like AdamW to improve convergence and generalization. However, the mechanisms by which quantum-inspired methods enhance classical training remain underexplore...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "framework",
        "LLM",
        "fine-tuning",
        "RAG",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Tool Zero: Training Tool-Augmented LLMs via Pure RL from Scratch",
      "url": "https://arxiv.org/abs/2511.01934",
      "description": "arXiv:2511.01934v1 Announce Type: new \nAbstract: Training tool-augmented LLMs has emerged as a promising approach to enhancing language models' capabilities for complex tasks. The current supervised fine-tuning paradigm relies on constructing extensive domain-specific datasets to train models. Howev...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "tool",
        "LLM",
        "reasoning",
        "fine-tuning",
        "experiment",
        "model",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "context",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "reasoning",
        "audio",
        "chain-of-thought",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "LLM",
        "API",
        "prompt",
        "model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "context",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "framework",
        "LLM",
        "reasoning",
        "knowledge base",
        "RAG",
        "model",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "fine-tuning",
        "tool",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "RAG",
        "product",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "platform",
        "framework",
        "LLM",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "framework",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Multimodal Detection of Fake Reviews using BERT and ResNet-50",
      "url": "https://arxiv.org/abs/2511.00020",
      "description": "arXiv:2511.00020v1 Announce Type: new \nAbstract: In the current digital commerce landscape, user-generated reviews play a critical role in shaping consumer behavior, product reputation, and platform credibility. However, the proliferation of fake or misleading reviews often generated by bots, paid a...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "platform",
        "framework",
        "study",
        "API",
        "multimodal",
        "analysis",
        "product",
        "experiment",
        "model",
        "image"
      ],
      "score": 0.8
    },
    {
      "title": "Advancing AI Challenges for the United States Department of the Air Force",
      "url": "https://arxiv.org/abs/2511.00267",
      "description": "arXiv:2511.00267v1 Announce Type: new \nAbstract: The DAF-MIT AI Accelerator is a collaboration between the United States Department of the Air Force (DAF) and the Massachusetts Institute of Technology (MIT). This program pioneers fundamental advances in artificial intelligence (AI) to expand the com...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "ICL",
        "LLM"
      ],
      "score": 0.8
    },
    {
      "title": "Neural Green's Functions",
      "url": "https://arxiv.org/abs/2511.01924",
      "description": "arXiv:2511.01924v1 Announce Type: new \nAbstract: We introduce Neural Green's Function, a neural solution operator for linear partial differential equations (PDEs) whose differential operators admit eigendecompositions. Inspired by Green's functions, the solution operators of linear PDEs that depend ...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "analysis",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "context",
        "model",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "GEPOC Parameters -- Open Source Parametrisation and Validation for Austria, Version 2.0",
      "url": "https://arxiv.org/abs/2511.00048",
      "description": "arXiv:2511.00048v1 Announce Type: new \nAbstract: GEPOC, short for Generic Population Concept, is a collection of models and methods for analysing population-level research questions. For the valid application of the models for a specific country or region, stable and reproducible data processes are ...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "study",
        "model",
        "ICL"
      ],
      "score": 0.6
    },
    {
      "title": "Deciphering Personalization: Towards Fine-Grained Explainability in Natural Language for Personalized Image Generation Models",
      "url": "https://arxiv.org/abs/2511.01932",
      "description": "arXiv:2511.01932v1 Announce Type: new \nAbstract: Image generation models are usually personalized in practical uses in order to better meet the individual users' heterogeneous needs, but most personalized models lack explainability about how they are being personalized. Such explainability can be pr...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "experiment",
        "model",
        "image"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "ARC-GEN: A Mimetic Procedural Benchmark Generator for the Abstraction and Reasoning Corpus",
      "url": "https://arxiv.org/abs/2511.00162",
      "description": "arXiv:2511.00162v2 Announce Type: new \nAbstract: The Abstraction and Reasoning Corpus remains one of the most compelling and challenging benchmarks for tracking progress toward achieving Artificial General Intelligence. In contrast to other evaluation datasets designed to assess an agent's task-spec...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "reasoning",
        "demonstration",
        "release"
      ],
      "score": 0.4
    },
    {
      "title": "The Eigenvalues Entropy as a Classifier Evaluation Measure",
      "url": "https://arxiv.org/abs/2511.01904",
      "description": "arXiv:2511.01904v1 Announce Type: new \nAbstract: Classification is a machine learning method used in many practical applications: text mining, handwritten character recognition, face recognition, pattern classification, scene labeling, computer vision, natural langage processing. A classifier predic...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "product",
        "example",
        "vision"
      ],
      "score": 0.4
    },
    {
      "title": "Variational Geometry-aware Neural Network based Method for Solving High-dimensional Diffeomorphic Mapping Problems",
      "url": "https://arxiv.org/abs/2511.01911",
      "description": "arXiv:2511.01911v1 Announce Type: new \nAbstract: Traditional methods for high-dimensional diffeomorphic mapping often struggle with the curse of dimensionality. We propose a mesh-free learning framework designed for $n$-dimensional mapping problems, seamlessly combining variational principles with q...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "image",
        "arxiv",
        "framework",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "DeepContour: A Hybrid Deep Learning Framework for Accelerating Generalized Eigenvalue Problem Solving via Efficient Contour Design",
      "url": "https://arxiv.org/abs/2511.01927",
      "description": "arXiv:2511.01927v1 Announce Type: new \nAbstract: Solving large-scale Generalized Eigenvalue Problems (GEPs) is a fundamental yet computationally prohibitive task in science and engineering. As a promising direction, contour integral (CI) methods, such as the CIRR algorithm, offer an efficient and pa...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "framework",
        "experiment",
        "API"
      ],
      "score": 0.4
    },
    {
      "title": "Dynamic Population Distribution Aware Human Trajectory Generation with Diffusion Model",
      "url": "https://arxiv.org/abs/2511.01929",
      "description": "arXiv:2511.01929v1 Announce Type: new \nAbstract: Human trajectory data is crucial in urban planning, traffic engineering, and public health. However, directly using real-world trajectory data often faces challenges such as privacy concerns, data acquisition costs, and data quality. A practical solut...",
      "published_date": "2025-11-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "framework",
        "experiment",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}