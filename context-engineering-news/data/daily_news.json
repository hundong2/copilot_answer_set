{
  "generated_at": "2026-01-26T20:06:41.455019",
  "total_items": 46,
  "items": [
    {
      "title": "ChiEngMixBench: Evaluating Large Language Models on Spontaneous and Natural Chinese-English Code-Mixed Generation",
      "url": "https://arxiv.org/abs/2601.16217",
      "description": "arXiv:2601.16217v1 Announce Type: new \nAbstract: Code-mixing is increasingly prevalent in interactions between humans and large language models, yet existing work often reduces it to a translation or convertibility problem, making it difficult to assess whether a model's switching behavior is contex...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "context",
        "alignment",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Domain Specific Specialization in Low-Resource Settings: The Efficacy of Offline Response-Based Knowledge Distillation in Large Language Models",
      "url": "https://arxiv.org/abs/2601.16219",
      "description": "arXiv:2601.16219v1 Announce Type: new \nAbstract: Large Language Models (LLMs) excel in general tasks but often struggle with hallucinations when handling domain-specific or institutional knowledge absent from their pre-training. We present an offline response-based knowledge distillation method that...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "context",
        "library",
        "experiment",
        "memory",
        "alignment",
        "arxiv",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Limits of n-gram Style Control for LLMs via Logit-Space Injection",
      "url": "https://arxiv.org/abs/2601.16224",
      "description": "arXiv:2601.16224v1 Announce Type: new \nAbstract: Large language models (LLMs) are typically personalized via prompt engineering or parameter-efficient fine-tuning such as LoRA. However, writing style can be difficult to distill into a single prompt, and LoRA fine-tuning requires computationally inte...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "RAG",
        "context",
        "fine-tuning",
        "arxiv",
        "prompting",
        "prompt",
        "LLM",
        "prompt engineering",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "GameTalk: Training LLMs for Strategic Conversation",
      "url": "https://arxiv.org/abs/2601.16276",
      "description": "arXiv:2601.16276v1 Announce Type: new \nAbstract: Strategic decision-making in multi-agent settings is a key challenge for large language models (LLMs), particularly when coordination and negotiation must unfold over extended conversations. While recent work has explored the use of LLMs in isolated d...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "large language model",
        "attention",
        "framework",
        "reasoning",
        "arxiv",
        "LLM",
        "fine-tuning",
        "API",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Better as Generators Than Classifiers: Leveraging LLMs and Synthetic Data for Low-Resource Multilingual Classification",
      "url": "https://arxiv.org/abs/2601.16278",
      "description": "arXiv:2601.16278v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable multilingual capabilities, making them promising tools in both high- and low-resource languages. One particularly valuable use case is generating synthetic samples that can be used to train sma...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "large language model",
        "RAG",
        "context",
        "instruction",
        "fine-tuning",
        "example",
        "experiment",
        "arxiv",
        "LLM",
        "in-context",
        "tool",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Generating Literature-Driven Scientific Theories at Scale",
      "url": "https://arxiv.org/abs/2601.16282",
      "description": "arXiv:2601.16282v1 Announce Type: new \nAbstract: Contemporary automated scientific discovery has focused on agents for generating scientific experiments, while systems that perform higher-level scientific activities such as theory building remain underexplored. In this work, we formulate the problem...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "memory",
        "paper",
        "arxiv",
        "LLM",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "A Longitudinal, Multinational, and Multilingual Corpus of News Coverage of the Russo-Ukrainian War",
      "url": "https://arxiv.org/abs/2601.16309",
      "description": "arXiv:2601.16309v1 Announce Type: new \nAbstract: We introduce DNIPRO, a novel longitudinal corpus of 246K news articles documenting the Russo-Ukrainian war from Feb 2022 to Aug 2024, spanning eleven media outlets across five nation states (Russia, Ukraine, U.S., U.K., and China) and three languages ...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "ICL",
        "experiment",
        "analysis",
        "research",
        "arxiv",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Teaching and Evaluating LLMs to Reason About Polymer Design Related Tasks",
      "url": "https://arxiv.org/abs/2601.16312",
      "description": "arXiv:2601.16312v1 Announce Type: new \nAbstract: Research in AI4Science has shown promise in many science applications, including polymer design. However, current LLMs prove ineffective on this problem space because: (i) most models lack polymer-specific knowledge (ii) existing aligned models lack c...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "knowledge base",
        "experiment",
        "alignment",
        "CoT",
        "reasoning",
        "research",
        "arxiv",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems",
      "url": "https://arxiv.org/abs/2601.16280",
      "description": "arXiv:2601.16280v1 Announce Type: new \nAbstract: Multi-agent systems powered by large language models (LLMs) are transforming enterprise automation, yet systematic evaluation methodologies for assessing tool-use reliability remain underdeveloped. We introduce a comprehensive diagnostic framework tha...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "GPT",
        "RAG",
        "augmented",
        "product",
        "analysis",
        "framework",
        "arxiv",
        "LLM",
        "tool",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "DSGym: A Holistic Framework for Evaluating and Training Data Science Agents",
      "url": "https://arxiv.org/abs/2601.16344",
      "description": "arXiv:2601.16344v1 Announce Type: new \nAbstract: Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark compari...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "GPT",
        "context",
        "example",
        "analysis",
        "vision",
        "framework",
        "arxiv",
        "tool",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs",
      "url": "https://arxiv.org/abs/2601.16479",
      "description": "arXiv:2601.16479v1 Announce Type: new \nAbstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although class...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "large language model",
        "RAG",
        "framework",
        "reasoning",
        "arxiv",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care",
      "url": "https://arxiv.org/abs/2601.16529",
      "description": "arXiv:2601.16529v1 Announce Type: new \nAbstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient ...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "large language model",
        "framework",
        "arxiv",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification",
      "url": "https://arxiv.org/abs/2601.16549",
      "description": "arXiv:2601.16549v1 Announce Type: new \nAbstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text ...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "large language model",
        "ICL",
        "experiment",
        "multimodal",
        "vision",
        "arxiv",
        "image",
        "prompt",
        "transformer",
        "LLM",
        "zero-shot",
        "fine-tuning",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents",
      "url": "https://arxiv.org/abs/2601.16649",
      "description": "arXiv:2601.16649v1 Announce Type: new \nAbstract: Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "RAG",
        "context",
        "framework",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning",
      "url": "https://arxiv.org/abs/2601.16685",
      "description": "arXiv:2601.16685v1 Announce Type: new \nAbstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "experiment",
        "alignment",
        "framework",
        "reasoning",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Ordering-based Causal Discovery via Generalized Score Matching",
      "url": "https://arxiv.org/abs/2601.16249",
      "description": "arXiv:2601.16249v1 Announce Type: new \nAbstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying D...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "experiment",
        "paper",
        "framework",
        "research",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning",
      "url": "https://arxiv.org/abs/2601.16399",
      "description": "arXiv:2601.16399v1 Announce Type: new \nAbstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward ...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "RLHF",
        "analysis",
        "arxiv",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Towards a Theoretical Understanding to the Generalization of RLHF",
      "url": "https://arxiv.org/abs/2601.16403",
      "description": "arXiv:2601.16403v1 Announce Type: new \nAbstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "RAG",
        "RLHF",
        "analysis",
        "framework",
        "arxiv",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context",
        "prompt",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "framework",
        "reasoning",
        "audio",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "prompt",
        "LLM",
        "tool",
        "API",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "RAG",
        "reasoning",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "knowledge base",
        "retrieval",
        "framework",
        "reasoning",
        "LLM",
        "vector",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "product",
        "retrieval",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "prompt",
        "platform",
        "LLM",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Analyzing Neural Network Information Flow Using Differential Geometry",
      "url": "https://arxiv.org/abs/2601.16366",
      "description": "arXiv:2601.16366v1 Announce Type: new \nAbstract: This paper provides a fresh view of the neural network (NN) data flow problem, i.e., identifying the NN connections that are most important for the performance of the full model, through the lens of graph theory. Understanding the NN data flow provide...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "example",
        "experiment",
        "analysis",
        "paper",
        "arxiv",
        "image",
        "tool",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "context",
        "API",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Towards Latent Diffusion Suitable For Text",
      "url": "https://arxiv.org/abs/2601.16220",
      "description": "arXiv:2601.16220v1 Announce Type: new \nAbstract: Language diffusion models aim to improve sampling speed and coherence over autoregressive LLMs. We introduce Neural Flow Diffusion Models for language generation, an extension of NFDM that enables the straightforward application of continuous diffusio...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "LLM"
      ],
      "score": 0.6
    },
    {
      "title": "SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems",
      "url": "https://arxiv.org/abs/2601.16286",
      "description": "arXiv:2601.16286v1 Announce Type: new \nAbstract: Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundar...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "platform",
        "LLM",
        "reasoning"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "M3Kang: Evaluating Multilingual Multimodal Mathematical Reasoning in Vision-Language Models",
      "url": "https://arxiv.org/abs/2601.16218",
      "description": "arXiv:2601.16218v1 Announce Type: new \nAbstract: Despite state-of-the-art vision-language models (VLMs) have demonstrated strong reasoning capabilities, their performance in multilingual mathematical reasoning remains underexplored, particularly when compared to human performance. To bridge this gap...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "analysis",
        "multimodal",
        "vision",
        "framework",
        "reasoning",
        "arxiv",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "LongCat-Flash-Thinking-2601 Technical Report",
      "url": "https://arxiv.org/abs/2601.16725",
      "description": "arXiv:2601.16725v1 Announce Type: new \nAbstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source mode...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "analysis",
        "framework",
        "reasoning",
        "arxiv",
        "tool",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Student Mental Health Screening via Fitbit Data Collected During the COVID-19 Pandemic",
      "url": "https://arxiv.org/abs/2601.16324",
      "description": "arXiv:2601.16324v1 Announce Type: new \nAbstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited conce...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "research"
      ],
      "score": 0.4
    },
    {
      "title": "Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction",
      "url": "https://arxiv.org/abs/2601.16406",
      "description": "arXiv:2601.16406v1 Announce Type: new \nAbstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional mode...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "vision",
        "framework",
        "reasoning",
        "arxiv",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning",
      "url": "https://arxiv.org/abs/2601.16414",
      "description": "arXiv:2601.16414v1 Announce Type: new \nAbstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enabl...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "product",
        "memory",
        "multimodal",
        "framework",
        "research",
        "arxiv",
        "tool",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance",
      "url": "https://arxiv.org/abs/2601.16425",
      "description": "arXiv:2601.16425v1 Announce Type: new \nAbstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experiment...",
      "published_date": "2026-01-26T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "example",
        "experiment",
        "framework",
        "arxiv",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "**NVIDIA Earth-2 Open Models Span the Whole Weather Stack**",
      "url": "https://huggingface.co/blog/nvidia/earth-2-open-models",
      "description": "...",
      "published_date": "2026-01-26T14:53:45",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model"
      ],
      "score": 0.2
    }
  ]
}