{
  "generated_at": "2025-07-22T13:20:45.828831",
  "total_items": 46,
  "items": [
    {
      "title": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base",
      "url": "https://arxiv.org/abs/2507.14189",
      "description": "arXiv:2507.14189v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in various applications. However, their use as writing assistants in specialized domains like finance, medicine, and law is often hampered by a lack of deep domain-specific knowled...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "LLM",
        "experiment",
        "knowledge base",
        "RAG",
        "model",
        "ICL",
        "augmented",
        "multimodal",
        "retrieval",
        "large language model"
      ],
      "score": 1.0,
      "korean_title": "팩트 기반 멀티모달 글쓰기 어시스튴트 DeepWriter: 오프라인 지식 베이스 활용",
      "korean_summary": "이 연구는 금융, 의료, 법률 등 전문 도메인에서 사용할 수 있는 오프라인 지식 베이스 기반의 멀티모달 글쓰기 도우미를 제안합니다. DeepWriter는 RAG 기술과 ICL 방식을 결합하여 사실 기반의 정확한 문서 생성을 가능하게 합니다.",
      "korean_keywords": [
        "대형 언어모델",
        "먀티모달",
        "지식베이스",
        "RAG",
        "글쓰기 도우미"
      ]
    },
    {
      "title": "Retention analysis of edited knowledge after fine-tuning",
      "url": "https://arxiv.org/abs/2507.14198",
      "description": "arXiv:2507.14198v1 Announce Type: new \nAbstract: Large language models (LLMs) store vast amounts of knowledge, which often requires updates to correct factual errors, incorporate newly acquired information, or adapt model behavior. Model editing methods have emerged as efficient solutions for such u...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "model",
        "fine-tuning",
        "large language model",
        "analysis"
      ],
      "score": 1.0,
      "korean_title": "파인튀닝 후 편집된 지식의 유지 분석",
      "korean_summary": "대형 언어 모델에 저장된 방대한 지식을 업데이트하고 팩트 오류를 수정하는 모델 편집 기법에 대한 연구입니다. 파인튀닝 후 편집된 지식이 얼마나 잘 유지되는지 분석하여 모델 성능 향상 방안을 제시합니다.",
      "korean_keywords": [
        "파인튀닝",
        "모델 편집",
        "지식 유지",
        "언어모델",
        "성능 분석"
      ]
    },
    {
      "title": "Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System",
      "url": "https://arxiv.org/abs/2507.14200",
      "description": "arXiv:2507.14200v1 Announce Type: new \nAbstract: This paper aims to demonstrate the potential and strengths of open-source collectives. It leads to a promising question: Can we harness multiple open-source LLMs to match or even beat the closed-source LLMs? To answer this, we propose SMACS, a scalabl...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "experiment",
        "paper",
        "RAG",
        "release",
        "GPT",
        "framework",
        "retrieval"
      ],
      "score": 1.0,
      "korean_title": "오픈소스 대형 언어모델 협력으로 비공개 모델 능가: 확장 가능한 멀티 에이전트 시스템",
      "korean_summary": "여러 오픈소스 대형 언어모델을 협력시켜 비공개 모델을 능가할 수 있는지를 탐구한 연구입니다. SMACS라는 확장 가능한 멀티 에이전트 시스템을 제안하여 GPT와 같은 비공개 모델에 준하는 성능을 달성합니다.",
      "korean_keywords": [
        "오픈소스",
        "멀티에이전트",
        "언어모델 협력",
        "GPT 대안",
        "확장성"
      ]
    },
    {
      "title": "Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale",
      "url": "https://arxiv.org/abs/2507.14214",
      "description": "arXiv:2507.14214v1 Announce Type: new \nAbstract: In modern times, people have numerous online accounts, but they rarely read the Terms of Service or Privacy Policy of those sites despite claiming otherwise. This paper introduces PoliAnalyzer, a neuro-symbolic system that assists users with personali...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "research",
        "RAG",
        "platform",
        "model",
        "tool",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media",
      "url": "https://arxiv.org/abs/2507.14231",
      "description": "arXiv:2507.14231v1 Announce Type: new \nAbstract: Bipolar disorder is a chronic mental illness frequently underdiagnosed due to subtle early symptoms and social stigma. This paper explores the advanced natural language processing (NLP) models for recognizing signs of bipolar disorder based on user-ge...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "experiment",
        "paper",
        "memory",
        "model",
        "study",
        "transformer",
        "embedding",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Language Models Change Facts Based on the Way You Talk",
      "url": "https://arxiv.org/abs/2507.14238",
      "description": "arXiv:2507.14238v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly being used in user-facing applications, from providing medical consultations to job interview advice. Recent research suggests that these models are becoming increasingly proficient at inferring identity i...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "research",
        "model",
        "tool",
        "large language model",
        "analysis"
      ],
      "score": 1.0,
      "korean_title": "언어 모델이 대화 방식에 따라 사실을 다르게 인식하는 현상",
      "korean_summary": "대형 언어 모델이 사용자의 언어 사용 패턴과 대화 방식에 따라 다른 사실 정보를 제공하는 현상을 분석한 연구입니다. 이는 AI 모델의 신뢰성과 공정성에 중요한 시사점을 제공합니다.",
      "korean_keywords": [
        "언어모델 편향",
        "대화 패턴",
        "AI 신뢰성",
        "사실 인식",
        "언어 영향"
      ]
    },
    {
      "title": "CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation",
      "url": "https://arxiv.org/abs/2507.14239",
      "description": "arXiv:2507.14239v1 Announce Type: new \nAbstract: Multilingual Large Language Models(MLLMs) demonstrate strong generalization across languages, yet they remain prone to hallucinations, especially in low-resource languages, due to training data imbalances. These hallucinations, which include inaccurat...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "LLM",
        "experiment",
        "alignment",
        "prompt",
        "prompting",
        "instruction",
        "chain-of-thought",
        "model",
        "framework",
        "fine-tuning",
        "retrieval",
        "large language model",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "HuggingGraph: Understanding the Supply Chain of LLM Ecosystem",
      "url": "https://arxiv.org/abs/2507.14240",
      "description": "arXiv:2507.14240v1 Announce Type: new \nAbstract: Large language models (LLMs) leverage deep learning to process and predict sequences of words from context, enabling them to perform various NLP tasks, such as translation, summarization, question answering, and content generation. However, the growin...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "example",
        "context",
        "RAG",
        "platform",
        "model",
        "study",
        "large language model",
        "summarization"
      ],
      "score": 1.0,
      "korean_title": "HuggingGraph: 대형 언어모델 생태계의 공급망 이해",
      "korean_summary": "대형 언어 모델 생태계의 복잡한 공급망을 분석하고 이해하기 위한 HuggingGraph 플랫폼을 소개합니다. 번역, 요약, 질의응답, 콘텐츠 생성 등 다양한 NLP 작업에서의 모델 활용 현황을 체계적으로 분석합니다.",
      "korean_keywords": [
        "LLM 생태계",
        "공급망 분석",
        "NLP 작업",
        "모델 활용",
        "요약 시스템"
      ]
    },
    {
      "title": "Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models",
      "url": "https://arxiv.org/abs/2507.14241",
      "description": "arXiv:2507.14241v1 Announce Type: new \nAbstract: Large Language Models (LLMs) perform best with well-crafted prompts, yet prompt engineering remains manual, inconsistent, and inaccessible to non-experts. We introduce Promptomatix, an automatic prompt optimization framework that transforms natural la...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "LLM",
        "prompt",
        "prompting",
        "model",
        "prompt engineering",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding",
      "url": "https://arxiv.org/abs/2507.14298",
      "description": "arXiv:2507.14298v1 Announce Type: new \nAbstract: Recent methods for customizing Large Vision Language Models (LVLMs) for domain-specific tasks have shown promising results in scientific chart comprehension. However, existing approaches face two major limitations: First, they rely on paired data from...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "paper",
        "alignment",
        "model",
        "vision",
        "multimodal",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation",
      "url": "https://arxiv.org/abs/2507.14267",
      "description": "arXiv:2507.14267v1 Announce Type: new \nAbstract: Materials discovery relies on high-throughput, high-fidelity simulation techniques such as Density Functional Theory (DFT), which require years of training, extensive parameter fine-tuning and systematic error handling. To address these challenges, we...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "context",
        "research",
        "RAG",
        "model",
        "framework",
        "fine-tuning",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "WebGuard: Building a Generalizable Guardrail for Web Agents",
      "url": "https://arxiv.org/abs/2507.14293",
      "description": "arXiv:2507.14293v1 Announce Type: new \nAbstract: The rapid development of autonomous web agents powered by Large Language Models (LLMs), while greatly elevating efficiency, exposes the frontier risk of taking unintended or harmful actions. This situation underscores an urgent need for effective safe...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "LLM",
        "API",
        "model",
        "fine-tuning",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Manimator: Transforming Research Papers into Visual Explanations",
      "url": "https://arxiv.org/abs/2507.14306",
      "description": "arXiv:2507.14306v1 Announce Type: new \nAbstract: Understanding complex scientific and mathematical concepts, particularly those presented in dense research papers, poses a significant challenge for learners. Dynamic visualizations can greatly enhance comprehension, but creating them manually is time...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "API",
        "paper",
        "research",
        "prompt",
        "RAG",
        "model",
        "tool",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Language Models as Ontology Encoders",
      "url": "https://arxiv.org/abs/2507.14334",
      "description": "arXiv:2507.14334v1 Announce Type: new \nAbstract: OWL (Web Ontology Language) ontologies which are able to formally represent complex knowledge and support semantic reasoning have been widely adopted across various domains such as healthcare and bioinformatics. Recently, ontology embeddings have gain...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "attention",
        "model",
        "embedding",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "ProofCompass: Enhancing Specialized Provers with LLM Guidance",
      "url": "https://arxiv.org/abs/2507.14335",
      "description": "arXiv:2507.14335v1 Announce Type: new \nAbstract: Language models have become increasingly powerful tools for formal mathematical reasoning. However, most existing approaches rely exclusively on either large general-purpose models or smaller specialized models, each with distinct limitations, while t...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "paper",
        "model",
        "tool",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering",
      "url": "https://arxiv.org/abs/2507.14406",
      "description": "arXiv:2507.14406v1 Announce Type: new \nAbstract: State-of-the-art reasoning LLMs are powerful problem solvers, but they still occasionally make mistakes. However, adopting AI models in risk-sensitive domains often requires error rates near 0%. To address this gap, we propose collaboration between a ...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "LLM",
        "RAG",
        "model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Routine: A Structural Planning Framework for LLM Agent System in Enterprise",
      "url": "https://arxiv.org/abs/2507.14447",
      "description": "arXiv:2507.14447v1 Announce Type: new \nAbstract: The deployment of agent systems in an enterprise environment is often hindered by several challenges: common models lack domain-specific process knowledge, leading to disorganized plans, missing key tools, and poor execution stability. To address this...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "experiment",
        "paper",
        "instruction",
        "model",
        "GPT",
        "tool",
        "vision",
        "fine-tuning",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI",
      "url": "https://arxiv.org/abs/2507.14172",
      "description": "arXiv:2507.14172v1 Announce Type: new \nAbstract: Many program synthesis tasks prove too challenging for even state-of-the-art language models to solve in single attempts. Search-based evolutionary methods offer a promising alternative by exploring solution spaces iteratively, but their effectiveness...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "RAG",
        "model",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Predictive Representativity: Uncovering Racial Bias in AI-based Skin Cancer Detection",
      "url": "https://arxiv.org/abs/2507.14176",
      "description": "arXiv:2507.14176v1 Announce Type: new \nAbstract: Artificial intelligence (AI) systems increasingly inform medical decision-making, yet concerns about algorithmic bias and inequitable outcomes persist, particularly for historically marginalized populations. This paper introduces the concept of Predic...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "paper",
        "model",
        "tool",
        "framework",
        "study",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Feature Bank Enhancement for Distance-based Out-of-Distribution Detection",
      "url": "https://arxiv.org/abs/2507.14178",
      "description": "arXiv:2507.14178v1 Announce Type: new \nAbstract: Out-of-distribution (OOD) detection is critical to ensuring the reliability of deep learning applications and has attracted significant attention in recent years. A rich body of literature has emerged to develop efficient score functions that assign h...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "attention",
        "image",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "A Sparsity Predicting Approach for Large Language Models via Activation Pattern Clustering",
      "url": "https://arxiv.org/abs/2507.14179",
      "description": "arXiv:2507.14179v1 Announce Type: new \nAbstract: Large Language Models (LLMs) exhibit significant activation sparsity, where only a subset of neurons are active for a given input. Although this sparsity presents opportunities to reduce computational cost, efficiently utilizing it requires predicting...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "arxiv",
        "LLM",
        "compression",
        "model",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Digital Twin-Assisted Explainable AI for Robust Beam Prediction in mmWave MIMO Systems",
      "url": "https://arxiv.org/abs/2507.14180",
      "description": "arXiv:2507.14180v1 Announce Type: new \nAbstract: In line with the AI-native 6G vision, explainability and robustness are crucial for building trust and ensuring reliable performance in millimeter-wave (mmWave) systems. Efficient beam alignment is essential for initial access, but deep learning (DL) ...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "paper",
        "alignment",
        "RAG",
        "model",
        "framework",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "Semi-Supervised Federated Learning via Dual Contrastive Learning and Soft Labeling for Intelligent Fault Diagnosis",
      "url": "https://arxiv.org/abs/2507.14181",
      "description": "arXiv:2507.14181v1 Announce Type: new \nAbstract: Intelligent fault diagnosis (IFD) plays a crucial role in ensuring the safe operation of industrial machinery and improving production efficiency. However, traditional supervised deep learning methods require a large amount of training data and labels...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "paper",
        "product",
        "RAG",
        "model",
        "ICL",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt",
        "prompt engineering",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "CoT",
        "framework",
        "audio",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "attention",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "LLM",
        "knowledge base",
        "RAG",
        "vector",
        "model",
        "framework",
        "retrieval",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "tool",
        "fine-tuning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "product",
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "prompt",
        "platform",
        "vector",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "The Free Will Equation: Quantum Field Analogies for AGI",
      "url": "https://arxiv.org/abs/2507.14154",
      "description": "arXiv:2507.14154v1 Announce Type: new \nAbstract: Artificial General Intelligence (AGI) research traditionally focuses on algorithms that optimize for specific goals under deterministic rules. Yet, human-like intelligence exhibits adaptive spontaneity - an ability to make unexpected choices or free d...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "research",
        "paper",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "tool",
        "API",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Understanding Two-Layer Neural Networks with Smooth Activation Functions",
      "url": "https://arxiv.org/abs/2507.14177",
      "description": "arXiv:2507.14177v1 Announce Type: new \nAbstract: This paper aims to understand the training solution, which is obtained by the back-propagation algorithm, of two-layer neural networks whose hidden layer is composed of the units with smooth activation functions, including the usual sigmoid type most ...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Adaptive Multi-Agent Reasoning via Automated Workflow Generation",
      "url": "https://arxiv.org/abs/2507.14393",
      "description": "arXiv:2507.14393v1 Announce Type: new \nAbstract: The rise of Large Reasoning Models (LRMs) promises a significant leap forward in language model capabilities, aiming to tackle increasingly sophisticated tasks with unprecedented efficiency and accuracy. However, despite their impressive performance, ...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "example",
        "paper",
        "prompt",
        "model",
        "tool",
        "framework",
        "reasoning"
      ],
      "score": 0.4
    },
    {
      "title": "Catalyst: a Novel Regularizer for Structured Pruning with Auxiliary Extension of Parameter Space",
      "url": "https://arxiv.org/abs/2507.14170",
      "description": "arXiv:2507.14170v1 Announce Type: new \nAbstract: Structured pruning aims to reduce the size and computational cost of deep neural networks by removing entire filters or channels. The traditional regularizers such as L1 or Group Lasso and its variants lead to magnitude-biased pruning decisions, such ...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning",
      "url": "https://arxiv.org/abs/2507.14171",
      "description": "arXiv:2507.14171v1 Announce Type: new \nAbstract: With the growth of demand on neural network compression methods, the structured pruning methods including importance-based approach are actively studied. The magnitude importance and many correlated modern importance criteria often limit the capacity ...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "compression",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "Latent Space Data Fusion Outperforms Early Fusion in Multimodal Mental Health Digital Phenotyping Data",
      "url": "https://arxiv.org/abs/2507.14175",
      "description": "arXiv:2507.14175v1 Announce Type: new \nAbstract: Background: Mental illnesses such as depression and anxiety require improved methods for early detection and personalized intervention. Traditional predictive models often rely on unimodal data or early fusion strategies that fail to capture the compl...",
      "published_date": "2025-07-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "multimodal",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}