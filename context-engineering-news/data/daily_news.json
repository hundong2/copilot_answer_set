{
  "generated_at": "2025-11-20T20:05:55.768463",
  "total_items": 45,
  "items": [
    {
      "title": "Test-time Scaling of LLMs: A Survey from A Subproblem Structure Perspective",
      "url": "https://arxiv.org/abs/2511.14772",
      "description": "arXiv:2511.14772v1 Announce Type: new \nAbstract: With this paper, we survey techniques for improving the predictive accuracy of pretrained large language models by allocating additional compute at inference time. In categorizing test-time scaling methods, we place special emphasis on how a problem i...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "model",
        "arxiv",
        "paper",
        "LLM",
        "chain-of-thought",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Temporal Predictors of Outcome in Reasoning Language Models",
      "url": "https://arxiv.org/abs/2511.14773",
      "description": "arXiv:2511.14773v1 Announce Type: new \nAbstract: The chain-of-thought (CoT) paradigm uses the elicitation of step-by-step rationales as a proxy for reasoning, gradually refining the model's latent representation of a solution. However, it remains unclear just how early a Large Language Model (LLM) i...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "large language model",
        "model",
        "reasoning",
        "arxiv",
        "step-by-step",
        "CoT",
        "LLM",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge Transfer in Multilingual LLMs",
      "url": "https://arxiv.org/abs/2511.14774",
      "description": "arXiv:2511.14774v1 Announce Type: new \nAbstract: Evaluating cross-lingual knowledge transfer in large language models is challenging, as correct answers in a target language may arise either from genuine transfer or from prior exposure during pre-training. We present LiveCLKTBench, an automated gene...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "model",
        "arxiv",
        "LLM",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "COMPASS: Context-Modulated PID Attention Steering System for Hallucination Mitigation",
      "url": "https://arxiv.org/abs/2511.14776",
      "description": "arXiv:2511.14776v1 Announce Type: new \nAbstract: Large language models (LLMs) often generate fluent but factually incorrect statements despite having access to relevant evidence, a failure mode rooted in how they allocate attention between contextual and parametric knowledge. Understanding and steer...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "RAG",
        "context",
        "model",
        "alignment",
        "framework",
        "arxiv",
        "attention",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "The Impact of Prosodic Segmentation on Speech Synthesis of Spontaneous Speech",
      "url": "https://arxiv.org/abs/2511.14779",
      "description": "arXiv:2511.14779v1 Announce Type: new \nAbstract: Spontaneous speech presents several challenges for speech synthesis, particularly in capturing the natural flow of conversation, including turn-taking, pauses, and disfluencies. Although speech synthesis systems have made significant progress in gener...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "research",
        "paper",
        "experiment",
        "ICL",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Human or LLM as Standardized Patients? A Comparative Study for Medical Education",
      "url": "https://arxiv.org/abs/2511.14783",
      "description": "arXiv:2511.14783v1 Announce Type: new \nAbstract: Standardized Patients (SP) are indispensable for clinical skills training but remain expensive, inflexible, and difficult to scale. Existing large-language-model (LLM)-based SP simulators promise lower cost yet show inconsistent behavior and lack rigo...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "study",
        "framework",
        "arxiv",
        "LLM",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Opinion Mining and Analysis Using Hybrid Deep Neural Networks",
      "url": "https://arxiv.org/abs/2511.14796",
      "description": "arXiv:2511.14796v1 Announce Type: new \nAbstract: Understanding customer attitudes has become a critical component of decision-making due to the growing influence of social media and e-commerce. Text-based opinions are the most structured, hence playing an important role in sentiment analysis. Most o...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "context",
        "study",
        "framework",
        "arxiv",
        "product",
        "memory",
        "experiment",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Hierarchical Token Prepending: Enhancing Information Flow in Decoder-based LLM Embeddings",
      "url": "https://arxiv.org/abs/2511.14868",
      "description": "arXiv:2511.14868v1 Announce Type: new \nAbstract: Large language models produce powerful text embeddings, but their causal attention mechanism restricts the flow of information from later to earlier tokens, degrading representation quality. While recent methods attempt to solve this by prepending a s...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "model",
        "context",
        "zero-shot",
        "embedding",
        "arxiv",
        "retrieval",
        "compression",
        "attention",
        "LLM",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation",
      "url": "https://arxiv.org/abs/2511.15005",
      "description": "arXiv:2511.15005v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are powerful linguistic engines but remain susceptible to hallucinations: plausible-sounding outputs that are factually incorrect or unsupported. In this work, we present a mathematically grounded framework to understand, ...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "model",
        "alignment",
        "framework",
        "arxiv",
        "retrieval",
        "LLM",
        "analysis",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs",
      "url": "https://arxiv.org/abs/2511.15163",
      "description": "arXiv:2511.15163v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their profi...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "model",
        "context",
        "framework",
        "arxiv",
        "instruction",
        "memory",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models",
      "url": "https://arxiv.org/abs/2511.13782",
      "description": "arXiv:2511.13782v1 Announce Type: new \nAbstract: Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial rea...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "large language model",
        "model",
        "API",
        "vision",
        "framework",
        "reasoning",
        "arxiv",
        "LLM",
        "experiment",
        "image"
      ],
      "score": 1.0
    },
    {
      "title": "Causal computations in Semi Markovian Structural Causal Models using divide and conquer",
      "url": "https://arxiv.org/abs/2511.13852",
      "description": "arXiv:2511.13852v1 Announce Type: new \nAbstract: Recently, Bj{\\o}ru et al. proposed a novel divide-and-conquer algorithm for bounding counterfactual probabilities in structural causal models (SCMs). They assumed that the SCMs were learned from purely observational data, leading to an imprecise chara...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "model",
        "study",
        "arxiv",
        "paper",
        "example"
      ],
      "score": 1.0
    },
    {
      "title": "Jailbreaking Large Vision Language Models in Intelligent Transportation Systems",
      "url": "https://arxiv.org/abs/2511.13892",
      "description": "arXiv:2511.13892v1 Announce Type: new \nAbstract: Large Vision Language Models (LVLMs) demonstrate strong capabilities in multimodal reasoning and many real-world applications, such as visual question answering. However, LVLMs are highly vulnerable to jailbreaking attacks. This paper systematically a...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "model",
        "vision",
        "multimodal",
        "reasoning",
        "GPT",
        "arxiv",
        "paper",
        "prompt",
        "experiment",
        "image",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Scene Graph-Guided Generative AI Framework for Synthesizing and Evaluating Industrial Hazard Scenarios",
      "url": "https://arxiv.org/abs/2511.13970",
      "description": "arXiv:2511.13970v1 Announce Type: new \nAbstract: Training vision models to detect workplace hazards accurately requires realistic images of unsafe conditions that could lead to accidents. However, acquiring such datasets is difficult because capturing accident-triggering scenarios as they occur is n...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "model",
        "context",
        "vision",
        "study",
        "framework",
        "reasoning",
        "GPT",
        "arxiv",
        "image"
      ],
      "score": 1.0
    },
    {
      "title": "Artificial Intelligence Agents in Music Analysis: An Integrative Perspective Based on Two Use Cases",
      "url": "https://arxiv.org/abs/2511.13987",
      "description": "arXiv:2511.13987v1 Announce Type: new \nAbstract: This paper presents an integrative review and experimental validation of artificial intelligence (AI) agents applied to music analysis and education. We synthesize the historical evolution from rule-based models to contemporary approaches involving de...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "model",
        "framework",
        "arxiv",
        "retrieval",
        "paper",
        "experiment",
        "research",
        "analysis",
        "platform",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "ALEX:A Light Editing-knowledge Extractor",
      "url": "https://arxiv.org/abs/2511.14018",
      "description": "arXiv:2511.14018v1 Announce Type: new \nAbstract: The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retriev...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "model",
        "framework",
        "reasoning",
        "arxiv",
        "retrieval",
        "paper",
        "memory",
        "LLM",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Syn-STARTS: Synthesized START Triage Scenario Generation Framework for Scalable LLM Evaluation",
      "url": "https://arxiv.org/abs/2511.14023",
      "description": "arXiv:2511.14023v1 Announce Type: new \nAbstract: Triage is a critically important decision-making process in mass casualty incidents (MCIs) to maximize victim survival rates. While the role of AI in such situations is gaining attention for making optimal decisions within limited resources and time, ...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "framework",
        "arxiv",
        "attention",
        "LLM",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Transformer Injectivity & Geometric Robustness - Analytic Margins and Bi-Lipschitz Uniformity of Sequence-Level Hidden States",
      "url": "https://arxiv.org/abs/2511.14808",
      "description": "arXiv:2511.14808v1 Announce Type: new \nAbstract: Under real-analytic assumptions on decoder-only Transformers, recent work shows that the map from discrete prompts to last-token hidden states is generically injective on finite prompt sets. We refine this picture: for each layer $\\ell$ we define a co...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "transformer",
        "study",
        "GPT",
        "arxiv",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "DEVAL: A Framework for Evaluating and Improving the Derivation Capability of Large Language Models",
      "url": "https://arxiv.org/abs/2511.14813",
      "description": "arXiv:2511.14813v1 Announce Type: new \nAbstract: Assessing the reasoning ability of Large Language Models (LLMs) over data remains an open and pressing research question. Compared with LLMs, human reasoning can derive corresponding modifications to the output based on certain kinds of changes to the...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "RAG",
        "model",
        "framework",
        "reasoning",
        "GPT",
        "arxiv",
        "paper",
        "prompt engineering",
        "prompt",
        "LLM",
        "research",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Dynamic Nested Hierarchies: Pioneering Self-Evolution in Machine Learning Architectures for Lifelong Intelligence",
      "url": "https://arxiv.org/abs/2511.14823",
      "description": "arXiv:2511.14823v1 Announce Type: new \nAbstract: Contemporary machine learning models, including large language models, exhibit remarkable capabilities in static tasks yet falter in non-stationary environments due to rigid architectures that hinder continual adaptation and lifelong learning. Buildin...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "large language model",
        "model",
        "context",
        "reasoning",
        "arxiv",
        "demonstration"
      ],
      "score": 1.0
    },
    {
      "title": "Empowering Multi-Turn Tool-Integrated Reasoning with Group Turn Policy Optimization",
      "url": "https://arxiv.org/abs/2511.14846",
      "description": "arXiv:2511.14846v1 Announce Type: new \nAbstract: Training Large Language Models (LLMs) for multi-turn Tool-Integrated Reasoning (TIR) - where models iteratively reason, generate code, and verify through execution - remains challenging for existing reinforcement learning (RL) approaches. Current RL m...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "large language model",
        "RAG",
        "API",
        "model",
        "vision",
        "reasoning",
        "arxiv",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "FinTRec: Transformer Based Unified Contextual Ads Targeting and Personalization for Financial Applications",
      "url": "https://arxiv.org/abs/2511.14865",
      "description": "arXiv:2511.14865v1 Announce Type: new \nAbstract: Transformer-based architectures are widely adopted in sequential recommendation systems, yet their application in Financial Services (FS) presents distinct practical and modeling challenges for real-time recommendation. These include:a) long-range use...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "context",
        "transformer",
        "alignment",
        "framework",
        "study",
        "arxiv",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "It's LIT! Reliability-Optimized LLMs with Inspectable Tools",
      "url": "https://arxiv.org/abs/2511.14903",
      "description": "arXiv:2511.14903v1 Announce Type: new \nAbstract: Large language models (LLMs) have exhibited remarkable capabilities across various domains. The ability to call external tools further expands their capability to handle real-world tasks. However, LLMs often follow an opaque reasoning process, which l...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "large language model",
        "model",
        "framework",
        "reasoning",
        "arxiv",
        "paper",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context",
        "prompt",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "reasoning",
        "audio",
        "CoT",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "API",
        "context",
        "prompt",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "context",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "model",
        "vector",
        "framework",
        "reasoning",
        "retrieval",
        "knowledge base",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "API",
        "retrieval",
        "product",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "framework",
        "prompt",
        "LLM",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "KANGURA: Kolmogorov-Arnold Network-Based Geometry-Aware Learning with Unified Representation Attention for 3D Modeling of Complex Structures",
      "url": "https://arxiv.org/abs/2511.13798",
      "description": "arXiv:2511.13798v1 Announce Type: new \nAbstract: Microbial Fuel Cells (MFCs) offer a promising pathway for sustainable energy generation by converting organic matter into electricity through microbial processes. A key factor influencing MFC performance is the anode structure, where design and materi...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "framework",
        "arxiv",
        "attention",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "Structured Contrastive Learning for Interpretable Latent Representations",
      "url": "https://arxiv.org/abs/2511.14920",
      "description": "arXiv:2511.14920v1 Announce Type: new \nAbstract: Neural networks exhibit severe brittleness to semantically irrelevant transformations. A mere 75ms electrocardiogram (ECG) phase shift degrades latent cosine similarity from 1.0 to 0.2, while sensor rotations collapse activity recognition performance ...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "framework",
        "experiment",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Integrating Causal Inference with Graph Neural Networks for Alzheimer's Disease Analysis",
      "url": "https://arxiv.org/abs/2511.14922",
      "description": "arXiv:2511.14922v1 Announce Type: new \nAbstract: Deep graph learning has advanced Alzheimer's (AD) disease classification from MRI, but most models remain correlational, confounding demographic and genetic factors with disease specific features. We present Causal-GCN, an interventional graph convolu...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "model",
        "framework",
        "arxiv",
        "analysis"
      ],
      "score": 0.8
    },
    {
      "title": "Introducing AnyLanguageModel: One API for Local and Remote LLMs on Apple Platforms",
      "url": "https://huggingface.co/blog/anylanguagemodel",
      "description": "...",
      "published_date": "2025-11-20T00:00:00",
      "source": "Hugging Face Blog",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "API",
        "platform",
        "LLM"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "context",
        "API",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Transformer-Guided Deep Reinforcement Learning for Optimal Takeoff Trajectory Design of an eVTOL Drone",
      "url": "https://arxiv.org/abs/2511.14887",
      "description": "arXiv:2511.14887v1 Announce Type: new \nAbstract: The rapid advancement of electric vertical take-off and landing (eVTOL) aircraft offers a promising opportunity to alleviate urban traffic congestion. Thus, developing optimal takeoff trajectories for minimum energy consumption becomes essential for b...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "transformer",
        "API",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Bringing Federated Learning to Space",
      "url": "https://arxiv.org/abs/2511.14889",
      "description": "arXiv:2511.14889v1 Announce Type: new \nAbstract: As Low Earth Orbit (LEO) satellite constellations rapidly expand to hundreds and thousands of spacecraft, the need for distributed on-board machine learning becomes critical to address downlink bandwidth limitations. Federated learning (FL) offers a p...",
      "published_date": "2025-11-20T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "API",
        "framework",
        "arxiv",
        "analysis"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}