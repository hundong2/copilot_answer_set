{
  "generated_at": "2025-12-05T20:05:49.481533",
  "total_items": 46,
  "items": [
    {
      "title": "On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral",
      "url": "https://arxiv.org/abs/2512.04220",
      "description": "arXiv:2512.04220v1 Announce Type: new \nAbstract: Tool-integrated (TI) reinforcement learning (RL) enables large language models (LLMs) to perform multi-step reasoning by interacting with external tools such as search engines and retrievers. Group Relative Policy Optimization (GRPO), exemplified by t...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "LLM",
        "model",
        "reasoning",
        "large language model",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Computational Linguistics Meets Libyan Dialect: A Study on Dialect Identification",
      "url": "https://arxiv.org/abs/2512.04257",
      "description": "arXiv:2512.04257v1 Announce Type: new \nAbstract: This study investigates logistic regression, linear support vector machine, multinomial Naive Bayes, and Bernoulli Naive Bayes for classifying Libyan dialect utterances gathered from Twitter. The dataset used is the QADI corpus, which consists of 540,...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "study",
        "arxiv",
        "analysis",
        "model",
        "vector",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "SQuARE: Structured Query & Adaptive Retrieval Engine For Tabular Formats",
      "url": "https://arxiv.org/abs/2512.04292",
      "description": "arXiv:2512.04292v1 Announce Type: new \nAbstract: Accurate question answering over real spreadsheets remains difficult due to multirow headers, merged cells, and unit annotations that disrupt naive chunking, while rigid SQL views fail on files lacking consistent schemas. We present SQuARE, a hybrid r...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "arxiv",
        "model",
        "retrieval",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle",
      "url": "https://arxiv.org/abs/2512.04324",
      "description": "arXiv:2512.04324v1 Announce Type: new \nAbstract: Real-world enterprise data intelligence workflows encompass data engineering that turns raw sources into analytical-ready tables and data analysis that convert those tables into decision-oriented insights. We introduce DAComp, a benchmark of 210 tasks...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "arxiv",
        "LLM",
        "analysis",
        "reasoning",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "ClusterFusion: Hybrid Clustering with Embedding Guidance and LLM Adaptation",
      "url": "https://arxiv.org/abs/2512.04350",
      "description": "arXiv:2512.04350v1 Announce Type: new \nAbstract: Text clustering is a fundamental task in natural language processing, yet traditional clustering algorithms with pre-trained embeddings often struggle in domain-specific contexts without costly fine-tuning. Large language models (LLMs) provide strong ...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "framework",
        "release",
        "LLM",
        "arxiv",
        "context",
        "reasoning",
        "fine-tuning",
        "model",
        "embedding",
        "large language model",
        "experiment",
        "summarization"
      ],
      "score": 1.0
    },
    {
      "title": "MASE: Interpretable NLP Models via Model-Agnostic Saliency Estimation",
      "url": "https://arxiv.org/abs/2512.04386",
      "description": "arXiv:2512.04386v1 Announce Type: new \nAbstract: Deep neural networks (DNNs) have made significant strides in Natural Language Processing (NLP), yet their interpretability remains elusive, particularly when evaluating their intricate decision-making processes. Traditional methods often rely on post-...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "framework",
        "arxiv",
        "model",
        "embedding",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "RapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning",
      "url": "https://arxiv.org/abs/2512.04457",
      "description": "arXiv:2512.04457v1 Announce Type: new \nAbstract: Removing specific data influence from large language models (LLMs) remains challenging, as retraining is costly and existing approximate unlearning methods are often unstable. The challenge is exacerbated when the forget set is small or imbalanced. We...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "API",
        "arxiv",
        "LLM",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "MSME: A Multi-Stage Multi-Expert Framework for Zero-Shot Stance Detection",
      "url": "https://arxiv.org/abs/2512.04492",
      "description": "arXiv:2512.04492v1 Announce Type: new \nAbstract: LLM-based approaches have recently achieved impressive results in zero-shot stance detection. However, they still struggle in complex real-world scenarios, where stance understanding requires dynamic background knowledge, target definitions involve co...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "zero-shot",
        "framework",
        "LLM",
        "arxiv",
        "reasoning",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation",
      "url": "https://arxiv.org/abs/2512.03048",
      "description": "arXiv:2512.03048v1 Announce Type: new \nAbstract: I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contr...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "paper",
        "framework",
        "arxiv",
        "experiment",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "When Do Symbolic Solvers Enhance Reasoning in Large Language Models?",
      "url": "https://arxiv.org/abs/2512.03272",
      "description": "arXiv:2512.03272v1 Announce Type: new \nAbstract: Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models \"overthink\" by producing lengthy rea...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "CoT",
        "RAG",
        "paper",
        "LLM",
        "arxiv",
        "experiment",
        "model",
        "reasoning",
        "large language model",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia",
      "url": "https://arxiv.org/abs/2512.03318",
      "description": "arXiv:2512.03318v1 Announce Type: new \nAbstract: Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "zero-shot",
        "LLM",
        "arxiv",
        "context",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks",
      "url": "https://arxiv.org/abs/2512.03549",
      "description": "arXiv:2512.03549v1 Announce Type: new \nAbstract: We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own acti...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "analysis",
        "experiment",
        "instruction"
      ],
      "score": 1.0
    },
    {
      "title": "Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks",
      "url": "https://arxiv.org/abs/2512.03560",
      "description": "arXiv:2512.03560v1 Announce Type: new \nAbstract: Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent a...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "context window",
        "RAG",
        "arxiv",
        "context",
        "model",
        "reasoning",
        "API",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "ASCIIBench: Evaluating Language-Model-Based Understanding of Visually-Oriented Text",
      "url": "https://arxiv.org/abs/2512.04125",
      "description": "arXiv:2512.04125v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated several emergent behaviors with scale, including reasoning and fluency in long-form text generation. However, they continue to struggle with tasks requiring precise spatial and positional reasoning. ASCII...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "release",
        "LLM",
        "embedding",
        "image",
        "arxiv",
        "ICL",
        "analysis",
        "reasoning",
        "large language model",
        "model",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Fine-Tuning ChemBERTa for Predicting Inhibitory Activity Against TDP1 Using Deep Learning",
      "url": "https://arxiv.org/abs/2512.04252",
      "description": "arXiv:2512.04252v1 Announce Type: new \nAbstract: Predicting the inhibitory potency of small molecules against Tyrosyl-DNA Phosphodiesterase 1 (TDP1)-a key target in overcoming cancer chemoresistance-remains a critical challenge in early drug discovery. We present a deep learning framework for the qu...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "RAG",
        "framework",
        "arxiv",
        "transformer",
        "fine-tuning",
        "model",
        "experiment",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "The Initialization Determines Whether In-Context Learning Is Gradient Descent",
      "url": "https://arxiv.org/abs/2512.04268",
      "description": "arXiv:2512.04268v1 Announce Type: new \nAbstract: In-context learning (ICL) in large language models (LLMs) is a striking phenomenon, yet its underlying mechanisms remain only partially understood. Previous work connects linear self-attention (LSA) to gradient descent (GD), this connection has primar...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "attention",
        "in-context",
        "LLM",
        "arxiv",
        "context",
        "ICL",
        "augmented",
        "model",
        "embedding",
        "large language model",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt engineering",
        "prompt",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "framework",
        "audio",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "prompt",
        "context",
        "model",
        "API",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "framework",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "knowledge base",
        "RAG",
        "framework",
        "LLM",
        "retrieval",
        "reasoning",
        "vector",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "product",
        "augmented",
        "retrieval",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "framework",
        "LLM",
        "prompt",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving",
      "url": "https://arxiv.org/abs/2512.04374",
      "description": "arXiv:2512.04374v1 Announce Type: new \nAbstract: Our work presents a novel reinforcement learning (RL) based framework to optimize heuristic selection within the conflict-driven clause learning (CDCL) process, improving the efficiency of Boolean satisfia- bility (SAT) solving. The proposed system, L...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "framework",
        "arxiv",
        "context",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Sarcasm Detection on Reddit Using Classical Machine Learning and Feature Engineering",
      "url": "https://arxiv.org/abs/2512.04396",
      "description": "arXiv:2512.04396v1 Announce Type: new \nAbstract: Sarcasm is common in online discussions, yet difficult for machines to identify because the intended meaning often contradicts the literal wording. In this work, I study sarcasm detection using only classical machine learning methods and explicit feat...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "study",
        "arxiv",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI",
      "url": "https://arxiv.org/abs/2512.03072",
      "description": "arXiv:2512.03072v1 Announce Type: new \nAbstract: Current AI paradigms, as \"architects of experience,\" face fundamental challenges in explainability and value alignment. This paper introduces \"Weight-Calculatism,\" a novel cognitive architecture grounded in first principles, and demonstrates its poten...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "model",
        "reasoning",
        "alignment"
      ],
      "score": 0.8
    },
    {
      "title": "Multimodal Reinforcement Learning with Agentic Verifier for AI Agents",
      "url": "https://arxiv.org/abs/2512.03438",
      "description": "arXiv:2512.03438v1 Announce Type: new \nAbstract: Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capable, yet they are almost universally optimized using sparse, outcome-based rewards computed based on the final answers. Richer rewards computed...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "paper",
        "arxiv",
        "model",
        "reasoning",
        "multimodal"
      ],
      "score": 0.8
    },
    {
      "title": "EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths",
      "url": "https://arxiv.org/abs/2512.03571",
      "description": "arXiv:2512.03571v1 Announce Type: new \nAbstract: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We ...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "LLM",
        "model",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "Mitigating the Curse of Detail: Scaling Arguments for Feature Learning and Sample Complexity",
      "url": "https://arxiv.org/abs/2512.04165",
      "description": "arXiv:2512.04165v1 Announce Type: new \nAbstract: Two pressing topics in the theory of deep learning are the interpretation of feature learning mechanisms and the determination of implicit bias of networks in the rich regime. Current theories of rich feature learning effects revolve around networks w...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "arxiv",
        "analysis"
      ],
      "score": 0.8
    },
    {
      "title": "BEP: A Binary Error Propagation Algorithm for Binary Neural Networks Training",
      "url": "https://arxiv.org/abs/2512.04189",
      "description": "arXiv:2512.04189v1 Announce Type: new \nAbstract: Binary Neural Networks (BNNs), which constrain both weights and activations to binary values, offer substantial reductions in computational complexity, memory footprint, and energy consumption. These advantages make them particularly well suited for d...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "release",
        "arxiv",
        "memory",
        "vector"
      ],
      "score": 0.8
    },
    {
      "title": "Studying Various Activation Functions and Non-IID Data for Machine Learning Model Robustness",
      "url": "https://arxiv.org/abs/2512.04264",
      "description": "arXiv:2512.04264v1 Announce Type: new \nAbstract: Adversarial training is an effective method to improve the machine learning (ML) model robustness. Most existing studies typically consider the Rectified linear unit (ReLU) activation function and centralized training environments. In this paper, we s...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "study",
        "arxiv",
        "model",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "model",
        "tool",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Prior preferences in active inference agents: soft, hard, and goal shaping",
      "url": "https://arxiv.org/abs/2512.03293",
      "description": "arXiv:2512.03293v1 Announce Type: new \nAbstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as t...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "API",
        "attention",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "MechDetect: Detecting Data-Dependent Errors",
      "url": "https://arxiv.org/abs/2512.04138",
      "description": "arXiv:2512.04138v1 Announce Type: new \nAbstract: Data quality monitoring is a core challenge in modern information processing systems. While many approaches to detect data errors or shifts have been proposed, few studies investigate the mechanisms governing error generation. We argue that knowing ho...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "study",
        "arxiv",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Network of Theseus (like the ship)",
      "url": "https://arxiv.org/abs/2512.04198",
      "description": "arXiv:2512.04198v1 Announce Type: new \nAbstract: A standard assumption in deep learning is that the inductive bias introduced by a neural network architecture must persist from training through inference. The architecture you train with is the architecture you deploy. This assumption constrains the ...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "GPT",
        "arxiv",
        "example"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "Decoding Large Language Diffusion Models with Foreseeing Movement",
      "url": "https://arxiv.org/abs/2512.04135",
      "description": "arXiv:2512.04135v1 Announce Type: new \nAbstract: Large Language Diffusion Models (LLDMs) benefit from a flexible decoding mechanism that enables parallelized inference and controllable generations over autoregressive models. Yet such flexibility introduces a critical challenge: inference performance...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "ActVAE: Modelling human activity schedules with a deep conditional generative approach",
      "url": "https://arxiv.org/abs/2512.04223",
      "description": "arXiv:2512.04223v1 Announce Type: new \nAbstract: Modelling the complexity and diversity of human activity scheduling behaviour is inherently challenging. We demonstrate a deep conditional-generative machine learning approach for the modelling of realistic activity schedules depending on input labels...",
      "published_date": "2025-12-05T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "framework",
        "arxiv",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "We Got Claude to Fine-Tune an Open Source LLM",
      "url": "https://huggingface.co/blog/hf-skills-training",
      "description": "...",
      "published_date": "2025-12-04T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}