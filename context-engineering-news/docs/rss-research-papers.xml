<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>WearVox: An Egocentric Multichannel Voice Assistant Benchmark for Wearables</title>
      <link>https://arxiv.org/abs/2601.02391</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.02391</guid>
      <description>arXiv:2601.02391v1 Announce Type: new 
Abstract: Wearable devices such as AI glasses are transforming voice assistants into always-available, hands-free collaborators that integrate seamlessly with daily life, but they also introduce challenges like egocentric audio affected by motion and noise, rap...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, LLM, arxiv, context, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>LLM</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Fact-Checking with Large Language Models via Probabilistic Certainty and Consistency</title>
      <link>https://arxiv.org/abs/2601.02574</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.02574</guid>
      <description>arXiv:2601.02574v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used in applications requiring factual accuracy, yet their outputs often contain hallucinated responses. While fact-checking can mitigate these errors, existing methods typically retrieve external evidence...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; retrieval, reasoning, LLM, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>retrieval</category>
      <category>reasoning</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Reconstructing Item Characteristic Curves using Fine-Tuned Large Language Models</title>
      <link>https://arxiv.org/abs/2601.02580</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.02580</guid>
      <description>arXiv:2601.02580v1 Announce Type: new 
Abstract: Traditional methods for determining assessment item parameters, such as difficulty and discrimination, rely heavily on expensive field testing to collect student performance data for Item Response Theory (IRT) calibration. This study introduces a nove...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, LLM, arxiv, model, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>fine-tuning</category>
      <category>LLM</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>FlowPlan-G2P: A Structured Generation Framework for Transforming Scientific Papers into Patent Descriptions</title>
      <link>https://arxiv.org/abs/2601.02589</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.02589</guid>
      <description>arXiv:2601.02589v1 Announce Type: new 
Abstract: Over 3.5 million patents are filed annually, with drafting patent descriptions requiring deep technical and legal expertise. Transforming scientific papers into patent descriptions is particularly challenging due to their differing rhetorical styles a...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, paper, prompt, LLM, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>paper</category>
      <category>prompt</category>
    </item>
    <item>
      <title>Scalable Construction of a Lung Cancer Knowledge Base: Profiling Semantic Reasoning in LLMs</title>
      <link>https://arxiv.org/abs/2601.02604</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.02604</guid>
      <description>arXiv:2601.02604v1 Announce Type: new 
Abstract: The integration of Large Language Models (LLMs) into biomedical research offers new opportunities for domainspecific reasoning and knowledge representation. However, their performance depends heavily on the semantic quality of training data. In oncolo...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, fine-tuning, LLM, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>fine-tuning</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections</title>
      <link>https://arxiv.org/abs/2601.00814</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.00814</guid>
      <description>arXiv:2601.00814v1 Announce Type: new 
Abstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned trans...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, arxiv, model, vector, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis</title>
      <link>https://arxiv.org/abs/2601.00828</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.00828</guid>
      <description>arXiv:2601.00828v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, arxiv, model, experiment, GPT | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Enhancing Temporal Awareness in LLMs for Temporal Point Processes</title>
      <link>https://arxiv.org/abs/2601.00845</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.00845</guid>
      <description>arXiv:2601.00845v1 Announce Type: new 
Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounti...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, LLM, arxiv, context, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>LLM</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Multi-scale Graph Autoregressive Modeling: Molecular Property Prediction via Next Token Prediction</title>
      <link>https://arxiv.org/abs/2601.02530</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.02530</guid>
      <description>arXiv:2601.02530v1 Announce Type: new 
Abstract: We present Connection-Aware Motif Sequencing (CamS), a graph-to-sequence representation that enables decoder-only Transformers to learn molecular graphs via standard next-token prediction (NTP). For molecular property prediction, SMILES-based NTP scal...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, arxiv, model, attention, transformer | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>CutisAI: Deep Learning Framework for Automated Dermatology and Cancer Screening</title>
      <link>https://arxiv.org/abs/2601.02562</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.02562</guid>
      <description>arXiv:2601.02562v1 Announce Type: new 
Abstract: The rapid growth of dermatological imaging and mobile diagnostic tools calls for systems that not only demonstrate empirical performance but also provide strong theoretical guarantees. Deep learning models have shown high predictive accuracy; however,...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, arxiv, model, tool, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Losses that Cook: Topological Optimal Transport for Structured Recipe Generation</title>
      <link>https://arxiv.org/abs/2601.02531</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.02531</guid>
      <description>arXiv:2601.02531v1 Announce Type: new 
Abstract: Cooking recipes are complex procedures that require not only a fluent and factual text, but also accurate timing, temperature, and procedural coherence, as well as the correct composition of ingredients. Standard training procedures are primarily base...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, arxiv, model, embedding | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models</title>
      <link>https://arxiv.org/abs/2601.00848</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.00848</guid>
      <description>arXiv:2601.00848v1 Announce Type: new 
Abstract: We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; release, example, fine-tuning, analysis, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>release</category>
      <category>example</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>mHC-GNN: Manifold-Constrained Hyper-Connections for Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2601.02451</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.02451</guid>
      <description>arXiv:2601.02451v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) suffer from over-smoothing in deep architectures and expressiveness bounded by the 1-Weisfeiler-Leman (1-WL) test. We adapt Manifold-Constrained Hyper-Connections (\mhc)~\citep{xie2025mhc}, recently proposed for Transforme...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, transformer | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>transformer</category>
    </item>
    <item>
      <title>Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making</title>
      <link>https://arxiv.org/abs/2601.00818</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.00818</guid>
      <description>arXiv:2601.00818v1 Announce Type: new 
Abstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, paper, arxiv, model, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>paper</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Polynomial Convergence of Riemannian Diffusion Models</title>
      <link>https://arxiv.org/abs/2601.02499</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.02499</guid>
      <description>arXiv:2601.02499v1 Announce Type: new 
Abstract: Diffusion models have demonstrated remarkable empirical success in the recent years and are considered one of the state-of-the-art generative models in modern AI. These models consist of a forward process, which gradually diffuses the data distributio...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, arxiv, model, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback</title>
      <link>https://arxiv.org/abs/2601.00816</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.00816</guid>
      <description>arXiv:2601.00816v1 Announce Type: new 
Abstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal ver...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Normalized Conditional Mutual Information Surrogate Loss for Deep Neural Classifiers</title>
      <link>https://arxiv.org/abs/2601.02543</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.02543</guid>
      <description>arXiv:2601.02543v1 Announce Type: new 
Abstract: In this paper, we propose a novel information theoretic surrogate loss; normalized conditional mutual information (NCMI); as a drop in alternative to the de facto cross-entropy (CE) for training deep neural network (DNN) based classifiers. We first ob...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; image, arxiv, model, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 07 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>image</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
  </channel>
</rss>