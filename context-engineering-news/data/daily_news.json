{
  "generated_at": "2026-01-16T20:06:19.073120",
  "total_items": 48,
  "items": [
    {
      "title": "LLM-Driven Preference Data Synthesis for Proactive Prediction of the Next User Utterance in Human-Machine Dialogue",
      "url": "https://arxiv.org/abs/2601.09713",
      "description": "arXiv:2601.09713v1 Announce Type: new \nAbstract: Proactively predicting a users next utterance in human-machine dialogue can streamline interaction and improve user experience. Existing commercial API-based solutions are subject to privacy concerns while deploying general-purpose LLMs locally remain...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "model",
        "research",
        "LLM",
        "API",
        "reasoning",
        "release"
      ],
      "score": 1.0
    },
    {
      "title": "Evaluating Novelty in AI-Generated Research Plans Using Multi-Workflow LLM Pipelines",
      "url": "https://arxiv.org/abs/2601.09714",
      "description": "arXiv:2601.09714v1 Announce Type: new \nAbstract: The integration of Large Language Models (LLMs) into the scientific ecosystem raises fundamental questions about the creativity and originality of AI-generated research. Recent work has identified ``smart plagiarism'' as a concern in single-step promp...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "large language model",
        "prompting",
        "arxiv",
        "model",
        "research",
        "paper",
        "LLM",
        "GPT",
        "prompt",
        "reasoning",
        "framework",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Introducing Axlerod: An LLM-based Chatbot for Assisting Independent Insurance Agents",
      "url": "https://arxiv.org/abs/2601.09715",
      "description": "arXiv:2601.09715v1 Announce Type: new \nAbstract: The insurance industry is undergoing a paradigm shift through the adoption of artificial intelligence (AI) technologies, particularly in the realm of intelligent conversational agents. Chatbots have evolved into sophisticated AI-driven systems capable...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "augmented",
        "arxiv",
        "research",
        "paper",
        "LLM",
        "RAG",
        "experiment",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Opportunities and Challenges of Natural Language Processing for Low-Resource Senegalese Languages in Social Science Research",
      "url": "https://arxiv.org/abs/2601.09716",
      "description": "arXiv:2601.09716v1 Announce Type: new \nAbstract: Natural Language Processing (NLP) is rapidly transforming research methodologies across disciplines, yet African languages remain largely underrepresented in this technological shift. This paper provides the first comprehensive overview of NLP progres...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "paper",
        "tool",
        "API",
        "ICL",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "SALP-CG: Standard-Aligned LLM Pipeline for Classifying and Grading Large Volumes of Online Conversational Health Data",
      "url": "https://arxiv.org/abs/2601.09717",
      "description": "arXiv:2601.09717v1 Announce Type: new \nAbstract: Online medical consultations generate large volumes of conversational health data that often embed protected health information, requiring robust methods to classify data categories and assign risk levels in line with policies and practice. However, e...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "large language model",
        "model",
        "study",
        "LLM",
        "few-shot"
      ],
      "score": 1.0
    },
    {
      "title": "StatLLaMA: A multi-stage training framework for building a domain-optimized statistical language model",
      "url": "https://arxiv.org/abs/2601.09718",
      "description": "arXiv:2601.09718v1 Announce Type: new \nAbstract: This study investigates how to efficiently build a domain-specialized large language model (LLM) for statistics using the lightweight LLaMA-3.2-3B family as the foundation model (FM). We systematically compare three multi-stage training pipelines, sta...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "large language model",
        "augmented",
        "arxiv",
        "model",
        "instruction",
        "study",
        "LLM",
        "reasoning",
        "framework",
        "RLHF",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Bounded Hyperbolic Tangent: A Stable and Efficient Alternative to Pre-Layer Normalization in Large Language Models",
      "url": "https://arxiv.org/abs/2601.09719",
      "description": "arXiv:2601.09719v1 Announce Type: new \nAbstract: Pre-Layer Normalization (Pre-LN) is the de facto choice for large language models (LLMs) and is crucial for stable pretraining and effective transfer learning. However, Pre-LN is inefficient due to repeated statistical calculations and suffers from th...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "large language model",
        "model",
        "LLM",
        "reasoning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Cross-Platform Evaluation of Large Language Model Safety in Pediatric Consultations: Evolution of Adversarial Robustness and the Scale Paradox",
      "url": "https://arxiv.org/abs/2601.09721",
      "description": "arXiv:2601.09721v1 Announce Type: new \nAbstract: Background Large language models (LLMs) are increasingly deployed in medical consultations, yet their safety under realistic user pressures remains understudied. Prior assessments focused on neutral conditions, overlooking vulnerabilities from anxious...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "large language model",
        "arxiv",
        "model",
        "study",
        "LLM",
        "API",
        "release",
        "platform",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "ADMEDTAGGER: an annotation framework for distillation of expert knowledge for the Polish medical language",
      "url": "https://arxiv.org/abs/2601.09722",
      "description": "arXiv:2601.09722v1 Announce Type: new \nAbstract: In this work, we present an annotation framework that demonstrates how a multilingual LLM pretrained on a large corpus can be used as a teacher model to distill the expert knowledge needed for tagging medical texts in Polish. This work is part of a la...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "arxiv",
        "large language model",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "AI Survival Stories: a Taxonomic Analysis of AI Existential Risk",
      "url": "https://arxiv.org/abs/2601.09765",
      "description": "arXiv:2601.09765v1 Announce Type: new \nAbstract: Since the release of ChatGPT, there has been a lot of debate about whether AI systems pose an existential risk to humanity. This paper develops a general framework for thinking about the existential risk of AI systems. We analyze a two premise argumen...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "paper",
        "GPT",
        "release",
        "framework",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Antisocial behavior towards large language model users: experimental evidence",
      "url": "https://arxiv.org/abs/2601.09772",
      "description": "arXiv:2601.09772v1 Announce Type: new \nAbstract: The rapid spread of large language models (LLMs) has raised concerns about the social reactions they provoke. Prior research documents negative attitudes toward AI users, but it remains unclear whether such disapproval translates into costly action. W...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "arxiv",
        "model",
        "research",
        "LLM",
        "API",
        "RAG",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention",
      "url": "https://arxiv.org/abs/2601.09805",
      "description": "arXiv:2601.09805v1 Announce Type: new \nAbstract: Modern logical reasoning with LLMs primarily relies on employing complex interactive frameworks that decompose the reasoning process into subtasks solved through carefully designed prompts or requiring external resources (e.g., symbolic solvers) to ex...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "attention",
        "arxiv",
        "model",
        "LLM",
        "prompt",
        "RAG",
        "reasoning",
        "few-shot",
        "framework",
        "experiment",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "Thinking Long, but Short: Stable Sequential Test-Time Scaling for Large Reasoning Models",
      "url": "https://arxiv.org/abs/2601.09855",
      "description": "arXiv:2601.09855v1 Announce Type: new \nAbstract: Sequential test-time scaling is a promising training-free method to improve large reasoning model accuracy, but as currently implemented, significant limitations have been observed. Inducing models to think for longer can increase their accuracy, but ...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "fine-tuning",
        "context",
        "arxiv",
        "model",
        "reasoning",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "A Scoping Review of the Ethical Perspectives on Anthropomorphising Large Language Model-Based Conversational Agents",
      "url": "https://arxiv.org/abs/2601.09869",
      "description": "arXiv:2601.09869v1 Announce Type: new \nAbstract: Anthropomorphisation -- the phenomenon whereby non-human entities are ascribed human-like qualities -- has become increasingly salient with the rise of large language model (LLM)-based conversational agents (CAs). Unlike earlier chatbots, LLM-based CA...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "large language model",
        "model",
        "research",
        "LLM",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Epistemology gives a Future to Complementarity in Human-AI Interactions",
      "url": "https://arxiv.org/abs/2601.09871",
      "description": "arXiv:2601.09871v1 Announce Type: new \nAbstract: Human-AI complementarity is the claim that a human supported by an AI system can outperform either alone in a decision-making process. Since its introduction in the human-AI interaction literature, it has gained traction by generalizing the reliance p...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "RAG",
        "reasoning",
        "arxiv",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL",
      "url": "https://arxiv.org/abs/2601.09883",
      "description": "arXiv:2601.09883v1 Announce Type: new \nAbstract: Most existing Large Language Model (LLM)-based Multi-Agent Systems (MAS) rely on predefined workflows, where human engineers enumerate task states in advance and specify routing rules and contextual injections accordingly. Such workflow-driven designs...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "large language model",
        "arxiv",
        "model",
        "tool",
        "LLM",
        "ICL",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Continuum Memory Architectures for Long-Horizon LLM Agents",
      "url": "https://arxiv.org/abs/2601.09913",
      "description": "arXiv:2601.09913v1 Announce Type: new \nAbstract: Retrieval-augmented generation (RAG) has become the default strategy for providing large language model (LLM) agents with contextual knowledge. Yet RAG treats memory as a stateless lookup table: information persists indefinitely, retrieval is read-onl...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "large language model",
        "augmented",
        "arxiv",
        "model",
        "LLM",
        "RAG",
        "memory",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Social Determinants of Health Prediction for ICD-9 Code with Reasoning Models",
      "url": "https://arxiv.org/abs/2601.09709",
      "description": "arXiv:2601.09709v1 Announce Type: new \nAbstract: Social Determinants of Health correlate with patient outcomes but are rarely captured in structured data. Recent attention has been given to automatically extracting these markers from clinical text to supplement diagnostic systems with knowledge of p...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "large language model",
        "arxiv",
        "model",
        "paper",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "The Geometry of Thought: Disclosing the Transformer as a Tropical Polynomial Circuit",
      "url": "https://arxiv.org/abs/2601.09775",
      "description": "arXiv:2601.09775v1 Announce Type: new \nAbstract: We prove that the Transformer self-attention mechanism in the high-confidence regime ($\\beta \\to \\infty$, where $\\beta$ is an inverse temperature) operates in the tropical semiring (max-plus algebra). In particular, we show that taking the tropical li...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "attention",
        "arxiv",
        "transformer",
        "product",
        "LLM",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "QFed: Parameter-Compact Quantum-Classical Federated Learning",
      "url": "https://arxiv.org/abs/2601.09809",
      "description": "arXiv:2601.09809v1 Announce Type: new \nAbstract: Organizations and enterprises across domains such as healthcare, finance, and scientific research are increasingly required to extract collective intelligence from distributed, siloed datasets while adhering to strict privacy, regulatory, and sovereig...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "arxiv",
        "model",
        "research",
        "study",
        "RAG",
        "framework",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "A pipeline for enabling path-specific causal fairness in observational health data",
      "url": "https://arxiv.org/abs/2601.09841",
      "description": "arXiv:2601.09841v1 Announce Type: new \nAbstract: When training machine learning (ML) models for potential deployment in a healthcare setting, it is essential to ensure that they do not replicate or exacerbate existing healthcare biases. Although many definitions of fairness exist, we focus on path-s...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "context",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment",
      "url": "https://arxiv.org/abs/2601.09865",
      "description": "arXiv:2601.09865v1 Announce Type: new \nAbstract: Large Language Models (LLMs) enable advanced natural language processing but face deployment challenges on resource-constrained edge devices due to high computational, memory, and energy demands. Optimizing these models requires addressing three key c...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "fine-tuning",
        "large language model",
        "arxiv",
        "model",
        "LLM",
        "GPT",
        "RAG",
        "compression",
        "framework",
        "memory"
      ],
      "score": 1.0
    },
    {
      "title": "The PROPER Approach to Proactivity: Benchmarking and Advancing Knowledge Gap Navigation",
      "url": "https://arxiv.org/abs/2601.09926",
      "description": "arXiv:2601.09926v1 Announce Type: new \nAbstract: Most language-based assistants follow a reactive ask-and-respond paradigm, requiring users to explicitly state their needs. As a result, relevant but unexpressed needs often go unmet. Existing proactive agents attempt to address this gap either by eli...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "arxiv",
        "LLM",
        "RAG",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Interpolation-Based Optimization for Enforcing lp-Norm Metric Differential Privacy in Continuous and Fine-Grained Domains",
      "url": "https://arxiv.org/abs/2601.09946",
      "description": "arXiv:2601.09946v1 Announce Type: new \nAbstract: Metric Differential Privacy (mDP) generalizes Local Differential Privacy (LDP) by adapting privacy guarantees based on pairwise distances, enabling context-aware protection and improved utility. While existing optimization-based methods reduce utility...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "arxiv",
        "paper",
        "framework",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt engineering",
        "context window",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "reasoning",
        "CoT",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "model",
        "tool",
        "LLM",
        "API",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "context",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "model",
        "LLM",
        "reasoning",
        "RAG",
        "framework",
        "knowledge base",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "product",
        "API",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "LLM",
        "prompt",
        "framework",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "context",
        "model",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "model",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Uncertainty-Aware Dynamic Knowledge Graphs for Reliable Question Answering",
      "url": "https://arxiv.org/abs/2601.09720",
      "description": "arXiv:2601.09720v1 Announce Type: new \nAbstract: Question answering (QA) systems are increasingly deployed across domains. However, their reliability is undermined when retrieved evidence is incomplete, noisy, or uncertain. Existing knowledge graph (KG) based QA frameworks typically represent facts ...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "arxiv",
        "model",
        "reasoning",
        "framework",
        "demonstration",
        "retrieval"
      ],
      "score": 0.6
    },
    {
      "title": "PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation",
      "url": "https://arxiv.org/abs/2601.09771",
      "description": "arXiv:2601.09771v1 Announce Type: new \nAbstract: Modern LLM-based recommenders can generate compelling ranked lists, but they struggle to reliably satisfy governance constraints such as minimum long-tail exposure or diversity requirements. We present PCN-Rec, a proof-carrying negotiation pipeline th...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "LLM",
        "reasoning"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents",
      "url": "https://arxiv.org/abs/2601.09770",
      "description": "arXiv:2601.09770v1 Announce Type: new \nAbstract: Recent advances in vision-language models (VLMs) and reinforcement learning (RL) have driven progress in GUI automation. However, most existing methods rely on static, one-shot visual inputs and passive perception, lacking the ability to adaptively de...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "augmented",
        "arxiv",
        "model",
        "tool",
        "reasoning",
        "vision",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "TimeSAE: Sparse Decoding for Faithful Explanations of Black-Box Time Series Models",
      "url": "https://arxiv.org/abs/2601.09776",
      "description": "arXiv:2601.09776v1 Announce Type: new \nAbstract: As black box models and pretrained models gain traction in time series applications, understanding and explaining their predictions becomes increasingly vital, especially in high-stakes domains where interpretability and trust are essential. However, ...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "framework",
        "library",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Eluder dimension: localise it!",
      "url": "https://arxiv.org/abs/2601.09825",
      "description": "arXiv:2601.09825v1 Announce Type: new \nAbstract: We establish a lower bound on the eluder dimension of generalised linear model classes, showing that standard eluder dimension-based analysis cannot lead to first-order regret bounds. To address this, we introduce a localisation method for the eluder ...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "analysis",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "A New Convergence Analysis of Plug-and-Play Proximal Gradient Descent Under Prior Mismatch",
      "url": "https://arxiv.org/abs/2601.09831",
      "description": "arXiv:2601.09831v1 Announce Type: new \nAbstract: In this work, we provide a new convergence theory for plug-and-play proximal gradient descent (PnP-PGD) under prior mismatch where the denoiser is trained on a different data distribution to the inference task at hand. To the best of our knowledge, th...",
      "published_date": "2026-01-16T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Introducing OptiMind, a research model designed for optimization",
      "url": "https://huggingface.co/blog/microsoft/optimind",
      "description": "...",
      "published_date": "2026-01-15T18:49:16",
      "source": "Hugging Face Blog",
      "category": "research_papers",
      "keywords": [
        "research",
        "model"
      ],
      "score": 0.2
    }
  ]
}