{
  "generated_at": "2025-09-16T20:05:56.944372",
  "total_items": 47,
  "items": [
    {
      "title": "Uncovering the Vulnerability of Large Language Models in the Financial Domain via Risk Concealment",
      "url": "https://arxiv.org/abs/2509.10546",
      "description": "arXiv:2509.10546v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly integrated into financial applications, yet existing red-teaming research primarily targets harmful content, largely neglecting regulatory risks. In this work, we aim to investigate the vulnerability of fi...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "model",
        "RAG",
        "context",
        "alignment",
        "framework",
        "GPT",
        "arxiv",
        "large language model",
        "research",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "No Answer Needed: Predicting LLM Answer Accuracy from Question-Only Linear Probes",
      "url": "https://arxiv.org/abs/2509.10625",
      "description": "arXiv:2509.10625v1 Announce Type: new \nAbstract: Do large language models (LLMs) anticipate when they will answer correctly? To study this, we extract activations after a question is read but before any tokens are generated, and train linear probes to predict whether the model's forthcoming answer w...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "study",
        "arxiv",
        "large language model",
        "reasoning",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Interdisciplinary Research in Conversation: A Case Study in Computational Morphology for Language Documentation",
      "url": "https://arxiv.org/abs/2509.10644",
      "description": "arXiv:2509.10644v1 Announce Type: new \nAbstract: Computational morphology has the potential to support language documentation through tasks like morphological segmentation and the generation of Interlinear Glossed Text (IGT). However, our research outputs have seen limited use in real-world language...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "model",
        "tool",
        "alignment",
        "context",
        "study",
        "arxiv",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Context Copying Modulation: The Role of Entropy Neurons in Managing Parametric and Contextual Knowledge Conflicts",
      "url": "https://arxiv.org/abs/2509.10663",
      "description": "arXiv:2509.10663v1 Announce Type: new \nAbstract: The behavior of Large Language Models (LLMs) when facing contextual information that conflicts with their internal parametric knowledge is inconsistent, with no generally accepted explanation for the expected outcome distribution. Recent work has iden...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "model",
        "context",
        "arxiv",
        "large language model",
        "LLM",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "Pluralistic Alignment for Healthcare: A Role-Driven Framework",
      "url": "https://arxiv.org/abs/2509.10685",
      "description": "arXiv:2509.10685v1 Announce Type: new \nAbstract: As large language models are increasingly deployed in sensitive domains such as healthcare, ensuring their outputs reflect the diverse values and perspectives held across populations is critical. However, existing alignment approaches, including plura...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "alignment",
        "framework",
        "arxiv",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Struct-Bench: A Benchmark for Differentially Private Structured Text Generation",
      "url": "https://arxiv.org/abs/2509.10696",
      "description": "arXiv:2509.10696v1 Announce Type: new \nAbstract: Differentially private (DP) synthetic data generation is a promising technique for utilizing private datasets that otherwise cannot be exposed for model training or other analytics. While much research literature has focused on generating private unst...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "platform",
        "image",
        "model",
        "ICL",
        "context",
        "framework",
        "study",
        "arxiv",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "A Survey on Retrieval And Structuring Augmented Generation with Large Language Models",
      "url": "https://arxiv.org/abs/2509.10697",
      "description": "arXiv:2509.10697v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have revolutionized natural language processing with their remarkable capabilities in text generation and reasoning. However, these models face critical challenges when deployed in real-world applications, including halluc...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "framework",
        "prompt",
        "augmented",
        "arxiv",
        "large language model",
        "reasoning",
        "research",
        "LLM",
        "multimodal",
        "retrieval",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation",
      "url": "https://arxiv.org/abs/2509.10708",
      "description": "arXiv:2509.10708v1 Announce Type: new \nAbstract: Supervised Fine-Tuning (SFT) is essential for training large language models (LLMs), significantly enhancing critical capabilities such as instruction following and in-context learning. Nevertheless, creating suitable training datasets tailored for sp...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "in-context",
        "paper",
        "ICL",
        "experiment",
        "model",
        "context",
        "augmented",
        "arxiv",
        "large language model",
        "LLM",
        "instruction",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "PolyTruth: Multilingual Disinformation Detection using Transformer-Based Language Models",
      "url": "https://arxiv.org/abs/2509.10737",
      "description": "arXiv:2509.10737v1 Announce Type: new \nAbstract: Disinformation spreads rapidly across linguistic boundaries, yet most AI models are still benchmarked only on English. We address this gap with a systematic comparison of five multilingual transformer models: mBERT, XLM, XLM-RoBERTa, RemBERT, and mT5 ...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "experiment",
        "model",
        "ICL",
        "RAG",
        "context",
        "augmented",
        "arxiv",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "Reasoning Under Uncertainty: Exploring Probabilistic Reasoning Capabilities of LLMs",
      "url": "https://arxiv.org/abs/2509.10739",
      "description": "arXiv:2509.10739v1 Announce Type: new \nAbstract: Despite widespread success in language understanding and generation, large language models (LLMs) exhibit unclear and often inconsistent behavior when faced with tasks that require probabilistic reasoning. In this work, we present the first comprehens...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "model",
        "prompting",
        "context",
        "study",
        "prompt",
        "arxiv",
        "large language model",
        "reasoning",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "ZapGPT: Free-form Language Prompting for Simulated Cellular Control",
      "url": "https://arxiv.org/abs/2509.10660",
      "description": "arXiv:2509.10660v1 Announce Type: new \nAbstract: Human language is one of the most expressive tools for conveying intent, yet most artificial or biological systems lack mechanisms to interpret or respond meaningfully to it. Bridging this gap could enable more natural forms of control over complex, d...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "model",
        "vision",
        "prompting",
        "tool",
        "prompt",
        "GPT",
        "arxiv",
        "instruction"
      ],
      "score": 1.0
    },
    {
      "title": "Maestro: Self-Improving Text-to-Image Generation via Agent Orchestration",
      "url": "https://arxiv.org/abs/2509.10704",
      "description": "arXiv:2509.10704v1 Announce Type: new \nAbstract: Text-to-image (T2I) models, while offering immense creative potential, are highly reliant on human intervention, posing significant usability challenges that often necessitate manual, iterative prompt engineering over often underspecified prompts. Thi...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "image",
        "paper",
        "experiment",
        "model",
        "prompt engineering",
        "prompt",
        "arxiv",
        "LLM",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Understanding AI Evaluation Patterns: How Different GPT Models Assess Vision-Language Descriptions",
      "url": "https://arxiv.org/abs/2509.10707",
      "description": "arXiv:2509.10707v1 Announce Type: new \nAbstract: As AI systems increasingly evaluate other AI outputs, understanding their assessment behavior becomes crucial for preventing cascading biases. This study analyzes vision-language descriptions generated by NVIDIA's Describe Anything Model and evaluated...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "experiment",
        "model",
        "vision",
        "study",
        "GPT",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering",
      "url": "https://arxiv.org/abs/2509.10818",
      "description": "arXiv:2509.10818v1 Announce Type: new \nAbstract: Difficult decision-making problems abound in various disciplines and domains. The proliferation of generative techniques, especially large language models (LLMs), has excited interest in using them for decision support. However, LLMs cannot yet resolv...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "paper",
        "model",
        "RAG",
        "context",
        "prompt engineering",
        "prompt",
        "augmented",
        "arxiv",
        "large language model",
        "example",
        "LLM",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Is the `Agent' Paradigm a Limiting Framework for Next-Generation Intelligent Systems?",
      "url": "https://arxiv.org/abs/2509.10875",
      "description": "arXiv:2509.10875v1 Announce Type: new \nAbstract: The concept of the 'agent' has profoundly shaped Artificial Intelligence (AI) research, guiding development from foundational theories to contemporary applications like Large Language Model (LLM)-based systems. This paper critically re-evaluates the n...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "paper",
        "model",
        "tool",
        "framework",
        "arxiv",
        "large language model",
        "research",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Harmful Prompt Laundering: Jailbreaking LLMs with Abductive Styles and Symbolic Encoding",
      "url": "https://arxiv.org/abs/2509.10931",
      "description": "arXiv:2509.10931v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse tasks, but their potential misuse for harmful purposes remains a significant concern. To strengthen defenses against such vulnerabilities, it is essential to investi...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "experiment",
        "model",
        "prompt",
        "GPT",
        "arxiv",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "AttnBoost: Retail Supply Chain Sales Insights via Gradient Boosting Perspective",
      "url": "https://arxiv.org/abs/2509.10506",
      "description": "arXiv:2509.10506v1 Announce Type: new \nAbstract: Forecasting product demand in retail supply chains presents a complex challenge due to noisy, heterogeneous features and rapidly shifting consumer behavior. While traditional gradient boosting decision trees (GBDT) offer strong predictive performance ...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "API",
        "attention",
        "model",
        "product",
        "framework",
        "study",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "The Anti-Ouroboros Effect: Emergent Resilience in Large Language Models from Recursive Selective Feedback",
      "url": "https://arxiv.org/abs/2509.10509",
      "description": "arXiv:2509.10509v1 Announce Type: new \nAbstract: The stability of recursively trained large language models (LLMs) is a foundational problem for AI safety. Prevailing theory predicts model collapse, a progressive degradation when models are trained on their own output. We challenge this narrative by...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "model",
        "arxiv",
        "large language model",
        "LLM",
        "summarization"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt engineering",
        "context window",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "audio",
        "framework",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "model",
        "tool",
        "context",
        "prompt",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "knowledge base",
        "model",
        "RAG",
        "framework",
        "vector",
        "reasoning",
        "LLM",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "tool",
        "model",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "product",
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "framework",
        "prompt",
        "vector",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "framework",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Situation Model of the Transport, Transport Emissions and Meteorological Conditions",
      "url": "https://arxiv.org/abs/2509.10541",
      "description": "arXiv:2509.10541v1 Announce Type: new \nAbstract: Air pollution in cities and the possibilities of reducing this pollution represents one of the most important factors that today's society has to deal with. This paper focuses on a systemic approach to traffic emissions with their relation to meteorol...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "model",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "AgentArch: A Comprehensive Benchmark to Evaluate Agent Architectures in Enterprise",
      "url": "https://arxiv.org/abs/2509.10769",
      "description": "arXiv:2509.10769v1 Announce Type: new \nAbstract: While individual components of agentic architectures have been studied in isolation, there remains limited empirical understanding of how different design dimensions interact within complex multi-agent systems. This study aims to address these gaps by...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "tool",
        "study",
        "prompt",
        "arxiv",
        "large language model",
        "memory"
      ],
      "score": 0.8
    },
    {
      "title": "SOH-KLSTM: A Hybrid Kolmogorov-Arnold Network and LSTM Model for Enhanced Lithium-Ion Battery Health Monitoring",
      "url": "https://arxiv.org/abs/2509.10496",
      "description": "arXiv:2509.10496v1 Announce Type: new \nAbstract: Accurate and reliable State Of Health (SOH) estimation for Lithium (Li) batteries is critical to ensure the longevity, safety, and optimal performance of applications like electric vehicles, unmanned aerial vehicles, consumer electronics, and renewabl...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "ICL",
        "RAG",
        "framework",
        "study",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "From Noise to Precision: A Diffusion-Driven Approach to Zero-Inflated Precipitation Prediction",
      "url": "https://arxiv.org/abs/2509.10501",
      "description": "arXiv:2509.10501v1 Announce Type: new \nAbstract: Zero-inflated data pose significant challenges in precipitation forecasting due to the predominance of zeros with sparse non-zero events. To address this, we propose the Zero Inflation Diffusion Framework (ZIDF), which integrates Gaussian perturbation...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "experiment",
        "framework",
        "arxiv",
        "transformer"
      ],
      "score": 0.8
    },
    {
      "title": "FEDEXCHANGE: Bridging the Domain Gap in Federated Object Detection for Free",
      "url": "https://arxiv.org/abs/2509.10503",
      "description": "arXiv:2509.10503v1 Announce Type: new \nAbstract: Federated Object Detection (FOD) enables clients to collaboratively train a global object detection model without accessing their local data from diverse domains. However, significant variations in environment, weather, and other domain specific facto...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "paper",
        "RAG",
        "framework",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Retrosynthesis Planning via Worst-path Policy Optimisation in Tree-structured MDPs",
      "url": "https://arxiv.org/abs/2509.10504",
      "description": "arXiv:2509.10504v1 Announce Type: new \nAbstract: Retrosynthesis planning aims to decompose target molecules into available building blocks, forming a synthesis tree where each internal node represents an intermediate compound and each leaf ideally corresponds to a purchasable reactant. However, this...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "LogGuardQ: A Cognitive-Enhanced Reinforcement Learning Framework for Cybersecurity Anomaly Detection in Security Logs",
      "url": "https://arxiv.org/abs/2509.10511",
      "description": "arXiv:2509.10511v1 Announce Type: new \nAbstract: Reinforcement learning (RL) has transformed sequential decision-making, but traditional algorithms like Deep Q-Networks (DQNs) and Proximal Policy Optimization (PPO) often struggle with efficient exploration, stability, and adaptability in dynamic env...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "RAG",
        "framework",
        "study",
        "arxiv",
        "memory"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "tool",
        "context",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "AI Answer Engine Citation Behavior An Empirical Analysis of the GEO16 Framework",
      "url": "https://arxiv.org/abs/2509.10762",
      "description": "arXiv:2509.10762v1 Announce Type: new \nAbstract: AI answer engines increasingly mediate access to domain knowledge by generating responses and citing web sources. We introduce GEO-16, a 16 pillar auditing framework that converts on page quality signals into banded pillar scores and a normalized GEO ...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "model",
        "product",
        "framework",
        "study",
        "prompt",
        "arxiv",
        "example"
      ],
      "score": 0.6
    },
    {
      "title": "From Grounding to Skolemization: A Logic-Constrained Vector Symbolic Architecture for Complex Query Answering",
      "url": "https://arxiv.org/abs/2509.10837",
      "description": "arXiv:2509.10837v1 Announce Type: new \nAbstract: Complex Query Answering (CQA) over incomplete Knowledge Graphs (KGs), typically formalized as reasoning with Existential First-Order predicate logic with one free variable (EFO$_1$), faces a fundamental trade-off between logical soundness and computat...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "framework",
        "arxiv",
        "vector",
        "reasoning"
      ],
      "score": 0.6
    },
    {
      "title": "The 1st International Workshop on Disentangled Representation Learning for Controllable Generation (DRL4Real): Methods and Results",
      "url": "https://arxiv.org/abs/2509.10463",
      "description": "arXiv:2509.10463v1 Announce Type: new \nAbstract: This paper reviews the 1st International Workshop on Disentangled Representation Learning for Controllable Generation (DRL4Real), held in conjunction with ICCV 2025. The workshop aimed to bridge the gap between the theoretical promise of Disentangled ...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "analysis",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "paper",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "Moment Estimates and DeepRitz Methods on Learning Diffusion Systems with Non-gradient Drifts",
      "url": "https://arxiv.org/abs/2509.10495",
      "description": "arXiv:2509.10495v1 Announce Type: new \nAbstract: Conservative-dissipative dynamics are ubiquitous across a variety of complex open systems. We propose a data-driven two-phase method, the Moment-DeepRitz Method, for learning drift decompositions in generalized diffusion systems involving conservative...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Exploring Multi-view Symbolic Regression methods in physical sciences",
      "url": "https://arxiv.org/abs/2509.10500",
      "description": "arXiv:2509.10500v1 Announce Type: new \nAbstract: Describing the world behavior through mathematical functions help scientists to achieve a better understanding of the inner mechanisms of different phenomena. Traditionally, this is done by deriving new equations from first principles and careful obse...",
      "published_date": "2025-09-16T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}