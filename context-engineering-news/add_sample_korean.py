#!/usr/bin/env python3
"""
ìƒ˜í”Œ í•œê¸€ ë²ˆì—­ ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ì¦‰ì‹œ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import json
import shutil
import os

def add_sample_translations():
    """ìƒ˜í”Œ í•œê¸€ ë²ˆì—­ ë°ì´í„° ì¶”ê°€"""
    print("ğŸ‡°ğŸ‡· ìƒ˜í”Œ í•œê¸€ ë²ˆì—­ ë°ì´í„° ì¶”ê°€ ì¤‘...")
    
    try:
        with open('data/daily_news.json', 'r', encoding='utf-8') as f:
            news_data = json.load(f)
    except FileNotFoundError:
        print("âŒ data/daily_news.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # ìƒ˜í”Œ ë²ˆì—­ ë°ì´í„° (ì²« 5ê°œ ê¸°ì‚¬ì— ìƒ˜í”Œ ë²ˆì—­ ì¶”ê°€)
    sample_translations = [
        {
            "title": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base",
            "korean_title": "íŒ©íŠ¸ ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ê¸€ì“°ê¸° ì–´ì‹œìŠ¤íŠ´íŠ¸ DeepWriter: ì˜¤í”„ë¼ì¸ ì§€ì‹ ë² ì´ìŠ¤ í™œìš©",
            "korean_summary": "ì´ ì—°êµ¬ëŠ” ê¸ˆìœµ, ì˜ë£Œ, ë²•ë¥  ë“± ì „ë¬¸ ë„ë©”ì¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜¤í”„ë¼ì¸ ì§€ì‹ ë² ì´ìŠ¤ ê¸°ë°˜ì˜ ë©€í‹°ëª¨ë‹¬ ê¸€ì“°ê¸° ë„ìš°ë¯¸ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. DeepWriterëŠ” RAG ê¸°ìˆ ê³¼ ICL ë°©ì‹ì„ ê²°í•©í•˜ì—¬ ì‚¬ì‹¤ ê¸°ë°˜ì˜ ì •í™•í•œ ë¬¸ì„œ ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.",
            "korean_keywords": ["ëŒ€í˜• ì–¸ì–´ëª¨ë¸", "ë¨€í‹°ëª¨ë‹¬", "ì§€ì‹ë² ì´ìŠ¤", "RAG", "ê¸€ì“°ê¸° ë„ìš°ë¯¸"]
        },
        {
            "title": "Retention analysis of edited knowledge after fine-tuning",
            "korean_title": "íŒŒì¸íŠ€ë‹ í›„ í¸ì§‘ëœ ì§€ì‹ì˜ ìœ ì§€ ë¶„ì„",
            "korean_summary": "ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì— ì €ì¥ëœ ë°©ëŒ€í•œ ì§€ì‹ì„ ì—…ë°ì´íŠ¸í•˜ê³  íŒ©íŠ¸ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ëŠ” ëª¨ë¸ í¸ì§‘ ê¸°ë²•ì— ëŒ€í•œ ì—°êµ¬ì…ë‹ˆë‹¤. íŒŒì¸íŠ€ë‹ í›„ í¸ì§‘ëœ ì§€ì‹ì´ ì–¼ë§ˆë‚˜ ì˜ ìœ ì§€ë˜ëŠ”ì§€ ë¶„ì„í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤.",
            "korean_keywords": ["íŒŒì¸íŠ€ë‹", "ëª¨ë¸ í¸ì§‘", "ì§€ì‹ ìœ ì§€", "ì–¸ì–´ëª¨ë¸", "ì„±ëŠ¥ ë¶„ì„"]
        },
        {
            "title": "Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System",
            "korean_title": "ì˜¤í”ˆì†ŒìŠ¤ ëŒ€í˜• ì–¸ì–´ëª¨ë¸ í˜‘ë ¥ìœ¼ë¡œ ë¹„ê³µê°œ ëª¨ë¸ ëŠ¥ê°€: í™•ì¥ ê°€ëŠ¥í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ",
            "korean_summary": "ì—¬ëŸ¬ ì˜¤í”ˆì†ŒìŠ¤ ëŒ€í˜• ì–¸ì–´ëª¨ë¸ì„ í˜‘ë ¥ì‹œì¼œ ë¹„ê³µê°œ ëª¨ë¸ì„ ëŠ¥ê°€í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ íƒêµ¬í•œ ì—°êµ¬ì…ë‹ˆë‹¤. SMACSë¼ëŠ” í™•ì¥ ê°€ëŠ¥í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì œì•ˆí•˜ì—¬ GPTì™€ ê°™ì€ ë¹„ê³µê°œ ëª¨ë¸ì— ì¤€í•˜ëŠ” ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.",
            "korean_keywords": ["ì˜¤í”ˆì†ŒìŠ¤", "ë©€í‹°ì—ì´ì „íŠ¸", "ì–¸ì–´ëª¨ë¸ í˜‘ë ¥", "GPT ëŒ€ì•ˆ", "í™•ì¥ì„±"]
        },
        {
            "title": "Language Models Change Facts Based on the Way You Talk",
            "korean_title": "ì–¸ì–´ ëª¨ë¸ì´ ëŒ€í™” ë°©ì‹ì— ë”°ë¼ ì‚¬ì‹¤ì„ ë‹¤ë¥´ê²Œ ì¸ì‹í•˜ëŠ” í˜„ìƒ",
            "korean_summary": "ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì´ ì‚¬ìš©ìì˜ ì–¸ì–´ ì‚¬ìš© íŒ¨í„´ê³¼ ëŒ€í™” ë°©ì‹ì— ë”°ë¼ ë‹¤ë¥¸ ì‚¬ì‹¤ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” í˜„ìƒì„ ë¶„ì„í•œ ì—°êµ¬ì…ë‹ˆë‹¤. ì´ëŠ” AI ëª¨ë¸ì˜ ì‹ ë¢°ì„±ê³¼ ê³µì •ì„±ì— ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤.",
            "korean_keywords": ["ì–¸ì–´ëª¨ë¸ í¸í–¥", "ëŒ€í™” íŒ¨í„´", "AI ì‹ ë¢°ì„±", "ì‚¬ì‹¤ ì¸ì‹", "ì–¸ì–´ ì˜í–¥"]
        },
        {
            "title": "HuggingGraph: Understanding the Supply Chain of LLM Ecosystem",
            "korean_title": "HuggingGraph: ëŒ€í˜• ì–¸ì–´ëª¨ë¸ ìƒíƒœê³„ì˜ ê³µê¸‰ë§ ì´í•´",
            "korean_summary": "ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ìƒíƒœê³„ì˜ ë³µì¡í•œ ê³µê¸‰ë§ì„ ë¶„ì„í•˜ê³  ì´í•´í•˜ê¸° ìœ„í•œ HuggingGraph í”Œë«í¼ì„ ì†Œê°œí•©ë‹ˆë‹¤. ë²ˆì—­, ìš”ì•½, ì§ˆì˜ì‘ë‹µ, ì½˜í…ì¸  ìƒì„± ë“± ë‹¤ì–‘í•œ NLP ì‘ì—…ì—ì„œì˜ ëª¨ë¸ í™œìš© í˜„í™©ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.",
            "korean_keywords": ["LLM ìƒíƒœê³„", "ê³µê¸‰ë§ ë¶„ì„", "NLP ì‘ì—…", "ëª¨ë¸ í™œìš©", "ìš”ì•½ ì‹œìŠ¤í…œ"]
        }
    ]
    
    # ìƒ˜í”Œ ë²ˆì—­ ì ìš©
    items = news_data['items']
    translated_count = 0
    
    for translation in sample_translations:
        for item in items:
            if item['title'] == translation['title']:
                item.update({
                    'korean_title': translation['korean_title'],
                    'korean_summary': translation['korean_summary'],
                    'korean_keywords': translation['korean_keywords']
                })
                translated_count += 1
                break
    
    # ê²°ê³¼ ì €ì¥
    try:
        with open('data/daily_news.json', 'w', encoding='utf-8') as f:
            json.dump(news_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… {translated_count}ê°œ ê¸°ì‚¬ì— ìƒ˜í”Œ í•œê¸€ ë²ˆì—­ ì¶”ê°€ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def regenerate_html():
    """ë²ˆì—­ëœ ë°ì´í„°ë¡œ HTML ì¬ìƒì„±"""
    print("\nğŸ—ï¸  HTML ë‰´ìŠ¤ë ˆí„° ì¬ìƒì„±...")
    
    try:
        from src.html_generator import NewsletterGenerator
        
        generator = NewsletterGenerator()
        html_content = generator.generate_html(
            data_file="data/daily_news.json",
            template_file="templates/simple_newsletter.html",
            output_file="docs/index.html"
        )
        
        # ë£¨íŠ¸ docsì—ë„ ë³µì‚¬
        shutil.copy("docs/index.html", "../docs/index.html")
        
        print("âœ… HTML ë‰´ìŠ¤ë ˆí„° ì¬ìƒì„± ì™„ë£Œ")
        print("ğŸ“– docs/index.html íŒŒì¼ì—ì„œ í•œê¸€ ë²ˆì—­ í™•ì¸ ê°€ëŠ¥")
        return True
        
    except Exception as e:
        print(f"âŒ HTML ìƒì„± ì‹¤íŒ¨: {e}")
        return False

def main():
    print("ğŸ‡°ğŸ‡· ìƒ˜í”Œ í•œê¸€ ë²ˆì—­ ë°ì´í„° ì¶”ê°€")
    print("=" * 40)
    
    if add_sample_translations():
        regenerate_html()
        print("\nğŸ‰ ì™„ë£Œ! ì´ì œ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:")
        print("  1. docs/index.html íŒŒì¼ì—ì„œ í•œê¸€ ë²ˆì—­")
        print("  2. ë²„ì „ ì¡°ì ˆì—ì„œ í•œê¸€ê³¼ ì˜ë¬¸ ë™ì‹œ ë…¸ì¶œ")
        print("  3. í•œê¸€ í‚¤ì›Œë“œì™€ ìš”ì•½")
        
        print("\nğŸ”„ ì „ì²´ ë°ì´í„° ë²ˆì—­ì„ ì›í•œë‹¤ë©´:")
        print("  GEMINI_API_KEY ì„¤ì • í›„ python translate_existing.py ì‹¤í–‰")
    else:
        print("âŒ ìƒ˜í”Œ ë²ˆì—­ ì¶”ê°€ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()
