{
  "generated_at": "2026-02-09T20:14:39.302550",
  "total_items": 48,
  "items": [
    {
      "title": "Recontextualizing Famous Quotes for Brand Slogan Generation",
      "url": "https://arxiv.org/abs/2602.06049",
      "description": "arXiv:2602.06049v1 Announce Type: new \nAbstract: Slogans are concise and memorable catchphrases that play a crucial role in advertising by conveying brand identity and shaping public perception. However, advertising fatigue reduces the effectiveness of repeated slogans, creating a growing demand for...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "arxiv",
        "RAG",
        "framework",
        "LLM",
        "context",
        "large language model",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "Relevance-aware Multi-context Contrastive Decoding for Retrieval-augmented Visual Question Answering",
      "url": "https://arxiv.org/abs/2602.06050",
      "description": "arXiv:2602.06050v1 Announce Type: new \nAbstract: Despite the remarkable capabilities of Large Vision Language Models (LVLMs), they still lack detailed knowledge about specific entities. Retrieval-augmented Generation (RAG) is a widely adopted solution that enhances LVLMs by providing additional cont...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "model",
        "vision",
        "arxiv",
        "augmented",
        "RAG",
        "context",
        "experiment",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "CAST: Character-and-Scene Episodic Memory for Agents",
      "url": "https://arxiv.org/abs/2602.06051",
      "description": "arXiv:2602.06051v1 Announce Type: new \nAbstract: Episodic memory is a central component of human memory, which refers to the ability to recall coherent events grounded in who, when, and where. However, most agent memory systems only emphasize semantic recall and treat experience as structures such a...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "memory",
        "arxiv",
        "RAG",
        "LLM",
        "experiment",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Rethinking Memory Mechanisms of Foundation Agents in the Second Half",
      "url": "https://arxiv.org/abs/2602.06052",
      "description": "arXiv:2602.06052v1 Announce Type: new \nAbstract: The research of artificial intelligence is undergoing a paradigm shift from prioritizing model innovations over benchmark scores towards emphasizing problem definition and rigorous real-world evaluation. As the field enters the \"second half,\" the cent...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "memory",
        "model",
        "paper",
        "arxiv",
        "context",
        "research",
        "release"
      ],
      "score": 1.0
    },
    {
      "title": "PersonaPlex: Voice and Role Control for Full Duplex Conversational Speech Models",
      "url": "https://arxiv.org/abs/2602.06053",
      "description": "arXiv:2602.06053v1 Announce Type: new \nAbstract: Recent advances in duplex speech models have enabled natural, low-latency speech-to-speech interactions. However, existing models are restricted to a fixed role and voice, limiting their ability to support structured, role-driven real-world applicatio...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "prompt",
        "arxiv",
        "LLM",
        "large language model",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "What Is Novel? A Knowledge-Driven Framework for Bias-Aware Literature Originality Evaluation",
      "url": "https://arxiv.org/abs/2602.06054",
      "description": "arXiv:2602.06054v1 Announce Type: new \nAbstract: Assessing research novelty is a core yet highly subjective aspect of peer review, typically based on implicit judgment and incomplete comparison to prior work. We introduce a literature-aware novelty assessment framework that explicitly learns how hum...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "paper",
        "arxiv",
        "framework",
        "large language model",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding",
      "url": "https://arxiv.org/abs/2602.06161",
      "description": "arXiv:2602.06161v1 Announce Type: new \nAbstract: Parallel diffusion decoding can accelerate diffusion language model inference by unmasking multiple tokens per step, but aggressive parallelism often harms quality. Revocable decoding mitigates this by rechecking earlier tokens, yet we observe that ex...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "model",
        "vision",
        "arxiv",
        "context",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning",
      "url": "https://arxiv.org/abs/2602.06107",
      "description": "arXiv:2602.06107v1 Announce Type: new \nAbstract: Reinforcement learning (RL) for large language models (LLMs) remains expensive, particularly because the rollout is expensive. Decoupling rollout generation from policy optimization (e.g., leveraging a more efficient model to rollout) could enable sub...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "alignment",
        "arxiv",
        "RAG",
        "framework",
        "LLM",
        "large language model",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Large Language Model Reasoning Failures",
      "url": "https://arxiv.org/abs/2602.06176",
      "description": "arXiv:2602.06176v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have exhibited remarkable reasoning capabilities, achieving impressive results across a wide range of tasks. Despite these advances, significant reasoning failures persist, occurring even in seemingly simple scenarios. To ...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "RAG",
        "framework",
        "LLM",
        "large language model",
        "research",
        "release",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Do It for HER: First-Order Temporal Logic Reward Specification in Reinforcement Learning (Extended Version)",
      "url": "https://arxiv.org/abs/2602.06227",
      "description": "arXiv:2602.06227v1 Announce Type: new \nAbstract: In this work, we propose a novel framework for the logical specification of non-Markovian rewards in Markov Decision Processes (MDPs) with large state spaces. Our approach leverages Linear Temporal Logic Modulo Theories over finite traces (LTLfMT), a ...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "framework",
        "context",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Do LLMs Act Like Rational Agents? Measuring Belief Coherence in Probabilistic Decision Making",
      "url": "https://arxiv.org/abs/2602.06286",
      "description": "arXiv:2602.06286v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly deployed as agents in high-stakes domains where optimal actions depend on both uncertainty about the world and consideration of utilities of different outcomes, yet their decision logic remains difficult t...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "study",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Exposing Weaknesses of Large Reasoning Models through Graph Algorithm Problems",
      "url": "https://arxiv.org/abs/2602.06319",
      "description": "arXiv:2602.06319v1 Announce Type: new \nAbstract: Large Reasoning Models (LRMs) have advanced rapidly; however, existing benchmarks in mathematics, code, and common-sense reasoning remain limited. They lack long-context evaluation, offer insufficient challenge, and provide answers that are difficult ...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "memory",
        "model",
        "arxiv",
        "study",
        "context",
        "experiment",
        "API",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Trifuse: Enhancing Attention-Based GUI Grounding via Multimodal Fusion",
      "url": "https://arxiv.org/abs/2602.06351",
      "description": "arXiv:2602.06351v1 Announce Type: new \nAbstract: GUI grounding maps natural language instructions to the correct interface elements, serving as the perception foundation for GUI agents. Existing approaches predominantly rely on fine-tuning multimodal large language models (MLLMs) using large-scale G...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "cross-modal",
        "model",
        "instruction",
        "multimodal",
        "arxiv",
        "image",
        "framework",
        "LLM",
        "large language model",
        "attention",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "Intrinsic Stability Limits of Autoregressive Reasoning: Structural Consequences for Long-Horizon Execution",
      "url": "https://arxiv.org/abs/2602.06413",
      "description": "arXiv:2602.06413v1 Announce Type: new \nAbstract: Large language models (LLMs) demonstrate remarkable reasoning capabilities, yet their performance often deteriorates sharply in long-horizon tasks, exhibiting systematic breakdown beyond certain scales. Conventional explanations primarily attribute th...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "arxiv",
        "LLM",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents",
      "url": "https://arxiv.org/abs/2602.06485",
      "description": "arXiv:2602.06485v1 Announce Type: new \nAbstract: While Large Language Model (LLM)-based agents have shown remarkable potential for solving complex tasks, existing systems remain heavily reliant on large-scale models, leaving the capabilities of edge-scale models largely underexplored. In this paper,...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "paper",
        "arxiv",
        "study",
        "context",
        "framework",
        "LLM",
        "large language model",
        "fine-tuning",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "NanoNet: Parameter-Efficient Learning with Label-Scarce Supervision for Lightweight Text Mining Model",
      "url": "https://arxiv.org/abs/2602.06093",
      "description": "arXiv:2602.06093v1 Announce Type: new \nAbstract: The lightweight semi-supervised learning (LSL) strategy provides an effective approach of conserving labeled samples and minimizing model inference costs. Prior research has effectively applied knowledge transfer learning and co-training regularizatio...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "vision",
        "prompt",
        "arxiv",
        "RAG",
        "framework",
        "research",
        "fine-tuning",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "Agentic Workflow Using RBA$_\\theta$ for Event Prediction",
      "url": "https://arxiv.org/abs/2602.06097",
      "description": "arXiv:2602.06097v1 Announce Type: new \nAbstract: Wind power ramp events are difficult to forecast due to strong variability, multi-scale dynamics, and site-specific meteorological effects. This paper proposes an event-first, frequency-aware forecasting paradigm that directly predicts ramp events and...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "zero-shot",
        "paper",
        "arxiv",
        "context",
        "framework",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Toward Faithful and Complete Answer Construction from a Single Document",
      "url": "https://arxiv.org/abs/2602.06103",
      "description": "arXiv:2602.06103v1 Announce Type: new \nAbstract: Modern large language models (LLMs) are powerful generators driven by statistical next-token prediction. While effective at producing fluent text, this design biases models toward high-probability continuations rather than exhaustive and faithful answ...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "model",
        "prompt",
        "arxiv",
        "RAG",
        "framework",
        "LLM",
        "large language model",
        "prompting",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Compressing LLMs with MoP: Mixture of Pruners",
      "url": "https://arxiv.org/abs/2602.06127",
      "description": "arXiv:2602.06127v1 Announce Type: new \nAbstract: The high computational demands of Large Language Models (LLMs) motivate methods that reduce parameter count and accelerate inference. In response, model pruning emerges as an effective strategy, yet current methods typically focus on a single dimensio...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "model",
        "vision",
        "arxiv",
        "framework",
        "LLM",
        "large language model",
        "compression",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "Urban Spatio-Temporal Foundation Models for Climate-Resilient Housing: Scaling Diffusion Transformers for Disaster Risk Prediction",
      "url": "https://arxiv.org/abs/2602.06129",
      "description": "arXiv:2602.06129v1 Announce Type: new \nAbstract: Climate hazards increasingly disrupt urban transportation and emergency-response operations by damaging housing stock, degrading infrastructure, and reducing network accessibility. This paper presents Skjold-DiT, a diffusion-transformer framework that...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "transformer",
        "model",
        "prompt",
        "paper",
        "arxiv",
        "image",
        "framework",
        "ICL",
        "attention",
        "experiment",
        "cross-modal"
      ],
      "score": 1.0
    },
    {
      "title": "Self-Improving World Modelling with Latent Actions",
      "url": "https://arxiv.org/abs/2602.06130",
      "description": "arXiv:2602.06130v1 Announce Type: new \nAbstract: Internal modelling of the world -- predicting transitions between previous states $X$ and next states $Y$ under actions $Z$ -- is essential to reasoning and planning for LLMs and VLMs. Learning such models typically requires costly action-labelled tra...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "arxiv",
        "RAG",
        "framework",
        "LLM",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "context window",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "framework",
        "chain-of-thought",
        "CoT",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "prompt",
        "context",
        "LLM",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "vector",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "model",
        "RAG",
        "framework",
        "LLM",
        "knowledge base",
        "vector",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "API",
        "RAG",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "framework",
        "LLM",
        "vector",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "Uncertainty Drives Social Bias Changes in Quantized Large Language Models",
      "url": "https://arxiv.org/abs/2602.06181",
      "description": "arXiv:2602.06181v1 Announce Type: new \nAbstract: Post-training quantization reduces the computational cost of large language models but fundamentally alters their social biases in ways that aggregate metrics fail to capture. We present the first large-scale study of 50 quantized models evaluated on ...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "study",
        "large language model",
        "compression"
      ],
      "score": 0.8
    },
    {
      "title": "BenchMarker: An Education-Inspired Toolkit for Highlighting Flaws in Multiple-Choice Benchmarks",
      "url": "https://arxiv.org/abs/2602.06221",
      "description": "arXiv:2602.06221v1 Announce Type: new \nAbstract: Multiple-choice question answering (MCQA) is standard in NLP, but benchmarks lack rigorous quality control. We present BenchMarker, an education-inspired toolkit using LLM judges to flag three common MCQ flaws: 1) contamination - items appearing exact...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "tool",
        "arxiv",
        "LLM",
        "research",
        "release"
      ],
      "score": 0.8
    },
    {
      "title": "Difficulty-Estimated Policy Optimization",
      "url": "https://arxiv.org/abs/2602.06375",
      "description": "arXiv:2602.06375v1 Announce Type: new \nAbstract: Recent advancements in Large Reasoning Models (LRMs), exemplified by DeepSeek-R1, have underscored the potential of scaling inference-time compute through Group Relative Policy Optimization (GRPO). However, GRPO frequently suffers from gradient signal...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "paper",
        "alignment",
        "arxiv",
        "framework",
        "release",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Pragmatic Curiosity: A Hybrid Learning-Optimization Paradigm via Active Inference",
      "url": "https://arxiv.org/abs/2602.06104",
      "description": "arXiv:2602.06104v1 Announce Type: new \nAbstract: Many engineering and scientific workflows depend on expensive black-box evaluations, requiring decision-making that simultaneously improves performance and reduces uncertainty. Bayesian optimization (BO) and Bayesian experimental design (BED) offer po...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "RAG"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "API",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Quantifying and Attributing Polarization to Annotator Groups",
      "url": "https://arxiv.org/abs/2602.06055",
      "description": "arXiv:2602.06055v1 Announce Type: new \nAbstract: Current annotation agreement metrics are not well-suited for inter-group analysis, are sensitive to group size imbalances and restricted to single-annotation settings. These restrictions render them insufficient for many subjective tasks such as toxic...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "library",
        "analysis"
      ],
      "score": 0.4
    },
    {
      "title": "Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization",
      "url": "https://arxiv.org/abs/2602.06394",
      "description": "arXiv:2602.06394v1 Announce Type: new \nAbstract: Current tokenization methods process sequential data without accounting for signal quality, limiting their effectiveness on noisy real-world corpora. We present QA-Token (Quality-Aware Tokenization), which incorporates data reliability directly into v...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Tempora: Characterising the Time-Contingent Utility of Online Test-Time Adaptation",
      "url": "https://arxiv.org/abs/2602.06136",
      "description": "arXiv:2602.06136v1 Announce Type: new \nAbstract: Test-time adaptation (TTA) offers a compelling remedy for machine learning (ML) models that degrade under domain shifts, improving generalisation on-the-fly with only unlabelled samples. This flexibility suits real deployments, yet conventional evalua...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "image",
        "framework",
        "research"
      ],
      "score": 0.4
    },
    {
      "title": "Flow Matching for Offline Reinforcement Learning with Discrete Actions",
      "url": "https://arxiv.org/abs/2602.06138",
      "description": "arXiv:2602.06138v1 Announce Type: new \nAbstract: Generative policies based on diffusion models and flow matching have shown strong promise for offline reinforcement learning (RL), but their applicability remains largely confined to continuous action spaces. To address a broader range of offline RL s...",
      "published_date": "2026-02-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "model",
        "experiment",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Transformers.js v4 Preview: Now Available on NPM!",
      "url": "https://huggingface.co/blog/transformersjs-v4",
      "description": "...",
      "published_date": "2026-02-09T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "transformer"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}