{
  "generated_at": "2025-10-27T20:04:56.324763",
  "total_items": 47,
  "items": [
    {
      "title": "Shoot First, Ask Questions Later? Building Rational Agents that Explore and Act Like People",
      "url": "https://arxiv.org/abs/2510.20886",
      "description": "arXiv:2510.20886v1 Announce Type: new \nAbstract: Many high-stakes applications of AI require forming data-driven hypotheses and making targeted guesses; e.g., in scientific and diagnostic settings. Given limited resources, to what extent do agents based on language models (LMs) act rationally? We de...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "GPT",
        "context",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Code-enabled language models can outperform reasoning models on diverse tasks",
      "url": "https://arxiv.org/abs/2510.20909",
      "description": "arXiv:2510.20909v1 Announce Type: new \nAbstract: Reasoning models (RMs), language models (LMs) trained with reinforcement learning to produce long-form natural language reasoning, have been remarkably successful, but they still require large amounts of computation and data to train, and can be slow ...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "augmented",
        "RAG",
        "model",
        "few-shot",
        "paper",
        "instruction",
        "in-context",
        "reasoning",
        "framework",
        "context",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Do LLMs Truly Understand When a Precedent Is Overruled?",
      "url": "https://arxiv.org/abs/2510.20941",
      "description": "arXiv:2510.20941v1 Announce Type: new \nAbstract: Large language models (LLMs) with extended context windows show promise for complex legal reasoning tasks, yet their ability to understand long legal documents remains insufficiently evaluated. Developing long-context benchmarks that capture realistic...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "LLM",
        "large language model",
        "model",
        "reasoning",
        "context",
        "context window",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Irish-BLiMP: A Linguistic Benchmark for Evaluating Human and Language Model Performance in a Low-Resource Setting",
      "url": "https://arxiv.org/abs/2510.20957",
      "description": "arXiv:2510.20957v1 Announce Type: new \nAbstract: We present Irish-BLiMP (Irish Benchmark of Linguistic Minimal Pairs), the first dataset and framework designed for fine-grained evaluation of linguistic competence in the Irish language, an endangered language. Drawing on a variety of linguistic liter...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "LLM",
        "large language model",
        "model",
        "GPT",
        "framework",
        "research",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Can Confidence Estimates Decide When Chain-of-thought is Necessary for Llms?",
      "url": "https://arxiv.org/abs/2510.21007",
      "description": "arXiv:2510.21007v1 Announce Type: new \nAbstract: Chain-of-thought (CoT) prompting has emerged as a common technique for enhancing the reasoning abilities of large language models (LLMs). While extended reasoning can boost accuracy on complex tasks, it is often unnecessary and substantially increases...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "LLM",
        "large language model",
        "model",
        "prompting",
        "study",
        "GPT",
        "chain-of-thought",
        "prompt",
        "reasoning",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Reasoning's Razor: Reasoning Improves Accuracy but Can Hurt Recall at Critical Operating Points in Safety and Hallucination Detection",
      "url": "https://arxiv.org/abs/2510.21049",
      "description": "arXiv:2510.21049v1 Announce Type: new \nAbstract: Reasoning has become a central paradigm for large language models (LLMs), consistently boosting accuracy across diverse benchmarks. Yet its suitability for precision-sensitive tasks remains unclear. We present the first systematic study of reasoning f...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "augmented",
        "LLM",
        "large language model",
        "RAG",
        "model",
        "study",
        "reasoning",
        "tool",
        "analysis",
        "zero-shot",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Dynamic Retriever for In-Context Knowledge Editing via Policy Optimization",
      "url": "https://arxiv.org/abs/2510.21059",
      "description": "arXiv:2510.21059v1 Announce Type: new \nAbstract: Large language models (LLMs) excel at factual recall yet still propagate stale or incorrect knowledge. In-context knowledge editing offers a gradient-free remedy suitable for black-box APIs, but current editors rely on static demonstration sets chosen...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "demonstration",
        "API",
        "LLM",
        "large language model",
        "model",
        "example",
        "prompt",
        "in-context",
        "framework",
        "context",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Bridging Language Gaps with Adaptive RAG: Improving Indonesian Language Question Answering",
      "url": "https://arxiv.org/abs/2510.21068",
      "description": "arXiv:2510.21068v1 Announce Type: new \nAbstract: Question Answering (QA) has seen significant improvements with the advancement of machine learning models, further studies enhanced this question answering system by retrieving external information, called Retrieval-Augmented Generation (RAG) to produ...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "model",
        "study",
        "retrieval",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Sketch2BIM: A Multi-Agent Human-AI Collaborative Pipeline to Convert Hand-Drawn Floor Plans to 3D BIM",
      "url": "https://arxiv.org/abs/2510.20838",
      "description": "arXiv:2510.20838v1 Announce Type: new \nAbstract: This study introduces a human-in-the-loop pipeline that converts unscaled, hand-drawn floor plan sketches into semantically consistent 3D BIM models. The workflow leverages multimodal large language models (MLLMs) within a multi-agent framework, combi...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "large language model",
        "RAG",
        "model",
        "alignment",
        "study",
        "multimodal",
        "reasoning",
        "framework",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Cultural Alien Sampler: Open-ended art generation balancing originality and coherence",
      "url": "https://arxiv.org/abs/2510.20849",
      "description": "arXiv:2510.20849v1 Announce Type: new \nAbstract: In open-ended domains like art, autonomous agents must generate ideas that are both original and internally coherent, yet current Large Language Models (LLMs) either default to familiar cultural patterns or sacrifice coherence when pushed toward novel...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "large language model",
        "model",
        "study",
        "GPT",
        "context",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Customizing Open Source LLMs for Quantitative Medication Attribute Extraction across Heterogeneous EHR Systems",
      "url": "https://arxiv.org/abs/2510.21027",
      "description": "arXiv:2510.21027v1 Announce Type: new \nAbstract: Harmonizing medication data across Electronic Health Record (EHR) systems is a persistent barrier to monitoring medications for opioid use disorder (MOUD). In heterogeneous EHR systems, key prescription attributes are scattered across differently form...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "large language model",
        "RAG",
        "model",
        "study",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "From Questions to Queries: An AI-powered Multi-Agent Framework for Spatial Text-to-SQL",
      "url": "https://arxiv.org/abs/2510.21045",
      "description": "arXiv:2510.21045v1 Announce Type: new \nAbstract: The complexity of Structured Query Language (SQL) and the specialized nature of geospatial functions in tools like PostGIS present significant barriers to non-experts seeking to analyze spatial data. While Large Language Models (LLMs) offer promise fo...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "LLM",
        "large language model",
        "knowledge base",
        "model",
        "analysis",
        "retrieval",
        "embedding",
        "tool",
        "context",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "MedAlign: A Synergistic Framework of Multimodal Preference Optimization and Federated Meta-Cognitive Reasoning",
      "url": "https://arxiv.org/abs/2510.21093",
      "description": "arXiv:2510.21093v1 Announce Type: new \nAbstract: Recently, large models have shown significant potential for smart healthcare. However, the deployment of Large Vision-Language Models (LVLMs) for clinical services is currently hindered by three critical challenges: a tendency to hallucinate answers n...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "augmented",
        "CoT",
        "RAG",
        "model",
        "paper",
        "image",
        "chain-of-thought",
        "multimodal",
        "vision",
        "retrieval",
        "reasoning",
        "framework",
        "context",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "DAO-AI: Evaluating Collective Decision-Making through Agentic AI in Decentralized Governance",
      "url": "https://arxiv.org/abs/2510.21117",
      "description": "arXiv:2510.21117v1 Announce Type: new \nAbstract: This paper presents a first empirical study of agentic AI as autonomous decision-makers in decentralized governance. Using more than 3K proposals from major protocols, we build an agentic AI voter that interprets proposal contexts, retrieves historica...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "alignment",
        "study",
        "paper",
        "tool",
        "context",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "PanicToCalm: A Proactive Counseling Agent for Panic Attacks",
      "url": "https://arxiv.org/abs/2510.21143",
      "description": "arXiv:2510.21143v1 Announce Type: new \nAbstract: Panic attacks are acute episodes of fear and distress, in which timely, appropriate intervention can significantly help individuals regain stability. However, suitable datasets for training such models remain scarce due to ethical and logistical issue...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "alignment",
        "GPT",
        "framework",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Incentivizing Consistent, Effective and Scalable Reasoning Capability in Audio LLMs via Reasoning Process Rewards",
      "url": "https://arxiv.org/abs/2510.20867",
      "description": "arXiv:2510.20867v1 Announce Type: new \nAbstract: The role of reasoning in Audio Large Language Models remains widely underexplored, as introducing a reasoning process often degrades rather than improves performance during inference, a phenomenon we term test-time inverse scaling, where longer reason...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "LLM",
        "large language model",
        "audio",
        "model",
        "GPT",
        "multimodal",
        "reasoning",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "MOBO-OSD: Batch Multi-Objective Bayesian Optimization via Orthogonal Search Directions",
      "url": "https://arxiv.org/abs/2510.20872",
      "description": "arXiv:2510.20872v1 Announce Type: new \nAbstract: Bayesian Optimization (BO) is a powerful tool for optimizing expensive black-box objective functions. While extensive research has been conducted on the single-objective optimization problem, the multi-objective optimization problem remains challengin...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "paper",
        "tool",
        "analysis",
        "research",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "HA-RAG: Hotness-Aware RAG Acceleration via Mixed Precision and Data Placement",
      "url": "https://arxiv.org/abs/2510.20878",
      "description": "arXiv:2510.20878v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) improves model output accuracy by leveraging external knowledge bases, serving as an effective solution to address hallucination issues and knowledge-update delays in Large Language Models (LLMs). However, the intr...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "LLM",
        "large language model",
        "RAG",
        "knowledge base",
        "model",
        "paper",
        "memory",
        "retrieval",
        "context",
        "research",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Meta-Learning for Cross-Task Generalization in Protein Mutation Property Prediction",
      "url": "https://arxiv.org/abs/2510.20943",
      "description": "arXiv:2510.20943v1 Announce Type: new \nAbstract: Protein mutations can have profound effects on biological function, making accurate prediction of property changes critical for drug discovery, protein engineering, and precision medicine. Current approaches rely on fine-tuning protein-specific transf...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "API",
        "model",
        "fine-tuning",
        "transformer",
        "analysis",
        "framework",
        "context",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "LLM-Integrated Bayesian State Space Models for Multimodal Time-Series Forecasting",
      "url": "https://arxiv.org/abs/2510.20952",
      "description": "arXiv:2510.20952v1 Announce Type: new \nAbstract: Forecasting in the real world requires integrating structured time-series data with unstructured textual information, but existing methods are architecturally limited by fixed input/output horizons and are unable to model or quantify uncertainty. We a...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "large language model",
        "model",
        "multimodal",
        "reasoning",
        "framework",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "context",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "audio",
        "chain-of-thought",
        "reasoning",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "LLM",
        "model",
        "prompt",
        "tool",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "context",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "LLM",
        "RAG",
        "knowledge base",
        "model",
        "vector",
        "retrieval",
        "reasoning",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "fine-tuning",
        "model",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "API",
        "RAG",
        "product",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "vector",
        "platform",
        "prompt",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "framework",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "FicSim: A Dataset for Multi-Faceted Semantic Similarity in Long-Form Fiction",
      "url": "https://arxiv.org/abs/2510.20926",
      "description": "arXiv:2510.20926v1 Announce Type: new \nAbstract: As language models become capable of processing increasingly long and complex texts, there has been growing interest in their application within computational literary studies. However, evaluating the usefulness of these models for such tasks remains ...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "model",
        "release",
        "embedding"
      ],
      "score": 0.8
    },
    {
      "title": "Global Dynamics of Heavy-Tailed SGDs in Nonconvex Loss Landscape: Characterization and Control",
      "url": "https://arxiv.org/abs/2510.20905",
      "description": "arXiv:2510.20905v1 Announce Type: new \nAbstract: Stochastic gradient descent (SGD) and its variants enable modern artificial intelligence. However, theoretical understanding lags far behind their empirical success. It is widely believed that SGD has a curious ability to avoid sharp local minima in t...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "paper",
        "experiment",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "context",
        "model",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Input Matters: Evaluating Input Structure's Impact on LLM Summaries of Sports Play-by-Play",
      "url": "https://arxiv.org/abs/2510.21034",
      "description": "arXiv:2510.21034v1 Announce Type: new \nAbstract: A major concern when deploying LLMs in accuracy-critical domains such as sports reporting is that the generated text may not faithfully reflect the input data. We quantify how input structure affects hallucinations and other factual errors in LLM-gene...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "LLM",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Epistemic Deference to AI",
      "url": "https://arxiv.org/abs/2510.21043",
      "description": "arXiv:2510.21043v1 Announce Type: new \nAbstract: When should we defer to AI outputs over human expert judgment? Drawing on recent work in social epistemology, I motivate the idea that some AI systems qualify as Artificial Epistemic Authorities (AEAs) due to their demonstrated reliability and epistem...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Crisis-Resilient Portfolio Management via Graph-based Spatio-Temporal Learning",
      "url": "https://arxiv.org/abs/2510.20868",
      "description": "arXiv:2510.20868v1 Announce Type: new \nAbstract: Financial time series forecasting faces a fundamental challenge: predicting optimal asset allocations requires understanding regime-dependent correlation structures that transform during crisis periods. Existing graph-based spatio-temporal learning ap...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "framework",
        "attention",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "CC-GRMAS: A Multi-Agent Graph Neural System for Spatiotemporal Landslide Risk Assessment in High Mountain Asia",
      "url": "https://arxiv.org/abs/2510.20875",
      "description": "arXiv:2510.20875v1 Announce Type: new \nAbstract: Landslides are a growing climate induced hazard with severe environmental and human consequences, particularly in high mountain Asia. Despite increasing access to satellite and temporal datasets, timely detection and disaster response remain underdeve...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "RAG",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Learning from Interval Targets",
      "url": "https://arxiv.org/abs/2510.20925",
      "description": "arXiv:2510.20925v1 Announce Type: new \nAbstract: We study the problem of regression with interval targets, where only upper and lower bounds on target values are available in the form of intervals. This problem arises when the exact target label is expensive or impossible to obtain, due to inherent ...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "experiment",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Fuzzy numbers revisited: operations on extensional fuzzy numbers",
      "url": "https://arxiv.org/abs/2510.20861",
      "description": "arXiv:2510.20861v1 Announce Type: new \nAbstract: Fuzzy numbers are commonly represented with fuzzy sets. Their objective is to better represent imprecise data. However, operations on fuzzy numbers are not as straightforward as maths on crisp numbers. Commonly, the Zadeh's extension rule is applied t...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "example",
        "paper",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Confounding Robust Deep Reinforcement Learning: A Causal Approach",
      "url": "https://arxiv.org/abs/2510.21110",
      "description": "arXiv:2510.21110v1 Announce Type: new \nAbstract: A key task in Artificial Intelligence is learning effective policies for controlling agents in unknown environments to optimize performance measures. Off-policy learning methods, like Q-learning, allow learners to make optimal decisions based on past ...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Multimodal Negative Learning",
      "url": "https://arxiv.org/abs/2510.20877",
      "description": "arXiv:2510.20877v1 Announce Type: new \nAbstract: Multimodal learning systems often encounter challenges related to modality imbalance, where a dominant modality may overshadow others, thereby hindering the learning of weak modalities. Conventional approaches often force weak modalities to align with...",
      "published_date": "2025-10-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "multimodal",
        "framework",
        "experiment",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}