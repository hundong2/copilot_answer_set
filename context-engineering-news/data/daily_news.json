{
  "generated_at": "2026-02-06T20:09:29.687968",
  "total_items": 49,
  "items": [
    {
      "title": "BioACE: An Automated Framework for Biomedical Answer and Citation Evaluations",
      "url": "https://arxiv.org/abs/2602.04982",
      "description": "arXiv:2602.04982v1 Announce Type: new \nAbstract: With the increasing use of large language models (LLMs) for generating answers to biomedical questions, it is crucial to evaluate the quality of the generated answers and the references provided to support the facts in the generated answers. Evaluatio...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "framework",
        "summarization",
        "LLM",
        "model",
        "augmented",
        "analysis",
        "arxiv",
        "retrieval",
        "large language model",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System",
      "url": "https://arxiv.org/abs/2602.05004",
      "description": "arXiv:2602.05004v1 Announce Type: new \nAbstract: Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "memory",
        "library",
        "model",
        "arxiv",
        "retrieval",
        "large language model",
        "reasoning",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Capacity Constraints and the Multilingual Penalty for Lexical Disambiguation",
      "url": "https://arxiv.org/abs/2602.05035",
      "description": "arXiv:2602.05035v1 Announce Type: new \nAbstract: Multilingual language models (LMs) sometimes under-perform their monolingual counterparts, possibly due to capacity limitations. We quantify this ``multilingual penalty'' for lexical disambiguation--a task requiring precise semantic representations an...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "attention",
        "model",
        "arxiv",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories",
      "url": "https://arxiv.org/abs/2602.05085",
      "description": "arXiv:2602.05085v1 Announce Type: new \nAbstract: In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks i...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "paper",
        "context",
        "memory",
        "context window",
        "LLM",
        "model",
        "arxiv",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "Data Kernel Perspective Space Performance Guarantees for Synthetic Data from Transformer Models",
      "url": "https://arxiv.org/abs/2602.05106",
      "description": "arXiv:2602.05106v1 Announce Type: new \nAbstract: Scarcity of labeled training data remains the long pole in the tent for building performant language technology and generative AI models. Transformer models -- particularly LLMs -- are increasingly being used to mitigate the data scarcity problem via ...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "model",
        "analysis",
        "arxiv",
        "research",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "GreekMMLU: A Native-Sourced Multitask Benchmark for Evaluating Language Models in Greek",
      "url": "https://arxiv.org/abs/2602.05150",
      "description": "arXiv:2602.05150v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are commonly trained on multilingual corpora that include Greek, yet reliable evaluation benchmarks for Greek-particularly those based on authentic, native-sourced content-remain limited. Existing datasets are often machin...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "release",
        "prompting",
        "prompt",
        "LLM",
        "ICL",
        "model",
        "analysis",
        "arxiv",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Among Us: Measuring and Mitigating Malicious Contributions in Model Collaboration Systems",
      "url": "https://arxiv.org/abs/2602.05176",
      "description": "arXiv:2602.05176v1 Announce Type: new \nAbstract: Language models (LMs) are increasingly used in collaboration: multiple LMs trained by different parties collaborate through routing systems, multi-agent debate, model merging, and more. Critical safety risks remain in this decentralized paradigm: what...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "LLM",
        "model",
        "arxiv",
        "research",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "The Single-Multi Evolution Loop for Self-Improving Model Collaboration Systems",
      "url": "https://arxiv.org/abs/2602.05182",
      "description": "arXiv:2602.05182v1 Announce Type: new \nAbstract: Model collaboration -- systems where multiple language models (LMs) collaborate -- combines the strengths of diverse models with cost in loading multiple LMs. We improve efficiency while preserving the strengths of collaboration by distilling collabor...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "model",
        "analysis",
        "arxiv",
        "reasoning",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Are Open-Weight LLMs Ready for Social Media Moderation? A Comparative Study on Bluesky",
      "url": "https://arxiv.org/abs/2602.05189",
      "description": "arXiv:2602.05189v1 Announce Type: new \nAbstract: As internet access expands, so does exposure to harmful content, increasing the need for effective moderation. Research has demonstrated that large language models (LLMs) can be effectively utilized for social media moderation tasks, including harmful...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "platform",
        "context",
        "LLM",
        "model",
        "zero-shot",
        "analysis",
        "arxiv",
        "research",
        "large language model",
        "reasoning",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks",
      "url": "https://arxiv.org/abs/2602.03900",
      "description": "arXiv:2602.03900v1 Announce Type: new \nAbstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "chain-of-thought",
        "framework",
        "paper",
        "context",
        "prompting",
        "prompt",
        "LLM",
        "model",
        "CoT",
        "arxiv",
        "large language model",
        "reasoning",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation",
      "url": "https://arxiv.org/abs/2602.03950",
      "description": "arXiv:2602.03950v1 Announce Type: new \nAbstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although r...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "release",
        "chain-of-thought",
        "context",
        "LLM",
        "model",
        "arxiv",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent",
      "url": "https://arxiv.org/abs/2602.03955",
      "description": "arXiv:2602.03955v1 Announce Type: new \nAbstract: While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framewo...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "framework",
        "paper",
        "LLM",
        "model",
        "arxiv",
        "research",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Active Epistemic Control for Query-Efficient Verified Planning",
      "url": "https://arxiv.org/abs/2602.03974",
      "description": "arXiv:2602.03974v1 Announce Type: new \nAbstract: Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world ...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "LLM",
        "model",
        "arxiv",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure",
      "url": "https://arxiv.org/abs/2602.03975",
      "description": "arXiv:2602.03975v1 Announce Type: new \nAbstract: Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant ...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "LLM",
        "model",
        "arxiv",
        "large language model",
        "reasoning",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning",
      "url": "https://arxiv.org/abs/2602.03978",
      "description": "arXiv:2602.03978v1 Announce Type: new \nAbstract: As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal ...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "attention",
        "prompt",
        "model",
        "instruction",
        "CoT",
        "analysis",
        "arxiv",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making",
      "url": "https://arxiv.org/abs/2602.04003",
      "description": "arXiv:2602.04003v1 Announce Type: new \nAbstract: Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model rec...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "LLM",
        "model",
        "arxiv",
        "large language model",
        "reasoning",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL",
      "url": "https://arxiv.org/abs/2602.04089",
      "description": "arXiv:2602.04089v1 Announce Type: new \nAbstract: Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial ...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "RAG",
        "framework",
        "paper",
        "context",
        "GPT",
        "LLM",
        "in-context",
        "model",
        "instruction",
        "arxiv",
        "large language model",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Interfaze: The Future of AI is built on Task-Specific Small Models",
      "url": "https://arxiv.org/abs/2602.04101",
      "description": "arXiv:2602.04101v1 Announce Type: new \nAbstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "tool",
        "context",
        "multimodal",
        "LLM",
        "model",
        "arxiv",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "Denoising diffusion networks for normative modeling in neuroimaging",
      "url": "https://arxiv.org/abs/2602.04886",
      "description": "arXiv:2602.04886v1 Announce Type: new \nAbstract: Normative modeling estimates reference distributions of biological measures conditional on covariates, enabling centiles and clinically interpretable deviation scores to be derived. Most neuroimaging pipelines fit one model per imaging-derived phenoty...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "attention",
        "multimodal",
        "model",
        "analysis",
        "arxiv",
        "embedding",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "A Causal Perspective for Enhancing Jailbreak Attack and Defense",
      "url": "https://arxiv.org/abs/2602.04893",
      "description": "arXiv:2602.04893v1 Announce Type: new \nAbstract: Uncovering the mechanisms behind \"jailbreaks\" in large language models (LLMs) is crucial for enhancing their safety and reliability, yet these mechanisms remain poorly understood. Existing studies predominantly analyze jailbreak prompts by probing lat...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "template",
        "RAG",
        "framework",
        "prompt",
        "LLM",
        "model",
        "analysis",
        "arxiv",
        "large language model",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Momentum Attention: The Physics of In-Context Learning and Spectral Forensics for Mechanistic Interpretability",
      "url": "https://arxiv.org/abs/2602.04902",
      "description": "arXiv:2602.04902v1 Announce Type: new \nAbstract: The Mechanistic Interpretability (MI) program has mapped the Transformer as a precise computational graph. We extend this graph with a conservation law and time-varying AC dynamics, viewing it as a physical circuit. We introduce Momentum Attention, a ...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "experiment",
        "framework",
        "tool",
        "context",
        "attention",
        "in-context",
        "model",
        "arxiv",
        "embedding",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "Mind the Performance Gap: Capability-Behavior Trade-offs in Feature Steering",
      "url": "https://arxiv.org/abs/2602.04903",
      "description": "arXiv:2602.04903v1 Announce Type: new \nAbstract: Feature steering has emerged as a promising approach for controlling LLM behavior through direct manipulation of internal representations, offering advantages over prompt engineering. However, its practical effectiveness in real-world applications rem...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompting",
        "prompt",
        "LLM",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "LISA: Laplacian In-context Spectral Analysis",
      "url": "https://arxiv.org/abs/2602.04906",
      "description": "arXiv:2602.04906v1 Announce Type: new \nAbstract: We propose Laplacian In-context Spectral Analysis (LISA), a method for inference-time adaptation of Laplacian-based time-series models using only an observed prefix. LISA combines delay-coordinate embeddings and Laplacian spectral learning to produce ...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "attention",
        "context window",
        "in-context",
        "model",
        "analysis",
        "arxiv",
        "embedding",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Learning Where It Matters: Geometric Anchoring for Robust Preference Alignment",
      "url": "https://arxiv.org/abs/2602.04909",
      "description": "arXiv:2602.04909v1 Announce Type: new \nAbstract: Direct Preference Optimization (DPO) and related methods align large language models from pairwise preferences by regularizing updates against a fixed reference policy. As the policy drifts, a static reference, however, can become increasingly miscali...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "alignment",
        "LLM",
        "model",
        "arxiv",
        "large language model",
        "reasoning",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context",
        "context window",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "framework",
        "audio",
        "CoT",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "context",
        "API",
        "prompt",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "vector",
        "RAG",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "RAG",
        "framework",
        "LLM",
        "model",
        "retrieval",
        "knowledge base",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "API",
        "product",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "framework",
        "platform",
        "prompt",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Multilingual Extraction and Recognition of Implicit Discourse Relations in Speech and Text",
      "url": "https://arxiv.org/abs/2602.05107",
      "description": "arXiv:2602.05107v1 Announce Type: new \nAbstract: Implicit discourse relation classification is a challenging task, as it requires inferring meaning from context. While contextual cues can be distributed across modalities and vary across languages, they are not always captured by text alone. To addre...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "context",
        "audio",
        "multimodal",
        "model",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Physics as the Inductive Bias for Causal Discovery",
      "url": "https://arxiv.org/abs/2602.04907",
      "description": "arXiv:2602.04907v1 Announce Type: new \nAbstract: Causal discovery is often a data-driven paradigm to analyze complex real-world systems. In parallel, physics-based models such as ordinary differential equations (ODEs) provide mechanistic structure for many dynamical processes. Integrating these para...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "framework",
        "model",
        "arxiv",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "Temporal Pair Consistency for Variance-Reduced Flow Matching",
      "url": "https://arxiv.org/abs/2602.04908",
      "description": "arXiv:2602.04908v1 Announce Type: new \nAbstract: Continuous-time generative models, such as diffusion models, flow matching, and rectified flow, learn time-dependent vector fields but are typically trained with objectives that treat timesteps independently, leading to high estimator variance and ine...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vector",
        "image",
        "model",
        "augmented",
        "analysis",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "context",
        "API",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Axiomatic Foundations of Counterfactual Explanations",
      "url": "https://arxiv.org/abs/2602.04028",
      "description": "arXiv:2602.04028v1 Announce Type: new \nAbstract: Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions coul...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "paper",
        "arxiv",
        "reasoning",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "DCER: Dual-Stage Compression and Energy-Based Reconstruction",
      "url": "https://arxiv.org/abs/2602.04904",
      "description": "arXiv:2602.04904v1 Announce Type: new \nAbstract: Multimodal fusion faces two robustness challenges: noisy inputs degrade representation quality, and missing modalities cause prediction failures. We propose DCER, a\n  unified framework addressing both challenges through dual-stage compression and ener...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "experiment",
        "compression",
        "framework",
        "audio",
        "multimodal",
        "arxiv",
        "cross-modal"
      ],
      "score": 0.6
    },
    {
      "title": "A logical re-conception of neural networks: Hamiltonian bitwise part-whole architecture",
      "url": "https://arxiv.org/abs/2602.04911",
      "description": "arXiv:2602.04911v1 Announce Type: new \nAbstract: We introduce a simple initial working system in which relations (such as part-whole) are directly represented via an architecture with operating and learning rules fundamentally distinct from standard artificial neural network methods. Arbitrary data ...",
      "published_date": "2026-02-06T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "vector",
        "arxiv",
        "example",
        "tool"
      ],
      "score": 0.6
    },
    {
      "title": "Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3â€™s Top Model",
      "url": "https://huggingface.co/blog/nvidia/nemotron-colembed-v2",
      "description": "...",
      "published_date": "2026-02-04T15:00:40",
      "source": "Hugging Face Blog",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "retrieval",
        "multimodal"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}