{
  "generated_at": "2025-08-18T20:05:59.573336",
  "total_items": 48,
  "items": [
    {
      "title": "A2HCoder: An LLM-Driven Coding Agent for Hierarchical Algorithm-to-HDL Translation",
      "url": "https://arxiv.org/abs/2508.10904",
      "description": "arXiv:2508.10904v1 Announce Type: new \nAbstract: In wireless communication systems, stringent requirements such as ultra-low latency and power consumption have significantly increased the demand for efficient algorithm-to-hardware deployment. However, a persistent and substantial gap remains between...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "RAG",
        "model",
        "tool",
        "LLM",
        "framework",
        "step-by-step",
        "memory",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "PersonaTwin: A Multi-Tier Prompt Conditioning Framework for Generating and Evaluating Personalized Digital Twins",
      "url": "https://arxiv.org/abs/2508.10906",
      "description": "arXiv:2508.10906v1 Announce Type: new \nAbstract: While large language models (LLMs) afford new possibilities for user modeling and approximation of human behaviors, they often fail to capture the multidimensional nuances of individual users. In this work, we introduce PersonaTwin, a multi-tier promp...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "tool",
        "analysis",
        "experiment",
        "GPT",
        "LLM",
        "framework",
        "context",
        "large language model",
        "arxiv",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "gpt-oss-120b & gpt-oss-20b Model Card",
      "url": "https://arxiv.org/abs/2508.10925",
      "description": "arXiv:2508.10925v1 Announce Type: new \nAbstract: We present gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models that push the frontier of accuracy and inference cost. The models use an efficient mixture-of-expert transformer architecture and are trained using large-scale distillation and ...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "tool",
        "research",
        "reasoning",
        "GPT",
        "instruction",
        "transformer",
        "release",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Modeling and Detecting Company Risks from News: A Case Study in Bloomberg News",
      "url": "https://arxiv.org/abs/2508.10927",
      "description": "arXiv:2508.10927v1 Announce Type: new \nAbstract: Identifying risks associated with a company is important to investors and the well-being of the overall financial market. In this study, we build a computational framework to automatically extract company risk factors from news articles. Our newly pro...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "model",
        "few-shot",
        "company",
        "experiment",
        "large language model",
        "study",
        "LLM",
        "framework",
        "ICL",
        "prompting",
        "zero-shot",
        "arxiv",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Rule2Text: A Framework for Generating and Evaluating Natural Language Explanations of Knowledge Graph Rules",
      "url": "https://arxiv.org/abs/2508.10971",
      "description": "arXiv:2508.10971v1 Announce Type: new \nAbstract: Knowledge graphs (KGs) can be enhanced through rule mining; however, the resulting logical rules are often difficult for humans to interpret due to their inherent complexity and the idiosyncratic labeling conventions of individual KGs. This work prese...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "RAG",
        "model",
        "few-shot",
        "experiment",
        "large language model",
        "reasoning",
        "LLM",
        "fine-tuning",
        "framework",
        "ICL",
        "prompting",
        "chain-of-thought",
        "zero-shot",
        "arxiv",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Improving Text Style Transfer using Masked Diffusion Language Models with Inference-time Scaling",
      "url": "https://arxiv.org/abs/2508.10995",
      "description": "arXiv:2508.10995v1 Announce Type: new \nAbstract: Masked diffusion language models (MDMs) have recently gained traction as a viable generative framework for natural language. This can be attributed to its scalability and ease of training compared to other diffusion model paradigms for discrete data, ...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "model",
        "experiment",
        "framework",
        "embedding",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "SproutBench: A Benchmark for Safe and Ethical Large Language Models for Youth",
      "url": "https://arxiv.org/abs/2508.11009",
      "description": "arXiv:2508.11009v1 Announce Type: new \nAbstract: The rapid proliferation of large language models (LLMs) in applications targeting children and adolescents necessitates a fundamental reassessment of prevailing AI safety frameworks, which are largely tailored to adult users and neglect the distinct d...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "RAG",
        "model",
        "paper",
        "LLM",
        "framework",
        "API",
        "large language model",
        "arxiv",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond the Rosetta Stone: Unification Forces in Generalization Dynamics",
      "url": "https://arxiv.org/abs/2508.11017",
      "description": "arXiv:2508.11017v1 Announce Type: new \nAbstract: Large language models (LLMs) struggle with cross-lingual knowledge transfer: they hallucinate when asked in one language about facts expressed in a different language during training. This work introduces a controlled setting to study the causes and d...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "study",
        "LLM",
        "transformer",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Hell or High Water: Evaluating Agentic Recovery from External Failures",
      "url": "https://arxiv.org/abs/2508.11027",
      "description": "arXiv:2508.11027v1 Announce Type: new \nAbstract: As language model agents are applied to real world problems of increasing complexity, they will be expected to formulate plans across large search spaces. If those plans fail for reasons beyond their control, how well do language agents search for alt...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "analysis",
        "study",
        "context",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "BIPOLAR: Polarization-based granular framework for LLM bias evaluation",
      "url": "https://arxiv.org/abs/2508.11061",
      "description": "arXiv:2508.11061v1 Announce Type: new \nAbstract: Large language models (LLMs) are known to exhibit biases in downstream tasks, especially when dealing with sensitive topics such as political discourse, gender identity, ethnic relations, or national stereotypes. Although significant progress has been...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "analysis",
        "study",
        "GPT",
        "framework",
        "LLM",
        "large language model",
        "arxiv",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Learn to optimize for automatic proton PBS treatment planning for H&N cancers",
      "url": "https://arxiv.org/abs/2508.11085",
      "description": "arXiv:2508.11085v1 Announce Type: new \nAbstract: Proton PBS treatment planning for H&amp;N cancers involves numerous conflicting objectives, requiring significant effort from human planners to balance and satisfy multiple clinical goals during planning. To achieve this, experience-demanding objectiv...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "study",
        "LLM",
        "framework",
        "context",
        "transformer",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "On Strong and Weak Admissibility in Non-Flat Assumption-Based Argumentation",
      "url": "https://arxiv.org/abs/2508.11182",
      "description": "arXiv:2508.11182v1 Announce Type: new \nAbstract: In this work, we broaden the investigation of admissibility notions in the context of assumption-based argumentation (ABA). More specifically, we study two prominent alternatives to the standard notion of admissibility from abstract argumentation, nam...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "study",
        "framework",
        "context",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information",
      "url": "https://arxiv.org/abs/2508.11252",
      "description": "arXiv:2508.11252v1 Announce Type: new \nAbstract: Large Reasoning Models (LRMs) have demonstrated remarkable problem-solving abilities in mathematics, as evaluated by existing benchmarks exclusively on well-defined problems. However, such evaluation setup constitutes a critical gap, since a genuine i...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "context",
        "fine-tuning",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding",
      "url": "https://arxiv.org/abs/2508.11347",
      "description": "arXiv:2508.11347v1 Announce Type: new \nAbstract: Traditional knowledge graph (KG) embedding methods aim to represent entities and relations in a low-dimensional space, primarily focusing on static graphs. However, real-world KGs are dynamically evolving with the constant addition of entities, relati...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "experiment",
        "framework",
        "ICL",
        "embedding",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager",
      "url": "https://arxiv.org/abs/2508.11416",
      "description": "arXiv:2508.11416v1 Announce Type: new \nAbstract: Recent advances in mathematical reasoning and the long-term planning capabilities of large language models (LLMs) have precipitated the development of agents, which are being increasingly leveraged in business operations processes. Decision models to ...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "model",
        "experiment",
        "reasoning",
        "LLM",
        "context",
        "large language model",
        "arxiv",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps",
      "url": "https://arxiv.org/abs/2508.11452",
      "description": "arXiv:2508.11452v1 Announce Type: new \nAbstract: Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) have ushered in a new era of AI capabilities, demonstrating near-human-level performance across diverse scenarios. While numerous benchmarks (e.g., MMLU) and leaderboards (e.g.,...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "model",
        "platform",
        "multimodal",
        "LLM",
        "augmented",
        "ICL",
        "large language model",
        "arxiv",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Apriel-Nemotron-15B-Thinker",
      "url": "https://arxiv.org/abs/2508.10948",
      "description": "arXiv:2508.10948v1 Announce Type: new \nAbstract: While large language models (LLMs) have achieved remarkable reasoning capabilities across domains like code, math and other enterprise tasks, their significant memory and computational costs often preclude their use in practical enterprise settings. T...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "LLM",
        "memory",
        "fine-tuning",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Retro-Expert: Collaborative Reasoning for Interpretable Retrosynthesis",
      "url": "https://arxiv.org/abs/2508.10967",
      "description": "arXiv:2508.10967v1 Announce Type: new \nAbstract: Retrosynthesis prediction aims to infer the reactant molecule based on a given product molecule, which is a fundamental task in chemical synthesis. However, existing models rely on static pattern-matching paradigm, which limits their ability to perfor...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "product",
        "experiment",
        "reasoning",
        "LLM",
        "framework",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale Pretraining",
      "url": "https://arxiv.org/abs/2508.10975",
      "description": "arXiv:2508.10975v1 Announce Type: new \nAbstract: Recent advances in large language model (LLM) pretraining have shown that simply scaling data quantity eventually leads to diminishing returns, hitting a data wall. In response, the use of synthetic data for pretraining has emerged as a promising para...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "model",
        "LLM",
        "framework",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Match & Choose: Model Selection Framework for Fine-tuning Text-to-Image Diffusion Models",
      "url": "https://arxiv.org/abs/2508.10993",
      "description": "arXiv:2508.10993v1 Announce Type: new \nAbstract: Text-to-image (T2I) models based on diffusion and transformer architectures advance rapidly. They are often pretrained on large corpora, and openly shared on a model platform, such as HuggingFace. Users can then build up AI applications, e.g., generat...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "platform",
        "paper",
        "image",
        "framework",
        "API",
        "transformer",
        "fine-tuning",
        "embedding",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "CURE: Critical-Token-Guided Re-concatenation for Entropy-collapse Prevention",
      "url": "https://arxiv.org/abs/2508.11016",
      "description": "arXiv:2508.11016v1 Announce Type: new \nAbstract: Recent advances in Reinforcement Learning with Verified Reward (RLVR) have driven the emergence of more sophisticated cognitive behaviors in large language models (LLMs), thereby enhancing their reasoning capabilities. However, in prior RLVR pipelines...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "experiment",
        "reasoning",
        "LLM",
        "framework",
        "API",
        "context",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "context window",
        "prompt engineering",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "framework",
        "audio",
        "CoT",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "context",
        "attention",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "model",
        "reasoning",
        "LLM",
        "framework",
        "knowledge base",
        "vector",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "fine-tuning",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "product",
        "augmented",
        "API",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "LLM",
        "framework",
        "vector",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Zono-Conformal Prediction: Zonotope-Based Uncertainty Quantification for Regression and Classification Tasks",
      "url": "https://arxiv.org/abs/2508.11025",
      "description": "arXiv:2508.11025v1 Announce Type: new \nAbstract: Conformal prediction is a popular uncertainty quantification method that augments a base predictor with prediction sets with statistically valid coverage guarantees. However, current methods are often computationally expensive and data-intensive, as t...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "model",
        "arxiv",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "context",
        "model",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "model",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "From Individual to Multi-Agent Algorithmic Recourse: Minimizing the Welfare Gap via Capacitated Bipartite Matching",
      "url": "https://arxiv.org/abs/2508.11070",
      "description": "arXiv:2508.11070v1 Announce Type: new \nAbstract: Decision makers are increasingly relying on machine learning in sensitive situations. In such settings, algorithmic recourse aims to provide individuals with actionable and minimally costly steps to reverse unfavorable AI-driven decisions. While exist...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "experiment",
        "research",
        "framework",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Landmark-Assisted Monte Carlo Planning",
      "url": "https://arxiv.org/abs/2508.11493",
      "description": "arXiv:2508.11493v1 Announce Type: new \nAbstract: Landmarks$\\unicode{x2013}$conditions that must be satisfied at some point in every solution plan$\\unicode{x2013}$have contributed to major advancements in classical planning, but they have seldom been used in stochastic domains. We formalize probabili...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "A Cooperative Game-Based Multi-Criteria Weighted Ensemble Approach for Multi-Class Classification",
      "url": "https://arxiv.org/abs/2508.10926",
      "description": "arXiv:2508.10926v1 Announce Type: new \nAbstract: Since the Fourth Industrial Revolution, AI technology has been widely used in many fields, but there are several limitations that need to be overcome, including overfitting/underfitting, class imbalance, and the limitations of representation (hypothes...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "paper",
        "arxiv",
        "experiment"
      ],
      "score": 0.6
    },
    {
      "title": "Towards Efficient Prompt-based Continual Learning in Distributed Medical AI",
      "url": "https://arxiv.org/abs/2508.10954",
      "description": "arXiv:2508.10954v1 Announce Type: new \nAbstract: Modern AI models achieve state-of-the-art performance with large-scale, high-quality datasets; however, ethical, social, and institutional constraints in the medical domain severely restrict data sharing, rendering centralized learning nearly impossib...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "image",
        "experiment",
        "study",
        "release",
        "arxiv",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "Quantization vs Pruning: Insights from the Strong Lottery Ticket Hypothesis",
      "url": "https://arxiv.org/abs/2508.11020",
      "description": "arXiv:2508.11020v1 Announce Type: new \nAbstract: Quantization is an essential technique for making neural networks more efficient, yet our theoretical understanding of it remains limited. Previous works demonstrated that extremely low-precision networks, such as binary networks, can be constructed b...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "framework",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Learning with Confidence",
      "url": "https://arxiv.org/abs/2508.11037",
      "description": "arXiv:2508.11037v1 Announce Type: new \nAbstract: We characterize a notion of confidence that arises in learning or updating beliefs: the amount of trust one has in incoming information and its impact on the belief state. This learner's confidence can be used alongside (and is easily mistaken for) pr...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vector",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks",
      "url": "https://arxiv.org/abs/2508.11360",
      "description": "arXiv:2508.11360v1 Announce Type: new \nAbstract: As autonomous agents become adept at understanding and interacting with graphical user interface (GUI) environments, a new era of automated task execution is emerging. Recent studies have demonstrated that Reinforcement Learning (RL) can effectively e...",
      "published_date": "2025-08-18T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "experiment",
        "framework",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels",
      "url": "https://huggingface.co/blog/kernel-builder",
      "description": "...",
      "published_date": "2025-08-18T00:00:00",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "product"
      ],
      "score": 0.2
    },
    {
      "title": "MCP for Research: How to Connect AI to Research Tools",
      "url": "https://huggingface.co/blog/mcp-for-research",
      "description": "...",
      "published_date": "2025-08-18T00:00:00",
      "source": "Hugging Face Blog",
      "category": "tools_frameworks",
      "keywords": [
        "research",
        "tool"
      ],
      "score": 0.2
    }
  ]
}