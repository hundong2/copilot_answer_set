{
  "generated_at": "2026-01-08T20:06:05.211495",
  "total_items": 46,
  "items": [
    {
      "title": "DeepResearch-Slice: Bridging the Retrieval-Utilization Gap via Explicit Text Slicing",
      "url": "https://arxiv.org/abs/2601.03261",
      "description": "arXiv:2601.03261v1 Announce Type: new \nAbstract: Deep Research agents predominantly optimize search policies to maximize retrieval probability. However, we identify a critical bottleneck: the retrieval-utilization gap, where models fail to use gold evidence even after it is retrieved, due to context...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "research",
        "context",
        "framework",
        "retrieval",
        "arxiv",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Internal Reasoning vs. External Control: A Thermodynamic Analysis of Sycophancy in Large Language Models",
      "url": "https://arxiv.org/abs/2601.03263",
      "description": "arXiv:2601.03263v1 Announce Type: new \nAbstract: Large Language Models frequently exhibit sycophancy, prioritizing user agreeableness over correctness. We investigate whether this requires external regulation or can be mitigated by internal reasoning alone. Using CAP-GSM8K (N=500), an adversarial da...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "large language model",
        "arxiv",
        "reasoning",
        "analysis",
        "model",
        "CoT",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Jailbreak-Zero: A Path to Pareto Optimal Red Teaming for Large Language Models",
      "url": "https://arxiv.org/abs/2601.03265",
      "description": "arXiv:2601.03265v1 Announce Type: new \nAbstract: This paper introduces Jailbreak-Zero, a novel red teaming methodology that shifts the paradigm of Large Language Model (LLM) safety evaluation from a constrained example-based approach to a more expansive and effective policy-based framework. By lever...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "large language model",
        "framework",
        "prompt",
        "paper",
        "arxiv",
        "fine-tuning",
        "model",
        "example",
        "LLM",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Benchmarking and Adapting On-Device Large Language Models for Clinical Decision Support",
      "url": "https://arxiv.org/abs/2601.03266",
      "description": "arXiv:2601.03266v1 Announce Type: new \nAbstract: Large language models (LLMs) have rapidly advanced in clinical decision-making, yet the deployment of proprietary systems is hindered by privacy concerns and reliance on cloud-based infrastructure. Open-source alternatives allow local inference but of...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "large language model",
        "API",
        "arxiv",
        "fine-tuning",
        "model",
        "LLM",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "OpenAI GPT-5 System Card",
      "url": "https://arxiv.org/abs/2601.03267",
      "description": "arXiv:2601.03267v1 Announce Type: new \nAbstract: This is the system card published alongside the OpenAI GPT-5 launch, August 2025.\n  GPT-5 is a unified system with a smart and fast model that answers most questions, a deeper reasoning model for harder problems, and a real-time router that quickly de...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "instruction",
        "tool",
        "framework",
        "prompt",
        "arxiv",
        "reasoning",
        "model",
        "example",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "WRAVAL -- WRiting Assist eVALuation",
      "url": "https://arxiv.org/abs/2601.03268",
      "description": "arXiv:2601.03268v1 Announce Type: new \nAbstract: The emergence of Large Language Models (LLMs) has shifted language model evaluation toward reasoning and problem-solving tasks as measures of general intelligence. Small Language Models (SLMs) -- defined here as models under 10B parameters -- typicall...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "large language model",
        "framework",
        "prompt",
        "arxiv",
        "reasoning",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "The Instruction Gap: LLMs get lost in Following Instruction",
      "url": "https://arxiv.org/abs/2601.03269",
      "description": "arXiv:2601.03269v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown remarkable capabilities in natural language understanding and generation, yet their deployment in enterprise environments reveals a critical limitation: inconsistent adherence to custom instructions. This study ...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "instruction",
        "augmented",
        "study",
        "RAG",
        "large language model",
        "retrieval",
        "arxiv",
        "model",
        "LLM",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Less is more: Not all samples are effective for evaluation",
      "url": "https://arxiv.org/abs/2601.03272",
      "description": "arXiv:2601.03272v1 Announce Type: new \nAbstract: The versatility of Large Language Models (LLMs) in vertical domains has spurred the development of numerous specialized evaluation benchmarks. However, these benchmarks often suffer from significant semantic redundancy and impose high computational co...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "compression",
        "LLM",
        "large language model",
        "framework",
        "arxiv",
        "fine-tuning",
        "model",
        "embedding",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "GuardEval: A Multi-Perspective Benchmark for Evaluating Safety, Fairness, and Robustness in LLM Moderators",
      "url": "https://arxiv.org/abs/2601.03273",
      "description": "arXiv:2601.03273v1 Announce Type: new \nAbstract: As large language models (LLMs) become deeply embedded in daily life, the urgent need for safer moderation systems, distinguishing between naive from harmful requests while upholding appropriate censorship boundaries, has never been greater. While exi...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "large language model",
        "prompt",
        "arxiv",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Digital Red Queen: Adversarial Program Evolution in Core War with LLMs",
      "url": "https://arxiv.org/abs/2601.03335",
      "description": "arXiv:2601.03335v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optim...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "large language model",
        "framework",
        "arxiv",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization",
      "url": "https://arxiv.org/abs/2601.03359",
      "description": "arXiv:2601.03359v1 Announce Type: new \nAbstract: Large Language Models (LLMs) often generate substantively relevant content but fail to adhere to formal constraints, leading to outputs that are conceptually correct but procedurally flawed. Traditional prompt refinement approaches focus on rephrasing...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "instruction",
        "large language model",
        "prompt",
        "arxiv",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "CPGPrompt: Translating Clinical Guidelines into LLM-Executable Decision Support",
      "url": "https://arxiv.org/abs/2601.03475",
      "description": "arXiv:2601.03475v1 Announce Type: new \nAbstract: Clinical practice guidelines (CPGs) provide evidence-based recommendations for patient care; however, integrating them into Artificial Intelligence (AI) remains challenging. Previous approaches, such as rule-based systems, face significant limitations...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompting",
        "large language model",
        "framework",
        "prompt",
        "arxiv",
        "reasoning",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Personalization of Large Foundation Models for Health Interventions",
      "url": "https://arxiv.org/abs/2601.03482",
      "description": "arXiv:2601.03482v1 Announce Type: new \nAbstract: Large foundation models (LFMs) transform healthcare AI in prevention, diagnostics, and treatment. However, whether LFMs can provide truly personalized treatment recommendations remains an open question. Recent research has revealed multiple challenges...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "study",
        "paper",
        "framework",
        "API",
        "arxiv",
        "model",
        "multimodal",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Evolving Programmatic Skill Networks",
      "url": "https://arxiv.org/abs/2601.03509",
      "description": "arXiv:2601.03509v1 Announce Type: new \nAbstract: We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are exe...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "study",
        "large language model",
        "framework",
        "library",
        "API",
        "arxiv",
        "model",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "STAR-S: Improving Safety Alignment through Self-Taught Reasoning on Safety Rules",
      "url": "https://arxiv.org/abs/2601.03537",
      "description": "arXiv:2601.03537v1 Announce Type: new \nAbstract: Defending against jailbreak attacks is crucial for the safe deployment of Large Language Models (LLMs). Recent research has attempted to improve safety by training models to reason over safety rules before responding. However, a key issue lies in dete...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "RAG",
        "large language model",
        "framework",
        "prompt",
        "arxiv",
        "fine-tuning",
        "reasoning",
        "model",
        "alignment",
        "LLM",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Lightweight Transformer Architectures for Edge Devices in Real-Time Applications",
      "url": "https://arxiv.org/abs/2601.03290",
      "description": "arXiv:2601.03290v1 Announce Type: new \nAbstract: The deployment of transformer-based models on resource-constrained edge devices represents a critical challenge in enabling real-time artificial intelligence applications. This comprehensive survey examines lightweight transformer architectures specif...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "transformer",
        "attention",
        "compression",
        "RAG",
        "framework",
        "platform",
        "arxiv",
        "model",
        "analysis",
        "memory",
        "experiment",
        "image"
      ],
      "score": 1.0
    },
    {
      "title": "Why LLMs Aren't Scientists Yet: Lessons from Four Autonomous Research Attempts",
      "url": "https://arxiv.org/abs/2601.03315",
      "description": "arXiv:2601.03315v1 Announce Type: new \nAbstract: We report a case study of four end-to-end attempts to autonomously generate ML research papers using a pipeline of six LLM agents mapped to stages of the scientific workflow. Of these four, three attempts failed during implementation or evaluation. On...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "study",
        "release",
        "context",
        "paper",
        "prompt",
        "arxiv",
        "memory",
        "LLM",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Ratio-Variance Regularized Policy Optimization for Efficient LLM Fine-tuning",
      "url": "https://arxiv.org/abs/2601.03320",
      "description": "arXiv:2601.03320v1 Announce Type: new \nAbstract: On-policy reinforcement learning (RL), particularly Proximal Policy Optimization (PPO) and Group Relative Policy Optimization (GRPO), has become the dominant paradigm for fine-tuning large language models (LLMs). While policy ratio clipping stabilizes...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "large language model",
        "framework",
        "arxiv",
        "fine-tuning",
        "reasoning",
        "model",
        "alignment",
        "LLM",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Aligning Findings with Diagnosis: A Self-Consistent Reinforcement Learning Framework for Trustworthy Radiology Reporting",
      "url": "https://arxiv.org/abs/2601.03321",
      "description": "arXiv:2601.03321v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) have shown strong potential for radiology report generation, yet their clinical translation is hindered by architectural heterogeneity and the prevalence of factual hallucinations. Standard supervised fine-tuni...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "vision",
        "large language model",
        "framework",
        "arxiv",
        "fine-tuning",
        "multimodal",
        "model",
        "LLM",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "HEEGNet: Hyperbolic Embeddings for EEG",
      "url": "https://arxiv.org/abs/2601.03322",
      "description": "arXiv:2601.03322v1 Announce Type: new \nAbstract: Electroencephalography (EEG)-based brain-computer interfaces facilitate direct communication with a computer, enabling promising applications in human-computer interactions. However, their utility is currently limited because EEG decoding often suffer...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "embedding",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Attention mechanisms in neural networks",
      "url": "https://arxiv.org/abs/2601.03329",
      "description": "arXiv:2601.03329v1 Announce Type: new \nAbstract: Attention mechanisms represent a fundamental paradigm shift in neural network architectures, enabling models to selectively focus on relevant portions of input sequences through learned weighting functions. This monograph provides a comprehensive and ...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "transformer",
        "attention",
        "vision",
        "arxiv",
        "model",
        "analysis",
        "multimodal",
        "image",
        "cross-modal"
      ],
      "score": 1.0
    },
    {
      "title": "LUT-KAN: Segment-wise LUT Quantization for Fast KAN Inference",
      "url": "https://arxiv.org/abs/2601.03332",
      "description": "arXiv:2601.03332v1 Announce Type: new \nAbstract: Kolmogorov--Arnold Networks (KAN) replace scalar weights by learnable univariate functions, often implemented with B-splines. This design can be accurate and interpretable, but it makes inference expensive on CPU because each layer requires many splin...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "release",
        "tool",
        "ICL",
        "paper",
        "vector",
        "arxiv",
        "model",
        "memory",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing Small Dataset Classification Using Projected Quantum Kernels with Convolutional Neural Networks",
      "url": "https://arxiv.org/abs/2601.03375",
      "description": "arXiv:2601.03375v1 Announce Type: new \nAbstract: Convolutional Neural Networks (CNNs) have shown promising results in efficiency and accuracy in image classification. However, their efficacy often relies on large, labeled datasets, posing challenges for applications with limited data availability. O...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "RAG",
        "arxiv",
        "experiment",
        "image"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context window",
        "prompt",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "CoT",
        "audio",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "context",
        "prompt",
        "API",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "framework",
        "retrieval",
        "vector",
        "knowledge base",
        "reasoning",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "API",
        "retrieval",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "prompt",
        "platform",
        "vector",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Advances and Challenges in Semantic Textual Similarity: A Comprehensive Survey",
      "url": "https://arxiv.org/abs/2601.03270",
      "description": "arXiv:2601.03270v1 Announce Type: new \nAbstract: Semantic Textual Similarity (STS) research has expanded rapidly since 2021, driven by advances in transformer architectures, contrastive learning, and domain-specific techniques. This survey reviews progress across six key areas: transformer-based mod...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "transformer",
        "research",
        "API",
        "arxiv",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Physics-Informed Gaussian Process Regression for the Constitutive Modeling of Concrete: A Data-Driven Improvement to Phenomenological Models",
      "url": "https://arxiv.org/abs/2601.03367",
      "description": "arXiv:2601.03367v1 Announce Type: new \nAbstract: Understanding and modeling the constitutive behavior of concrete is crucial for civil and defense applications, yet widely used phenomenological models such as Karagozian \\& Case concrete (KCC) model depend on empirically calibrated failure surfaces t...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "compression",
        "RAG",
        "framework",
        "arxiv",
        "model",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "model",
        "API",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "paper",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "Exploration Through Introspection: A Self-Aware Reward Model",
      "url": "https://arxiv.org/abs/2601.03389",
      "description": "arXiv:2601.03389v1 Announce Type: new \nAbstract: Understanding how artificial agents model internal mental states is central to advancing Theory of Mind in AI. Evidence points to a unified system for self- and other-awareness. We explore this self-awareness by having reinforcement learning agents in...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "framework",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Toward Maturity-Based Certification of Embodied AI: Quantifying Trustworthiness Through Measurement Mechanisms",
      "url": "https://arxiv.org/abs/2601.03470",
      "description": "arXiv:2601.03470v1 Announce Type: new \nAbstract: We propose a maturity-based framework for certifying embodied AI systems through explicit measurement mechanisms. We argue that certifiable embodied AI requires structured assessment frameworks, quantitative scoring mechanisms, and methods for navigat...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "Extreme-value forest fire prediction A study of the Loss Function in an Ordinality Scheme",
      "url": "https://arxiv.org/abs/2601.03327",
      "description": "arXiv:2601.03327v1 Announce Type: new \nAbstract: Wildfires are highly imbalanced natural hazards in both space and severity, making the prediction of extreme events particularly challenging. In this work, we introduce the first ordinal classification framework for forecasting wildfire severity level...",
      "published_date": "2026-01-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "vision",
        "framework",
        "arxiv",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "NVIDIA Cosmos Reason 2 Brings Advanced Reasoning To Physical AI",
      "url": "https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning",
      "description": "...",
      "published_date": "2026-01-05T22:56:51",
      "source": "Hugging Face Blog",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning"
      ],
      "score": 0.2
    }
  ]
}