{
  "generated_at": "2025-10-24T20:05:50.429625",
  "total_items": 47,
  "items": [
    {
      "title": "Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis",
      "url": "https://arxiv.org/abs/2510.19836",
      "description": "arXiv:2510.19836v1 Announce Type: new \nAbstract: Artificial intelligence and machine learning are increasingly used for forecasting, optimization, and policy design in the energy sector, yet no standardized framework exists to evaluate whether these systems reason correctly. Current validation pract...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "reasoning",
        "GPT",
        "framework",
        "model",
        "large language model",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory",
      "url": "https://arxiv.org/abs/2510.19838",
      "description": "arXiv:2510.19838v1 Announce Type: new \nAbstract: Autonomous web agents powered by large language models (LLMs) show strong potential for performing goal-oriented tasks such as information retrieval, report generation, and online transactions. These agents mark a key step toward practical embodied re...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "context",
        "RAG",
        "reasoning",
        "memory",
        "framework",
        "LLM",
        "model",
        "large language model",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs",
      "url": "https://arxiv.org/abs/2510.19842",
      "description": "arXiv:2510.19842v1 Announce Type: new \nAbstract: Large Language Models (LLMs) demonstrate strong performance on mathematical problems when prompted with Chain-of-Thought (CoT), yet it remains unclear whether this success stems from search, rote procedures, or rule-consistent reasoning. To address th...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "analysis",
        "chain-of-thought",
        "CoT",
        "reasoning",
        "framework",
        "LLM",
        "model",
        "large language model",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Surfer 2: The Next Generation of Cross-Platform Computer Use Agents",
      "url": "https://arxiv.org/abs/2510.19949",
      "description": "arXiv:2510.19949v1 Announce Type: new \nAbstract: Building agents that generalize across web, desktop, and mobile environments remains an open challenge, as prior systems rely on environment-specific interfaces that limit cross-platform deployment. We introduce Surfer 2, a unified architecture operat...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "arxiv",
        "fine-tuning",
        "context",
        "vision",
        "model",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits",
      "url": "https://arxiv.org/abs/2510.19964",
      "description": "arXiv:2510.19964v1 Announce Type: new \nAbstract: The study explores the potential of AI technologies in personalized learning, suggesting the prediction of academic success through leadership personality traits and machine learning modelling. The primary data were obtained from 129 master's students...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "analysis",
        "tool",
        "model",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "LLMs can hide text in other text of the same length.ipynb",
      "url": "https://arxiv.org/abs/2510.20075",
      "description": "arXiv:2510.20075v1 Announce Type: new \nAbstract: A meaningful text can be hidden inside another, completely different yet still coherent and plausible, text of the same length. For example, a tweet containing a harsh political critique could be embedded in a tweet that celebrates the same political ...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "product",
        "company",
        "example",
        "paper",
        "LLM",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "AI PB: A Grounded Generative Agent for Personalized Investment Insights",
      "url": "https://arxiv.org/abs/2510.20099",
      "description": "arXiv:2510.20099v1 Announce Type: new \nAbstract: We present AI PB, a production-scale generative agent deployed in real retail finance. Unlike reactive chatbots that answer queries passively, AI PB proactively generates grounded, compliant, and user-specific investment insights. It integrates (i) a ...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "context",
        "product",
        "LLM",
        "embedding",
        "model",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Some Attention is All You Need for Retrieval",
      "url": "https://arxiv.org/abs/2510.19861",
      "description": "arXiv:2510.19861v1 Announce Type: new \nAbstract: We demonstrate complete functional segregation in hybrid SSM-Transformer architectures: retrieval depends exclusively on self-attention layers. Across RecurrentGemma-2B/9B and Jamba-Mini-1.6, attention ablation causes catastrophic retrieval failure (0...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "context",
        "attention",
        "transformer",
        "model",
        "prompting",
        "retrieval",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph",
      "url": "https://arxiv.org/abs/2510.19873",
      "description": "arXiv:2510.19873v1 Announce Type: new \nAbstract: Despite significant evolution of CUDA programming and domain-specific libraries, effectively utilizing GPUs with massively parallel engines remains difficult. Large language models (LLMs) show strong potential in generating optimized CUDA code from se...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "RAG",
        "API",
        "augmented",
        "reasoning",
        "framework",
        "LLM",
        "experiment",
        "model",
        "large language model",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem",
      "url": "https://arxiv.org/abs/2510.19889",
      "description": "arXiv:2510.19889v1 Announce Type: new \nAbstract: The traffic assignment problem is essential for traffic flow analysis, traditionally solved using mathematical programs under the Equilibrium principle. These methods become computationally prohibitive for large-scale networks due to non-linear growth...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "API",
        "analysis",
        "transformer",
        "experiment",
        "model",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "FairGRPO: Fair Reinforcement Learning for Equitable Clinical Reasoning",
      "url": "https://arxiv.org/abs/2510.19893",
      "description": "arXiv:2510.19893v1 Announce Type: new \nAbstract: Medical artificial intelligence systems have achieved remarkable diagnostic capabilities, yet they consistently exhibit performance disparities across demographic groups, causing real-world harm to underrepresented populations. While recent multimodal...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "release",
        "analysis",
        "reasoning",
        "multimodal",
        "LLM",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond the Ideal: Analyzing the Inexact Muon Update",
      "url": "https://arxiv.org/abs/2510.19933",
      "description": "arXiv:2510.19933v1 Announce Type: new \nAbstract: The Muon optimizer has rapidly emerged as a powerful, geometry-aware alternative to AdamW, demonstrating strong performance in large-scale training of neural networks. However, a critical theory-practice disconnect exists: Muon's efficiency relies on ...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "API",
        "GPT",
        "framework",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Contextual Augmentation for Entity Linking using Large Language Models",
      "url": "https://arxiv.org/abs/2510.18888",
      "description": "arXiv:2510.18888v1 Announce Type: new \nAbstract: Entity Linking involves detecting and linking entity mentions in natural language texts to a knowledge graph. Traditional methods use a two-step process with separate models for entity recognition and disambiguation, which can be computationally inten...",
      "published_date": "2025-10-23T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "context",
        "RAG",
        "framework",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Small Language Models Offer Significant Potential for Science Community",
      "url": "https://arxiv.org/abs/2510.18890",
      "description": "arXiv:2510.18890v1 Announce Type: new \nAbstract: Recent advancements in natural language processing, particularly with large language models (LLMs), are transforming how scientists engage with the literature. While the adoption of LLMs is increasing, concerns remain regarding potential information b...",
      "published_date": "2025-10-23T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "research",
        "analysis",
        "API",
        "image",
        "GPT",
        "tool",
        "framework",
        "LLM",
        "model",
        "large language model",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "When Models Can't Follow: Testing Instruction Adherence Across 256 LLMs",
      "url": "https://arxiv.org/abs/2510.18892",
      "description": "arXiv:2510.18892v1 Announce Type: new \nAbstract: Despite widespread deployment of Large Language Models, systematic evaluation of instruction-following capabilities remains challenging. While comprehensive benchmarks exist, focused assessments that quickly diagnose specific instruction adherence pat...",
      "published_date": "2025-10-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "research",
        "analysis",
        "instruction",
        "tool",
        "framework",
        "LLM",
        "paper",
        "study",
        "large language model",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Transformer-Based Low-Resource Language Translation: A Study on Standard Bengali to Sylheti",
      "url": "https://arxiv.org/abs/2510.18898",
      "description": "arXiv:2510.18898v1 Announce Type: new \nAbstract: Machine Translation (MT) has advanced from rule-based and statistical methods to neural approaches based on the Transformer architecture. While these methods have achieved impressive results for high-resource languages, low-resource varieties such as ...",
      "published_date": "2025-10-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "fine-tuning",
        "zero-shot",
        "transformer",
        "LLM",
        "experiment",
        "model",
        "large language model",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "DuoLens: A Framework for Robust Detection of Machine-Generated Multilingual Text and Code",
      "url": "https://arxiv.org/abs/2510.18904",
      "description": "arXiv:2510.18904v1 Announce Type: new \nAbstract: The prevalence of Large Language Models (LLMs) for generating multilingual text and source code has only increased the imperative for machine-generated content detectors to be accurate and efficient across domains. Current detectors, predominantly uti...",
      "published_date": "2025-10-23T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "release",
        "fine-tuning",
        "zero-shot",
        "GPT",
        "framework",
        "LLM",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Improving Topic Modeling of Social Media Short Texts with Rephrasing: A Case Study of COVID-19 Related Tweets",
      "url": "https://arxiv.org/abs/2510.18908",
      "description": "arXiv:2510.18908v1 Announce Type: new \nAbstract: Social media platforms such as Twitter (now X) provide rich data for analyzing public discourse, especially during crises such as the COVID-19 pandemic. However, the brevity, informality, and noise of social media short texts often hinder the effectiv...",
      "published_date": "2025-10-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "RAG",
        "analysis",
        "framework",
        "LLM",
        "study",
        "large language model",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection",
      "url": "https://arxiv.org/abs/2510.18909",
      "description": "arXiv:2510.18909v1 Announce Type: new \nAbstract: High-quality pre-training data is crutial for large language models, where quality captures factual reliability and semantic value, and diversity ensures broad coverage and distributional heterogeneity. Existing approaches typically rely on single or ...",
      "published_date": "2025-10-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "analysis",
        "LLM",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-aware Fairness Evaluation and Mitigation in LLMs",
      "url": "https://arxiv.org/abs/2510.18914",
      "description": "arXiv:2510.18914v1 Announce Type: new \nAbstract: Large language models often display undesirable behaviors embedded in their internal representations, undermining fairness, inconsistency drift, amplification of harmful content, and the propagation of unwanted patterns during extended dialogue and co...",
      "published_date": "2025-10-23T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "arxiv",
        "context",
        "memory",
        "framework",
        "LLM",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Misinformation Detection using Large Language Models with Explainability",
      "url": "https://arxiv.org/abs/2510.18918",
      "description": "arXiv:2510.18918v1 Announce Type: new \nAbstract: The rapid spread of misinformation on online platforms undermines trust among individuals and hinders informed decision making. This paper shows an explainable and computationally efficient pipeline to detect misinformation using transformer-based pre...",
      "published_date": "2025-10-23T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "fine-tuning",
        "API",
        "transformer",
        "framework",
        "paper",
        "model",
        "large language model",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context",
        "prompt",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "CoT",
        "reasoning",
        "framework",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "tool",
        "LLM",
        "model",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "reasoning",
        "knowledge base",
        "vector",
        "LLM",
        "framework",
        "model",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "fine-tuning",
        "tool",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "API",
        "product",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "vector",
        "LLM",
        "framework",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs",
      "url": "https://arxiv.org/abs/2510.19954",
      "description": "arXiv:2510.19954v1 Announce Type: new \nAbstract: Relational multi-table data is common in domains such as e-commerce, healthcare, and scientific research, and can be naturally represented as heterogeneous temporal graphs with multi-modal node attributes. Existing graph neural networks (GNNs) rely on...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "attention",
        "multimodal",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "context",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "FINDER: Feature Inference on Noisy Datasets using Eigenspace Residuals",
      "url": "https://arxiv.org/abs/2510.19917",
      "description": "arXiv:2510.19917v1 Announce Type: new \nAbstract: ''Noisy'' datasets (regimes with low signal to noise ratios, small sample sizes, faulty data collection, etc) remain a key research frontier for classification methods with both theoretical and practical implications. We introduce FINDER, a rigorous f...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "analysis",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via $f$-Differential Privacy",
      "url": "https://arxiv.org/abs/2510.19934",
      "description": "arXiv:2510.19934v1 Announce Type: new \nAbstract: Differentially private (DP) decentralized Federated Learning (FL) allows local users to collaborate without sharing their data with a central server. However, accurately quantifying the privacy budget of private FL algorithms is challenging due to the...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "tool",
        "framework",
        "paper",
        "experiment"
      ],
      "score": 0.6
    },
    {
      "title": "Are Greedy Task Orderings Better Than Random in Continual Linear Regression?",
      "url": "https://arxiv.org/abs/2510.19941",
      "description": "arXiv:2510.19941v1 Announce Type: new \nAbstract: We analyze task orderings in continual learning for linear regression, assuming joint realizability of training data. We focus on orderings that greedily maximize dissimilarity between consecutive tasks, a concept briefly explored in prior work but st...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "tool",
        "RAG"
      ],
      "score": 0.6
    },
    {
      "title": "MMAO-Bench: MultiModal All in One Benchmark Reveals Compositional Law between Uni-modal and Omni-modal in OmniModels",
      "url": "https://arxiv.org/abs/2510.18915",
      "description": "arXiv:2510.18915v1 Announce Type: new \nAbstract: Multimodal Large Languages models have been progressing from uni-modal understanding toward unifying visual, audio and language modalities, collectively termed omni models. However, the correlation between uni-modal and omni-modal remains unclear, whi...",
      "published_date": "2025-10-23T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "arxiv",
        "reasoning",
        "multimodal",
        "experiment",
        "model",
        "cross-modal",
        "audio"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "paper",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "A new wave of vehicle insurance fraud fueled by generative AI",
      "url": "https://arxiv.org/abs/2510.19957",
      "description": "arXiv:2510.19957v1 Announce Type: new \nAbstract: Generative AI is supercharging insurance fraud by making it easier to falsify accident evidence at scale and in rapid time. Insurance fraud is a pervasive and costly problem, amounting to tens of billions of dollars in losses each year. In the vehicle...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "API",
        "image",
        "tool",
        "paper",
        "ICL"
      ],
      "score": 0.4
    },
    {
      "title": "An Integrated Approach to Neural Architecture Search for Deep Q-Networks",
      "url": "https://arxiv.org/abs/2510.19872",
      "description": "arXiv:2510.19872v1 Announce Type: new \nAbstract: The performance of deep reinforcement learning agents is fundamentally constrained by their neural network architecture, a choice traditionally made through expensive hyperparameter searches and then fixed throughout training. This work investigates w...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable SHAP-Guided Feature Selection and Classification",
      "url": "https://arxiv.org/abs/2510.19896",
      "description": "arXiv:2510.19896v1 Announce Type: new \nAbstract: In this paper, we propose an approach to support the diagnosis of urinary tract diseases, with a focus on bladder cancer, using SHAP (SHapley Additive exPlanations)-based feature selection to enhance the transparency and effectiveness of predictive mo...",
      "published_date": "2025-10-24T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "Sentence Transformers is joining Hugging Face!",
      "url": "https://huggingface.co/blog/sentence-transformers-joins-hf",
      "description": "...",
      "published_date": "2025-10-22T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "transformer"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}