{
  "generated_at": "2025-09-15T20:05:59.728004",
  "total_items": 47,
  "items": [
    {
      "title": "Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs",
      "url": "https://arxiv.org/abs/2509.09699",
      "description": "arXiv:2509.09699v1 Announce Type: new \nAbstract: Mapping clinical documents to standardised clinical vocabularies is an important task, as it provides structured data for information retrieval and analysis, which is essential to clinical research, hospital administration and improving patient care. ...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "experiment",
        "retrieval",
        "arxiv",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Cross-Layer Attention Probing for Fine-Grained Hallucination Detection",
      "url": "https://arxiv.org/abs/2509.09700",
      "description": "arXiv:2509.09700v1 Announce Type: new \nAbstract: With the large-scale adoption of Large Language Models (LLMs) in various applications, there is a growing reliability concern due to their tendency to generate inaccurate text, i.e. hallucinations. In this work, we propose Cross-Layer Attention Probin...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "prompt",
        "large language model",
        "model",
        "attention",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Creativity Benchmark: A benchmark for marketing creativity for LLM models",
      "url": "https://arxiv.org/abs/2509.09702",
      "description": "arXiv:2509.09702v1 Announce Type: new \nAbstract: We introduce Creativity Benchmark, an evaluation framework for large language models (LLMs) in marketing creativity. The benchmark covers 100 brands (12 categories) and three prompt types (Insights, Ideas, Wild Ideas). Human pairwise preferences from ...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "prompt",
        "large language model",
        "framework",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor",
      "url": "https://arxiv.org/abs/2509.09703",
      "description": "arXiv:2509.09703v1 Announce Type: new \nAbstract: The widespread deployment of large language models (LLMs) has intensified concerns around intellectual property (IP) protection, as model theft and unauthorized redistribution become increasingly feasible. To address this, model fingerprinting aims to...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "experiment",
        "arxiv",
        "large language model",
        "framework",
        "model",
        "ICL",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Temporal Preferences in Language Models for Long-Horizon Assistance",
      "url": "https://arxiv.org/abs/2509.09704",
      "description": "arXiv:2509.09704v1 Announce Type: new \nAbstract: We study whether language models (LMs) exhibit future- versus present-oriented preferences in intertemporal choice and whether those preferences can be systematically manipulated. Using adapted human experimental protocols, we evaluate multiple LMs on...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "research",
        "context",
        "experiment",
        "reasoning",
        "arxiv",
        "prompt",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal",
      "url": "https://arxiv.org/abs/2509.09708",
      "description": "arXiv:2509.09708v1 Announce Type: new \nAbstract: Refusal on harmful prompts is a key safety behaviour in instruction-tuned large language models (LLMs), yet the internal causes of this behaviour remain poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT and LLaMA-3.1-8B-IT...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "study",
        "instruction",
        "arxiv",
        "prompt",
        "large language model",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement",
      "url": "https://arxiv.org/abs/2509.09709",
      "description": "arXiv:2509.09709v1 Announce Type: new \nAbstract: Large language models (LLMs) like ChatGPT are increasingly used in academic writing, yet issues such as incorrect or fabricated references raise ethical concerns. Moreover, current content quality evaluations often rely on subjective human judgment, w...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "research",
        "context",
        "experiment",
        "GPT",
        "arxiv",
        "prompt",
        "large language model",
        "framework",
        "model",
        "LLM",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data",
      "url": "https://arxiv.org/abs/2509.09710",
      "description": "arXiv:2509.09710v1 Announce Type: new \nAbstract: This study introduces a Large Language Model (LLM) scheme for generating individual travel diaries in agent-based transportation models. While traditional approaches rely on large quantities of proprietary household travel surveys, the method presente...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "study",
        "zero-shot",
        "arxiv",
        "prompt",
        "large language model",
        "model",
        "LLM",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Human-AI Collaboration Increases Efficiency in Regulatory Writing",
      "url": "https://arxiv.org/abs/2509.09738",
      "description": "arXiv:2509.09738v1 Announce Type: new \nAbstract: Background: Investigational New Drug (IND) application preparation is time-intensive and expertise-dependent, slowing early clinical development. Objective: To evaluate whether a large language model (LLM) platform (AutoIND) can reduce first-draft com...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "platform",
        "analysis",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "How well can LLMs provide planning feedback in grounded environments?",
      "url": "https://arxiv.org/abs/2509.09790",
      "description": "arXiv:2509.09790v1 Announce Type: new \nAbstract: Learning to plan in grounded environments typically requires carefully designed reward functions or high-quality annotated demonstrations. Recent works show that pretrained foundation models, such as large language models (LLMs) and vision language mo...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "context",
        "in-context",
        "demonstration",
        "reasoning",
        "vision",
        "arxiv",
        "large language model",
        "model",
        "chain-of-thought",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Towards a Common Framework for Autoformalization",
      "url": "https://arxiv.org/abs/2509.09810",
      "description": "arXiv:2509.09810v1 Announce Type: new \nAbstract: Autoformalization has emerged as a term referring to the automation of formalization - specifically, the formalization of mathematics using interactive theorem provers (proof assistants). Its rapid development has been driven by progress in deep learn...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "API",
        "RAG",
        "reasoning",
        "arxiv",
        "paper",
        "large language model",
        "framework",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation",
      "url": "https://arxiv.org/abs/2509.09848",
      "description": "arXiv:2509.09848v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly being recognised as valuable knowledge communication tools in many industries. However, their application in livestock farming remains limited, being constrained by several factors not least the availabili...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "study",
        "knowledge base",
        "context",
        "RAG",
        "experiment",
        "retrieval",
        "analysis",
        "tool",
        "arxiv",
        "large language model",
        "augmented",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO",
      "url": "https://arxiv.org/abs/2509.09867",
      "description": "arXiv:2509.09867v1 Announce Type: new \nAbstract: LLMs promise to assist humans -- not just by answering questions, but by offering useful guidance across a wide range of tasks. But how far does that assistance go? Can a large language model based agent actually help someone accomplish their goal as ...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "tool",
        "arxiv",
        "prompt",
        "large language model",
        "model",
        "LLM",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference",
      "url": "https://arxiv.org/abs/2509.09747",
      "description": "arXiv:2509.09747v1 Announce Type: new \nAbstract: Cross-modal transfer learning is used to improve multi-modal classification models (e.g., for human activity recognition in human-robot collaboration). However, existing methods require paired sensor data at both training and inference, limiting deplo...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "audio",
        "alignment",
        "arxiv",
        "cross-modal",
        "framework",
        "attention",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Meta-Learning Reinforcement Learning for Crypto-Return Prediction",
      "url": "https://arxiv.org/abs/2509.09751",
      "description": "arXiv:2509.09751v1 Announce Type: new \nAbstract: Predicting cryptocurrency returns is notoriously difficult: price movements are driven by a fast-shifting blend of on-chain activity, news flow, and social sentiment, while labeled training data are scarce and expensive. In this paper, we present Meta...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "instruction",
        "RAG",
        "experiment",
        "vision",
        "multimodal",
        "arxiv",
        "paper",
        "transformer",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation",
      "url": "https://arxiv.org/abs/2509.09754",
      "description": "arXiv:2509.09754v1 Announce Type: new \nAbstract: KV Cache is commonly used to accelerate LLM inference with long contexts, yet its high memory demand drives the need for cache compression. Existing compression methods, however, are largely heuristic and lack dynamic budget allocation. To address thi...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "context",
        "experiment",
        "arxiv",
        "transformer",
        "compression",
        "framework",
        "memory",
        "attention",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection",
      "url": "https://arxiv.org/abs/2509.09782",
      "description": "arXiv:2509.09782v1 Announce Type: new \nAbstract: The proliferation of large language models (LLMs) with varying computational costs and performance profiles presents a critical challenge for scalable, cost-effective deployment in real-world applications. We introduce a unified routing framework that...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "arxiv",
        "large language model",
        "framework",
        "model",
        "attention",
        "ICL",
        "LLM",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "HGEN: Heterogeneous Graph Ensemble Networks",
      "url": "https://arxiv.org/abs/2509.09843",
      "description": "arXiv:2509.09843v1 Announce Type: new \nAbstract: This paper presents HGEN that pioneers ensemble learning for heterogeneous graphs. We argue that the heterogeneity in node types, nodal features, and local neighborhood topology poses significant challenges for ensemble learning, particularly in accom...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "paper",
        "framework",
        "attention",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context window",
        "prompt",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "audio",
        "reasoning",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "tool",
        "prompt",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "RAG",
        "reasoning",
        "retrieval",
        "knowledge base",
        "framework",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "fine-tuning",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "RAG",
        "retrieval",
        "augmented",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "platform",
        "prompt",
        "framework",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "framework",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks",
      "url": "https://arxiv.org/abs/2509.09705",
      "description": "arXiv:2509.09705v1 Announce Type: new \nAbstract: This work explores the consistency of small LLMs (2B-8B parameters) in answering multiple times the same question. We present a study on known, open-source LLMs responding to 10 repetitions of questions from the multiple-choice benchmarks MMLU-Redux a...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "tool",
        "arxiv",
        "LLM",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Distinguishing Startle from Surprise Events Based on Physiological Signals",
      "url": "https://arxiv.org/abs/2509.09799",
      "description": "arXiv:2509.09799v1 Announce Type: new \nAbstract: Unexpected events can impair attention and delay decision-making, posing serious safety risks in high-risk environments such as aviation. In particular, reactions like startle and surprise can impact pilot performance in different ways, yet are often ...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "attention",
        "research",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "model",
        "context",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task",
      "url": "https://arxiv.org/abs/2509.09701",
      "description": "arXiv:2509.09701v1 Announce Type: new \nAbstract: End-to-end speech-to-text translation typically suffers from the scarcity of paired speech-text data. One way to overcome this shortcoming is to utilize the bitext data from the Machine Translation (MT) task and perform Multi-Task Learning (MTL). In t...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "experiment"
      ],
      "score": 0.6
    },
    {
      "title": "A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes",
      "url": "https://arxiv.org/abs/2509.09794",
      "description": "arXiv:2509.09794v1 Announce Type: new \nAbstract: Computational models have emerged as powerful tools for energy modeling research, touting scalability and quantitative results. However, these models require a plethora of data, some of which is inaccessible, expensive, or raises privacy concerns. We ...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "experiment",
        "multimodal",
        "tool",
        "arxiv",
        "framework",
        "ICL",
        "model",
        "image"
      ],
      "score": 0.6
    },
    {
      "title": "A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments",
      "url": "https://arxiv.org/abs/2509.09919",
      "description": "arXiv:2509.09919v1 Announce Type: new \nAbstract: Procedural content generation often requires satisfying both designer-specified objectives and adjacency constraints implicitly imposed by the underlying tile set. To address the challenges of jointly optimizing both constraints and objectives, we ref...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "RAG"
      ],
      "score": 0.6
    },
    {
      "title": "Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management",
      "url": "https://arxiv.org/abs/2509.09772",
      "description": "arXiv:2509.09772v1 Announce Type: new \nAbstract: Population health management programs for Medicaid populations coordinate longitudinal outreach and services (e.g., benefits navigation, behavioral health, social needs support, and clinical scheduling) and must be safe, fair, and auditable. We presen...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "arxiv",
        "RAG",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning",
      "url": "https://arxiv.org/abs/2509.09838",
      "description": "arXiv:2509.09838v1 Announce Type: new \nAbstract: Value-based approaches such as DQN are the default methods for off-policy reinforcement learning with discrete-action environments such as Atari. Common policy-based methods are either on-policy and do not effectively learn from off-policy data (e.g. ...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "arxiv",
        "LLM"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture",
      "url": "https://arxiv.org/abs/2509.09775",
      "description": "arXiv:2509.09775v1 Announce Type: new \nAbstract: This paper presents boldsea, Boldachev's semantic-event approach -- an architecture for modeling complex dynamic systems using executable ontologies -- semantic models that act as dynamic structures, directly controlling process execution. We demonstr...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "paper",
        "arxiv",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science",
      "url": "https://arxiv.org/abs/2509.09915",
      "description": "arXiv:2509.09915v1 Announce Type: new \nAbstract: Modern scientific discovery increasingly requires coordinating distributed facilities and heterogeneous resources, forcing researchers to act as manual workflow coordinators rather than scientists. Advances in AI leading to AI agents show exciting new...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "research"
      ],
      "score": 0.4
    },
    {
      "title": "Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae",
      "url": "https://arxiv.org/abs/2509.09982",
      "description": "arXiv:2509.09982v1 Announce Type: new \nAbstract: Evaluating explainable AI (XAI) approaches is a challenging task in general, due to the subjectivity of explanations. In this paper, we focus on tabular data and the specific use case of AI models predicting the values of Boolean functions. We extend ...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "tool",
        "paper",
        "arxiv",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis",
      "url": "https://arxiv.org/abs/2509.09744",
      "description": "arXiv:2509.09744v1 Announce Type: new \nAbstract: The limited availability of labeled brain network data makes it challenging to achieve accurate and interpretable psychiatric diagnoses. While self-supervised learning (SSL) offers a promising solution, existing methods often rely on augmentation stra...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "experiment",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms",
      "url": "https://arxiv.org/abs/2509.09793",
      "description": "arXiv:2509.09793v1 Announce Type: new \nAbstract: In this paper we analyze the Gradient-Step Denoiser and its usage in Plug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms uses off the shelf denoisers to replace a proximity operator or a gradient descent operator of an imag...",
      "published_date": "2025-09-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "image"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}