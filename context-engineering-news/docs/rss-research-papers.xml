<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12</title>
      <link>https://arxiv.org/abs/2509.13569</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13569</guid>
      <description>arXiv:2509.13569v1 Announce Type: new 
Abstract: The rapid advancement of Large Language Models (LLMs) has intensified the need for robust dialogue system evaluation, yet comprehensive assessment remains challenging. Traditional metrics often prove insufficient, and safety considerations are frequen...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, arxiv, paper, API, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>arxiv</category>
      <category>paper</category>
    </item>
    <item>
      <title>Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning</title>
      <link>https://arxiv.org/abs/2509.13624</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13624</guid>
      <description>arXiv:2509.13624v1 Announce Type: new 
Abstract: Large language models are increasingly deployed across diverse applications. This often includes tasks LLMs have not encountered during training. This implies that enumerating and obtaining the high-quality training data for all tasks is infeasible. T...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, model, arxiv, LLM, fine-tuning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>model</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction</title>
      <link>https://arxiv.org/abs/2509.13672</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13672</guid>
      <description>arXiv:2509.13672v1 Announce Type: new 
Abstract: The growing demand for automated writing assistance in diverse academic domains highlights the need for robust Chinese Grammatical Error Correction (CGEC) systems that can adapt across disciplines. However, existing CGEC research largely lacks dedicat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; large language model, model, experiment, research, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>large language model</category>
      <category>model</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness</title>
      <link>https://arxiv.org/abs/2509.13332</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13332</guid>
      <description>arXiv:2509.13332v1 Announce Type: new 
Abstract: As Large Language Models (LLMs) are increasingly adopted as automated judges in benchmarking and reward modeling, ensuring their reliability, efficiency, and robustness has become critical. In this work, we present a systematic comparison of &amp;quot;thinking...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, in-context, model, arxiv, few-shot learning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>in-context</category>
      <category>model</category>
    </item>
    <item>
      <title>Evaluation Awareness Scales Predictably in Open-Weights Large Language Models</title>
      <link>https://arxiv.org/abs/2509.13333</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13333</guid>
      <description>arXiv:2509.13333v1 Announce Type: new 
Abstract: Large language models (LLMs) can internally distinguish between evaluation and deployment contexts, a behaviour known as \emph{evaluation awareness}. This undermines AI safety evaluations, as models may conceal dangerous capabilities during testing. P...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, arxiv, vector, paper, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>arxiv</category>
      <category>vector</category>
    </item>
    <item>
      <title>Position: AI Safety Must Embrace an Antifragile Perspective</title>
      <link>https://arxiv.org/abs/2509.13339</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13339</guid>
      <description>arXiv:2509.13339v1 Announce Type: new 
Abstract: This position paper contends that modern AI research must adopt an antifragile perspective on safety -- one in which the system&amp;#x27;s capacity to guarantee long-term AI safety such as handling rare or out-of-distribution (OOD) events expands over time. Co...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, paper, API, alignment, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>paper</category>
      <category>API</category>
    </item>
    <item>
      <title>Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning</title>
      <link>https://arxiv.org/abs/2509.13351</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13351</guid>
      <description>arXiv:2509.13351v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated impressive capabilities across diverse tasks, yet their ability to perform structured symbolic planning remains limited, particularly in domains requiring formal representations like the Planning Domain D...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, instruction, model, arxiv, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>instruction</category>
      <category>model</category>
    </item>
    <item>
      <title>Asterisk Operator</title>
      <link>https://arxiv.org/abs/2509.13364</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13364</guid>
      <description>arXiv:2509.13364v1 Announce Type: new 
Abstract: We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified framework for abstract reasoning based on Adjacency-Structured Parallel Propagation (ASPP). The operator formalizes structured reasoning tasks as local, parallel state evolut...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, framework, embedding, experiment, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>framework</category>
      <category>embedding</category>
    </item>
    <item>
      <title>An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training</title>
      <link>https://arxiv.org/abs/2509.13516</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13516</guid>
      <description>arXiv:2509.13516v1 Announce Type: new 
Abstract: As machine learning models grow increasingly complex and computationally demanding, understanding the environmental impact of training decisions becomes critical for sustainable AI development. This paper presents a comprehensive empirical study inves...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, paper, memory, study, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>paper</category>
      <category>memory</category>
    </item>
    <item>
      <title>Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework</title>
      <link>https://arxiv.org/abs/2509.13520</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13520</guid>
      <description>arXiv:2509.13520v1 Announce Type: new 
Abstract: Neural surrogates and operator networks for solving partial differential equation (PDE) problems have attracted significant research interest in recent years. However, most existing approaches are limited in their ability to generalize solutions acros...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, API, research, analysis, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>API</category>
      <category>research</category>
    </item>
    <item>
      <title>Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection</title>
      <link>https://arxiv.org/abs/2509.13608</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13608</guid>
      <description>arXiv:2509.13608v1 Announce Type: new 
Abstract: As Large Multimodal Models (LMMs) become integral to daily digital life, understanding their safety architectures is a critical problem for AI Alignment. This paper presents a systematic analysis of OpenAI&amp;#x27;s GPT-4o mini, a globally deployed model, on ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, model, arxiv, GPT, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>model</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Unsupervised Anomaly Detection in ALS EPICS Event Logs</title>
      <link>https://arxiv.org/abs/2509.13621</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13621</guid>
      <description>arXiv:2509.13621v1 Announce Type: new 
Abstract: This paper introduces an automated fault analysis framework for the Advanced Light Source (ALS) that processes real-time event logs from its EPICS control system. By treating log entries as natural language, we transform them into contextual vector re...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, paper, API, analysis, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>vector</category>
      <category>paper</category>
      <category>API</category>
    </item>
    <item>
      <title>DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis</title>
      <link>https://arxiv.org/abs/2509.13633</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13633</guid>
      <description>arXiv:2509.13633v1 Announce Type: new 
Abstract: Despite the significant progress of deep learning models in multitude of applications, their adaption in planning and policy related areas remains challenging due to the black-box nature of these models. In this work, we develop a set of DeepLogit mod...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, example, study, transformer, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>example</category>
      <category>study</category>
    </item>
    <item>
      <title>AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation</title>
      <link>https://arxiv.org/abs/2509.13677</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13677</guid>
      <description>arXiv:2509.13677v1 Announce Type: new 
Abstract: Although significant progress has been made in many tasks within the field of Natural Language Processing (NLP), Controlled Text Generation (CTG) continues to face numerous challenges, particularly in achieving fine-grained conditional control over ge...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, prompt, framework, arxiv, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>prompt</category>
      <category>framework</category>
    </item>
    <item>
      <title>OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft</title>
      <link>https://arxiv.org/abs/2509.13347</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13347</guid>
      <description>arXiv:2509.13347v1 Announce Type: new 
Abstract: The choice of action spaces is a critical yet unresolved challenge in developing capable, end-to-end trainable agents. This paper first presents a large-scale, systematic comparison of prominent abstracted action spaces and tokenizers for Vision-Langu...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, model, paper, research, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>model</category>
      <category>paper</category>
    </item>
    <item>
      <title>AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions</title>
      <link>https://arxiv.org/abs/2509.13523</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13523</guid>
      <description>arXiv:2509.13523v1 Announce Type: new 
Abstract: Generative machine learning offers new opportunities to better understand complex Earth system dynamics. Recent diffusion-based methods address spectral biases and improve ensemble calibration in weather forecasting compared to deterministic methods, ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; transformer, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>transformer</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs</title>
      <link>https://arxiv.org/abs/2509.13634</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.13634</guid>
      <description>arXiv:2509.13634v1 Announce Type: new 
Abstract: Federated learning (FL) has gained popularity as a privacy-preserving method of training machine learning models on decentralized networks. However to ensure reliable operation of UAV-assisted FL systems, issues like as excessive energy consumption, c...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, framework, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 18 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>framework</category>
      <category>arxiv</category>
    </item>
  </channel>
</rss>