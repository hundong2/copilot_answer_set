<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Context Engineering Daily</title>
    <link>https://your-username.github.io/context-engineering-news</link>
    <description>Daily news and research updates in AI Context Engineering, Prompt Engineering, RAG, and LLM development</description>
    <language>en-us</language>
    <copyright>Copyright 2026 Context Engineering Daily</copyright>
    <generator>Context Engineering News Generator</generator>
    <lastBuildDate>Tue, 03 Feb 2026 20:12:24 +0000</lastBuildDate>
    <atom:link href="https://your-username.github.io/context-engineering-news/rss.xml" rel="self" type="application/rss+xml"/>
    <category>Technology</category>
    <category>Artificial Intelligence</category>
    <category>Machine Learning</category>
    <item>
      <title>PPoGA: Predictive Plan-on-Graph with Action for Knowledge Graph Question Answering</title>
      <link>https://arxiv.org/abs/2602.00007</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00007</guid>
      <description>arXiv:2602.00007v1 Announce Type: new 
Abstract: Large Language Models (LLMs) augmented with Knowledge Graphs (KGs) have advanced complex question answering, yet they often remain susceptible to failure when their initial high-level reasoning plan is flawed. This limitation, analogous to cognitive f...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, RAG, experiment, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>RAG</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Unlocking Electronic Health Records: A Hybrid Graph RAG Approach to Safe Clinical AI for Patient QA</title>
      <link>https://arxiv.org/abs/2602.00009</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00009</guid>
      <description>arXiv:2602.00009v1 Announce Type: new 
Abstract: Electronic health record (EHR) systems present clinicians with vast repositories of clinical information, creating a significant cognitive burden where critical details are easily overlooked. While Large Language Models (LLMs) offer transformative pot...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, embedding, augmented, RAG, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>vector</category>
      <category>embedding</category>
      <category>augmented</category>
    </item>
    <item>
      <title>G-MemLLM: Gated Latent Memory Augmentation for Long-Context Reasoning in Large Language Models</title>
      <link>https://arxiv.org/abs/2602.00015</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00015</guid>
      <description>arXiv:2602.00015v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, yet they remain constrained by the finite capacity of their context windows and the inherent difficulty of maintaining long-term factual consiste...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, augmented, paper, context, compression | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Context Management</category>
      <category>GPT</category>
      <category>augmented</category>
      <category>paper</category>
    </item>
    <item>
      <title>PTCBENCH: Benchmarking Contextual Stability of Personality Traits in LLM Systems</title>
      <link>https://arxiv.org/abs/2602.00016</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00016</guid>
      <description>arXiv:2602.00016v1 Announce Type: new 
Abstract: With the increasing deployment of large language models (LLMs) in affective agents and AI systems, maintaining a consistent and authentic LLM personality becomes critical for user trust and engagement. However, existing work overlooks a fundamental ps...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, LLM, model, arxiv, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>Construct, Align, and Reason: Large Ontology Models for Enterprise Knowledge Management</title>
      <link>https://arxiv.org/abs/2602.00029</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00029</guid>
      <description>arXiv:2602.00029v1 Announce Type: new 
Abstract: Enterprise-scale knowledge management faces significant challenges in integrating multi-source heterogeneous data and enabling effective semantic reasoning. Traditional knowledge graphs often struggle with implicit relationship discovery and lack suff...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, model, arxiv, reasoning, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Prompt Engineering</category>
      <category>fine-tuning</category>
      <category>model</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>DIVERGE: Diversity-Enhanced RAG for Open-Ended Information Seeking</title>
      <link>https://arxiv.org/abs/2602.00238</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00238</guid>
      <description>arXiv:2602.00238v1 Announce Type: new 
Abstract: Existing retrieval-augmented generation (RAG) systems are primarily designed under the assumption that each query has a single correct answer. This overlooks common information-seeking scenarios with multiple plausible answers, where diversity is esse...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, RAG, retrieval, context, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>RAG</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>Benchmarking Uncertainty Calibration in Large Language Model Long-Form Question Answering</title>
      <link>https://arxiv.org/abs/2602.00279</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00279</guid>
      <description>arXiv:2602.00279v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are commonly used in Question Answering (QA) settings, increasingly in the natural sciences if not science at large. Reliable Uncertainty Quantification (UQ) is critical for the trustworthy uptake of generated answers. Exi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, prompting, retrieval, LLM, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Prompt Engineering</category>
      <category>prompt</category>
      <category>prompting</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>Faithful-Patchscopes: Understanding and Mitigating Model Bias in Hidden Representations Explanation of Large Language Models</title>
      <link>https://arxiv.org/abs/2602.00300</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00300</guid>
      <description>arXiv:2602.00300v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated strong capabilities for hidden representation interpretation through Patchscopes, a framework that uses LLMs themselves to generate human-readable explanations by decoding from internal hidden representat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, example, RAG, context, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>prompt</category>
      <category>example</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes</title>
      <link>https://arxiv.org/abs/2602.00053</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00053</guid>
      <description>arXiv:2602.00053v1 Announce Type: new 
Abstract: Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing req...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, RAG, experiment, analysis, product | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>RAG</category>
      <category>experiment</category>
    </item>
    <item>
      <title>From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models</title>
      <link>https://arxiv.org/abs/2602.00190</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00190</guid>
      <description>arXiv:2602.00190v1 Announce Type: new 
Abstract: Deep learning agents can achieve high performance in complex game domains without often understanding the underlying causal game mechanics. To address this, we investigate Causal Induction: the ability to infer governing laws from observational data, ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, embedding, prompting, context, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Prompt Engineering</category>
      <category>prompt</category>
      <category>embedding</category>
      <category>prompting</category>
    </item>
    <item>
      <title>Localizing and Correcting Errors for LLM-based Planners</title>
      <link>https://arxiv.org/abs/2602.00276</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00276</guid>
      <description>arXiv:2602.00276v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities on math and coding, but frequently fail on symbolic classical planning tasks. Our studies, as well as prior work, show that LLM-generated plans routinely violate domain const...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; example, context, LLM, ICL, demonstration | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>In Context Learning</category>
      <category>example</category>
      <category>context</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning</title>
      <link>https://arxiv.org/abs/2602.00298</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00298</guid>
      <description>arXiv:2602.00298v1 Announce Type: new 
Abstract: Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluatin...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, prompt, fine-tuning, paper, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>GPT</category>
      <category>prompt</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>Autonomous Data Processing using Meta-Agents</title>
      <link>https://arxiv.org/abs/2602.00307</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00307</guid>
      <description>arXiv:2602.00307v1 Announce Type: new 
Abstract: Traditional data processing pipelines are typically static and handcrafted for specific tasks, limiting their adaptability to evolving requirements. While general-purpose agents and coding assistants can generate code for well-understood data pipeline...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, context, arxiv, framework, tool | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>RAG</category>
      <category>context</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?</title>
      <link>https://arxiv.org/abs/2602.00327</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00327</guid>
      <description>arXiv:2602.00327v1 Announce Type: new 
Abstract: We explore the use of large language models (LLMs) for next-utterance prediction in human dialogue. Despite recent advances in LLMs demonstrating their ability to engage in natural conversations with users, we show that even leading models surprisingl...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, experiment, multimodal, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>experiment</category>
      <category>multimodal</category>
    </item>
    <item>
      <title>MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants</title>
      <link>https://arxiv.org/abs/2602.00353</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00353</guid>
      <description>arXiv:2602.00353v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly applied in mental health support systems, where reliable recognition of high-risk states such as suicidal ideation and self-harm is safety-critical. However, existing evaluations primarily rely on aggregat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; platform, LLM, analysis, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>platform</category>
      <category>LLM</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Position: Agentic Evolution is the Path to Evolving LLMs</title>
      <link>https://arxiv.org/abs/2602.00359</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00359</guid>
      <description>arXiv:2602.00359v1 Announce Type: new 
Abstract: As Large Language Models (LLMs) move from curated training sets into open-ended real-world environments, a fundamental limitation emerges: static training cannot keep pace with continual deployment environment change. Scaling training-time and inferen...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, LLM, framework, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Context Management</category>
      <category>fine-tuning</category>
      <category>LLM</category>
      <category>framework</category>
    </item>
    <item>
      <title>OGD4All: A Framework for Accessible Interaction with Geospatial Open Government Data Based on Large Language Models</title>
      <link>https://arxiv.org/abs/2602.00012</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00012</guid>
      <description>arXiv:2602.00012v1 Announce Type: new 
Abstract: We present OGD4All, a transparent, auditable, and reproducible framework based on Large Language Models (LLMs) to enhance citizens&amp;#x27; interaction with geospatial Open Government Data (OGD). The system combines semantic data retrieval, agentic reasoning ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; retrieval, multimodal, LLM, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Chain Of Thought</category>
      <category>retrieval</category>
      <category>multimodal</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Measurement for Opaque Systems: Multi-source Triangulation with Interpretable Machine Learning</title>
      <link>https://arxiv.org/abs/2602.00022</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00022</guid>
      <description>arXiv:2602.00022v1 Announce Type: new 
Abstract: We propose a measurement framework for difficult-to-access contexts that uses indirect data traces, interpretable machine-learning models, and theory-guided triangulation to fill inaccessible measurement spaces. Many high-stakes systems of scientific ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, context, analysis, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>context</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Representation Learning Enhanced Deep Reinforcement Learning for Optimal Operation of Hydrogen-based Multi-Energy Systems</title>
      <link>https://arxiv.org/abs/2602.00027</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00027</guid>
      <description>arXiv:2602.00027v1 Announce Type: new 
Abstract: Hydrogen-based multi-energy systems (HMES) have emerged as a promising low-carbon and energy-efficient solution, as it can enable the coordinated operation of electricity, heating and cooling supply and demand to enhance operational flexibility, impro...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, RAG, experiment, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>RAG</category>
      <category>experiment</category>
    </item>
    <item>
      <title>ELLMPEG: An Edge-based Agentic LLM Video Processing Tool</title>
      <link>https://arxiv.org/abs/2602.00028</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00028</guid>
      <description>arXiv:2602.00028v1 Announce Type: new 
Abstract: Large language models (LLMs), the foundation of generative AI systems like ChatGPT, are transforming many fields and applications, including multimedia, enabling more advanced content generation, analysis, and interaction. However, cloud-based LLM dep...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, prompt, augmented, paper, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>GPT</category>
      <category>prompt</category>
      <category>augmented</category>
    </item>
    <item>
      <title>RAPTOR-AI for Disaster OODA Loop: Hierarchical Multimodal RAG with Experience-Driven Agentic Decision-Making</title>
      <link>https://arxiv.org/abs/2602.00030</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00030</guid>
      <description>arXiv:2602.00030v1 Announce Type: new 
Abstract: Effective humanitarian assistance and disaster relief (HADR) requires rapid situational understanding, reliable decision support, and the ability to generalize across diverse and previously unseen disaster contexts. This work introduces an agentic Ret...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, embedding, knowledge base, RAG, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>embedding</category>
      <category>knowledge base</category>
    </item>
    <item>
      <title>Enhancing few-shot time series forecasting with LLM-guided diffusion</title>
      <link>https://arxiv.org/abs/2602.00040</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00040</guid>
      <description>arXiv:2602.00040v1 Announce Type: new 
Abstract: Time series forecasting in specialized domains is often constrained by limited data availability, where conventional models typically require large-scale datasets to effectively capture underlying temporal dynamics. To tackle this few-shot challenge, ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, LLM, few-shot, analysis, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>LLM</category>
      <category>few-shot</category>
    </item>
    <item>
      <title>Extending Beacon to Hindi: Cultural Adaptation Drives Cross-Lingual Sycophancy</title>
      <link>https://arxiv.org/abs/2602.00046</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00046</guid>
      <description>arXiv:2602.00046v1 Announce Type: new 
Abstract: Sycophancy, the tendency of language models to prioritize agreement with user preferences over principled reasoning, has been identified as a persistent alignment failure in English-language evaluations. However, it remains unclear whether such diagno...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, context, alignment, analysis, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Prompt Engineering</category>
      <category>prompt</category>
      <category>context</category>
      <category>alignment</category>
    </item>
    <item>
      <title>Lightweight Edge Learning via Dataset Pruning</title>
      <link>https://arxiv.org/abs/2602.00047</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00047</guid>
      <description>arXiv:2602.00047v1 Announce Type: new 
Abstract: Edge learning facilitates ubiquitous intelligence by enabling model training and adaptation directly on data-generating devices, thereby mitigating privacy risks and communication latency. However, the high computational and energy overhead of on-devi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, RAG, experiment, image, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>RAG</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Context-Engineering - &amp;quot;Context engineering is the delicate art and science of filling the context window with just the right information for the next step.&amp;quot; â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.</title>
      <link>https://github.com/davidkimai/Context-Engineering</link>
      <guid isPermaLink="false">https://github.com/davidkimai/Context-Engineering</guid>
      <description>&amp;quot;Context engineering is the delicate art and science of filling the context window with just the right information for the next step.&amp;quot; â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, prompt engineering, prompt, context window | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 29 Jun 2025 00:16:36 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>context</category>
      <category>prompt engineering</category>
      <category>prompt</category>
    </item>
    <item>
      <title>ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.</title>
      <link>https://github.com/FunAudioLLM/ThinkSound</link>
      <guid isPermaLink="false">https://github.com/FunAudioLLM/ThinkSound</guid>
      <description>[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; chain-of-thought, CoT, reasoning, framework, audio | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 27 Jun 2025 02:27:00 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>chain-of-thought</category>
      <category>CoT</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>mcp-context-forge - A Model Context Protocol (MCP) Gateway &amp;amp; Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).</title>
      <link>https://github.com/IBM/mcp-context-forge</link>
      <guid isPermaLink="false">https://github.com/IBM/mcp-context-forge</guid>
      <description>A Model Context Protocol (MCP) Gateway &amp;amp; Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, context, LLM, model, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 08 May 2025 08:16:59 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>prompt</category>
      <category>context</category>
      <category>LLM</category>
    </item>
    <item>
      <title>PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG</title>
      <link>https://github.com/VectifyAI/PageIndex</link>
      <guid isPermaLink="false">https://github.com/VectifyAI/PageIndex</guid>
      <description>ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, RAG, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 01 Apr 2025 10:53:54 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>vector</category>
      <category>RAG</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code</title>
      <link>https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-</link>
      <guid isPermaLink="false">https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-</guid>
      <description>A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, framework, chain-of-thought | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 18 Feb 2025 15:45:30 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>context</category>
      <category>framework</category>
      <category>chain-of-thought</category>
    </item>
    <item>
      <title>airweave - Open-source context retrieval layer for AI agents</title>
      <link>https://github.com/airweave-ai/airweave</link>
      <guid isPermaLink="false">https://github.com/airweave-ai/airweave</guid>
      <description>Open-source context retrieval layer for AI agents&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 24 Dec 2024 10:00:06 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>context</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>LightRAG - [EMNLP2025] &amp;quot;LightRAG: Simple and Fast Retrieval-Augmented Generation&amp;quot;</title>
      <link>https://github.com/HKUDS/LightRAG</link>
      <guid isPermaLink="false">https://github.com/HKUDS/LightRAG</guid>
      <description>[EMNLP2025] &amp;quot;LightRAG: Simple and Fast Retrieval-Augmented Generation&amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, RAG, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 02 Oct 2024 11:57:54 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>RAG</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&amp;amp;A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.</title>
      <link>https://github.com/OpenSPG/KAG</link>
      <guid isPermaLink="false">https://github.com/OpenSPG/KAG</guid>
      <description>KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&amp;amp;A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, knowledge base, RAG, retrieval, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sat, 21 Sep 2024 13:56:44 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>vector</category>
      <category>knowledge base</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.</title>
      <link>https://github.com/Kiln-AI/Kiln</link>
      <guid isPermaLink="false">https://github.com/Kiln-AI/Kiln</guid>
      <description>Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 23 Jul 2024 23:10:13 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>fine-tuning</category>
      <category>RAG</category>
    </item>
    <item>
      <title>graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system</title>
      <link>https://github.com/microsoft/graphrag</link>
      <guid isPermaLink="false">https://github.com/microsoft/graphrag</guid>
      <description>A modular graph-based Retrieval-Augmented Generation (RAG) system&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, RAG, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 27 Mar 2024 17:57:52 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>RAG</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.</title>
      <link>https://github.com/SciPhi-AI/R2R</link>
      <guid isPermaLink="false">https://github.com/SciPhi-AI/R2R</guid>
      <description>SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, RAG, retrieval, product, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 12 Feb 2024 03:24:27 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>RAG</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.</title>
      <link>https://github.com/openlit/openlit</link>
      <guid isPermaLink="false">https://github.com/openlit/openlit</guid>
      <description>Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; platform, prompt, vector, LLM, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 23 Jan 2024 17:40:59 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>platform</category>
      <category>prompt</category>
      <category>vector</category>
    </item>
    <item>
      <title>SafeTalkCoach: Diversity-Driven Multi-Agent Simulation for Parent-Teen Health Conversations</title>
      <link>https://arxiv.org/abs/2602.00017</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00017</guid>
      <description>arXiv:2602.00017v1 Announce Type: new 
Abstract: The importance of effective parent-child communication about sexual health is widely acknowledged, but real-world data on these conversations is scarce and challenging to collect, due to their private and sensitive nature. Although LLMs have been wide...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, LLM, company, arxiv, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>LLM</category>
      <category>company</category>
    </item>
    <item>
      <title>Reversible Diffusion Decoding for Diffusion Language Models</title>
      <link>https://arxiv.org/abs/2602.00150</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00150</guid>
      <description>arXiv:2602.00150v1 Announce Type: new 
Abstract: Diffusion language models enable parallel token generation through block-wise decoding, but their irreversible commitments can lead to stagnation, where the reverse diffusion process fails to make further progress under a suboptimal context.We propose...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, experiment, model, arxiv, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>experiment</category>
      <category>model</category>
    </item>
    <item>
      <title>Distributional Reinforcement Learning for Condition-Based Maintenance of Multi-Pump Equipment</title>
      <link>https://arxiv.org/abs/2602.00051</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00051</guid>
      <description>arXiv:2602.00051v1 Announce Type: new 
Abstract: Condition-Based Maintenance (CBM) signifies a paradigm shift from reactive to proactive equipment management strategies in modern industrial systems. Conventional time-based maintenance schedules frequently engender superfluous expenditures and unanti...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, arxiv, paper, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>arxiv</category>
      <category>paper</category>
    </item>
    <item>
      <title>TextBFGS: Quasi-Newton Optimization for Discrete Executable Text via Gradient-Operator Retrieval</title>
      <link>https://arxiv.org/abs/2602.00059</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00059</guid>
      <description>arXiv:2602.00059v1 Announce Type: new 
Abstract: Optimizing discrete executable text such as prompts and code has recently been framed as a gradient-based process, effectively translating backpropagation concepts to the semantic space. However, existing methods predominantly operate as first-order o...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, knowledge base, retrieval, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>prompt</category>
      <category>knowledge base</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!</title>
      <link>https://github.com/tadata-org/fastapi_mcp</link>
      <guid isPermaLink="false">https://github.com/tadata-org/fastapi_mcp</guid>
      <description>Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, API, model, tool | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sat, 08 Mar 2025 11:15:43 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>context</category>
      <category>API</category>
      <category>model</category>
    </item>
    <item>
      <title>cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.</title>
      <link>https://github.com/nvidia-cosmos/cosmos-reason1</link>
      <guid isPermaLink="false">https://github.com/nvidia-cosmos/cosmos-reason1</guid>
      <description>Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, reasoning, chain-of-thought | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 02 Mar 2025 15:23:55 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>model</category>
      <category>reasoning</category>
      <category>chain-of-thought</category>
    </item>
    <item>
      <title>Learning to Price: Interpretable Attribute-Level Models for Dynamic Markets</title>
      <link>https://arxiv.org/abs/2602.00188</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00188</guid>
      <description>arXiv:2602.00188v1 Announce Type: new 
Abstract: Dynamic pricing in high-dimensional markets poses fundamental challenges of scalability, uncertainty, and interpretability. Existing low-rank bandit formulations learn efficiently but rely on latent features that obscure how individual product attribu...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, API, model, product | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Industry News</category>
      <category>arxiv</category>
      <category>API</category>
      <category>model</category>
    </item>
    <item>
      <title>excel-mcp-server - A Model Context Protocol server for Excel file manipulation</title>
      <link>https://github.com/haris-musa/excel-mcp-server</link>
      <guid isPermaLink="false">https://github.com/haris-musa/excel-mcp-server</guid>
      <description>A Model Context Protocol server for Excel file manipulation&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Feb 2025 06:39:48 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Industry News</category>
      <category>context</category>
      <category>model</category>
    </item>
    <item>
      <title>mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns</title>
      <link>https://github.com/lastmile-ai/mcp-agent</link>
      <guid isPermaLink="false">https://github.com/lastmile-ai/mcp-agent</guid>
      <description>Build effective agents using Model Context Protocol and simple workflow patterns&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 18 Dec 2024 01:55:10 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Industry News</category>
      <category>context</category>
      <category>model</category>
    </item>
    <item>
      <title>AlphaCodium - Official implementation for the paper: &amp;quot;Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering&amp;quot;&amp;quot;</title>
      <link>https://github.com/Codium-ai/AlphaCodium</link>
      <guid isPermaLink="false">https://github.com/Codium-ai/AlphaCodium</guid>
      <description>Official implementation for the paper: &amp;quot;Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering&amp;quot;&amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt engineering, prompt, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 14 Jan 2024 15:17:18 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>prompt engineering</category>
      <category>prompt</category>
      <category>paper</category>
    </item>
    <item>
      <title>H Company&amp;#x27;s new Holo2 model takes the lead in UI Localization</title>
      <link>https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b</link>
      <guid isPermaLink="false">https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b</guid>
      <description>...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; Hugging Face Blog | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, company | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 17:40:14 </pubDate>
      <author>noreply@contextengineering.news (Hugging Face Blog)</author>
      <category>Industry News</category>
      <category>model</category>
      <category>company</category>
    </item>
    <item>
      <title>optillm - Optimizing inference proxy for LLMs</title>
      <link>https://github.com/algorithmicsuperintelligence/optillm</link>
      <guid isPermaLink="false">https://github.com/algorithmicsuperintelligence/optillm</guid>
      <description>Optimizing inference proxy for LLMs&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 22 Aug 2024 19:46:07 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Training Design for Text-to-Image Models: Lessons from Ablations</title>
      <link>https://huggingface.co/blog/Photoroom/prx-part2</link>
      <guid isPermaLink="false">https://huggingface.co/blog/Photoroom/prx-part2</guid>
      <description>...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; Hugging Face Blog | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, image | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 20%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 11:25:53 </pubDate>
      <author>noreply@contextengineering.news (Hugging Face Blog)</author>
      <category>Multimodal Context</category>
      <category>model</category>
      <category>image</category>
    </item>
  </channel>
</rss>