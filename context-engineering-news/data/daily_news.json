{
  "generated_at": "2025-09-12T20:05:45.617139",
  "total_items": 48,
  "items": [
    {
      "title": "Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC",
      "url": "https://arxiv.org/abs/2509.08903",
      "description": "arXiv:2509.08903v1 Announce Type: new \nAbstract: RAG and fine-tuning are prevalent strategies for improving the quality of LLM outputs. However, in constrained situations, such as that of the 2025 LM-KBC challenge, such techniques are restricted. In this work we investigate three facets of the tripl...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "fine-tuning",
        "LLM",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach",
      "url": "https://arxiv.org/abs/2509.08907",
      "description": "arXiv:2509.08907v1 Announce Type: new \nAbstract: InfluenceMap's LobbyMap Platform monitors the climate policy engagement of over 500 companies and 250 industry associations, assessing each entity's support or opposition to science-based policy pathways for achieving the Paris Agreement's goal of lim...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "analysis",
        "embedding",
        "few-shot",
        "retrieval",
        "augmented",
        "platform",
        "prompting",
        "arxiv",
        "prompt",
        "framework",
        "RAG",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Documents Are People and Words Are Items: A Psychometric Approach to Textual Data with Contextual Embeddings",
      "url": "https://arxiv.org/abs/2509.08920",
      "description": "arXiv:2509.08920v1 Announce Type: new \nAbstract: This research introduces a novel psychometric method for analyzing textual data using large language models. By leveraging contextual embeddings to create contextual scores, we transform textual data into response data suitable for psychometric analys...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "embedding",
        "research",
        "experiment",
        "transformer",
        "arxiv",
        "RAG",
        "context",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "BRoverbs -- Measuring how much LLMs understand Portuguese proverbs",
      "url": "https://arxiv.org/abs/2509.08960",
      "description": "arXiv:2509.08960v1 Announce Type: new \nAbstract: Large Language Models (LLMs) exhibit significant performance variations depending on the linguistic and cultural context in which they are applied. This disparity signals the necessity of mature evaluation frameworks that can assess their capabilities...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "analysis",
        "arxiv",
        "LLM",
        "framework",
        "tool",
        "context",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation",
      "url": "https://arxiv.org/abs/2509.09043",
      "description": "arXiv:2509.09043v1 Announce Type: new \nAbstract: We introduce and evaluate Stated Preference for Interaction and Continued Engagement (SPICE), a simple diagnostic signal elicited by asking a Large Language Model a YES or NO question about its willingness to re-engage with a user's behavior after rev...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "CoT",
        "release",
        "arxiv",
        "LLM",
        "tool",
        "study",
        "context",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M",
      "url": "https://arxiv.org/abs/2509.09055",
      "description": "arXiv:2509.09055v1 Announce Type: new \nAbstract: This research investigates the effectiveness of alignment techniques, Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a combined SFT+DPO approach on improving the safety and helpfulness of the OPT-350M language model. Utilizing...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "alignment",
        "fine-tuning",
        "research",
        "RLHF",
        "arxiv",
        "LLM",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "MR-UIE: Multi-Perspective Reasoning with Reinforcement Learning for Universal Information Extraction",
      "url": "https://arxiv.org/abs/2509.09082",
      "description": "arXiv:2509.09082v1 Announce Type: new \nAbstract: Large language models (LLMs) demonstrate robust capabilities across diverse research domains. However, their performance in universal information extraction (UIE) remains insufficient, especially when tackling structured output scenarios that involve ...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "experiment",
        "reasoning",
        "arxiv",
        "LLM",
        "large language model",
        "context",
        "model",
        "instruction",
        "in-context"
      ],
      "score": 1.0
    },
    {
      "title": "TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla",
      "url": "https://arxiv.org/abs/2509.09101",
      "description": "arXiv:2509.09101v1 Announce Type: new \nAbstract: Despite being the 5th most spoken language, Bangla remains underrepresented in Large Language Models (LLMs), particularly for code generation. This primarily stems from the scarcity of high-quality data to pre-train and/or finetune such models. Hence,...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "LLM",
        "model",
        "instruction",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia",
      "url": "https://arxiv.org/abs/2509.09121",
      "description": "arXiv:2509.09121v1 Announce Type: new \nAbstract: Large language models (LLMs) excel in general-domain applications, yet their performance often degrades in specialized tasks requiring domain-specific knowledge. E-commerce is particularly challenging, as its data are noisy, heterogeneous, multilingua...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "alignment",
        "platform",
        "arxiv",
        "LLM",
        "model",
        "instruction",
        "large language model",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs",
      "url": "https://arxiv.org/abs/2509.08847",
      "description": "arXiv:2509.08847v1 Announce Type: new \nAbstract: This paper presents a novel framework for automated game template generation by transforming Game Design Documents (GDDs) into functional Unity game prototypes using Natural Language Processing (NLP) and multi-modal Large Language Models (LLMs). We in...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "template",
        "arxiv",
        "LLM",
        "tool",
        "RAG",
        "framework",
        "paper",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Global Constraint LLM Agents for Text-to-Model Translation",
      "url": "https://arxiv.org/abs/2509.08970",
      "description": "arXiv:2509.08970v1 Announce Type: new \nAbstract: Natural language descriptions of optimization or satisfaction problems are challenging to translate into correct MiniZinc models, as this process demands both logical reasoning and constraint programming expertise. We introduce a framework that addres...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "experiment",
        "reasoning",
        "chain-of-thought",
        "prompting",
        "arxiv",
        "prompt",
        "LLM",
        "framework",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Instructional Prompt Optimization for Few-Shot LLM-Based Recommendations on Cold-Start Users",
      "url": "https://arxiv.org/abs/2509.09066",
      "description": "arXiv:2509.09066v1 Announce Type: new \nAbstract: The cold-start user issue further compromises the effectiveness of recommender systems in limiting access to the historical behavioral information. It is an effective pipeline to optimize instructional prompts on a few-shot large language model (LLM) ...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "alignment",
        "embedding",
        "few-shot",
        "experiment",
        "transformer",
        "attention",
        "arxiv",
        "LLM",
        "prompt",
        "paper",
        "context",
        "model",
        "instruction",
        "large language model",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games",
      "url": "https://arxiv.org/abs/2509.09071",
      "description": "arXiv:2509.09071v1 Announce Type: new \nAbstract: Coordination tasks traditionally performed by humans are increasingly being delegated to autonomous agents. As this pattern progresses, it becomes critical to evaluate not only these agents' performance but also the processes through which they negoti...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "alignment",
        "arxiv",
        "LLM",
        "context",
        "model",
        "large language model",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective",
      "url": "https://arxiv.org/abs/2509.09154",
      "description": "arXiv:2509.09154v1 Announce Type: new \nAbstract: Recent advances in agentic AI have led to systems capable of autonomous task execution and language-based reasoning, yet their spatial reasoning abilities remain limited and underexplored, largely constrained to symbolic and sequential processing. In ...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "research",
        "reasoning",
        "memory",
        "arxiv",
        "multimodal",
        "framework",
        "context",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Instance-Optimal Matrix Multiplicative Weight Update and Its Quantum Applications",
      "url": "https://arxiv.org/abs/2509.08911",
      "description": "arXiv:2509.08911v1 Announce Type: new \nAbstract: The Matrix Multiplicative Weight Update (MMWU) is a seminal online learning algorithm with numerous applications. Applied to the matrix version of the Learning from Expert Advice (LEA) problem on the $d$-dimensional spectraplex, it is well known that ...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "memory",
        "arxiv",
        "paper",
        "framework",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "FoundationalECGNet: A Lightweight Foundational Model for ECG-based Multitask Cardiac Analysis",
      "url": "https://arxiv.org/abs/2509.08961",
      "description": "arXiv:2509.08961v1 Announce Type: new \nAbstract: Cardiovascular diseases (CVDs) remain a leading cause of mortality worldwide, underscoring the importance of accurate and scalable diagnostic systems. Electrocardiogram (ECG) analysis is central to detecting cardiac abnormalities, yet challenges such ...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "transformer",
        "attention",
        "arxiv",
        "framework",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Green Federated Learning via Carbon-Aware Client and Time Slot Scheduling",
      "url": "https://arxiv.org/abs/2509.08980",
      "description": "arXiv:2509.08980v1 Announce Type: new \nAbstract: Training large-scale machine learning models incurs substantial carbon emissions. Federated Learning (FL), by distributing computation across geographically dispersed clients, offers a natural framework to leverage regional and temporal variations in ...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "experiment",
        "arxiv",
        "paper",
        "framework",
        "RAG",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Fast attention mechanisms: a tale of parallelism",
      "url": "https://arxiv.org/abs/2509.09001",
      "description": "arXiv:2509.09001v1 Announce Type: new \nAbstract: Transformers have the representational capacity to simulate Massively Parallel Computation (MPC) algorithms, but they suffer from quadratic time complexity, which severely limits their scalability. We introduce an efficient attention mechanism called ...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "transformer",
        "reasoning",
        "attention",
        "arxiv",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Open-sci-ref-0.01: open and reproducible reference baselines for language model and dataset comparison",
      "url": "https://arxiv.org/abs/2509.09009",
      "description": "arXiv:2509.09009v1 Announce Type: new \nAbstract: We introduce open-sci-ref, a family of dense transformer models trained as research baselines across multiple model (0.13B to 1.7B parameters) and token scales (up to 1T) on 8 recent open reference datasets. Evaluating the models on various standardiz...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "product",
        "research",
        "transformer",
        "release",
        "study",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context window",
        "prompt",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "LLM",
        "tool",
        "prompt",
        "context",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "context",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "knowledge base",
        "reasoning",
        "retrieval",
        "LLM",
        "framework",
        "vector",
        "RAG",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "automated-prompt-engineering-from-scratch - A repo with an automated prompt engineering workflow from scratch. It leverages the OPRO technique.",
      "url": "https://github.com/heiko-hotz/automated-prompt-engineering-from-scratch",
      "description": "A repo with an automated prompt engineering workflow from scratch. It leverages the OPRO technique.",
      "published_date": "2024-08-12T11:41:09+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "fine-tuning",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "product",
        "retrieval",
        "API",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "LLM",
        "prompt",
        "framework",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Value bounds and Convergence Analysis for Averages of LRP attributions",
      "url": "https://arxiv.org/abs/2509.08963",
      "description": "arXiv:2509.08963v1 Announce Type: new \nAbstract: We analyze numerical properties of Layer-wise relevance propagation (LRP)-type attribution methods by representing them as a product of modified gradient matrices. This representation creates an analogy to matrix multiplications of Jacobi-matrices whi...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "product",
        "analysis",
        "arxiv",
        "RAG"
      ],
      "score": 0.8
    },
    {
      "title": "Tricks from OpenAI gpt-oss YOU 🫵 can use with transformers",
      "url": "https://huggingface.co/blog/faster-transformers",
      "description": "...",
      "published_date": "2025-09-11T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "transformer",
        "GPT"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "model",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Uncertainty Awareness and Trust in Explainable AI- On Trust Calibration using Local and Global Explanations",
      "url": "https://arxiv.org/abs/2509.08989",
      "description": "arXiv:2509.08989v1 Announce Type: new \nAbstract: Explainable AI has become a common term in the literature, scrutinized by computer scientists and statisticians and highlighted by psychological or philosophical researchers. One major effort many researchers tackle is constructing general guidelines ...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "research"
      ],
      "score": 0.6
    },
    {
      "title": "Anti-Money Laundering Machine Learning Pipelines; A Technical Analysis on Identifying High-risk Bank Clients with Supervised Learning",
      "url": "https://arxiv.org/abs/2509.09127",
      "description": "arXiv:2509.09127v1 Announce Type: new \nAbstract: Anti-money laundering (AML) actions and measurements are among the priorities of financial institutions, for which machine learning (ML) has shown to have a high potential. In this paper, we propose a comprehensive and systematic approach for developi...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "paper",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Group Distributionally Robust Machine Learning under Group Level Distributional Uncertainty",
      "url": "https://arxiv.org/abs/2509.08942",
      "description": "arXiv:2509.08942v1 Announce Type: new \nAbstract: The performance of machine learning (ML) models critically depends on the quality and representativeness of the training data. In applications with multiple heterogeneous data generating sources, standard ML methods often learn spurious correlations t...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "arxiv",
        "framework",
        "RAG"
      ],
      "score": 0.6
    },
    {
      "title": "Active Learning and Explainable AI for Multi-Objective Optimization of Spin Coated Polymers",
      "url": "https://arxiv.org/abs/2509.08988",
      "description": "arXiv:2509.08988v1 Announce Type: new \nAbstract: Spin coating polymer thin films to achieve specific mechanical properties is inherently a multi-objective optimization problem. We present a framework that integrates an active Pareto front learning algorithm (PyePAL) with visualization and explainabl...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "experiment",
        "arxiv",
        "framework",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "ReasonFlux - ReasonFlux Series - A family of LLM post-training algorithms focusing on long-cot data selection, reinforcement learning, and inference scaling",
      "url": "https://github.com/Gen-Verse/ReasonFlux",
      "description": "ReasonFlux Series - A family of LLM post-training algorithms focusing on long-cot data selection, reinforcement learning, and inference scaling",
      "published_date": "2025-02-10T11:04:39+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "LLM"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "Can Vision-Language Models Solve Visual Math Equations?",
      "url": "https://arxiv.org/abs/2509.09013",
      "description": "arXiv:2509.09013v1 Announce Type: new \nAbstract: Despite strong performance in visual understanding and language-based reasoning, Vision-Language Models (VLMs) struggle with tasks requiring integrated perception and symbolic computation. We study this limitation through visual equation solving, wher...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "reasoning",
        "vision",
        "study",
        "arxiv",
        "model",
        "image"
      ],
      "score": 0.4
    },
    {
      "title": "An Interval Type-2 Version of Bayes Theorem Derived from Interval Probability Range Estimates Provided by Subject Matter Experts",
      "url": "https://arxiv.org/abs/2509.08834",
      "description": "arXiv:2509.08834v1 Announce Type: new \nAbstract: Bayesian inference is widely used in many different fields to test hypotheses against observations. In most such applications, an assumption is made of precise input values to produce a precise output value. However, this is unrealistic for real-world...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "ForTIFAI: Fending Off Recursive Training Induced Failure for AI Models",
      "url": "https://arxiv.org/abs/2509.08972",
      "description": "arXiv:2509.08972v1 Announce Type: new \nAbstract: The increasing reliance on generative AI models has accelerated the generation rate of synthetic data, with some projections suggesting that most available new data for training could be machine-generated by 2030. This shift to a mainly synthetic cont...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "paper",
        "framework",
        "tool",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Corruption-Tolerant Asynchronous Q-Learning with Near-Optimal Rates",
      "url": "https://arxiv.org/abs/2509.08933",
      "description": "arXiv:2509.08933v1 Announce Type: new \nAbstract: We consider the problem of learning the optimal policy in a discounted, infinite-horizon reinforcement learning (RL) setting where the reward signal is subject to adversarial corruption. Such corruption, which may arise from extreme noise, sensor faul...",
      "published_date": "2025-09-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "model",
        "arxiv",
        "tool"
      ],
      "score": 0.4
    },
    {
      "title": "Jupyter Agents: training LLMs to reason with notebooks",
      "url": "https://huggingface.co/blog/jupyter-agent-2",
      "description": "...",
      "published_date": "2025-09-10T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}