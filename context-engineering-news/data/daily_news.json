{
  "generated_at": "2026-01-29T20:08:23.009410",
  "total_items": 48,
  "items": [
    {
      "title": "Modeling Next-Token Prediction as Left-Nested Intuitionistic Implication",
      "url": "https://arxiv.org/abs/2601.19915",
      "description": "arXiv:2601.19915v1 Announce Type: new \nAbstract: We introduce the \\emph{Arrow Language Model}, a neural architecture derived from an intuitionistic-logic interpretation of next-token prediction. Instead of representing tokens as additive embeddings mixed by attention, we encode a prefix as a \\emph{l...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "embedding",
        "model",
        "transformer",
        "attention",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "PaperAudit-Bench: Benchmarking Error Detection in Research Papers for Critical Automated Peer Review",
      "url": "https://arxiv.org/abs/2601.19916",
      "description": "arXiv:2601.19916v1 Announce Type: new \nAbstract: Large language models can generate fluent peer reviews, yet their assessments often lack sufficient critical rigor when substantive issues are subtle and distributed across a paper. In this paper, we introduce PaperAudit-Bench, which consists of two c...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "context",
        "model",
        "research",
        "LLM",
        "reasoning",
        "paper",
        "framework",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "PILOT: Planning via Internalized Latent Optimization Trajectories for Large Language Models",
      "url": "https://arxiv.org/abs/2601.19917",
      "description": "arXiv:2601.19917v1 Announce Type: new \nAbstract: Strategic planning is critical for multi-step reasoning, yet compact Large Language Models (LLMs) often lack the capacity to formulate global strategies, leading to error propagation in long-horizon tasks. Our analysis reveals that LLMs possess latent...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "experiment",
        "model",
        "vector",
        "LLM",
        "reasoning",
        "framework",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Lowest Span Confidence: A Zero-Shot Metric for Efficient and Black-Box Hallucination Detection in LLMs",
      "url": "https://arxiv.org/abs/2601.19918",
      "description": "arXiv:2601.19918v1 Announce Type: new \nAbstract: Hallucinations in Large Language Models (LLMs), i.e., the tendency to generate plausible but non-factual content, pose a significant challenge for their reliable deployment in high-stakes environments. However, existing hallucination detection methods...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "model",
        "LLM",
        "zero-shot",
        "large language model",
        "API",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Demystifying Multi-Agent Debate: The Role of Confidence and Diversity",
      "url": "https://arxiv.org/abs/2601.19921",
      "description": "arXiv:2601.19921v1 Announce Type: new \nAbstract: Multi-agent debate (MAD) is widely used to improve large language model (LLM) performance through test-time scaling, yet recent work shows that vanilla MAD often underperforms simple majority vote despite higher computational cost. Studies show that, ...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "LLM",
        "reasoning",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "HEART: A Unified Benchmark for Assessing Humans and LLMs in Emotional Support Dialogue",
      "url": "https://arxiv.org/abs/2601.19922",
      "description": "arXiv:2601.19922v1 Announce Type: new \nAbstract: Supportive conversation depends on skills that go beyond language fluency, including reading emotions, adjusting tone, and navigating moments of resistance, frustration, or distress. Despite rapid progress in language models, we still lack a clear way...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "RAG",
        "model",
        "alignment",
        "LLM",
        "reasoning",
        "framework",
        "API",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Table-BiEval: A Self-Supervised, Dual-Track Framework for Decoupling Structure and Content in LLM Evaluation",
      "url": "https://arxiv.org/abs/2601.19923",
      "description": "arXiv:2601.19923v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) evolve into autonomous agents, the capability to faithfully translate natural language into rigorous structured formats-essential for tool invocation-and to convert complex tabular information into machine-readable spec...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "RAG",
        "model",
        "LLM",
        "paper",
        "tool",
        "framework",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning",
      "url": "https://arxiv.org/abs/2601.20014",
      "description": "arXiv:2601.20014v1 Announce Type: new \nAbstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "LLM",
        "reasoning",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Insight Agents: An LLM-Based Multi-Agent System for Data Insights",
      "url": "https://arxiv.org/abs/2601.20048",
      "description": "arXiv:2601.20048v1 Announce Type: new \nAbstract: Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Ins...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "model",
        "LLM",
        "paper",
        "tool",
        "retrieval",
        "API",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Should I Have Expressed a Different Intent? Counterfactual Generation for LLM-Based Autonomous Control",
      "url": "https://arxiv.org/abs/2601.20090",
      "description": "arXiv:2601.20090v1 Announce Type: new \nAbstract: Large language model (LLM)-powered agents can translate high-level user intents into plans and actions in an environment. Yet after observing an outcome, users may wonder: What if I had phrased my intent differently? We introduce a framework that enab...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "RAG",
        "model",
        "LLM",
        "reasoning",
        "framework",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Towards Intelligent Urban Park Development Monitoring: LLM Agents for Multi-Modal Information Fusion and Analysis",
      "url": "https://arxiv.org/abs/2601.20206",
      "description": "arXiv:2601.20206v1 Announce Type: new \nAbstract: As an important part of urbanization, the development monitoring of newly constructed parks is of great significance for evaluating the effect of urban planning and optimizing resource allocation. However, traditional change detection methods based on...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "analysis",
        "alignment",
        "LLM",
        "study",
        "reasoning",
        "image",
        "tool",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning",
      "url": "https://arxiv.org/abs/2601.20221",
      "description": "arXiv:2601.20221v1 Announce Type: new \nAbstract: Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning tra...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "reasoning",
        "vision",
        "tool",
        "framework",
        "retrieval",
        "large language model",
        "augmented",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Endogenous Reprompting: Self-Evolving Cognitive Alignment for Unified Multimodal Models",
      "url": "https://arxiv.org/abs/2601.20305",
      "description": "arXiv:2601.20305v1 Announce Type: new \nAbstract: Unified Multimodal Models (UMMs) exhibit strong understanding, yet this capability often fails to effectively guide generation. We identify this as a Cognitive Gap: the model lacks the understanding of how to enhance its own generation process. To bri...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "instruction",
        "RAG",
        "prompting",
        "experiment",
        "model",
        "prompt",
        "alignment",
        "reasoning",
        "framework",
        "multimodal",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "ECG-Agent: On-Device Tool-Calling Agent for ECG Multi-Turn Dialogue",
      "url": "https://arxiv.org/abs/2601.20323",
      "description": "arXiv:2601.20323v1 Announce Type: new \nAbstract: Recent advances in Multimodal Large Language Models have rapidly expanded to electrocardiograms, focusing on classification, report generation, and single-turn QA tasks. However, these models fall short in real-world scenarios, lacking multi-turn conv...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "experiment",
        "model",
        "LLM",
        "tool",
        "large language model",
        "API",
        "multimodal",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "AMA: Adaptive Memory via Multi-Agent Collaboration",
      "url": "https://arxiv.org/abs/2601.20352",
      "description": "arXiv:2601.20352v1 Announce Type: new \nAbstract: The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from si...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "memory",
        "experiment",
        "context",
        "model",
        "research",
        "LLM",
        "reasoning",
        "framework",
        "retrieval",
        "large language model",
        "API",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Gap-K%: Measuring Top-1 Prediction Gap for Detecting Pretraining Data",
      "url": "https://arxiv.org/abs/2601.19936",
      "description": "arXiv:2601.19936v1 Announce Type: new \nAbstract: The opacity of massive pretraining corpora in Large Language Models (LLMs) raises significant privacy and copyright concerns, making pretraining data detection a critical challenge. Existing state-of-the-art methods typically rely on token likelihoods...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "experiment",
        "model",
        "LLM",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "oculomix: Hierarchical Sampling for Retinal-Based Systemic Disease Prediction",
      "url": "https://arxiv.org/abs/2601.19939",
      "description": "arXiv:2601.19939v1 Announce Type: new \nAbstract: Oculomics - the concept of predicting systemic diseases, such as cardiovascular disease and dementia, through retinal imaging - has advanced rapidly due to the data efficiency of transformer-based foundation models like RETFound. Image-level mixed sam...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "RAG",
        "model",
        "transformer",
        "image",
        "API",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "NCSAM Noise-Compensated Sharpness-Aware Minimization for Noisy Label Learning",
      "url": "https://arxiv.org/abs/2601.19947",
      "description": "arXiv:2601.19947v1 Announce Type: new \nAbstract: Learning from Noisy Labels (LNL) presents a fundamental challenge in deep learning, as real-world datasets often contain erroneous or corrupted annotations, \\textit{e.g.}, data crawled from Web. Current research focuses on sophisticated label correcti...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "analysis",
        "experiment",
        "research",
        "paper",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "MeanCache: From Instantaneous to Average Velocity for Accelerating Flow Matching Inference",
      "url": "https://arxiv.org/abs/2601.19961",
      "description": "arXiv:2601.19961v1 Announce Type: new \nAbstract: We present MeanCache, a training-free caching framework for efficient Flow Matching inference. Existing caching methods reduce redundant computation but typically rely on instantaneous velocity information (e.g., feature caching), which often leads to...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "RAG",
        "experiment",
        "model",
        "vector",
        "image",
        "tool",
        "framework",
        "product",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" ‚Äî Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" ‚Äî Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "context window",
        "prompt",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "CoT",
        "reasoning",
        "framework",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "model",
        "prompt",
        "LLM",
        "tool",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "RAG",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "model",
        "vector",
        "LLM",
        "reasoning",
        "framework",
        "retrieval",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "API",
        "product",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. üöÄüíª Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. üöÄüíª Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "vector",
        "LLM",
        "framework",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "From Intuition to Expertise: Rubric-Based Cognitive Calibration for Human Detection of LLM-Generated Korean Text",
      "url": "https://arxiv.org/abs/2601.19913",
      "description": "arXiv:2601.19913v1 Announce Type: new \nAbstract: Distinguishing human-written Korean text from fluent LLM outputs remains difficult even for linguistically trained readers, who can over-trust surface well-formedness. We study whether expert detection can be treated as a learnable skill and improved ...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "release",
        "arxiv",
        "LLM"
      ],
      "score": 0.8
    },
    {
      "title": "Latent Object Permanence: Topological Phase Transitions, Free-Energy Principles, and Renormalization Group Flows in Deep Transformer Manifolds",
      "url": "https://arxiv.org/abs/2601.19942",
      "description": "arXiv:2601.19942v1 Announce Type: new \nAbstract: We study the emergence of multi-step reasoning in deep Transformer language models through a geometric and statistical-physics lens. Treating the hidden-state trajectory as a flow on an implicit Riemannian manifold, we analyze the layerwise covariance...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "transformer",
        "study",
        "reasoning",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Classifier Calibration at Scale: An Empirical Study of Model-Agnostic Post-Hoc Methods",
      "url": "https://arxiv.org/abs/2601.19944",
      "description": "arXiv:2601.19944v1 Announce Type: new \nAbstract: We study model-agnostic post-hoc calibration methods intended to improve probabilistic predictions in supervised binary classification on real i.i.d. tabular data, with particular emphasis on conformal and Venn-based approaches that provide distributi...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "RAG",
        "arxiv",
        "study"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "tool",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "model",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints",
      "url": "https://arxiv.org/abs/2601.20021",
      "description": "arXiv:2601.20021v1 Announce Type: new \nAbstract: Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verif...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM"
      ],
      "score": 0.6
    },
    {
      "title": "DecHW: Heterogeneous Decentralized Federated Learning Exploiting Second-Order Information",
      "url": "https://arxiv.org/abs/2601.19938",
      "description": "arXiv:2601.19938v1 Announce Type: new \nAbstract: Decentralized Federated Learning (DFL) is a serverless collaborative machine learning paradigm where devices collaborate directly with neighbouring devices to exchange model information for learning a generalized model. However, variations in individu...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "model",
        "paper",
        "vision",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Simulating Complex Multi-Turn Tool Calling Interactions in Stateless Execution Environments",
      "url": "https://arxiv.org/abs/2601.19914",
      "description": "arXiv:2601.19914v1 Announce Type: new \nAbstract: Synthetic data has proven itself to be a valuable resource for tuning smaller, cost-effective language models to handle the complexities of multi-turn tool calling conversations. While many frameworks and systems for producing synthetic multi-turn too...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "framework",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "NeuroAI and Beyond",
      "url": "https://arxiv.org/abs/2601.19955",
      "description": "arXiv:2601.19955v1 Announce Type: new \nAbstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Probabilistic Sensing: Intelligence in Data Sampling",
      "url": "https://arxiv.org/abs/2601.19953",
      "description": "arXiv:2601.19953v1 Announce Type: new \nAbstract: Extending the intelligence of sensors to the data-acquisition process - deciding whether to sample or not - can result in transformative energy-efficiency gains. However, making such a decision in a deterministic manner involves risk of losing informa...",
      "published_date": "2026-01-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Alyah ‚≠êÔ∏è: Toward Robust Evaluation of Emirati Dialect Capabilities in Arabic LLMs",
      "url": "https://huggingface.co/blog/tiiuae/emirati-benchmarks",
      "description": "...",
      "published_date": "2026-01-27T10:26:42",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Unlocking Agentic RL Training for GPT-OSS: A Practical Retrospective",
      "url": "https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl",
      "description": "...",
      "published_date": "2026-01-27T01:53:15",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "GPT"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "We Got Claude to Build CUDA Kernels and teach open models!",
      "url": "https://huggingface.co/blog/upskill",
      "description": "...",
      "published_date": "2026-01-28T00:00:00",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model"
      ],
      "score": 0.2
    }
  ]
}