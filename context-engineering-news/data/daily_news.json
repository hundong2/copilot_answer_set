{
  "generated_at": "2025-08-22T20:05:35.655830",
  "total_items": 46,
  "items": [
    {
      "title": "Efficient Switchable Safety Control in LLMs via Magic-Token-Guided Co-Training",
      "url": "https://arxiv.org/abs/2508.14904",
      "description": "arXiv:2508.14904v1 Announce Type: new \nAbstract: Current methods for content safety in Large Language Models (LLMs), such as Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF), often rely on multi-stage training pipelines and lack fine-grained, post-deployment control...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "context",
        "large language model",
        "LLM",
        "alignment",
        "RLHF",
        "framework",
        "instruction",
        "fine-tuning",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Bridging the Culture Gap: A Framework for LLM-Driven Socio-Cultural Localization of Math Word Problems in Low-Resource Languages",
      "url": "https://arxiv.org/abs/2508.14913",
      "description": "arXiv:2508.14913v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated significant capabilities in solving mathematical problems expressed in natural language. However, multilingual and culturally-grounded mathematical reasoning in low-resource languages lags behind English ...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "experiment",
        "tool",
        "context",
        "large language model",
        "LLM",
        "framework",
        "reasoning",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Improving LLMs for Machine Translation Using Synthetic Preference Data",
      "url": "https://arxiv.org/abs/2508.14951",
      "description": "arXiv:2508.14951v1 Announce Type: new \nAbstract: Large language models have emerged as effective machine translation systems. In this paper, we explore how a general instruction-tuned large language model can be improved for machine translation using relatively few easily produced data resources. Us...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "LLM",
        "paper",
        "instruction",
        "arxiv",
        "ICL",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Multilingual Datasets for Custom Input Extraction and Explanation Requests Parsing in Conversational XAI Systems",
      "url": "https://arxiv.org/abs/2508.14982",
      "description": "arXiv:2508.14982v1 Announce Type: new \nAbstract: Conversational explainable artificial intelligence (ConvXAI) systems based on large language models (LLMs) have garnered considerable attention for their ability to enhance user comprehension through dialogue-based explanations. Current ConvXAI system...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "large language model",
        "LLM",
        "attention",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Reward-Shifted Speculative Sampling Is An Efficient Test-Time Weak-to-Strong Aligner",
      "url": "https://arxiv.org/abs/2508.15044",
      "description": "arXiv:2508.15044v1 Announce Type: new \nAbstract: Aligning large language models (LLMs) with human preferences has become a critical step in their development. Recent research has increasingly focused on test-time alignment, where additional compute is allocated during inference to enhance LLM safety...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "large language model",
        "research",
        "LLM",
        "alignment",
        "RLHF",
        "model",
        "reasoning",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "LongRecall: A Structured Approach for Robust Recall Evaluation in Long-Form Text",
      "url": "https://arxiv.org/abs/2508.15085",
      "description": "arXiv:2508.15085v1 Announce Type: new \nAbstract: LongRecall. The completeness of machine-generated text, ensuring that it captures all relevant information, is crucial in domains such as medicine and law and in tasks like list-based question answering (QA), where omissions can have serious consequen...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "context",
        "LLM",
        "alignment",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Mapping the Course for Prompt-based Structured Prediction",
      "url": "https://arxiv.org/abs/2508.15090",
      "description": "arXiv:2508.15090v1 Announce Type: new \nAbstract: LLMs have been shown to be useful for a variety of language tasks, without requiring task-specific fine-tuning. However, these models often struggle with hallucinations and complex reasoning problems due to their autoregressive nature. We propose to a...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "experiment",
        "prompt",
        "LLM",
        "model",
        "fine-tuning",
        "reasoning",
        "arxiv",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset",
      "url": "https://arxiv.org/abs/2508.15096",
      "description": "arXiv:2508.15096v1 Announce Type: new \nAbstract: Pretraining large language models (LLMs) on high-quality, structured data such as mathematics and code substantially enhances reasoning capabilities. However, existing math-focused datasets built from Common Crawl suffer from degraded quality due to b...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "release",
        "large language model",
        "LLM",
        "model",
        "reasoning",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Identifying and Answering Questions with False Assumptions: An Interpretable Approach",
      "url": "https://arxiv.org/abs/2508.15139",
      "description": "arXiv:2508.15139v1 Announce Type: new \nAbstract: People often ask questions with false assumptions, a type of question that does not have regular answers. Answering such questions require first identifying the false assumptions. Large Language Models (LLMs) often generate misleading answers because ...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "large language model",
        "LLM",
        "paper",
        "model",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone",
      "url": "https://arxiv.org/abs/2508.14923",
      "description": "arXiv:2508.14923v1 Announce Type: new \nAbstract: We propose a fully spectral, neuro\\-symbolic reasoning architecture that leverages Graph Signal Processing (GSP) as the primary computational backbone for integrating symbolic logic and neural inference. Unlike conventional reasoning models that treat...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "framework",
        "attention",
        "model",
        "reasoning",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism",
      "url": "https://arxiv.org/abs/2508.15030",
      "description": "arXiv:2508.15030v1 Announce Type: new \nAbstract: We propose Collab-REC, a multi-agent framework designed to counteract popularity bias and enhance diversity in tourism recommendations. In our setting, three LLM-based agents -- Personalization, Popularity, and Sustainability generate city suggestions...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "context",
        "LLM",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions",
      "url": "https://arxiv.org/abs/2508.15047",
      "description": "arXiv:2508.15047v1 Announce Type: new \nAbstract: Animating and simulating crowds using an agent-based approach is a well-established area where every agent in the crowd is individually controlled such that global human-like behaviour emerges. We observe that human navigation and movement in crowds a...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "large language model",
        "vision",
        "LLM",
        "framework",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Don't Think Twice! Over-Reasoning Impairs Confidence Calibration",
      "url": "https://arxiv.org/abs/2508.15050",
      "description": "arXiv:2508.15050v1 Announce Type: new \nAbstract: Large Language Models deployed as question answering tools require robust calibration to avoid overconfidence. We systematically evaluate how reasoning capabilities and budget affect confidence assessment accuracy, using the ClimateX dataset (Lacombe ...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "tool",
        "large language model",
        "LLM",
        "augmented",
        "reasoning",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner",
      "url": "https://arxiv.org/abs/2508.15068",
      "description": "arXiv:2508.15068v1 Announce Type: new \nAbstract: Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning (PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based agents. However, these adaptations can unintentionally compromise safety alignment, leading to un...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "large language model",
        "LLM",
        "alignment",
        "framework",
        "instruction",
        "fine-tuning",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Open-Universe Assistance Games",
      "url": "https://arxiv.org/abs/2508.15119",
      "description": "arXiv:2508.15119v1 Announce Type: new \nAbstract: Embodied AI agents must infer and act in an interpretable way on diverse human goals and preferences that are not predefined. To formalize this setting, we introduce Open-Universe Assistance Games (OU-AGs), a framework where the agent must reason over...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "context",
        "LLM",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists",
      "url": "https://arxiv.org/abs/2508.15126",
      "description": "arXiv:2508.15126v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) have enabled AI agents to autonomously generate scientific proposals, conduct experiments, author papers, and perform peer reviews. Yet this flood of AI-generated research content collides with a fragmen...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "large language model",
        "platform",
        "research",
        "LLM",
        "API",
        "paper",
        "model",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Cohort-Aware Agents for Individualized Lung Cancer Risk Prediction Using a Retrieval-Augmented Model Selection Framework",
      "url": "https://arxiv.org/abs/2508.14940",
      "description": "arXiv:2508.14940v1 Announce Type: new \nAbstract: Accurate lung cancer risk prediction remains challenging due to substantial variability across patient populations and clinical settings -- no single model performs best for all cohorts. To address this, we propose a personalized lung cancer risk pred...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "prompt",
        "large language model",
        "retrieval",
        "vision",
        "LLM",
        "augmented",
        "framework",
        "reasoning",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Structure-Aware Temporal Modeling for Chronic Disease Progression Prediction",
      "url": "https://arxiv.org/abs/2508.14942",
      "description": "arXiv:2508.14942v1 Announce Type: new \nAbstract: This study addresses the challenges of symptom evolution complexity and insufficient temporal dependency modeling in Parkinson's disease progression prediction. It proposes a unified prediction framework that integrates structural perception and tempo...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "transformer",
        "analysis",
        "framework",
        "model",
        "multimodal",
        "arxiv",
        "study",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Large Foundation Model for Ads Recommendation",
      "url": "https://arxiv.org/abs/2508.14948",
      "description": "arXiv:2508.14948v1 Announce Type: new \nAbstract: Online advertising relies on accurate recommendation models, with recent advances using pre-trained large-scale foundation models (LFMs) to capture users' general interests across multiple scenarios and tasks. However, existing methods have critical l...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "platform",
        "embedding",
        "framework",
        "paper",
        "retrieval",
        "arxiv",
        "product",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Aura-CAPTCHA: A Reinforcement Learning and GAN-Enhanced Multi-Modal CAPTCHA System",
      "url": "https://arxiv.org/abs/2508.14976",
      "description": "arXiv:2508.14976v1 Announce Type: new \nAbstract: Aura-CAPTCHA was developed as a multi-modal CAPTCHA system to address vulnerabilities in traditional methods that are increasingly bypassed by AI technologies, such as Optical Character Recognition (OCR) and adversarial image processing. The design in...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "image",
        "prompt",
        "large language model",
        "research",
        "LLM",
        "audio",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt",
        "prompt engineering",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "audio",
        "CoT",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "context",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "LLM",
        "attention",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "LLM",
        "knowledge base",
        "framework",
        "model",
        "reasoning",
        "retrieval",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "model",
        "tool",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "augmented",
        "retrieval",
        "product",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "vector",
        "platform",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving",
      "url": "https://arxiv.org/abs/2508.14926",
      "description": "arXiv:2508.14926v1 Announce Type: new \nAbstract: Autonomous vehicles hold great promise for reducing traffic fatalities and improving transportation efficiency, yet their widespread adoption hinges on embedding robust ethical reasoning into routine and emergency maneuvers. Here, we present a hierarc...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "embedding",
        "framework",
        "arxiv",
        "reasoning",
        "ICL",
        "study"
      ],
      "score": 0.8
    },
    {
      "title": "Linear Preference Optimization: Decoupled Gradient Control via Absolute Regularization",
      "url": "https://arxiv.org/abs/2508.14947",
      "description": "arXiv:2508.14947v1 Announce Type: new \nAbstract: DPO (Direct Preference Optimization) has become a widely used offline preference optimization algorithm due to its simplicity and training stability. However, DPO is prone to overfitting and collapse. To address these challenges, we propose Linear Pre...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "release",
        "alignment",
        "framework",
        "arxiv",
        "ICL",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "CuMoLoS-MAE: A Masked Autoencoder for Remote Sensing Data Reconstruction",
      "url": "https://arxiv.org/abs/2508.14957",
      "description": "arXiv:2508.14957v1 Announce Type: new \nAbstract: Accurate atmospheric profiles from remote sensing instruments such as Doppler Lidar, Radar, and radiometers are frequently corrupted by low-SNR (Signal to Noise Ratio) gates, range folding, and spurious discontinuities. Traditional gap filling blurs f...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "analysis",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "API",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Goals and the Structure of Experience",
      "url": "https://arxiv.org/abs/2508.15013",
      "description": "arXiv:2508.15013v1 Announce Type: new \nAbstract: Purposeful behavior is a hallmark of natural and artificial intelligence. Its acquisition is often believed to rely on world models, comprising both descriptive (what is) and prescriptive (what is desirable) aspects that identify and evaluate state of...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "model",
        "arxiv",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "HHNAS-AM: Hierarchical Hybrid Neural Architecture Search using Adaptive Mutation Policies",
      "url": "https://arxiv.org/abs/2508.14946",
      "description": "arXiv:2508.14946v1 Announce Type: new \nAbstract: Neural Architecture Search (NAS) has garnered significant research interest due to its capability to discover architectures superior to manually designed ones. Learning text representation is crucial for text classification and other language-related ...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "research",
        "template",
        "arxiv",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Generative Neural Operators of Log-Complexity Can Simultaneously Solve Infinitely Many Convex Programs",
      "url": "https://arxiv.org/abs/2508.14995",
      "description": "arXiv:2508.14995v1 Announce Type: new \nAbstract: Neural operators (NOs) are a class of deep learning models designed to simultaneously solve infinitely many related problems by casting them into an infinite-dimensional space, whereon these NOs operate. A significant gap remains between theory and pr...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "model",
        "experiment"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Preliminary Ranking of WMT25 General Machine Translation Systems",
      "url": "https://arxiv.org/abs/2508.14909",
      "description": "arXiv:2508.14909v1 Announce Type: new \nAbstract: We present the preliminary ranking of the WMT25 General Machine Translation Shared Task, in which MT systems have been evaluated using automatic metrics. As this ranking is based on automatic evaluations, it may be biased in favor of systems that empl...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning",
      "url": "https://arxiv.org/abs/2508.15053",
      "description": "arXiv:2508.15053v1 Announce Type: new \nAbstract: In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is demonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6). CS-6 is a satellite with a visible and near infrared range hyperspectral instrument and neural ne...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis"
      ],
      "score": 0.4
    },
    {
      "title": "Argumentation for Explainable Workforce Optimisation (with Appendix)",
      "url": "https://arxiv.org/abs/2508.15118",
      "description": "arXiv:2508.15118v1 Announce Type: new \nAbstract: Workforce management is a complex problem optimising the makespan and travel distance required for a team of operators to complete a set of jobs, using a set of instruments. A crucial challenge in workforce management is accommodating changes at execu...",
      "published_date": "2025-08-22T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "tool",
        "study"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}