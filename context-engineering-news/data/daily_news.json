{
  "generated_at": "2025-10-13T20:06:17.990779",
  "total_items": 47,
  "items": [
    {
      "title": "Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models",
      "url": "https://arxiv.org/abs/2510.08592",
      "description": "arXiv:2510.08592v1 Announce Type: new \nAbstract: Test-Time Scaling (TTS) improves LLM reasoning by exploring multiple candidate responses and then operating over this set to find the best output. A tacit premise behind TTS is that sufficiently diverse candidate pools enhance reliability. In this wor...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "LLM",
        "reasoning",
        "API",
        "large language model",
        "prompt",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Hierarchical Self-Supervised Representation Learning for Depression Detection from Speech",
      "url": "https://arxiv.org/abs/2510.08593",
      "description": "arXiv:2510.08593v1 Announce Type: new \nAbstract: Speech-based depression detection (SDD) is a promising, non-invasive alternative to traditional clinical assessments. However, it remains limited by the difficulty of extracting meaningful features and capturing sparse, heterogeneous depressive cues o...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "RAG",
        "embedding",
        "model",
        "vision",
        "cross-modal",
        "attention",
        "framework",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Systematic Diagnosis of Brittle Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2510.08595",
      "description": "arXiv:2510.08595v1 Announce Type: new \nAbstract: A central question in artificial intelligence is the extent to which machine learning models comprehend mathematics. To address this, we propose a novel framework for measuring mathematical reasoning that moves beyond standard benchmarks to diagnose s...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "reasoning",
        "analysis",
        "step-by-step",
        "large language model",
        "model",
        "GPT",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Confidence, Not Perplexity: A Better Metric for the Creative Era of LLMs",
      "url": "https://arxiv.org/abs/2510.08596",
      "description": "arXiv:2510.08596v1 Announce Type: new \nAbstract: Reference-free metrics like self-perplexity are strongly biased against creative text generation. We propose the Confidence Score (CS), derived from a model's output probability distribution, as a less biased alternative. Experiments on gpt-4o-mini sh...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "prompt",
        "model",
        "experiment",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Mnemosyne: An Unsupervised, Human-Inspired Long-Term Memory Architecture for Edge-Based LLMs",
      "url": "https://arxiv.org/abs/2510.08601",
      "description": "arXiv:2510.08601v1 Announce Type: new \nAbstract: Long-term memory is essential for natural, realistic dialogue. However, current large language model (LLM) memory systems rely on either brute-force context expansion or static retrieval pipelines that fail on edge-constrained devices. We introduce Mn...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "arxiv",
        "RAG",
        "LLM",
        "reasoning",
        "memory",
        "large language model",
        "model",
        "context",
        "experiment",
        "example",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Human Texts Are Outliers: Detecting LLM-generated Texts via Out-of-distribution Detection",
      "url": "https://arxiv.org/abs/2510.08602",
      "description": "arXiv:2510.08602v1 Announce Type: new \nAbstract: The rapid advancement of large language models (LLMs) such as ChatGPT, DeepSeek, and Claude has significantly increased the presence of AI-generated text in digital communication. This trend has heightened the need for reliable detection methods to di...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "API",
        "large language model",
        "model",
        "experiment",
        "GPT",
        "zero-shot",
        "release",
        "paper",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "YpathRAG:A Retrieval-Augmented Generation Framework and Benchmark for Pathology",
      "url": "https://arxiv.org/abs/2510.08603",
      "description": "arXiv:2510.08603v1 Announce Type: new \nAbstract: Large language models (LLMs) excel on general tasks yet still hallucinate in high-barrier domains such as pathology. Prior work often relies on domain fine-tuning, which neither expands the knowledge boundary nor enforces evidence-grounded constraints...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "fine-tuning",
        "RAG",
        "arxiv",
        "LLM",
        "vector",
        "large language model",
        "model",
        "release",
        "framework",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback",
      "url": "https://arxiv.org/abs/2510.08604",
      "description": "arXiv:2510.08604v1 Announce Type: new \nAbstract: Jailbreaks are adversarial attacks designed to bypass the built-in safety mechanisms of large language models. Automated jailbreaks typically optimize an adversarial suffix or adapt long prompt templates by forcing the model to generate the initial pa...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "RAG",
        "template",
        "large language model",
        "prompt",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Hypothesis Hunting with Evolving Networks of Autonomous Scientific Agents",
      "url": "https://arxiv.org/abs/2510.08619",
      "description": "arXiv:2510.08619v1 Announce Type: new \nAbstract: Large-scale scientific datasets -- spanning health biobanks, cell atlases, Earth reanalyses, and more -- create opportunities for exploratory discovery unconstrained by specific research questions. We term this process hypothesis hunting: the cumulati...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "LLM",
        "model",
        "experiment",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Optimizing delivery for quick commerce factoring qualitative assessment of generated routes",
      "url": "https://arxiv.org/abs/2510.08671",
      "description": "arXiv:2510.08671v1 Announce Type: new \nAbstract: Indias e-commerce market is projected to grow rapidly, with last-mile delivery accounting for nearly half of operational expenses. Although vehicle routing problem (VRP) based solvers are widely used for delivery planning, their effectiveness in real-...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "LLM",
        "reasoning",
        "study",
        "API",
        "ICL",
        "large language model",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation",
      "url": "https://arxiv.org/abs/2510.08713",
      "description": "arXiv:2510.08713v1 Announce Type: new \nAbstract: Enabling embodied agents to effectively imagine future states is critical for robust and generalizable visual navigation. Current state-of-the-art approaches, however, adopt modular architectures that separate navigation planning from visual world mod...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "alignment",
        "reasoning",
        "memory",
        "model",
        "context",
        "experiment",
        "framework",
        "zero-shot",
        "multimodal",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Robust Heuristic Algorithm Design with LLMs",
      "url": "https://arxiv.org/abs/2510.08755",
      "description": "arXiv:2510.08755v1 Announce Type: new \nAbstract: We posit that we can generate more robust and performant heuristics if we augment approaches using LLMs for heuristic design with tools that explain why heuristics underperform and suggestions about how to fix them. We find even simple ideas that (1) ...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "RAG",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context",
      "url": "https://arxiv.org/abs/2510.08790",
      "description": "arXiv:2510.08790v1 Announce Type: new \nAbstract: Long-horizon tasks that require sustained reasoning and multiple tool interactions remain challenging for LLM agents: small errors compound across steps, and even state-of-the-art models often hallucinate or lose coherence. We identify context managem...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "research",
        "arxiv",
        "LLM",
        "reasoning",
        "tool",
        "model",
        "context",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Everyone prefers human writers, including AI",
      "url": "https://arxiv.org/abs/2510.08831",
      "description": "arXiv:2510.08831v1 Announce Type: new \nAbstract: As AI writing tools become widespread, we need to understand how both humans and machines evaluate literary style, a domain where objective standards are elusive and judgments are inherently subjective. We conducted controlled experiments using Raymon...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "tool",
        "study",
        "model",
        "experiment",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment",
      "url": "https://arxiv.org/abs/2510.08847",
      "description": "arXiv:2510.08847v1 Announce Type: new \nAbstract: We introduce the Agent GPA (Goal-Plan-Action) framework: an evaluation paradigm based on an agent's operational loop of setting goals, devising plans, and executing actions. The framework includes five evaluation metrics: Goal Fulfillment, Logical Con...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "product",
        "experiment",
        "framework",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review",
      "url": "https://arxiv.org/abs/2510.08867",
      "description": "arXiv:2510.08867v1 Announce Type: new \nAbstract: Peer review is the cornerstone of scientific publishing, yet it suffers from inconsistencies, reviewer subjectivity, and scalability challenges. We introduce ReviewerToo, a modular framework for studying and deploying AI-assisted peer review to comple...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "LLM",
        "analysis",
        "study",
        "ICL",
        "model",
        "experiment",
        "GPT",
        "paper",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare",
      "url": "https://arxiv.org/abs/2510.08872",
      "description": "arXiv:2510.08872v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have achieved remarkable progress in reasoning, yet sometimes produce responses that are suboptimal for users in tasks such as writing, information seeking, or providing practical guidance. Conventional alignment practices...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "LLM",
        "reasoning",
        "large language model",
        "model",
        "experiment",
        "framework",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Energy-Driven Steering: Reducing False Refusals in Large Language Models",
      "url": "https://arxiv.org/abs/2510.08646",
      "description": "arXiv:2510.08646v1 Announce Type: new \nAbstract: Safety alignment of large language models (LLMs) faces a key challenge: current alignment techniques often only focus on improving safety against harmful prompts, causing LLMs to become over-cautious and refuse to respond to benign prompts. Therefore,...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "arxiv",
        "LLM",
        "paper",
        "large language model",
        "prompt",
        "experiment",
        "model",
        "example",
        "framework",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Inverse-Free Wilson Loops for Transformers: A Practical Diagnostic for Invariance and Order Sensitivity",
      "url": "https://arxiv.org/abs/2510.08648",
      "description": "arXiv:2510.08648v1 Announce Type: new \nAbstract: Large language models can change answers under harmless edits that matter in practice: RAG outputs flip when passages are reordered, fine-tuning erodes invariances learned at pretraining, debate or chain-of-thought prompts take path-dependent routes, ...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "fine-tuning",
        "RAG",
        "arxiv",
        "transformer",
        "large language model",
        "prompt",
        "context",
        "model",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "Provably Robust Adaptation for Language-Empowered Foundation Models",
      "url": "https://arxiv.org/abs/2510.08659",
      "description": "arXiv:2510.08659v1 Announce Type: new \nAbstract: Language-empowered foundation models (LeFMs), such as CLIP and GraphCLIP, have transformed multimodal learning by aligning visual (or graph) features with textual representations, enabling powerful downstream capabilities like few-shot learning. Howev...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "few-shot",
        "study",
        "few-shot learning",
        "embedding",
        "model",
        "experiment",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "FreqCa: Accelerating Diffusion Models via Frequency-Aware Caching",
      "url": "https://arxiv.org/abs/2510.08669",
      "description": "arXiv:2510.08669v1 Announce Type: new \nAbstract: The application of diffusion transformers is suffering from their significant inference costs. Recently, feature caching has been proposed to solve this problem by reusing features from previous timesteps, thereby skipping computation in future timest...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "transformer",
        "analysis",
        "memory",
        "model",
        "experiment",
        "image",
        "release",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting",
      "url": "https://arxiv.org/abs/2510.08696",
      "description": "arXiv:2510.08696v1 Announce Type: new \nAbstract: Reinforcement learning with verifiable rewards (RLVR) has become a standard recipe for improving large language models (LLMs) on reasoning tasks, with Group Relative Policy Optimization (GRPO) widely used in practice. Yet GRPO wastes substantial compu...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "RAG",
        "LLM",
        "reasoning",
        "large language model",
        "model",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "context",
        "context window",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "CoT",
        "chain-of-thought",
        "audio",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "tool",
        "API",
        "prompt",
        "model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "LLM",
        "reasoning",
        "vector",
        "model",
        "knowledge base",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "fine-tuning",
        "tool",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "product",
        "API",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "vector",
        "prompt",
        "platform",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "framework",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "How Scale Breaks \"Normalized Stress\" and KL Divergence: Rethinking Quality Metrics",
      "url": "https://arxiv.org/abs/2510.08660",
      "description": "arXiv:2510.08660v1 Announce Type: new \nAbstract: Complex, high-dimensional data is ubiquitous across many scientific disciplines, including machine learning, biology, and the social sciences. One of the primary methods of visualizing these datasets is with two-dimensional scatter plots that visually...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "embedding",
        "research",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "context",
        "tool",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Recover-LoRA: Data-Free Accuracy Recovery of Degraded Language Models via Low-Rank Adaptation",
      "url": "https://arxiv.org/abs/2510.08600",
      "description": "arXiv:2510.08600v1 Announce Type: new \nAbstract: Inference optimizations such as quantization, pruning, format and datatype conversion, model export, and serialization can lead to functional degradations in language model task performance. While most efforts on performance recovery for deployment fo...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "arxiv",
        "model",
        "attention"
      ],
      "score": 0.6
    },
    {
      "title": "CATS-Linear: Classification Auxiliary Linear Model for Time Series Forecasting",
      "url": "https://arxiv.org/abs/2510.08661",
      "description": "arXiv:2510.08661v1 Announce Type: new \nAbstract: Recent research demonstrates that linear models achieve forecasting performance competitive with complex architectures, yet methodologies for enhancing linear models remain underexplored. Motivated by the hypothesis that distinct time series instances...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "model",
        "experiment",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops",
      "url": "https://arxiv.org/abs/2510.08662",
      "description": "arXiv:2510.08662v1 Announce Type: new \nAbstract: Genomic Selection (GS) uses whole-genome information to predict crop phenotypes and accelerate breeding. Traditional GS methods, however, struggle with prediction accuracy for complex traits and large datasets. We propose DPCformer, a deep learning mo...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "CoT",
        "tool",
        "model",
        "attention"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "paper",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Enhancing Biomedical Named Entity Recognition using GLiNER-BioMed with Targeted Dictionary-Based Post-processing for BioASQ 2025 task 6",
      "url": "https://arxiv.org/abs/2510.08588",
      "description": "arXiv:2510.08588v1 Announce Type: new \nAbstract: Biomedical Named Entity Recognition (BioNER), task6 in BioASQ (A challenge in large-scale biomedical semantic indexing and question answering), is crucial for extracting information from scientific literature but faces hurdles such as distinguishing b...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "study"
      ],
      "score": 0.4
    },
    {
      "title": "LM Fight Arena: Benchmarking Large Multimodal Models via Game Competition",
      "url": "https://arxiv.org/abs/2510.08928",
      "description": "arXiv:2510.08928v1 Announce Type: new \nAbstract: Existing benchmarks for large multimodal models (LMMs) often fail to capture their performance in real-time, adversarial environments. We introduce LM Fight Arena (Large Model Fight Arena), a novel framework that evaluates LMMs by pitting them against...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "reasoning",
        "API",
        "prompt",
        "model",
        "multimodal",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "Knowledge Graph Sparsification for GNN-based Rare Disease Diagnosis",
      "url": "https://arxiv.org/abs/2510.08655",
      "description": "arXiv:2510.08655v1 Announce Type: new \nAbstract: Rare genetic disease diagnosis faces critical challenges: insufficient patient data, inaccessible full genome sequencing, and the immense number of possible causative genes. These limitations cause prolonged diagnostic journeys, inappropriate treatmen...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "tool",
        "framework",
        "analysis"
      ],
      "score": 0.4
    },
    {
      "title": "Inner-Instance Normalization for Time Series Forecasting",
      "url": "https://arxiv.org/abs/2510.08657",
      "description": "arXiv:2510.08657v1 Announce Type: new \nAbstract: Real-world time series are influenced by numerous factors and exhibit complex non-stationary characteristics. Non-stationarity can lead to distribution shifts, where the statistical properties of time series change over time, negatively impacting mode...",
      "published_date": "2025-10-13T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}