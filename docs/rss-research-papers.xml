<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>InteChar: A Unified Oracle Bone Character List for Ancient Chinese Language Modeling</title>
      <link>https://arxiv.org/abs/2508.15791</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15791</guid>
      <description>arXiv:2508.15791v1 Announce Type: new 
Abstract: Constructing historical language models (LMs) plays a crucial role in aiding archaeological provenance studies and understanding ancient cultures. However, existing resources present major challenges for training effective LMs on historical texts. Fir...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, experiment, research, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>experiment</category>
      <category>research</category>
    </item>
    <item>
      <title>Format as a Prior: Quantifying and Analyzing Bias in LLMs for Heterogeneous Data</title>
      <link>https://arxiv.org/abs/2508.15793</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15793</guid>
      <description>arXiv:2508.15793v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly employed in applications that require processing information from heterogeneous formats, including text, tables, infoboxes, and knowledge graphs. However, systematic biases toward particular formats may un...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, large language model, research, arxiv, attention | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>large language model</category>
      <category>research</category>
    </item>
    <item>
      <title>Benchmarking the Legal Reasoning of LLMs in Arabic Islamic Inheritance Cases</title>
      <link>https://arxiv.org/abs/2508.15796</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15796</guid>
      <description>arXiv:2508.15796v1 Announce Type: new 
Abstract: Islamic inheritance domain holds significant importance for Muslims to ensure fair distribution of shares between heirs. Manual calculation of shares under numerous scenarios is complex, time-consuming, and error-prone. Recent advancements in Large La...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, alignment, large language model, analysis, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>alignment</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Benchmarking the Medical Understanding and Reasoning of Large Language Models in Arabic Healthcare Tasks</title>
      <link>https://arxiv.org/abs/2508.15797</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15797</guid>
      <description>arXiv:2508.15797v1 Announce Type: new 
Abstract: Recent progress in large language models (LLMs) has showcased impressive proficiency in numerous Arabic natural language processing (NLP) applications. Nevertheless, their effectiveness in Arabic medical NLP domains has received limited investigation....&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, alignment, large language model, research, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>alignment</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Persuasiveness and Bias in LLM: Investigating the Impact of Persuasiveness and Reinforcement of Bias in Language Models</title>
      <link>https://arxiv.org/abs/2508.15798</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15798</guid>
      <description>arXiv:2508.15798v1 Announce Type: new 
Abstract: Warning: This research studies AI persuasion and bias amplification that could be misused; all experiments are for safety evaluation. Large Language Models (LLMs) now generate convincing, human-like text and are widely used in content creation, decisi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, alignment, experiment, large language model, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>alignment</category>
      <category>experiment</category>
    </item>
    <item>
      <title>A BERT-based Hierarchical Classification Model with Applications in Chinese Commodity Classification</title>
      <link>https://arxiv.org/abs/2508.15800</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15800</guid>
      <description>arXiv:2508.15800v1 Announce Type: new 
Abstract: Existing e-commerce platforms heavily rely on manual annotation for product categorization, which is inefficient and inconsistent. These platforms often employ a hierarchical structure for categorizing products; however, few studies have leveraged thi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, fine-tuning, arxiv, model, platform | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>fine-tuning</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Urban Comfort Assessment in the Era of Digital Planning: A Multidimensional, Data-driven, and AI-assisted Framework</title>
      <link>https://arxiv.org/abs/2508.16057</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16057</guid>
      <description>arXiv:2508.16057v1 Announce Type: new 
Abstract: Ensuring liveability and comfort is one of the fundamental objectives of urban planning. Numerous studies have employed computational methods to assess and quantify factors related to urban comfort such as greenery coverage, thermal comfort, and walka...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, analysis, arxiv, framework, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>analysis</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Integrating Time Series into LLMs via Multi-layer Steerable Embedding Fusion for Enhanced Forecasting</title>
      <link>https://arxiv.org/abs/2508.16059</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16059</guid>
      <description>arXiv:2508.16059v1 Announce Type: new 
Abstract: Time series (TS) data are ubiquitous across various application areas, rendering time series forecasting (TSF) a fundamental task. With the astounding advances in large language models (LLMs), a variety of methods have been developed to adapt LLMs for...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, alignment, experiment, large language model, embedding | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>alignment</category>
      <category>experiment</category>
    </item>
    <item>
      <title>InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles</title>
      <link>https://arxiv.org/abs/2508.16072</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16072</guid>
      <description>arXiv:2508.16072v1 Announce Type: new 
Abstract: LLMs have shown strong performance on human-centric reasoning tasks. While previous evaluations have explored whether LLMs can infer intentions or detect deception, they often overlook the individualized reasoning styles that influence how people inte...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, alignment, arxiv, context, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>alignment</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>IR-Agent: Expert-Inspired LLM Agents for Structure Elucidation from Infrared Spectra</title>
      <link>https://arxiv.org/abs/2508.16112</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16112</guid>
      <description>arXiv:2508.16112v1 Announce Type: new 
Abstract: Spectral analysis provides crucial clues for the elucidation of unknown materials. Among various techniques, infrared spectroscopy (IR) plays an important role in laboratory settings due to its high accessibility and low cost. However, existing approa...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, experiment, analysis, arxiv, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>experiment</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Extending FKG.in: Towards a Food Claim Traceability Network</title>
      <link>https://arxiv.org/abs/2508.16117</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16117</guid>
      <description>arXiv:2508.16117v1 Announce Type: new 
Abstract: The global food landscape is rife with scientific, cultural, and commercial claims about what foods are, what they do, what they should not do, or should not do. These range from rigorously studied health benefits (probiotics improve gut health) and m...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; large language model, research, arxiv, context, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>large language model</category>
      <category>research</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Z-Pruner: Post-Training Pruning of Large Language Models for Efficiency without Retraining</title>
      <link>https://arxiv.org/abs/2508.15828</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15828</guid>
      <description>arXiv:2508.15828v1 Announce Type: new 
Abstract: Large language models (LLMs) have rapidly advanced in recent years, achieving remarkable performance across a wide range of natural language processing tasks. However, this progress has come at the cost of increasingly large model sizes, which pose si...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, API, experiment, large language model, fine-tuning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>API</category>
      <category>experiment</category>
    </item>
    <item>
      <title>PGF-Net: A Progressive Gated-Fusion Framework for Efficient Multimodal Sentiment Analysis</title>
      <link>https://arxiv.org/abs/2508.15852</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15852</guid>
      <description>arXiv:2508.15852v1 Announce Type: new 
Abstract: We introduce PGF-Net (Progressive Gated-Fusion Network), a novel deep learning framework designed for efficient and interpretable multimodal sentiment analysis. Our framework incorporates three primary innovations. Firstly, we propose a Progressive In...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, analysis, fine-tuning, arxiv, attention | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>analysis</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>Transforming Causality: Transformer-Based Temporal Causal Discovery with Prior Knowledge Integration</title>
      <link>https://arxiv.org/abs/2508.15928</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15928</guid>
      <description>arXiv:2508.15928v1 Announce Type: new 
Abstract: We introduce a novel framework for temporal causal discovery and inference that addresses two key challenges: complex nonlinear dependencies and spurious correlations. Our approach employs a multi-layer Transformer-based time-series forecaster to capt...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, analysis, arxiv, attention, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>analysis</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Low-dimensional embeddings of high-dimensional data</title>
      <link>https://arxiv.org/abs/2508.15929</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15929</guid>
      <description>arXiv:2508.15929v1 Announce Type: new 
Abstract: Large collections of high-dimensional data have become nearly ubiquitous across many academic fields and application domains, ranging from biology to the humanities. Since working directly with high-dimensional data poses challenges, the demand for al...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, analysis, embedding, arxiv, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>analysis</category>
      <category>embedding</category>
    </item>
    <item>
      <title>An Efficient Hybridization of Graph Representation Learning and Metaheuristics for the Constrained Incremental Graph Drawing Problem</title>
      <link>https://arxiv.org/abs/2508.15949</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15949</guid>
      <description>arXiv:2508.15949v1 Announce Type: new 
Abstract: Hybridizing machine learning techniques with metaheuristics has attracted significant attention in recent years. Many attempts employ supervised or reinforcement learning to support the decision-making of heuristic methods. However, in some cases, the...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, embedding, arxiv, attention, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>embedding</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Vector preference-based contextual bandits under distributional shifts</title>
      <link>https://arxiv.org/abs/2508.15966</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15966</guid>
      <description>arXiv:2508.15966v1 Announce Type: new 
Abstract: We consider contextual bandit learning under distribution shift when reward vectors are ordered according to a given preference cone. We propose an adaptive-discretization and optimistic elimination based policy that self-tunes to the underlying distr...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, study, context, vector | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>study</category>
      <category>context</category>
    </item>
    <item>
      <title>Advancing rail safety: An onboard measurement system of rolling stock wheel flange wear based on dynamic machine learning algorithms</title>
      <link>https://arxiv.org/abs/2508.15963</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15963</guid>
      <description>arXiv:2508.15963v1 Announce Type: new 
Abstract: Rail and wheel interaction functionality is pivotal to the railway system safety, requiring accurate measurement systems for optimal safety monitoring operation. This paper introduces an innovative onboard measurement system for monitoring wheel flang...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, analysis, arxiv, model, ICL | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>analysis</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Bhav-Net: Knowledge Transfer for Cross-Lingual Antonym vs Synonym Distinction via Dual-Space Graph Transformers</title>
      <link>https://arxiv.org/abs/2508.15792</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15792</guid>
      <description>arXiv:2508.15792v1 Announce Type: new 
Abstract: Antonym vs synonym distinction across multiple languages presents unique computational challenges due to the paradoxical nature of antonymous relationships words that share semantic domains while expressing opposite meanings. This work introduces Bhav...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; transformer, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>transformer</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Physics-Based Explainable AI for ECG Segmentation: A Lightweight Model</title>
      <link>https://arxiv.org/abs/2508.15872</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.15872</guid>
      <description>arXiv:2508.15872v1 Announce Type: new 
Abstract: The heart&amp;#x27;s electrical activity, recorded through Electrocardiography (ECG), is essential for diagnosing various cardiovascular conditions. However, many existing ECG segmentation models rely on complex, multi-layered architectures such as BiLSTM, whi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, study, model, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 25 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>study</category>
      <category>model</category>
    </item>
  </channel>
</rss>