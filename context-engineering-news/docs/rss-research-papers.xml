<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Direct Confidence Alignment: Aligning Verbalized Confidence with Internal Confidence In Large Language Models</title>
      <link>https://arxiv.org/abs/2512.11998</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11998</guid>
      <description>arXiv:2512.11998v1 Announce Type: new 
Abstract: Producing trustworthy and reliable Large Language Models (LLMs) has become increasingly important as their usage becomes more widespread. Calibration seeks to achieve this by improving the alignment between the model&amp;#x27;s confidence and the actual likeli...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, alignment, model, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>alignment</category>
    </item>
    <item>
      <title>Benchmarking Contextual Understanding for In-Car Conversational Systems</title>
      <link>https://arxiv.org/abs/2512.12042</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.12042</guid>
      <description>arXiv:2512.12042v1 Announce Type: new 
Abstract: In-Car Conversational Question Answering (ConvQA) systems significantly enhance user experience by enabling seamless voice interactions. However, assessing their accuracy and reliability remains a challenge. This paper explores the use of Large Langua...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, LLM, reasoning, arxiv, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>LLM</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>VOYAGER: A Training Free Approach for Generating Diverse Datasets using LLMs</title>
      <link>https://arxiv.org/abs/2512.12072</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.12072</guid>
      <description>arXiv:2512.12072v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly being used to generate synthetic datasets for the evaluation and training of downstream models. However, prior work has noted that such generated data lacks diversity. In this paper, we propose Voyager, a ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, experiment, model, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>experiment</category>
    </item>
    <item>
      <title>A Monad-Based Clause Architecture for Artificial Age Score (AAS) in Large Language Models</title>
      <link>https://arxiv.org/abs/2512.11835</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11835</guid>
      <description>arXiv:2512.11835v1 Announce Type: new 
Abstract: Large language models (LLMs) are often deployed as powerful yet opaque systems, leaving open how their internal memory and &amp;quot;self-like&amp;quot; behavior should be governed in a principled and auditable way. The Artificial Age Score (AAS) was previously introdu...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, framework, experiment, memory | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>framework</category>
    </item>
    <item>
      <title>Structured Personalization: Modeling Constraints as Matroids for Data-Minimal LLM Agents</title>
      <link>https://arxiv.org/abs/2512.11907</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11907</guid>
      <description>arXiv:2512.11907v1 Announce Type: new 
Abstract: Personalizing Large Language Model (LLM) agents requires conditioning them on user-specific data, creating a critical trade-off between task utility and data disclosure. While the utility of adding user data often exhibits diminishing returns (i.e., s...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, arxiv, LLM, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>arxiv</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Hypergame Rationalisability: Solving Agent Misalignment In Strategic Play</title>
      <link>https://arxiv.org/abs/2512.11942</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11942</guid>
      <description>arXiv:2512.11942v1 Announce Type: new 
Abstract: Differences in perception, information asymmetries, and bounded rationality lead game-theoretic players to derive a private, subjective view of the game that may diverge from the underlying ground-truth scenario and may be misaligned with other player...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, arxiv, framework, alignment, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>arxiv</category>
      <category>framework</category>
    </item>
    <item>
      <title>Semantic Nutrition Estimation: Predicting Food Healthfulness from Text Descriptions</title>
      <link>https://arxiv.org/abs/2512.11836</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11836</guid>
      <description>arXiv:2512.11836v1 Announce Type: new 
Abstract: Accurate nutritional assessment is critical for public health, but existing profiling systems require detailed data often unavailable or inaccessible from colloquial text descriptions of food. This paper presents a machine learning pipeline that predi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, embedding, vector, research, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>embedding</category>
      <category>vector</category>
    </item>
    <item>
      <title>D-STEER - Preference Alignment Techniques Learn to Behave, not to Believe -- Beneath the Surface, DPO as Steering Vector Perturbation in Activation Space</title>
      <link>https://arxiv.org/abs/2512.11838</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11838</guid>
      <description>arXiv:2512.11838v1 Announce Type: new 
Abstract: Direct Preference Optimization (DPO) has become a standard recipe for aligning large language models, yet it is still unclear what kind of change it actually induces inside the network. This paper argues that DPO does not rewrite a models internal bel...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, embedding, alignment, vector, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>embedding</category>
      <category>alignment</category>
    </item>
    <item>
      <title>Large Language Models as Generalist Policies for Network Optimization</title>
      <link>https://arxiv.org/abs/2512.11839</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11839</guid>
      <description>arXiv:2512.11839v1 Announce Type: new 
Abstract: Designing control policies to ensure robust network services is essential to modern digital infrastructure. However, the dominant paradigm for network optimization relies on designing specialist policies based on handcrafted rules or deep learning mod...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, framework, alignment, knowledge base | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>framework</category>
    </item>
    <item>
      <title>Amortized Causal Discovery with Prior-Fitted Networks</title>
      <link>https://arxiv.org/abs/2512.11840</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11840</guid>
      <description>arXiv:2512.11840v1 Announce Type: new 
Abstract: In recent years, differentiable penalized likelihood methods have gained popularity, optimizing the causal structure by maximizing its likelihood with respect to the data. However, recent research has shown that errors in likelihood estimation, even o...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, research, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>research</category>
    </item>
    <item>
      <title>Robustness of Probabilistic Models to Low-Quality Data: A Multi-Perspective Analysis</title>
      <link>https://arxiv.org/abs/2512.11912</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11912</guid>
      <description>arXiv:2512.11912v1 Announce Type: new 
Abstract: A systematic, comparative investigation into the effects of low-quality data reveals a stark spectrum of robustness across modern probabilistic models. We find that autoregressive language models, from token prediction to sequence-to-sequence tasks, a...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, analysis, model, GPT, image | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>analysis</category>
      <category>model</category>
    </item>
    <item>
      <title>CR3G: Causal Reasoning for Patient-Centric Explanations in Radiology Report Generation</title>
      <link>https://arxiv.org/abs/2512.11830</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11830</guid>
      <description>arXiv:2512.11830v1 Announce Type: new 
Abstract: Automatic chest X-ray report generation is an important area of research aimed at improving diagnostic accuracy and helping doctors make faster decisions. Current AI models are good at finding correlations (or patterns) in medical images. Still, they ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, reasoning, framework, analysis, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>reasoning</category>
      <category>framework</category>
    </item>
    <item>
      <title>Performance and Efficiency of Climate In-Situ Data Reconstruction: Why Optimized IDW Outperforms kriging and Implicit Neural Representation</title>
      <link>https://arxiv.org/abs/2512.11832</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11832</guid>
      <description>arXiv:2512.11832v1 Announce Type: new 
Abstract: This study evaluates three reconstruction methods for sparse climate data: the simple inverse distance weighting (IDW), the statistically grounded ordinary kriging (OK), and the advanced implicit neural representation model (MMGN architecture). All me...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, study, analysis, experiment, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>study</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Mirror Mode in Fire Emblem: Beating Players at their own Game with Imitation and Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2512.11902</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11902</guid>
      <description>arXiv:2512.11902v1 Announce Type: new 
Abstract: Enemy strategies in turn-based games should be surprising and unpredictable. This study introduces Mirror Mode, a new game mode where the enemy AI mimics the personal strategy of a player to challenge them to keep changing their gameplay. A simplified...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, demonstration, study, experiment, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>demonstration</category>
      <category>study</category>
    </item>
    <item>
      <title>Soft Decision Tree classifier: explainable and extendable PyTorch implementation</title>
      <link>https://arxiv.org/abs/2512.11833</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11833</guid>
      <description>arXiv:2512.11833v1 Announce Type: new 
Abstract: We implemented a Soft Decision Tree (SDT) and a Short-term Memory Soft Decision Tree (SM-SDT) using PyTorch. The methods were extensively tested on simulated and clinical datasets. The SDT was visualized to demonstrate the potential for its explainabi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, research, memory | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>research</category>
      <category>memory</category>
    </item>
    <item>
      <title>Hybrid twinning using PBDW and DeepONet for the effective state estimation and prediction on partially known systems</title>
      <link>https://arxiv.org/abs/2512.11834</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.11834</guid>
      <description>arXiv:2512.11834v1 Announce Type: new 
Abstract: The accurate estimation of the state of complex uncertain physical systems requires reconciling theoretical models, with inherent imperfections, with noisy experimental data. In this work, we propose an effective hybrid approach that combines physics-...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, arxiv, experiment, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 16 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
  </channel>
</rss>