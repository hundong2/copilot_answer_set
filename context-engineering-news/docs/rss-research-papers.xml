<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting</title>
      <link>https://arxiv.org/abs/2512.05243</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05243</guid>
      <description>arXiv:2512.05243v1 Announce Type: new 
Abstract: Prompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabil...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, prompt, LLM, study, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>prompt</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Exposing Pink Slime Journalism: Linguistic Signatures and Robust Detection Against LLM-Generated Threats</title>
      <link>https://arxiv.org/abs/2512.05331</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05331</guid>
      <description>arXiv:2512.05331v1 Announce Type: new 
Abstract: The local news landscape, a vital source of reliable information for 28 million Americans, faces a growing threat from Pink Slime Journalism, a low-quality, auto-generated articles that mimic legitimate local reporting. Detecting these deceptive artic...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, study, LLM, model, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>study</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Transformer-Enabled Diachronic Analysis of Vedic Sanskrit: Neural Methods for Quantifying Types of Language Change</title>
      <link>https://arxiv.org/abs/2512.05364</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05364</guid>
      <description>arXiv:2512.05364v1 Announce Type: new 
Abstract: This study demonstrates how hybrid neural-symbolic methods can yield significant new insights into the evolution of a morphologically rich, low-resource language. We challenge the naive assumption that linguistic change is simplification by quantitati...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, transformer, study, fine-tuning, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>transformer</category>
      <category>study</category>
    </item>
    <item>
      <title>Learning from Self Critique and Refinement for Faithful LLM Summarization</title>
      <link>https://arxiv.org/abs/2512.05387</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05387</guid>
      <description>arXiv:2512.05387v1 Announce Type: new 
Abstract: Large Language Models (LLMs) often suffer from hallucinations: output content that is not grounded in the input context, when performing long-form text generation tasks such as summarization. Prior works have shown that hallucinations can be reduced b...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; summarization, arxiv, LLM, model, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>summarization</category>
      <category>arxiv</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Documenting SME Processes with Conversational AI: From Tacit Knowledge to BPMN</title>
      <link>https://arxiv.org/abs/2512.05122</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05122</guid>
      <description>arXiv:2512.05122v1 Announce Type: new 
Abstract: Small and medium-sized enterprises (SMEs) still depend heavily on tacit, experience-based know-how that rarely makes its way into formal documentation. This paper introduces a large-language-model (LLM)-driven conversational assistant that captures su...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, study, LLM, model, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>study</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Bridging Traditional Machine Learning and Large Language Models: A Two-Part Course Design for Modern AI Education</title>
      <link>https://arxiv.org/abs/2512.05167</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05167</guid>
      <description>arXiv:2512.05167v1 Announce Type: new 
Abstract: This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science that systematically bridges traditional machine learning techniques with modern Large Language Models (LLMs). We describe a course structured ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, model, paper, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare</title>
      <link>https://arxiv.org/abs/2512.05365</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05365</guid>
      <description>arXiv:2512.05365v1 Announce Type: new 
Abstract: Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: com...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, prompt, LLM, memory, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>prompt</category>
      <category>LLM</category>
    </item>
    <item>
      <title>BEAVER: An Efficient Deterministic LLM Verifier</title>
      <link>https://arxiv.org/abs/2512.05439</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05439</guid>
      <description>arXiv:2512.05439v1 Announce Type: new 
Abstract: As large language models (LLMs) transition from research prototypes to production systems, practitioners often need reliable methods to verify that model outputs satisfy required constraints. While sampling-based estimates provide an intuition of mode...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, model, framework, product | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>Advanced Unsupervised Learning: A Comprehensive Overview of Multi-View Clustering Techniques</title>
      <link>https://arxiv.org/abs/2512.05169</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05169</guid>
      <description>arXiv:2512.05169v1 Announce Type: new 
Abstract: Machine learning techniques face numerous challenges to achieve optimal performance. These include computational constraints, the limitations of single-view learning algorithms and the complexity of processing large datasets from different domains, so...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, study, research, analysis, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>study</category>
      <category>research</category>
    </item>
    <item>
      <title>Variance Matters: Improving Domain Adaptation via Stratified Sampling</title>
      <link>https://arxiv.org/abs/2512.05226</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05226</guid>
      <description>arXiv:2512.05226v1 Announce Type: new 
Abstract: Domain shift remains a key challenge in deploying machine learning models to the real world. Unsupervised domain adaptation (UDA) aims to address this by minimising domain discrepancy during training, but the discrepancy estimates suffer from high var...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, model, paper, alignment, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>model</category>
      <category>paper</category>
    </item>
    <item>
      <title>Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale</title>
      <link>https://arxiv.org/abs/2512.05179</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05179</guid>
      <description>arXiv:2512.05179v1 Announce Type: new 
Abstract: Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick&amp;#x27;s D...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, study, fine-tuning, model, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>study</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning</title>
      <link>https://arxiv.org/abs/2512.05325</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05325</guid>
      <description>arXiv:2512.05325v1 Announce Type: new 
Abstract: Large reasoning models achieve strong performance on complex tasks by generating extended chains of thought, but they often &amp;quot;overthink&amp;quot;: continuing to reason long after they have enough information to answer correctly. This wastes inference-time compu...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, model, zero-shot, analysis, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>model</category>
      <category>zero-shot</category>
    </item>
    <item>
      <title>Edged Weisfeiler-Lehman Algorithm</title>
      <link>https://arxiv.org/abs/2512.05238</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05238</guid>
      <description>arXiv:2512.05238v1 Announce Type: new 
Abstract: As a classical approach on graph learning, the propagation-aggregation methodology is widely exploited by many of Graph Neural Networks (GNNs), wherein the representation of a node is updated by aggregating representations from itself and neighbor nod...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, RAG, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>RAG</category>
    </item>
    <item>
      <title>When unlearning is free: leveraging low influence points to reduce computational costs</title>
      <link>https://arxiv.org/abs/2512.05254</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05254</guid>
      <description>arXiv:2512.05254v1 Announce Type: new 
Abstract: As concerns around data privacy in machine learning grow, the ability to unlearn, or remove, specific data points from trained models becomes increasingly important. While state of the art unlearning methods have emerged in response, they typically tr...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, model, framework, analysis, example | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>model</category>
      <category>framework</category>
    </item>
    <item>
      <title>AI &amp;amp; Human Co-Improvement for Safer Co-Superintelligence</title>
      <link>https://arxiv.org/abs/2512.05356</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05356</guid>
      <description>arXiv:2512.05356v1 Announce Type: new 
Abstract: Self-improvement is a goal currently exciting the field of AI, but is fraught with danger, and may take time to fully achieve. We advocate that a more achievable and better goal for humanity is to maximize co-improvement: collaboration between human r...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>research</category>
    </item>
    <item>
      <title>Mitigating Self-Preference by Authorship Obfuscation</title>
      <link>https://arxiv.org/abs/2512.05379</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05379</guid>
      <description>arXiv:2512.05379v1 Announce Type: new 
Abstract: Language models (LMs) judges are widely used to evaluate the quality of LM outputs. Despite many advantages, LM judges display concerning biases that can impair their integrity in evaluations. One such bias is self-preference: LM judges preferring the...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, paper, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>paper</category>
      <category>model</category>
    </item>
    <item>
      <title>On the Computability of Artificial General Intelligence</title>
      <link>https://arxiv.org/abs/2512.05212</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05212</guid>
      <description>arXiv:2512.05212v1 Announce Type: new 
Abstract: In recent years we observed rapid and significant advancements in artificial intelligence (A.I.). So much so that many wonder how close humanity is to developing an A.I. model that can achieve human level of intelligence, also known as artificial gene...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; API, arxiv, study, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>API</category>
      <category>arxiv</category>
      <category>study</category>
    </item>
    <item>
      <title>Coefficient of Variation Masking: A Volatility-Aware Strategy for EHR Foundation Models</title>
      <link>https://arxiv.org/abs/2512.05216</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.05216</guid>
      <description>arXiv:2512.05216v1 Announce Type: new 
Abstract: Masked autoencoders (MAEs) are increasingly applied to electronic health records (EHR) for learning general-purpose representations that support diverse clinical tasks. However, existing approaches typically rely on uniform random masking, implicitly ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 08 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>model</category>
    </item>
  </channel>
</rss>