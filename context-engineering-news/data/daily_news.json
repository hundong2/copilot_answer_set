{
  "generated_at": "2025-11-25T20:06:02.667526",
  "total_items": 43,
  "items": [
    {
      "title": "SCARE: A Benchmark for SQL Correction and Question Answerability Classification for Reliable EHR Question Answering",
      "url": "https://arxiv.org/abs/2511.17559",
      "description": "arXiv:2511.17559v1 Announce Type: new \nAbstract: Recent advances in Large Language Models (LLMs) have enabled the development of text-to-SQL models that allow clinicians to query structured data stored in Electronic Health Records (EHRs) using natural language. However, deploying these models for EH...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "experiment",
        "research",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "$A^3$: Attention-Aware Accurate KV Cache Fusion for Fast Large Language Model Serving",
      "url": "https://arxiv.org/abs/2511.17560",
      "description": "arXiv:2511.17560v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated strong capabilities in processing long contexts, enabling them to tackle tasks involving long textual inputs such as multi-turn conversations, legal documents, or retrieved documents in Retrieval-Augmente...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "attention",
        "alignment",
        "RAG",
        "arxiv",
        "augmented",
        "experiment",
        "memory",
        "model",
        "LLM",
        "large language model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LexInstructEval: Lexical Instruction Following Evaluation for Large Language Models",
      "url": "https://arxiv.org/abs/2511.17561",
      "description": "arXiv:2511.17561v1 Announce Type: new \nAbstract: The ability of Large Language Models (LLMs) to precisely follow complex and fine-grained lexical instructions is a cornerstone of their utility and controllability. However, evaluating this capability remains a significant challenge. Current methods e...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "instruction",
        "release",
        "framework",
        "arxiv",
        "research",
        "model",
        "LLM",
        "large language model",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Generative Caching for Structurally Similar Prompts and Responses",
      "url": "https://arxiv.org/abs/2511.17565",
      "description": "arXiv:2511.17565v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly being used to plan, reason, and execute tasks across diverse scenarios. In use cases like repeatable workflows and agentic settings, prompts are often reused with minor variations while having a similar st...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "arxiv",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Community-Aligned Behavior Under Uncertainty: Evidence of Epistemic Stance Transfer in LLMs",
      "url": "https://arxiv.org/abs/2511.17572",
      "description": "arXiv:2511.17572v1 Announce Type: new \nAbstract: When large language models (LLMs) are aligned to a specific online community, do they exhibit generalizable behavioral patterns that mirror that community's attitudes and responses to new uncertainty, or are they simply recalling patterns from trainin...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "alignment",
        "framework",
        "arxiv",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Random Text, Zipf's Law, Critical Length,and Implications for Large Language Models",
      "url": "https://arxiv.org/abs/2511.17575",
      "description": "arXiv:2511.17575v1 Announce Type: new \nAbstract: We study a deliberately simple, fully non-linguistic model of text: a sequence of independent draws from a finite alphabet of letters plus a single space symbol. A word is defined as a maximal block of non-space symbols. Within this symbol-level frame...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "RAG",
        "framework",
        "arxiv",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Computational frame analysis revisited: On LLMs for studying news coverage",
      "url": "https://arxiv.org/abs/2511.17746",
      "description": "arXiv:2511.17746v1 Announce Type: new \nAbstract: Computational approaches have previously shown various promises and pitfalls when it comes to the reliable identification of media frames. Generative LLMs like GPT and Claude are increasingly being used as content analytical tools, but how effective a...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "transformer",
        "analysis",
        "study",
        "RAG",
        "arxiv",
        "research",
        "model",
        "LLM",
        "GPT",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "PoETa v2: Toward More Robust Evaluation of Large Language Models in Portuguese",
      "url": "https://arxiv.org/abs/2511.17808",
      "description": "arXiv:2511.17808v1 Announce Type: new \nAbstract: Large Language Models (LLMs) exhibit significant variations in performance across linguistic and cultural contexts, underscoring the need for systematic evaluation in diverse languages. In this work, we present the most extensive evaluation of LLMs fo...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "RAG",
        "arxiv",
        "research",
        "model",
        "LLM",
        "analysis",
        "large language model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic Simulation",
      "url": "https://arxiv.org/abs/2511.17813",
      "description": "arXiv:2511.17813v1 Announce Type: new \nAbstract: Large language models offer opportunities to simulate multi-party deliberation, but realistic modeling remains limited by a lack of speaker-attributed data. Transcripts produced via automatic speech recognition (ASR) assign anonymous speaker labels (e...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "release",
        "model",
        "RAG",
        "arxiv",
        "fine-tuning",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Hybrid Neuro-Symbolic Models for Ethical AI in Risk-Sensitive Domains",
      "url": "https://arxiv.org/abs/2511.17644",
      "description": "arXiv:2511.17644v1 Announce Type: new \nAbstract: Artificial intelligence deployed in risk-sensitive domains such as healthcare, finance, and security must not only achieve predictive accuracy but also ensure transparency, ethical alignment, and compliance with regulatory expectations. Hybrid neuro s...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "reasoning",
        "paper",
        "alignment",
        "framework",
        "arxiv",
        "embedding",
        "model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Cognitive Inception: Agentic Reasoning against Visual Deceptions by Injecting Skepticism",
      "url": "https://arxiv.org/abs/2511.17672",
      "description": "arXiv:2511.17672v1 Announce Type: new \nAbstract: As the development of AI-generated contents (AIGC), multi-modal Large Language Models (LLM) struggle to identify generated visual inputs from real ones. Such shortcoming causes vulnerability against visual deceptions, where the models are deceived by ...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "reasoning",
        "framework",
        "arxiv",
        "model",
        "LLM",
        "API",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop",
      "url": "https://arxiv.org/abs/2511.17673",
      "description": "arXiv:2511.17673v1 Announce Type: new \nAbstract: Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly s...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "reasoning",
        "prompt",
        "tool",
        "framework",
        "arxiv",
        "augmented",
        "experiment",
        "model",
        "LLM",
        "GPT",
        "large language model",
        "memory"
      ],
      "score": 1.0
    },
    {
      "title": "M3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark",
      "url": "https://arxiv.org/abs/2511.17729",
      "description": "arXiv:2511.17729v1 Announce Type: new \nAbstract: We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool depe...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "reasoning",
        "alignment",
        "tool",
        "arxiv",
        "multimodal",
        "image",
        "model",
        "LLM",
        "large language model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "AI- and Ontology-Based Enhancements to FMEA for Advanced Systems Engineering: Current Developments and Future Directions",
      "url": "https://arxiv.org/abs/2511.17743",
      "description": "arXiv:2511.17743v1 Announce Type: new \nAbstract: This article presents a state-of-the-art review of recent advances aimed at transforming traditional Failure Mode and Effects Analysis (FMEA) into a more intelligent, data-driven, and semantically enriched process. As engineered systems grow in comple...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "reasoning",
        "tool",
        "RAG",
        "arxiv",
        "ICL",
        "embedding",
        "model",
        "analysis",
        "large language model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Learning to Debug: LLM-Organized Knowledge Trees for Solving RTL Assertion Failures",
      "url": "https://arxiv.org/abs/2511.17833",
      "description": "arXiv:2511.17833v1 Announce Type: new \nAbstract: Debugging is the dominant cost in modern hardware verification, where assertion failures are among the most frequent and expensive to resolve. While Large Language Models (LLMs) show promise, they often fail to capture the precise, reusable expertise ...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "arxiv",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "QuickLAP: Quick Language-Action Preference Learning for Autonomous Driving Agents",
      "url": "https://arxiv.org/abs/2511.17855",
      "description": "arXiv:2511.17855v1 Announce Type: new \nAbstract: Robots must learn from both what people do and what they say, but either modality alone is often incomplete: physical corrections are grounded but ambiguous in intent, while language expresses high-level goals but lacks physical grounding. We introduc...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "study",
        "framework",
        "arxiv",
        "multimodal",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Practical Machine Learning for Aphasic Discourse Analysis",
      "url": "https://arxiv.org/abs/2511.17553",
      "description": "arXiv:2511.17553v1 Announce Type: new \nAbstract: Analyzing spoken discourse is a valid means of quantifying language ability in persons with aphasia. There are many ways to quantify discourse, one common way being to evaluate the informativeness of the discourse. That is, given the total number of w...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "company",
        "study",
        "RAG",
        "arxiv",
        "multimodal",
        "model",
        "analysis",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Binary BPE: A Family of Cross-Platform Tokenizers for Binary Analysis",
      "url": "https://arxiv.org/abs/2511.17573",
      "description": "arXiv:2511.17573v1 Announce Type: new \nAbstract: Sequence models for binary analysis are bottlenecked by byte-level tokenization: raw bytes waste precious context window capacity for transformers and other neural network architectures, and many existing text-oriented tokenizers fail on arbitrary 0x0...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "instruction",
        "platform",
        "release",
        "context window",
        "tool",
        "compression",
        "arxiv",
        "research",
        "model",
        "transformer",
        "analysis",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Efficient Mathematical Reasoning Models via Dynamic Pruning and Knowledge Distillation",
      "url": "https://arxiv.org/abs/2511.17577",
      "description": "arXiv:2511.17577v1 Announce Type: new \nAbstract: With the rapid development of deep learning, large language models have shown strong capabilities in complex reasoning tasks such as mathematical equation solving. However, their substantial computational and storage costs hinder practical deployment....",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "reasoning",
        "paper",
        "RAG",
        "example",
        "arxiv",
        "experiment",
        "model",
        "API",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Multi-Value Alignment for LLMs via Value Decorrelation and Extrapolation",
      "url": "https://arxiv.org/abs/2511.17579",
      "description": "arXiv:2511.17579v1 Announce Type: new \nAbstract: With the rapid advancement of large language models (LLMs), aligning them with human values for safety and ethics has become a critical challenge. This problem is especially challenging when multiple, potentially conflicting human values must be consi...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "alignment",
        "RLHF",
        "framework",
        "arxiv",
        "experiment",
        "model",
        "LLM",
        "API",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "GateRA: Token-Aware Modulation for Parameter-Efficient Fine-Tuning",
      "url": "https://arxiv.org/abs/2511.17582",
      "description": "arXiv:2511.17582v1 Announce Type: new \nAbstract: Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, DoRA, and HiRA, enable lightweight adaptation of large pre-trained models via low-rank updates. However, existing PEFT approaches apply static, input-agnostic updates to all tokens, disrega...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "reasoning",
        "paper",
        "model",
        "RAG",
        "framework",
        "arxiv",
        "experiment",
        "fine-tuning",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt",
        "prompt engineering",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "CoT",
        "framework",
        "chain-of-thought",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "tool",
        "model",
        "LLM",
        "API",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "reasoning",
        "vector",
        "RAG",
        "framework",
        "model",
        "LLM",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "product",
        "RAG",
        "augmented",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "platform",
        "vector",
        "framework",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Fluid Grey 2: How Well Does Generative Adversarial Network Learn Deeper Topology Structure in Architecture That Matches Images?",
      "url": "https://arxiv.org/abs/2511.17643",
      "description": "arXiv:2511.17643v1 Announce Type: new \nAbstract: Taking into account the regional characteristics of intrinsic and extrinsic properties of space is an essential issue in architectural design and urban renewal, which is often achieved step by step using image and graph-based GANs. However, each model...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "study",
        "arxiv",
        "image",
        "research",
        "model",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "Root Cause Analysis for Microservice Systems via Cascaded Conditional Learning with Hypergraphs",
      "url": "https://arxiv.org/abs/2511.17566",
      "description": "arXiv:2511.17566v1 Announce Type: new \nAbstract: Root cause analysis in microservice systems typically involves two core tasks: root cause localization (RCL) and failure type identification (FTI). Despite substantial research efforts, conventional diagnostic approaches still face two key challenges....",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "experiment",
        "research",
        "model",
        "analysis"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "model",
        "context",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Leibniz's Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation",
      "url": "https://arxiv.org/abs/2511.17541",
      "description": "arXiv:2511.17541v1 Announce Type: new \nAbstract: This paper develops a mathematically rigorous, philosophically grounded framework for evaluating artificial memory systems, rooted in the metaphysical structure of Leibniz's Monadology. Building on a previously formalized metric, the Artificial Age Sc...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "study",
        "framework",
        "arxiv",
        "memory"
      ],
      "score": 0.6
    },
    {
      "title": "EgoCogNav: Cognition-aware Human Egocentric Navigation",
      "url": "https://arxiv.org/abs/2511.17581",
      "description": "arXiv:2511.17581v1 Announce Type: new \nAbstract: Modeling the cognitive and experiential factors of human navigation is central to deepening our understanding of human-environment interaction and to enabling safe social navigation and effective assistive wayfinding. Most existing methods focus on fo...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "multimodal",
        "experiment",
        "research",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "ChineseErrorCorrector3-4B: State-of-the-Art Chinese Spelling and Grammar Corrector",
      "url": "https://arxiv.org/abs/2511.17562",
      "description": "arXiv:2511.17562v1 Announce Type: new \nAbstract: This paper introduces ChineseErrorCorrector3-4B, a unified model for Chinese spelling and grammatical error correction based on Qwen3-4B. The model demonstrates outstanding performance in general text correction tasks and achieves state-of-the-art res...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "ICL",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Classification of Transient Astronomical Object Light Curves Using LSTM Neural Networks",
      "url": "https://arxiv.org/abs/2511.17564",
      "description": "arXiv:2511.17564v1 Announce Type: new \nAbstract: This study presents a bidirectional Long Short-Term Memory (LSTM) neural network for classifying transient astronomical object light curves from the Photometric LSST Astronomical Time-series Classification Challenge (PLAsTiCC) dataset. The original fo...",
      "published_date": "2025-11-25T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "memory",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}