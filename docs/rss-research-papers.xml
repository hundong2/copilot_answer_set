<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Multimodal Consistency-Guided Reference-Free Data Selection for ASR Accent Adaptation</title>
      <link>https://arxiv.org/abs/2602.13263</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13263</guid>
      <description>arXiv:2602.13263v1 Announce Type: new 
Abstract: Automatic speech recognition (ASR) systems often degrade on accented speech because acoustic-phonetic and prosodic shifts induce a mismatch to training data, making labeled accent adaptation costly. However, common pseudo-label selection heuristics ar...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; multimodal, alignment, embedding, experiment, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>multimodal</category>
      <category>alignment</category>
      <category>embedding</category>
    </item>
    <item>
      <title>Using Machine Learning to Enhance the Detection of Obfuscated Abusive Words in Swahili: A Focus on Child Safety</title>
      <link>https://arxiv.org/abs/2602.13455</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13455</guid>
      <description>arXiv:2602.13455v1 Announce Type: new 
Abstract: The rise of digital technology has dramatically increased the potential for cyberbullying and online abuse, necessitating enhanced measures for detection and prevention, especially among children. This study focuses on detecting abusive obfuscated lan...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; multimodal, study, research, analysis, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>multimodal</category>
      <category>study</category>
      <category>research</category>
    </item>
    <item>
      <title>From Perceptions To Evidence: Detecting AI-Generated Content In Turkish News Media With A Fine-Tuned Bert Classifier</title>
      <link>https://arxiv.org/abs/2602.13504</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13504</guid>
      <description>arXiv:2602.13504v1 Announce Type: new 
Abstract: The rapid integration of large language models into newsroom workflows has raised urgent questions about the prevalence of AI-generated content in online media. While computational studies have begun to quantify this phenomenon in English-language out...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, research, RAG, ICL, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>research</category>
      <category>RAG</category>
    </item>
    <item>
      <title>On Calibration of Large Language Models: From Response To Capability</title>
      <link>https://arxiv.org/abs/2602.13540</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13540</guid>
      <description>arXiv:2602.13540v1 Announce Type: new 
Abstract: Large language models (LLMs) are widely deployed as general-purpose problem solvers, making accurate confidence estimation critical for reliable use. Prior work on LLM calibration largely focuses on response-level confidence, which estimates the corre...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, model, large language model, arxiv, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>model</category>
      <category>large language model</category>
    </item>
    <item>
      <title>DistillLens: Symmetric Knowledge Distillation Through Logit Lens</title>
      <link>https://arxiv.org/abs/2602.13567</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13567</guid>
      <description>arXiv:2602.13567v1 Announce Type: new 
Abstract: Standard Knowledge Distillation (KD) compresses Large Language Models (LLMs) by optimizing final outputs, yet it typically treats the teacher&amp;#x27;s intermediate layer&amp;#x27;s thought process as a black box. While feature-based distillation attempts to bridge th...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, alignment, analysis, experiment, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>alignment</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Variation is the Key: A Variation-Based Framework for LLM-Generated Text Detection</title>
      <link>https://arxiv.org/abs/2602.13226</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13226</guid>
      <description>arXiv:2602.13226v1 Announce Type: new 
Abstract: Detecting text generated by large language models (LLMs) is crucial but challenging. Existing detectors depend on impractical assumptions, such as white-box settings, or solely rely on text-level features, leading to imprecise detection ability. In th...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, RAG, experiment, model, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>RAG</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Exploring the Performance of ML/DL Architectures on the MNIST-1D Dataset</title>
      <link>https://arxiv.org/abs/2602.13348</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13348</guid>
      <description>arXiv:2602.13348v1 Announce Type: new 
Abstract: Small datasets like MNIST have historically been instrumental in advancing machine learning research by providing a controlled environment for rapid experimentation and model evaluation. However, their simplicity often limits their utility for disting...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, research, RAG, API, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>research</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Finding Highly Interpretable Prompt-Specific Circuits in Language Models</title>
      <link>https://arxiv.org/abs/2602.13483</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13483</guid>
      <description>arXiv:2602.13483v1 Announce Type: new 
Abstract: Understanding the internal circuits that language models use to solve tasks remains a central challenge in mechanistic interpretability. Most prior work identifies circuits at the task level by averaging across many prompts, implicitly assuming a sing...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, template, GPT, analysis, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>template</category>
      <category>GPT</category>
    </item>
    <item>
      <title>Agentic AI for Commercial Insurance Underwriting with Adversarial Self-Critique</title>
      <link>https://arxiv.org/abs/2602.13213</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13213</guid>
      <description>arXiv:2602.13213v1 Announce Type: new 
Abstract: Commercial insurance underwriting is a labor-intensive process that requires manual review of extensive documentation to assess risk and determine policy pricing. While AI offers substantial efficiency improvements, existing solutions lack comprehensi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, framework, reasoning, research, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>framework</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>Why is Normalization Preferred? A Worst-Case Complexity Theory for Stochastically Preconditioned SGD under Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2602.13413</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13413</guid>
      <description>arXiv:2602.13413v1 Announce Type: new 
Abstract: We develop a worst-case complexity theory for stochastically preconditioned stochastic gradient descent (SPSGD) and its accelerated variants under heavy-tailed noise, a setting that encompasses widely used adaptive methods such as Adam, RMSProp, and S...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, model, tool, arxiv, vector | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>model</category>
      <category>tool</category>
    </item>
    <item>
      <title>Comparing Classifiers: A Case Study Using PyCM</title>
      <link>https://arxiv.org/abs/2602.13482</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13482</guid>
      <description>arXiv:2602.13482v1 Announce Type: new 
Abstract: Selecting an optimal classification model requires a robust and comprehensive understanding of the performance of the model. This paper provides a tutorial on the PyCM library, demonstrating its utility in conducting deep-dive evaluations of multi-cla...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, framework, library, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>framework</category>
      <category>library</category>
    </item>
    <item>
      <title>VeRA: Verified Reasoning Data Augmentation at Scale</title>
      <link>https://arxiv.org/abs/2602.13217</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13217</guid>
      <description>arXiv:2602.13217v1 Announce Type: new 
Abstract: The main issue with most evaluation schemes today is their &amp;quot;static&amp;quot; nature: the same problems are reused repeatedly, allowing for memorization, format exploitation, and eventual saturation. To measure genuine AI progress, we need evaluation that is ro...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; template, framework, vision, reasoning, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>template</category>
      <category>framework</category>
      <category>vision</category>
    </item>
    <item>
      <title>The Speed-up Factor: A Quantitative Multi-Iteration Active Learning Performance Metric</title>
      <link>https://arxiv.org/abs/2602.13359</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13359</guid>
      <description>arXiv:2602.13359v1 Announce Type: new 
Abstract: Machine learning models excel with abundant annotated data, but annotation is often costly and time-intensive. Active learning (AL) aims to improve the performance-to-annotation ratio by using query methods (QMs) to iteratively select the most informa...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>model</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Accelerated Discovery of Cryoprotectant Cocktails via Multi-Objective Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2602.13398</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.13398</guid>
      <description>arXiv:2602.13398v1 Announce Type: new 
Abstract: Designing cryoprotectant agent (CPA) cocktails for vitrification is challenging because formulations must be concentrated enough to suppress ice formation yet non-toxic enough to preserve cell viability. This tradeoff creates a large, multi-objective ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, model, arxiv, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 17 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>model</category>
      <category>arxiv</category>
    </item>
  </channel>
</rss>