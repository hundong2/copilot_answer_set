<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Trust but Verify! A Survey on Verification Design for Test-time Scaling</title>
      <link>https://arxiv.org/abs/2508.16665</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16665</guid>
      <description>arXiv:2508.16665v1 Announce Type: new 
Abstract: Test-time scaling (TTS) has emerged as a new frontier for scaling the performance of Large Language Models. In test-time scaling, by using more computational resources during inference, LLMs can improve their reasoning process and task performance. Se...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, model, reasoning, large language model, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>model</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>Do Cognitively Interpretable Reasoning Traces Improve LLM Performance?</title>
      <link>https://arxiv.org/abs/2508.16695</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16695</guid>
      <description>arXiv:2508.16695v1 Announce Type: new 
Abstract: Recent progress in reasoning-oriented Large Language Models (LLMs) has been driven by introducing Chain-of-Thought (CoT) traces, where models generate intermediate reasoning traces before producing an answer. These traces, as in DeepSeek R1, are not o...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; chain-of-thought, CoT, LLM, fine-tuning, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>chain-of-thought</category>
      <category>CoT</category>
      <category>LLM</category>
    </item>
    <item>
      <title>How Good are LLM-based Rerankers? An Empirical Analysis of State-of-the-Art Reranking Models</title>
      <link>https://arxiv.org/abs/2508.16757</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16757</guid>
      <description>arXiv:2508.16757v1 Announce Type: new 
Abstract: In this work, we present a systematic and comprehensive empirical evaluation of state-of-the-art reranking methods, encompassing large language model (LLM)-based, lightweight contextual, and zero-shot approaches, with respect to their performance in i...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; retrieval, analysis, LLM, study, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>retrieval</category>
      <category>analysis</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Revisiting Rule-Based Stuttering Detection: A Comprehensive Analysis of Interpretable Models for Clinical Applications</title>
      <link>https://arxiv.org/abs/2508.16681</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16681</guid>
      <description>arXiv:2508.16681v1 Announce Type: new 
Abstract: Stuttering affects approximately 1% of the global population, impacting communication and quality of life. While recent advances in deep learning have pushed the boundaries of automatic speech dysfluency detection, rule-based approaches remain crucial...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, model, paper, framework, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>model</category>
      <category>paper</category>
    </item>
    <item>
      <title>Explainable AI for Predicting and Understanding Mathematics Achievement: A Cross-National Analysis of PISA 2018</title>
      <link>https://arxiv.org/abs/2508.16747</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16747</guid>
      <description>arXiv:2508.16747v1 Announce Type: new 
Abstract: Understanding the factors that shape students&amp;#x27; mathematics performance is vital for designing effective educational policies. This study applies explainable artificial intelligence (XAI) techniques to PISA 2018 data to predict math achievement and ide...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, study, model, research, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>study</category>
      <category>model</category>
    </item>
    <item>
      <title>Quantifying Sycophancy as Deviations from Bayesian Rationality in LLMs</title>
      <link>https://arxiv.org/abs/2508.16846</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16846</guid>
      <description>arXiv:2508.16846v1 Announce Type: new 
Abstract: Sycophancy, or overly agreeable or flattering behavior, is a documented issue in large language models (LLMs), and is critical to understand in the context of human/AI collaboration. Prior works typically quantify sycophancy by measuring shifts in beh...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, LLM, study, model, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>LLM</category>
      <category>study</category>
    </item>
    <item>
      <title>RADAR: A Reasoning-Guided Attribution Framework for Explainable Visual Data Analysis</title>
      <link>https://arxiv.org/abs/2508.16850</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16850</guid>
      <description>arXiv:2508.16850v1 Announce Type: new 
Abstract: Data visualizations like charts are fundamental tools for quantitative analysis and decision-making across fields, requiring accurate interpretation and mathematical reasoning. The emergence of Multimodal Large Language Models (MLLMs) offers promising...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, experiment, LLM, RAG, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>experiment</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Quantum-Inspired DRL Approach with LSTM and OU Noise for Cut Order Planning Optimization</title>
      <link>https://arxiv.org/abs/2508.16611</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16611</guid>
      <description>arXiv:2508.16611v1 Announce Type: new 
Abstract: Cut order planning (COP) is a critical challenge in the textile industry, directly impacting fabric utilization and production costs. Conventional methods based on static heuristics and catalog-based estimations often struggle to adapt to dynamic prod...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, RAG, model, research, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>RAG</category>
      <category>model</category>
    </item>
    <item>
      <title>Learn to Memorize: Optimizing LLM-based Agents with Adaptive Memory Framework</title>
      <link>https://arxiv.org/abs/2508.16629</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16629</guid>
      <description>arXiv:2508.16629v1 Announce Type: new 
Abstract: LLM-based agents have been extensively applied across various domains, where memory stands out as one of their most essential capabilities. Previous memory mechanisms of LLM-based agents are manually predefined by human experts, leading to higher labo...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; retrieval, experiment, LLM, RAG, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>retrieval</category>
      <category>experiment</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Recurrent Transformer U-Net Surrogate for Flow Modeling and Data Assimilation in Subsurface Formations with Faults</title>
      <link>https://arxiv.org/abs/2508.16631</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16631</guid>
      <description>arXiv:2508.16631v1 Announce Type: new 
Abstract: Many subsurface formations, including some of those under consideration for large-scale geological carbon storage, include extensive faults that can strongly impact fluid flow. In this study, we develop a new recurrent transformer U-Net surrogate mode...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, transformer, study, RAG, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>transformer</category>
      <category>study</category>
    </item>
    <item>
      <title>Few-shot Class-incremental Fault Diagnosis by Preserving Class-Agnostic Knowledge with Dual-Granularity Representations</title>
      <link>https://arxiv.org/abs/2508.16634</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16634</guid>
      <description>arXiv:2508.16634v1 Announce Type: new 
Abstract: Few-Shot Class-Incremental Fault Diagnosis (FSC-FD), which aims to continuously learn from new fault classes with only a few samples without forgetting old ones, is critical for real-world industrial systems. However, this challenging task severely am...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, few-shot, model, paper, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>few-shot</category>
      <category>model</category>
    </item>
    <item>
      <title>A Novel Unified Extended Matrix for Graph Signal Processing: Theory and Application</title>
      <link>https://arxiv.org/abs/2508.16633</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16633</guid>
      <description>arXiv:2508.16633v1 Announce Type: new 
Abstract: Graph signal processing has become an essential tool for analyzing data structured on irregular domains. While conventional graph shift operators (GSOs) are effective for certain tasks, they inherently lack flexibility in modeling dependencies between...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, experiment, model, paper, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>experiment</category>
      <category>model</category>
    </item>
    <item>
      <title>Solving the Min-Max Multiple Traveling Salesmen Problem via Learning-Based Path Generation and Optimal Splitting</title>
      <link>https://arxiv.org/abs/2508.17087</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.17087</guid>
      <description>arXiv:2508.17087v1 Announce Type: new 
Abstract: This study addresses the Min-Max Multiple Traveling Salesmen Problem ($m^3$-TSP), which aims to coordinate tours for multiple salesmen such that the length of the longest tour is minimized. Due to its NP-hard nature, exact solvers become impractical u...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, study, model, framework, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>study</category>
      <category>model</category>
    </item>
    <item>
      <title>CrystalDiT: A Diffusion Transformer for Crystal Generation</title>
      <link>https://arxiv.org/abs/2508.16614</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16614</guid>
      <description>arXiv:2508.16614v1 Announce Type: new 
Abstract: We present CrystalDiT, a diffusion transformer for crystal structure generation that achieves state-of-the-art performance by challenging the trend of architectural complexity. Instead of intricate, multi-stream designs, CrystalDiT employs a unified t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; transformer, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>transformer</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Adaptive Variance-Penalized Continual Learning with Fisher Regularization</title>
      <link>https://arxiv.org/abs/2508.16632</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.16632</guid>
      <description>arXiv:2508.16632v1 Announce Type: new 
Abstract: The persistent challenge of catastrophic forgetting in neural networks has motivated extensive research in continual learning . This work presents a novel continual learning framework that integrates Fisher-weighted asymmetric regularization of parame...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, model, research, framework, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 26 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>model</category>
      <category>research</category>
    </item>
  </channel>
</rss>