{
  "generated_at": "2025-08-12T20:05:41.478506",
  "total_items": 47,
  "items": [
    {
      "title": "Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction",
      "url": "https://arxiv.org/abs/2508.06495",
      "description": "arXiv:2508.06495v1 Announce Type: new \nAbstract: The accelerated dissemination of disinformation often outpaces the capacity for manual fact-checking, highlighting the urgent need for Semi-Automated Fact-Checking (SAFC) systems. Within the Portuguese language context, there is a noted scarcity of pu...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "retrieval",
        "arxiv",
        "model",
        "ICL",
        "LLM",
        "API",
        "large language model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models",
      "url": "https://arxiv.org/abs/2508.06504",
      "description": "arXiv:2508.06504v1 Announce Type: new \nAbstract: Biomedical named entity recognition (NER) is a high-utility natural language processing (NLP) task, and large language models (LLMs) show promise particularly in few-shot settings (i.e., limited training data). In this article, we address the performa...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "retrieval",
        "arxiv",
        "augmented",
        "GPT",
        "model",
        "RAG",
        "prompting",
        "ICL",
        "in-context",
        "prompt",
        "LLM",
        "prompt engineering",
        "few-shot",
        "large language model",
        "example"
      ],
      "score": 1.0
    },
    {
      "title": "CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models",
      "url": "https://arxiv.org/abs/2508.06524",
      "description": "arXiv:2508.06524v1 Announce Type: new \nAbstract: Neural scaling laws have driven the development of increasingly large language models (LLMs) by linking accuracy improvements to growth in parameter count, dataset size, and compute. However, these laws overlook the carbon emissions that scale exponen...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "LLM",
        "paper",
        "large language model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "The Art of Breaking Words: Rethinking Multilingual Tokenizer Design",
      "url": "https://arxiv.org/abs/2508.06533",
      "description": "arXiv:2508.06533v1 Announce Type: new \nAbstract: While model architecture and training objectives are well-studied, tokenization, particularly in multilingual contexts, remains a relatively neglected aspect of Large Language Model (LLM) development. Existing tokenizers often exhibit high token-to-wo...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "arxiv",
        "experiment",
        "model",
        "RAG",
        "study",
        "analysis",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Factor Augmented Supervised Learning with Text Embeddings",
      "url": "https://arxiv.org/abs/2508.06548",
      "description": "arXiv:2508.06548v1 Announce Type: new \nAbstract: Large language models (LLMs) generate text embeddings from text data, producing vector representations that capture the semantic meaning and contextual relationships of words. However, the high dimensionality of these embeddings often impedes efficien...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "vector",
        "arxiv",
        "experiment",
        "model",
        "LLM",
        "augmented",
        "large language model",
        "framework",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs",
      "url": "https://arxiv.org/abs/2508.06583",
      "description": "arXiv:2508.06583v1 Announce Type: new \nAbstract: The conversational capabilities of large language models hold significant promise for enabling scalable and interactive tutoring. While prior research has primarily examined their capacity for Socratic questioning, it often overlooks a critical dimens...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "instruction",
        "model",
        "RAG",
        "study",
        "prompt",
        "LLM",
        "large language model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LLM Unlearning Without an Expert Curated Dataset",
      "url": "https://arxiv.org/abs/2508.06595",
      "description": "arXiv:2508.06595v1 Announce Type: new \nAbstract: Modern large language models often encode sensitive, harmful, or copyrighted knowledge, raising the need for post-hoc unlearning-the ability to remove specific domains of knowledge from a model without full retraining. A major bottleneck in current un...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "experiment",
        "release",
        "model",
        "prompt",
        "LLM",
        "prompting",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent",
      "url": "https://arxiv.org/abs/2508.06600",
      "description": "arXiv:2508.06600v1 Announce Type: new \nAbstract: Deep-Research agents, which integrate large language models (LLMs) with search tools, have shown success in improving the effectiveness of handling complex queries that require iterative search planning and reasoning over search results. Evaluations o...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "retrieval",
        "research",
        "arxiv",
        "GPT",
        "experiment",
        "model",
        "analysis",
        "reasoning",
        "LLM",
        "API",
        "large language model",
        "tool",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Measuring Stereotype and Deviation Biases in Large Language Models",
      "url": "https://arxiv.org/abs/2508.06649",
      "description": "arXiv:2508.06649v1 Announce Type: new \nAbstract: Large language models (LLMs) are widely applied across diverse domains, raising concerns about their limitations and potential risks. In this study, we investigate two types of bias that LLMs may display: stereotype bias and deviation bias. Stereotype...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "model",
        "study",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop",
      "url": "https://arxiv.org/abs/2508.06569",
      "description": "arXiv:2508.06569v1 Announce Type: new \nAbstract: The history of science is punctuated by serendipitous discoveries, where unexpected observations, rather than targeted hypotheses, opened new fields of inquiry. While modern autonomous laboratories excel at accelerating hypothesis testing, their optim...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "research",
        "arxiv",
        "experiment",
        "model",
        "analysis",
        "reasoning",
        "large language model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "CountQA: How Well Do MLLMs Count in the Wild?",
      "url": "https://arxiv.org/abs/2508.06585",
      "description": "arXiv:2508.06585v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in understanding visual scenes, yet they exhibit a critical lack in a fundamental cognitive skill: object counting. This blind spot severely limits their reliability in real-world...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "multimodal",
        "model",
        "image",
        "LLM",
        "paper",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis",
      "url": "https://arxiv.org/abs/2508.06668",
      "description": "arXiv:2508.06668v1 Announce Type: new \nAbstract: Formal Concept Analysis (FCA) is a mathematical framework for knowledge representation and discovery. It performs a hierarchical clustering over a set of objects described by attributes, resulting in conceptual structures in which objects are organize...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "analysis",
        "paper",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Zero-Shot Cellular Trajectory Map Matching",
      "url": "https://arxiv.org/abs/2508.06674",
      "description": "arXiv:2508.06674v1 Announce Type: new \nAbstract: Cellular Trajectory Map-Matching (CTMM) aims to align cellular location sequences to road networks, which is a necessary preprocessing in location-based services on web platforms like Google Maps, including navigation and route optimization. Current a...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "experiment",
        "arxiv",
        "model",
        "zero-shot",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search",
      "url": "https://arxiv.org/abs/2508.06736",
      "description": "arXiv:2508.06736v1 Announce Type: new \nAbstract: Solving Mixed-Integer Programming (MIP) problems often requires substantial computational resources due to their combinatorial nature. Parallelization has emerged as a critical strategy to accelerate solution times and enhance scalability to tackle la...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "paper",
        "arxiv",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Semi-Supervised Supply Chain Fraud Detection with Unsupervised Pre-Filtering",
      "url": "https://arxiv.org/abs/2508.06574",
      "description": "arXiv:2508.06574v1 Announce Type: new \nAbstract: Detecting fraud in modern supply chains is a growing challenge, driven by the complexity of global networks and the scarcity of labeled data. Traditional detection methods often struggle with class imbalance and limited supervision, reducing their eff...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vector",
        "arxiv",
        "vision",
        "analysis",
        "paper",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Hypergraph Neural Network with State Space Models for Node Classification",
      "url": "https://arxiv.org/abs/2508.06587",
      "description": "arXiv:2508.06587v1 Announce Type: new \nAbstract: In recent years, graph neural networks (GNNs) have gained significant attention for node classification tasks on graph-structured data. However, traditional GNNs primarily focus on adjacency relationships between nodes, often overlooking the rich role...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "experiment",
        "model",
        "RAG",
        "transformer",
        "attention",
        "tool",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning",
      "url": "https://arxiv.org/abs/2508.06588",
      "description": "arXiv:2508.06588v1 Announce Type: new \nAbstract: Vector Quantization (VQ) has recently emerged as a promising approach for learning discrete representations of graph-structured data. However, a fundamental challenge, i.e., codebook collapse, remains underexplored in the graph domain, significantly l...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vector",
        "arxiv",
        "experiment",
        "vision",
        "study",
        "analysis",
        "paper",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis",
      "url": "https://arxiv.org/abs/2508.06589",
      "description": "arXiv:2508.06589v1 Announce Type: new \nAbstract: Computer-aided diagnosis (CAD) systems play a crucial role in analyzing neuroimaging data for neurological and psychiatric disorders. However, small-sample studies suffer from low reproducibility, while large-scale datasets introduce confounding heter...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "model",
        "RAG",
        "study",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials",
      "url": "https://arxiv.org/abs/2508.06591",
      "description": "arXiv:2508.06591v1 Announce Type: new \nAbstract: Large language models (LLMs) have reshaped the research landscape by enabling new approaches to knowledge retrieval and creative ideation. Yet their application in discipline-specific experimental science, particularly in highly multi-disciplinary dom...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "research",
        "arxiv",
        "experiment",
        "model",
        "RAG",
        "API",
        "LLM",
        "augmented",
        "large language model",
        "tool",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs",
      "url": "https://arxiv.org/abs/2508.06601",
      "description": "arXiv:2508.06601v1 Announce Type: new \nAbstract: Open-weight AI systems offer unique benefits, including enhanced transparency, open research, and decentralized access. However, they are vulnerable to tampering attacks which can efficiently elicit harmful behaviors by modifying weights or activation...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "research",
        "arxiv",
        "model",
        "RAG",
        "LLM",
        "fine-tuning",
        "paper",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "context",
        "prompt engineering",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "audio",
        "reasoning",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "LLM",
        "attention",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "retrieval",
        "model",
        "knowledge base",
        "RAG",
        "reasoning",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "fine-tuning",
        "tool",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "API",
        "product",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "prompt",
        "LLM",
        "platform",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "framework",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization",
      "url": "https://arxiv.org/abs/2508.06559",
      "description": "arXiv:2508.06559v1 Announce Type: new \nAbstract: Pasur is a fishing card game played over six rounds and is played similarly to games such as Cassino and Scopa, and Bastra. This paper introduces a CUDA-accelerated computational framework for simulating Pasur, emphasizing efficient memory management....",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "RAG",
        "paper",
        "memory",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets",
      "url": "https://arxiv.org/abs/2508.06706",
      "description": "arXiv:2508.06706v1 Announce Type: new \nAbstract: Rule-based methods for knowledge graph completion provide explainable results but often require a significantly large number of rules to achieve competitive performance. This can hinder explainability due to overwhelmingly large rule sets. We discover...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "arxiv",
        "reasoning",
        "API",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "Generalizing Scaling Laws for Dense and Sparse Large Language Models",
      "url": "https://arxiv.org/abs/2508.06617",
      "description": "arXiv:2508.06617v1 Announce Type: new \nAbstract: Over the past few years, the size of language models has grown exponentially, as has the computational cost to train these large models. This rapid growth has motivated researchers to develop new techniques aimed at enhancing the efficiency of the tra...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "research",
        "model",
        "API",
        "large language model",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "tool",
        "model",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Train It and Forget It: Merge Lists are Unnecessary for BPE Inference in Language Models",
      "url": "https://arxiv.org/abs/2508.06621",
      "description": "arXiv:2508.06621v1 Announce Type: new \nAbstract: Standard Byte-Pair Encoding (BPE) tokenization compresses text by pairing a learned token vocabulary with a detailed merge list. Recent work has shown that this merge list exposes a potential attack surface for extracting information about language mo...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "model",
        "experiment"
      ],
      "score": 0.6
    },
    {
      "title": "IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model",
      "url": "https://arxiv.org/abs/2508.06571",
      "description": "arXiv:2508.06571v1 Announce Type: new \nAbstract: Vision-Language-Action (VLA) models have demonstrated potential in autonomous driving. However, two critical challenges hinder their development: (1) Existing VLA architectures are typically based on imitation learning in open-loop setup which tends t...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "vision",
        "model",
        "paper",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning",
      "url": "https://arxiv.org/abs/2508.06716",
      "description": "arXiv:2508.06716v1 Announce Type: new \nAbstract: Differentiable inductive logic programming (ILP) techniques have proven effective at finding approximate rule-based solutions to link prediction and node classification problems on knowledge graphs; however, the common assumption of chain-like rule st...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "model",
        "reasoning",
        "embedding"
      ],
      "score": 0.6
    },
    {
      "title": "Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism",
      "url": "https://arxiv.org/abs/2508.06746",
      "description": "arXiv:2508.06746v1 Announce Type: new \nAbstract: With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in sensitive applications, such as urban monitoring, emergency response, and secure sensing, ensuring reliable connectivity and covert communication has become increasingly vital. Howe...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "model",
        "ICL",
        "paper",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "Local Diffusion Models and Phases of Data Distributions",
      "url": "https://arxiv.org/abs/2508.06614",
      "description": "arXiv:2508.06614v1 Announce Type: new \nAbstract: As a class of generative artificial intelligence frameworks inspired by statistical physics, diffusion models have shown extraordinary performance in synthesizing complicated data distributions through a denoising process gradually guided by score fun...",
      "published_date": "2025-08-12T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "model",
        "image",
        "study",
        "API",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "TextQuests: How Good are LLMs at Text-Based Video Games?",
      "url": "https://huggingface.co/blog/textquests",
      "description": "...",
      "published_date": "2025-08-12T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "ðŸ‡µðŸ‡­ FilBench - Can LLMs Understand and Generate Filipino?",
      "url": "https://huggingface.co/blog/filbench",
      "description": "...",
      "published_date": "2025-08-12T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}