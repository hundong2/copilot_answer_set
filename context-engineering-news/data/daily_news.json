{
  "generated_at": "2025-12-29T20:05:55.906907",
  "total_items": 45,
  "items": [
    {
      "title": "Teaching People LLM's Errors and Getting it Right",
      "url": "https://arxiv.org/abs/2512.21422",
      "description": "arXiv:2512.21422v1 Announce Type: new \nAbstract: People use large language models (LLMs) when they should not. This is partly because they see LLMs compose poems and answer intricate questions, so they understandably, but incorrectly, assume LLMs won't stumble on basic tasks like simple arithmetic. ...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "study",
        "analysis",
        "prompting",
        "prompt",
        "large language model",
        "LLM",
        "embedding",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Morality is Contextual: Learning Interpretable Moral Contexts from Human Data with Probabilistic Clustering and Large Language Models",
      "url": "https://arxiv.org/abs/2512.21439",
      "description": "arXiv:2512.21439v1 Announce Type: new \nAbstract: Moral actions are judged not only by their outcomes but by the context in which they occur. We present COMETH (Contextual Organization of Moral Evaluation from Textual Human inputs), a framework that integrates a probabilistic context learner with LLM...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "RAG",
        "prompting",
        "prompt",
        "large language model",
        "context",
        "LLM",
        "embedding",
        "model",
        "framework",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Oogiri-Master: Benchmarking Humor Understanding via Oogiri",
      "url": "https://arxiv.org/abs/2512.21494",
      "description": "arXiv:2512.21494v1 Announce Type: new \nAbstract: Humor is a salient testbed for human-like creative thinking in large language models (LLMs). We study humor using the Japanese creative response game Oogiri, in which participants produce witty responses to a given prompt, and ask the following resear...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "augmented",
        "study",
        "analysis",
        "prompting",
        "prompt",
        "large language model",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond Heuristics: A Decision-Theoretic Framework for Agent Memory Management",
      "url": "https://arxiv.org/abs/2512.21567",
      "description": "arXiv:2512.21567v1 Announce Type: new \nAbstract: External memory is a key component of modern large language model (LLM) systems, enabling long-term interaction and personalization. Despite its importance, memory management is still largely driven by hand-designed heuristics, offering little insight...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "research",
        "arxiv",
        "RAG",
        "retrieval",
        "memory",
        "large language model",
        "LLM",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "A Unified Definition of Hallucination, Or: It's the World Model, Stupid",
      "url": "https://arxiv.org/abs/2512.21577",
      "description": "arXiv:2512.21577v1 Announce Type: new \nAbstract: Despite numerous attempts to solve the issue of hallucination since the inception of neural language models, it remains a problem in even frontier large language models today. Why is this the case? We walk through definitions of hallucination used in ...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "arxiv",
        "knowledge base",
        "context",
        "large language model",
        "model",
        "in-context"
      ],
      "score": 1.0
    },
    {
      "title": "Gamayun's Path to Multilingual Mastery: Cost-Efficient Training of a 1.5B-Parameter LLM",
      "url": "https://arxiv.org/abs/2512.21580",
      "description": "arXiv:2512.21580v1 Announce Type: new \nAbstract: We present Gamayun, a 1.5B-parameter multilingual language model trained entirely from scratch on 2.5T tokens. Designed for efficiency and deployment in resource-constrained environments, Gamayun addresses the lack of research on small non-English-cen...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "LLM",
        "model",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards",
      "url": "https://arxiv.org/abs/2512.21625",
      "description": "arXiv:2512.21625v1 Announce Type: new \nAbstract: Large reasoning models (LRMs) are typically trained using reinforcement learning with verifiable reward (RLVR) to enhance their reasoning abilities. In this paradigm, policies are updated using both positive and negative self-generated rollouts, which...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "RAG",
        "paper",
        "API",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations",
      "url": "https://arxiv.org/abs/2512.21635",
      "description": "arXiv:2512.21635v1 Announce Type: new \nAbstract: Hallucinations in large language models (LLMs) are commonly regarded as errors to be minimized. However, recent perspectives suggest that some hallucinations may encode creative or epistemically valuable content, a dimension that remains underquantifi...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "experiment",
        "RAG",
        "prompt",
        "large language model",
        "LLM",
        "model",
        "framework",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles",
      "url": "https://arxiv.org/abs/2512.21708",
      "description": "arXiv:2512.21708v1 Announce Type: new \nAbstract: Despite recent advancements of fine-tuning large language models (LLMs) to facilitate agent tasks, parameter-efficient fine-tuning (PEFT) methodologies for agent remain largely unexplored. In this paper, we introduce three key strategies for PEFT in a...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "RAG",
        "paper",
        "large language model",
        "LLM",
        "model",
        "ICL",
        "framework",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration",
      "url": "https://arxiv.org/abs/2512.21360",
      "description": "arXiv:2512.21360v1 Announce Type: new \nAbstract: Background: The House-Tree-Person (HTP) drawing test, introduced by John Buck in 1948, remains a widely used projective technique in clinical psychology. However, it has long faced challenges such as heterogeneous scoring standards, reliance on examin...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "framework",
        "tool",
        "experiment",
        "large language model",
        "LLM",
        "model",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Three-way conflict analysis based on alliance and conflict functions",
      "url": "https://arxiv.org/abs/2512.21419",
      "description": "arXiv:2512.21419v1 Announce Type: new \nAbstract: Trisecting agents, issues, and agent pairs are essential topics of three-way conflict analysis. They have been commonly studied based on either a rating or an auxiliary function. A rating function defines the positive, negative, or neutral ratings of ...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "example",
        "RAG",
        "study",
        "analysis",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Feasible strategies in three-way conflict analysis with three-valued ratings",
      "url": "https://arxiv.org/abs/2512.21420",
      "description": "arXiv:2512.21420v1 Announce Type: new \nAbstract: Most existing work on three-way conflict analysis has focused on trisecting agent pairs, agents, or issues, which contributes to understanding the nature of conflicts but falls short in addressing their resolution. Specifically, the formulation of fea...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "arxiv",
        "paper",
        "analysis",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis",
      "url": "https://arxiv.org/abs/2512.21482",
      "description": "arXiv:2512.21482v1 Announce Type: new \nAbstract: Sophisticated text-centric forgeries, fueled by rapid AIGC advancements, pose a significant threat to societal security and information authenticity. Current methods for text-centric forgery analysis are often limited to coarse-grained visual analysis...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "image",
        "GPT",
        "RAG",
        "zero-shot",
        "experiment",
        "API",
        "analysis",
        "reasoning",
        "LLM",
        "model",
        "ICL",
        "framework",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model",
      "url": "https://arxiv.org/abs/2512.21540",
      "description": "arXiv:2512.21540v1 Announce Type: new \nAbstract: Existing approaches typically rely on fixed length penalties, but such penalties are hard to tune and fail to adapt to the evolving reasoning abilities of LLMs, leading to suboptimal trade-offs between accuracy and conciseness. To address this challen...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "experiment",
        "RAG",
        "API",
        "reasoning",
        "instruction",
        "LLM",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "NEMO-4-PAYPAL: Leveraging NVIDIA's Nemo Framework for empowering PayPal's Commerce Agent",
      "url": "https://arxiv.org/abs/2512.21578",
      "description": "arXiv:2512.21578v1 Announce Type: new \nAbstract: We present the development and optimization of PayPal's Commerce Agent, powered by NEMO-4-PAYPAL, a multi-agent system designed to revolutionize agentic commerce on the PayPal platform. Through our strategic partnership with NVIDIA, we leveraged the N...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "experiment",
        "RAG",
        "fine-tuning",
        "retrieval",
        "LLM",
        "model",
        "product",
        "framework",
        "demonstration",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning",
      "url": "https://arxiv.org/abs/2512.21583",
      "description": "arXiv:2512.21583v1 Announce Type: new \nAbstract: With the rapid growth of large language models (LLMs) and vision-language models (VLMs) in medicine, simply integrating clinical text and medical imaging does not guarantee reliable reasoning. Existing multimodal models often produce hallucinations or...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "arxiv",
        "framework",
        "image",
        "cross-modal",
        "API",
        "reasoning",
        "large language model",
        "LLM",
        "vision",
        "model",
        "multimodal",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Statistical vs. Deep Learning Models for Estimating Substance Overdose Excess Mortality in the US",
      "url": "https://arxiv.org/abs/2512.21456",
      "description": "arXiv:2512.21456v1 Announce Type: new \nAbstract: Substance overdose mortality in the United States claimed over 80,000 lives in 2023, with the COVID-19 pandemic exacerbating existing trends through healthcare disruptions and behavioral changes. Estimating excess mortality, defined as deaths beyond e...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "arxiv",
        "transformer",
        "RAG",
        "analysis",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt",
        "prompt engineering",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "reasoning",
        "CoT",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "memvid - Memory layer for AI Agents. Replace complex RAG pipelines with a serverless, single-file memory layer. Give your agents instant retrieval and long-term memory.",
      "url": "https://github.com/memvid/memvid",
      "description": "Memory layer for AI Agents. Replace complex RAG pipelines with a serverless, single-file memory layer. Give your agents instant retrieval and long-term memory.",
      "published_date": "2025-05-27T16:01:08+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "memory",
        "retrieval",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "retrieval",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "RAG",
        "knowledge base",
        "retrieval",
        "reasoning",
        "LLM",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "retrieval",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "API",
        "augmented",
        "retrieval",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "prompt",
        "LLM",
        "framework",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech",
      "url": "https://arxiv.org/abs/2512.21706",
      "description": "arXiv:2512.21706v1 Announce Type: new \nAbstract: Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this causal pathway is key to building natural full-duplex interactive systems. We introduce a framework that enables reasoning over conver...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "framework",
        "transformer",
        "experiment",
        "reasoning",
        "model",
        "multimodal"
      ],
      "score": 0.8
    },
    {
      "title": "AMS-IO-Bench and AMS-IO-Agent: Benchmarking and Structured Reasoning for Analog and Mixed-Signal Integrated Circuit Input/Output Design",
      "url": "https://arxiv.org/abs/2512.21613",
      "description": "arXiv:2512.21613v1 Announce Type: new \nAbstract: In this paper, we propose AMS-IO-Agent, a domain-specialized LLM-based agent for structure-aware input/output (I/O) subsystem generation in analog and mixed-signal (AMS) integrated circuits (ICs). The central contribution of this work is a framework t...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "knowledge base",
        "reasoning",
        "LLM",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "tool",
        "API",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers",
      "url": "https://arxiv.org/abs/2512.21365",
      "description": "arXiv:2512.21365v1 Announce Type: new \nAbstract: This paper analyzes the behavior of solving Life-and-Death (L&amp;D) problems in the game of Go using current state-of-the-art computer Go solvers with two techniques: the Relevance-Zone Based Search (RZS) and the relevance-zone pattern table. We exam...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "Three-way decision with incomplete information based on similarity and satisfiability",
      "url": "https://arxiv.org/abs/2512.21421",
      "description": "arXiv:2512.21421v1 Announce Type: new \nAbstract: Three-way decision is widely applied with rough set theory to learn classification or decision rules. The approaches dealing with complete information are well established in the literature, including the two complementary computational and conceptual...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "Physics-Informed Neural Solvers for Periodic Quantum Eigenproblems",
      "url": "https://arxiv.org/abs/2512.21349",
      "description": "arXiv:2512.21349v1 Announce Type: new \nAbstract: This thesis presents a physics-informed machine learning framework for solving the Floquet-Bloch eigenvalue problem associated with particles in two-dimensional periodic potentials, with a focus on honeycomb lattice geometry, due to its distinctive ba...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "arxiv",
        "RAG",
        "vision",
        "model",
        "ICL",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning",
      "url": "https://arxiv.org/abs/2512.21446",
      "description": "arXiv:2512.21446v1 Announce Type: new \nAbstract: Masked diffusion language models (MDLMs) offer the potential for parallel token generation, but most open-source MDLMs decode fewer than 5 tokens per model forward pass even with sophisticated sampling strategies. As a result, their sampling speeds ar...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "reasoning",
        "LLM",
        "model",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "RLLaVA: An RL-central Framework for Language and Vision Assistants",
      "url": "https://arxiv.org/abs/2512.21450",
      "description": "arXiv:2512.21450v1 Announce Type: new \nAbstract: We present an RL-central framework for Language and Vision Assistants (RLLaVA) with its formulation of Markov decision process (MDP). RLLaVA decouples RL algorithmic logic from model architecture and distributed execution, supporting researchers in im...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "experiment",
        "vision",
        "model",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "kooplearn: A Scikit-Learn Compatible Library of Algorithms for Evolution Operator Learning",
      "url": "https://arxiv.org/abs/2512.21409",
      "description": "arXiv:2512.21409v1 Announce Type: new \nAbstract: kooplearn is a machine-learning library that implements linear, kernel, and deep-learning estimators of dynamical operators and their spectral decompositions. kooplearn can model both discrete-time evolution operators (Koopman/Transfer) and continuous...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "experiment",
        "API",
        "model",
        "library"
      ],
      "score": 0.4
    },
    {
      "title": "DeepCQ: General-Purpose Deep-Surrogate Framework for Lossy Compression Quality Prediction",
      "url": "https://arxiv.org/abs/2512.21433",
      "description": "arXiv:2512.21433v1 Announce Type: new \nAbstract: Error-bounded lossy compression techniques have become vital for scientific data management and analytics, given the ever-increasing volume of data generated by modern scientific simulations and instruments. Nevertheless, assessing data quality post-c...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "compression",
        "model",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "An Equivariance Toolbox for Learning Dynamics",
      "url": "https://arxiv.org/abs/2512.21447",
      "description": "arXiv:2512.21447v1 Announce Type: new \nAbstract: Many theoretical results in deep learning can be traced to symmetry or equivariance of neural networks under parameter transformations. However, existing analyses are typically problem-specific and focus on first-order consequences such as conservatio...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "framework",
        "tool"
      ],
      "score": 0.4
    },
    {
      "title": "When Bayesian Tensor Completion Meets Multioutput Gaussian Processes: Functional Universality and Rank Learning",
      "url": "https://arxiv.org/abs/2512.21486",
      "description": "arXiv:2512.21486v1 Announce Type: new \nAbstract: Functional tensor decomposition can analyze multi-dimensional data with real-valued indices, paving the path for applications in machine learning and signal processing. A limitation of existing approaches is the assumption that the tensor rank-a criti...",
      "published_date": "2025-12-29T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "framework",
        "model",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}