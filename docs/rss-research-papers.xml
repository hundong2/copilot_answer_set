<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs</title>
      <link>https://arxiv.org/abs/2509.18113</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18113</guid>
      <description>arXiv:2509.18113v1 Announce Type: new 
Abstract: This study addresses the generalization limitations commonly observed in large language models under multi-task and cross-domain settings. Unlike prior methods such as SPoT, which depends on fixed prompt templates, our study introduces a unified multi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; alignment, LLM, framework, arxiv, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>alignment</category>
      <category>LLM</category>
      <category>framework</category>
    </item>
    <item>
      <title>GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models</title>
      <link>https://arxiv.org/abs/2509.18122</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18122</guid>
      <description>arXiv:2509.18122v1 Announce Type: new 
Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of \textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a benchmark that evaluates LLMs&amp;#x27; mathematical abilities across twelve core skill dimensions, grouped into thr...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, GPT, arxiv, large language model, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>GPT</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>On the Non-Uniqueness of Representation of $(U,N)$-Implications</title>
      <link>https://arxiv.org/abs/2509.16299</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.16299</guid>
      <description>arXiv:2509.16299v1 Announce Type: new 
Abstract: Fuzzy implication functions constitute fundamental operators in fuzzy logic systems, extending classical conditionals to manage uncertainty in logical inference. Among the extensive families of these operators, generalizations of the classical materia...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; attention, paper, arxiv, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>attention</category>
      <category>paper</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models</title>
      <link>https://arxiv.org/abs/2509.16332</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.16332</guid>
      <description>arXiv:2509.16332v1 Announce Type: new 
Abstract: Large Language Models increasingly mediate high-stakes interactions, intensifying research on their capabilities and safety. While recent work has shown that LLMs exhibit consistent and measurable synthetic personality traits, little is known about ho...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; alignment, LLM, API, framework, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>alignment</category>
      <category>LLM</category>
      <category>API</category>
    </item>
    <item>
      <title>Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation</title>
      <link>https://arxiv.org/abs/2509.16372</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.16372</guid>
      <description>arXiv:2509.16372v1 Announce Type: new 
Abstract: This study evaluates causal reasoning in large language models (LLMs) using 99 clinically grounded laboratory test scenarios aligned with Pearl&amp;#x27;s Ladder of Causation: association, intervention, and counterfactual reasoning. We examined common laborato...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, GPT, context, arxiv, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>GPT</category>
      <category>context</category>
    </item>
    <item>
      <title>Machine Learnability as a Measure of Order in Aperiodic Sequences</title>
      <link>https://arxiv.org/abs/2509.18103</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18103</guid>
      <description>arXiv:2509.18103v1 Announce Type: new 
Abstract: Research on the distribution of prime numbers has revealed a dual character: deterministic in definition yet exhibiting statistical behavior reminiscent of random processes. In this paper we show that it is possible to use an image-focused machine lea...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; image, paper, arxiv, RAG, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>image</category>
      <category>paper</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>AdaMixT: Adaptive Weighted Mixture of Multi-Scale Expert Transformers for Time Series Forecasting</title>
      <link>https://arxiv.org/abs/2509.18107</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18107</guid>
      <description>arXiv:2509.18107v1 Announce Type: new 
Abstract: Multivariate time series forecasting involves predicting future values based on historical observations. However, existing approaches primarily rely on predefined single-scale patches or lack effective mechanisms for multi-scale feature fusion. These ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, transformer, experiment, model, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>transformer</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Solve it with EASE</title>
      <link>https://arxiv.org/abs/2509.18108</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18108</guid>
      <description>arXiv:2509.18108v1 Announce Type: new 
Abstract: This paper presents EASE (Effortless Algorithmic Solution Evolution), an open-source and fully modular framework for iterative algorithmic solution generation leveraging large language models (LLMs). EASE integrates generation, testing, analysis, and ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, framework, paper, arxiv, platform | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>framework</category>
      <category>paper</category>
    </item>
    <item>
      <title>Large language models surpass domain-specific architectures for antepartum electronic fetal monitoring analysis</title>
      <link>https://arxiv.org/abs/2509.18112</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18112</guid>
      <description>arXiv:2509.18112v1 Announce Type: new 
Abstract: Foundation models (FMs) and large language models (LLMs) demonstrate remarkable capabilities across diverse domains through training on massive datasets. These models have demonstrated exceptional performance in healthcare applications, yet their pote...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, arxiv, large language model, analysis, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>arxiv</category>
      <category>large language model</category>
    </item>
    <item>
      <title>ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers</title>
      <link>https://arxiv.org/abs/2509.18175</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18175</guid>
      <description>arXiv:2509.18175v1 Announce Type: new 
Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in call center analytics, opinion mining, finance, retail, healthcare, and other industries. In a call center scenario, the role of the call center agent is not just confined to...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Exploiting Tree Structure for Credit Assignment in RL Training of LLMs</title>
      <link>https://arxiv.org/abs/2509.18314</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18314</guid>
      <description>arXiv:2509.18314v1 Announce Type: new 
Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over long sequences makes token-level credit assignment the key bottleneck. We study the verifiable-reward setting, where the final answer is checkable and multiple responses can...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, arxiv, study, reasoning, prompt | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>arxiv</category>
      <category>study</category>
    </item>
    <item>
      <title>A global view of diverse construction methods of fuzzy implication functions rooted on F-chains</title>
      <link>https://arxiv.org/abs/2509.16298</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.16298</guid>
      <description>arXiv:2509.16298v1 Announce Type: new 
Abstract: Fuzzy implication functions are one of the most important operators used in the fuzzy logic framework. While their flexible definition allows for diverse families with distinct properties, this variety needs a deeper theoretical understanding of their...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, context, study, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>context</category>
      <category>study</category>
    </item>
    <item>
      <title>Data Valuation and Selection in a Federated Model Marketplace</title>
      <link>https://arxiv.org/abs/2509.18104</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18104</guid>
      <description>arXiv:2509.18104v1 Announce Type: new 
Abstract: In the era of Artificial Intelligence (AI), marketplaces have become essential platforms for facilitating the exchange of data products to foster data sharing. Model transactions provide economic solutions in data marketplaces that enhance data reusab...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; product, framework, paper, arxiv, platform | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>product</category>
      <category>framework</category>
      <category>paper</category>
    </item>
    <item>
      <title>Machine Learning-Based Classification of Vessel Types in Straits Using AIS Tracks</title>
      <link>https://arxiv.org/abs/2509.18109</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18109</guid>
      <description>arXiv:2509.18109v1 Announce Type: new 
Abstract: Accurate recognition of vessel types from Automatic Identification System (AIS) tracks is essential for safety oversight and combating illegal, unreported, and unregulated (IUU) activity. This paper presents a strait-scale, machine-learning pipeline t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, paper, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>paper</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>BULL-ODE: Bullwhip Learning with Neural ODEs and Universal Differential Equations under Stochastic Demand</title>
      <link>https://arxiv.org/abs/2509.18105</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18105</guid>
      <description>arXiv:2509.18105v1 Announce Type: new 
Abstract: We study learning of continuous-time inventory dynamics under stochastic demand and quantify when structure helps or hurts forecasting of the bullwhip effect. BULL-ODE compares a fully learned Neural ODE (NODE) that models the entire right-hand side a...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Model-Based Transfer Learning for Real-Time Damage Assessment of Bridge Networks</title>
      <link>https://arxiv.org/abs/2509.18106</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18106</guid>
      <description>arXiv:2509.18106v1 Announce Type: new 
Abstract: The growing use of permanent monitoring systems has increased data availability, offering new opportunities for structural assessment but also posing scalability challenges, especially across large bridge networks. Managing multiple structures require...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, study, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>study</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Localized PCA-Net Neural Operators for Scalable Solution Reconstruction of Elliptic PDEs</title>
      <link>https://arxiv.org/abs/2509.18110</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.18110</guid>
      <description>arXiv:2509.18110v1 Announce Type: new 
Abstract: Neural operator learning has emerged as a powerful approach for solving partial differential equations (PDEs) in a data-driven manner. However, applying principal component analysis (PCA) to high-dimensional solution fields incurs significant computat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, analysis, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>analysis</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Gaia2 and ARE: Empowering the community to study agents</title>
      <link>https://huggingface.co/blog/gaia2</link>
      <guid isPermaLink="false">https://huggingface.co/blog/gaia2</guid>
      <description>...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; Hugging Face Blog | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 20%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 22 Sep 2025 00:00:00 </pubDate>
      <author>noreply@contextengineering.news (Hugging Face Blog)</author>
      <category>Research Papers</category>
      <category>study</category>
    </item>
  </channel>
</rss>