{
  "generated_at": "2026-01-13T20:06:23.382094",
  "total_items": 46,
  "items": [
    {
      "title": "TeleMem: Building Long-Term and Multimodal Memory for Agentic AI",
      "url": "https://arxiv.org/abs/2601.06037",
      "description": "arXiv:2601.06037v1 Announce Type: new \nAbstract: Large language models (LLMs) excel at many NLP tasks but struggle to sustain long-term interactions due to limited attention over extended dialogue histories. Retrieval-augmented generation (RAG) mitigates this issue but lacks reliable mechanisms for ...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "experiment",
        "context",
        "arxiv",
        "memory",
        "retrieval",
        "augmented",
        "attention",
        "LLM",
        "large language model",
        "RAG",
        "multimodal",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Operation Veja: Fixing Fundamental Concepts Missing from Modern Roleplaying Training Paradigms",
      "url": "https://arxiv.org/abs/2601.06039",
      "description": "arXiv:2601.06039v1 Announce Type: new \nAbstract: Modern roleplaying models are increasingly sophisticated, yet they consistently struggle to capture the essence of believable, engaging characters. We argue this failure stems from training paradigms that overlook the dynamic interplay of a character'...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "paper",
        "arxiv",
        "retrieval",
        "augmented",
        "LLM",
        "RAG",
        "study",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Lexical and Statistical Analysis of Bangla Newspaper and Literature: A Corpus-Driven Study on Diversity, Readability, and NLP Adaptation",
      "url": "https://arxiv.org/abs/2601.06041",
      "description": "arXiv:2601.06041v1 Announce Type: new \nAbstract: In this paper, we present a comprehensive corpus-driven analysis of Bangla literary and newspaper texts to investigate their lexical diversity, structural complexity and readability. We undertook Vacaspati and IndicCorp, which are the most extensive l...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "analysis",
        "RAG",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization",
      "url": "https://arxiv.org/abs/2601.06052",
      "description": "arXiv:2601.06052v1 Announce Type: new \nAbstract: Chain-of-thought reasoning in large language models often creates an \"overthinking trap,\" leading to excessive computational cost and latency for unreliable accuracy gains. Prior work has typically relied on global, static controls that risk penalizin...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "experiment",
        "arxiv",
        "chain-of-thought",
        "large language model",
        "instruction",
        "RAG",
        "compression",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "A Multi-Stage Workflow for the Review of Marketing Content with Reasoning Large Language Models",
      "url": "https://arxiv.org/abs/2601.06054",
      "description": "arXiv:2601.06054v1 Announce Type: new \nAbstract: Reasoning Large Language Models (LLMs) have shown promising results when tasked with solving complex problems. In this paper, we propose and evaluate a multi-stage workflow that leverages the capabilities of fine-tuned reasoning LLMs to assist in the ...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "LLM",
        "large language model",
        "RAG",
        "fine-tuning",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "AzeroS: Extending LLM to Speech with Self-Generated Instruction-Free Tuning",
      "url": "https://arxiv.org/abs/2601.06086",
      "description": "arXiv:2601.06086v1 Announce Type: new \nAbstract: Extending large language models (LLMs) to the speech domain has recently gained significant attention. A typical approach connects a pretrained LLM with an audio encoder through a projection module and trains the resulting model on large-scale, task-s...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "ICL",
        "vision",
        "arxiv",
        "audio",
        "attention",
        "LLM",
        "large language model",
        "instruction",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Is Sanskrit the most token-efficient language? A quantitative study using GPT, Gemini, and SentencePiece",
      "url": "https://arxiv.org/abs/2601.06142",
      "description": "arXiv:2601.06142v1 Announce Type: new \nAbstract: Tokens are the basic units of Large Language Models (LLMs). LLMs rely on tokenizers to segment text into these tokens, and tokenization is the primary determinant of computational and inference cost. Sanskrit, one of the oldest languages, is hypothesi...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "research",
        "arxiv",
        "LLM",
        "large language model",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Amory: Building Coherent Narrative-Driven Agent Memory through Agentic Reasoning",
      "url": "https://arxiv.org/abs/2601.06282",
      "description": "arXiv:2601.06282v1 Announce Type: new \nAbstract: Long-term conversational agents face a fundamental scalability challenge as interactions extend over time: repeatedly processing entire conversation histories becomes computationally prohibitive. Current approaches attempt to solve this through memory...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "context",
        "arxiv",
        "memory",
        "retrieval",
        "analysis",
        "RAG",
        "reasoning",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "How well can off-the-shelf LLMs elucidate molecular structures from mass spectra using chain-of-thought reasoning?",
      "url": "https://arxiv.org/abs/2601.06289",
      "description": "arXiv:2601.06289v1 Announce Type: new \nAbstract: Mass spectrometry (MS) is a powerful analytical technique for identifying small molecules, yet determining complete molecular structures directly from tandem mass spectra (MS/MS) remains a long-standing challenge due to complex fragmentation patterns ...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "GPT",
        "prompting",
        "prompt",
        "CoT",
        "framework",
        "arxiv",
        "chain-of-thought",
        "LLM",
        "large language model",
        "analysis",
        "RAG",
        "reasoning",
        "zero-shot",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "$\\texttt{AMEND++}$: Benchmarking Eligibility Criteria Amendments in Clinical Trials",
      "url": "https://arxiv.org/abs/2601.06300",
      "description": "arXiv:2601.06300v1 Announce Type: new \nAbstract: Clinical trial amendments frequently introduce delays, increased costs, and administrative burden, with eligibility criteria being the most commonly amended component. We introduce \\textit{eligibility criteria amendment prediction}, a novel NLP task t...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vision",
        "experiment",
        "arxiv",
        "LLM",
        "RAG",
        "release",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Naiad: Novel Agentic Intelligent Autonomous System for Inland Water Monitoring",
      "url": "https://arxiv.org/abs/2601.05256",
      "description": "arXiv:2601.05256v1 Announce Type: new \nAbstract: Inland water monitoring is vital for safeguarding public health and ecosystems, enabling timely interventions to mitigate risks. Existing methods often address isolated sub-problems such as cyanobacteria, chlorophyll, or other quality indicators separ...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "image",
        "platform",
        "prompt",
        "arxiv",
        "retrieval",
        "augmented",
        "LLM",
        "large language model",
        "tool",
        "RAG",
        "study",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Mathematical Knowledge Graph-Driven Framework for Equation-Based Predictive and Reliable Additive Manufacturing",
      "url": "https://arxiv.org/abs/2601.05298",
      "description": "arXiv:2601.05298v1 Announce Type: new \nAbstract: Additive manufacturing (AM) relies critically on understanding and extrapolating process-property relationships; however, existing data-driven approaches remain limited by fragmented knowledge representations and unreliable extrapolation under sparse ...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "arxiv",
        "augmented",
        "LLM",
        "large language model",
        "tool",
        "RAG",
        "study",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Effects of personality steering on cooperative behavior in Large Language Model agents",
      "url": "https://arxiv.org/abs/2601.05302",
      "description": "arXiv:2601.05302v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly used as autonomous agents in strategic and social interactions. Although recent studies suggest that assigning personality traits to LLMs can influence their behavior, how personality steering affects coop...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "framework",
        "arxiv",
        "LLM",
        "large language model",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Improving Enzyme Prediction with Chemical Reaction Equations by Hypergraph-Enhanced Knowledge Graph Embeddings",
      "url": "https://arxiv.org/abs/2601.05330",
      "description": "arXiv:2601.05330v1 Announce Type: new \nAbstract: Predicting enzyme-substrate interactions has long been a fundamental problem in biochemistry and metabolic engineering. While existing methods could leverage databases of expert-curated enzyme-substrate pairs for models to learn from known pair intera...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "experiment",
        "arxiv",
        "product",
        "retrieval",
        "model",
        "RAG",
        "transformer",
        "example",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models",
      "url": "https://arxiv.org/abs/2601.05376",
      "description": "arXiv:2601.05376v1 Announce Type: new \nAbstract: Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly cha...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "arxiv",
        "LLM",
        "large language model",
        "RAG",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "ART: Adaptive Reasoning Trees for Explainable Claim Verification",
      "url": "https://arxiv.org/abs/2601.05455",
      "description": "arXiv:2601.05455v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are powerful candidates for complex decision-making, leveraging vast encoded knowledge and remarkable zero-shot abilities. However, their adoption in high-stakes environments is hindered by their opacity; their outputs lac...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "paper",
        "arxiv",
        "chain-of-thought",
        "LLM",
        "large language model",
        "RAG",
        "reasoning",
        "zero-shot",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering",
      "url": "https://arxiv.org/abs/2601.05465",
      "description": "arXiv:2601.05465v1 Announce Type: new \nAbstract: Answering real-world open-domain multi-hop questions over massive corpora is a critical challenge in Retrieval-Augmented Generation (RAG) systems. Recent research employs reinforcement learning (RL) to end-to-end optimize the retrieval-augmented reaso...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "research",
        "experiment",
        "context",
        "arxiv",
        "retrieval",
        "augmented",
        "RAG",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "MMUEChange: A Generalized LLM Agent Framework for Intelligent Multi-Modal Urban Environment Change Analysis",
      "url": "https://arxiv.org/abs/2601.05483",
      "description": "arXiv:2601.05483v1 Announce Type: new \nAbstract: Understanding urban environment change is essential for sustainable development. However, current approaches, particularly remote sensing change detection, often rely on rigid, single-modal analysis. To overcome these limitations, we propose MMUEChang...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "alignment",
        "arxiv",
        "analysis",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "CrossTrafficLLM: A Human-Centric Framework for Interpretable Traffic Intelligence via Large Language Model",
      "url": "https://arxiv.org/abs/2601.06042",
      "description": "arXiv:2601.06042v1 Announce Type: new \nAbstract: While accurate traffic forecasting is vital for Intelligent Transportation Systems (ITS), effectively communicating predicted conditions via natural language for human-centric decision support remains a challenge and is often handled separately. To ad...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "ICL",
        "framework",
        "context",
        "arxiv",
        "LLM",
        "large language model",
        "RAG",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Enabling Long FFT Convolutions on Memory-Constrained FPGAs via Chunking",
      "url": "https://arxiv.org/abs/2601.06065",
      "description": "arXiv:2601.06065v1 Announce Type: new \nAbstract: The need for long-context reasoning has led to alternative neural network architectures besides Transformers and self-attention, a popular model being Hyena, which employs causal 1D-convolutions implemented with FFTs. Long convolutions enable efficien...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "context",
        "arxiv",
        "memory",
        "attention",
        "model",
        "reasoning",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "The Hessian of tall-skinny networks is easy to invert",
      "url": "https://arxiv.org/abs/2601.06096",
      "description": "arXiv:2601.06096v1 Announce Type: new \nAbstract: We describe an exact algorithm for solving linear systems $Hx=b$ where $H$ is the Hessian of a deep net. The method computes Hessian-inverse-vector products without storing the Hessian or its inverse in time and storage that scale linearly in the numb...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "vector",
        "arxiv",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "Filtering Beats Fine Tuning: A Bayesian Kalman View of In Context Learning in LLMs",
      "url": "https://arxiv.org/abs/2601.06100",
      "description": "arXiv:2601.06100v1 Announce Type: new \nAbstract: We present a theory-first framework that interprets inference-time adaptation in large language models (LLMs) as online Bayesian state estimation. Rather than modeling rapid adaptation as implicit optimization or meta-learning, we formulate task- and ...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "in-context",
        "prompt",
        "framework",
        "context",
        "arxiv",
        "LLM",
        "large language model",
        "experiment",
        "API",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "The Impact of Post-training on Data Contamination",
      "url": "https://arxiv.org/abs/2601.06103",
      "description": "arXiv:2601.06103v1 Announce Type: new \nAbstract: We present a controlled study of how dataset contamination interacts with the post-training stages now standard in large language model training pipelines. Starting from clean checkpoints of Qwen2.5 (0.5B/1.5B) and Gemma3 (1B/4B), we inject five copie...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "large language model",
        "fine-tuning",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Judge Model for Large-scale Multimodality Benchmarks",
      "url": "https://arxiv.org/abs/2601.06106",
      "description": "arXiv:2601.06106v1 Announce Type: new \nAbstract: We propose a dedicated multimodal Judge Model designed to provide reliable, explainable evaluation across a diverse suite of tasks. Our benchmark spans text, audio, image, and video modalities, drawing from carefully sampled public datasets with fixed...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "image",
        "alignment",
        "framework",
        "research",
        "arxiv",
        "audio",
        "LLM",
        "multimodal",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "GroupSegment-SHAP: Shapley Value Explanations with Group-Segment Players for Multivariate Time Series",
      "url": "https://arxiv.org/abs/2601.06114",
      "description": "arXiv:2601.06114v1 Announce Type: new \nAbstract: Multivariate time-series models achieve strong predictive performance in healthcare, industry, energy, and finance, but how they combine cross-variable interactions with temporal dynamics remains unclear. SHapley Additive exPlanations (SHAP) are widel...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "RAG",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context",
        "context window",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "CoT",
        "audio",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "context",
        "LLM",
        "tool",
        "API",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "context",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "retrieval",
        "LLM",
        "knowledge base",
        "RAG",
        "vector",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "product",
        "retrieval",
        "augmented",
        "RAG",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "framework",
        "prompt",
        "LLM",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Tree-Preconditioned Differentiable Optimization and Axioms as Layers",
      "url": "https://arxiv.org/abs/2601.06036",
      "description": "arXiv:2601.06036v1 Announce Type: new \nAbstract: This paper introduces a differentiable framework that embeds the axiomatic structure of Random Utility Models (RUM) directly into deep neural networks. Although projecting empirical choice data onto the RUM polytope is NP-hard in general, we uncover a...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "paper",
        "arxiv",
        "RAG",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Stress Testing Machine Learning at $10^{10}$ Scale: A Comprehensive Study of Adversarial Robustness on Algebraically Structured Integer Streams",
      "url": "https://arxiv.org/abs/2601.06117",
      "description": "arXiv:2601.06117v1 Announce Type: new \nAbstract: This paper presents a large-scale stress test of machine learning systems using structured mathematical data as a benchmark. We evaluate the robustness of tree-based classifiers at an unprecedented scale, utilizing ten billion deterministic samples an...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "paper",
        "arxiv",
        "model",
        "experiment",
        "study",
        "example"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "model",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Conformity and Social Impact on AI Agents",
      "url": "https://arxiv.org/abs/2601.05384",
      "description": "arXiv:2601.05384v1 Announce Type: new \nAbstract: As AI agents increasingly operate in multi-agent environments, understanding their collective behavior becomes critical for predicting the dynamics of artificial societies. This study examines conformity, the tendency to align with group opinions unde...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "study",
        "multimodal",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Australian Bushfire Intelligence with AI-Driven Environmental Analytics",
      "url": "https://arxiv.org/abs/2601.06105",
      "description": "arXiv:2601.06105v1 Announce Type: new \nAbstract: Bushfires are among the most destructive natural hazards in Australia, causing significant ecological, economic, and social damage. Accurate prediction of bushfire intensity is therefore essential for effective disaster preparedness and response. This...",
      "published_date": "2026-01-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "model",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}