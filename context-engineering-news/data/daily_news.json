{
  "generated_at": "2025-08-15T20:05:37.129368",
  "total_items": 45,
  "items": [
    {
      "title": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry",
      "url": "https://arxiv.org/abs/2508.09991",
      "description": "arXiv:2508.09991v1 Announce Type: new \nAbstract: Automating data extraction from clinical documents offers significant potential to improve efficiency in healthcare settings, yet deploying Natural Language Processing (NLP) solutions presents practical challenges. Drawing upon our experience implemen...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "paper",
        "attention",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "A Transparent Fairness Evaluation Protocol for Open-Source Language Model Benchmarking on the Blockchain",
      "url": "https://arxiv.org/abs/2508.09993",
      "description": "arXiv:2508.09993v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly deployed in realworld applications, yet concerns about their fairness persist especially in highstakes domains like criminal justice, education, healthcare, and finance. This paper introduces transparent e...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "prompt",
        "LLM",
        "model",
        "arxiv",
        "analysis",
        "large language model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Thematic and Task-Based Categorization of K-12 GenAI Usages with Hierarchical Topic Modeling",
      "url": "https://arxiv.org/abs/2508.09997",
      "description": "arXiv:2508.09997v1 Announce Type: new \nAbstract: We analyze anonymous interaction data of minors in class-rooms spanning several months, schools, and subjects employing a novel, simple topic modeling approach. Specifically, we categorize more than 17,000 messages generated by students, teachers, and...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "LLM",
        "instruction",
        "arxiv",
        "model",
        "research",
        "alignment",
        "analysis",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs",
      "url": "https://arxiv.org/abs/2508.09999",
      "description": "arXiv:2508.09999v1 Announce Type: new \nAbstract: The rapid spread of multimodal misinformation on social media calls for more effective and robust detection methods. Recent advances leveraging multimodal large language models (MLLMs) have shown the potential in addressing this challenge. However, it...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "multimodal",
        "RAG",
        "framework",
        "API",
        "LLM",
        "model",
        "arxiv",
        "retrieval",
        "analysis",
        "release",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "AutoGeTS: Knowledge-based Automated Generation of Text Synthetics for Improving Text Classification",
      "url": "https://arxiv.org/abs/2508.10000",
      "description": "arXiv:2508.10000v1 Announce Type: new \nAbstract: When developing text classification models for real world applications, one major challenge is the difficulty to collect sufficient data for all text classes. In this work, we address this challenge by utilizing large language models (LLMs) to generat...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "example",
        "LLM",
        "model",
        "arxiv",
        "large language model",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish",
      "url": "https://arxiv.org/abs/2508.10001",
      "description": "arXiv:2508.10001v1 Announce Type: new \nAbstract: Fact-checking in code-mixed, low-resource languages such as Hinglish remains an underexplored challenge in natural language processing. Existing fact-verification systems largely focus on high-resource, monolingual settings and fail to generalize to r...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "augmented",
        "model",
        "reasoning",
        "arxiv",
        "retrieval",
        "tool",
        "alignment",
        "research",
        "experiment",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Semantic Structure in Large Language Model Embeddings",
      "url": "https://arxiv.org/abs/2508.10003",
      "description": "arXiv:2508.10003v1 Announce Type: new \nAbstract: Psychological research consistently finds that human ratings of words across diverse semantic scales can be reduced to a low-dimensional form with relatively little information loss. We find that the semantic associations encoded in the embedding matr...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "embedding",
        "LLM",
        "model",
        "arxiv",
        "research",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents",
      "url": "https://arxiv.org/abs/2508.10004",
      "description": "arXiv:2508.10004v1 Announce Type: new \nAbstract: The attention mechanism is a core component of the Transformer architecture. Beyond improving performance, attention has been proposed as a mechanism for explainability via attention weights, which are associated with input features (e.g., tokens in a...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "attention",
        "model",
        "arxiv",
        "research",
        "ICL",
        "context",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation",
      "url": "https://arxiv.org/abs/2508.10005",
      "description": "arXiv:2508.10005v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in mathematical problem-solving. However, the transition from providing answers to generating high-quality educational questions presents significant challenges that remain underex...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "LLM",
        "model",
        "arxiv",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions",
      "url": "https://arxiv.org/abs/2508.10047",
      "description": "arXiv:2508.10047v1 Announce Type: new \nAbstract: By virtue of its great utility in solving real-world problems, optimization modeling has been widely employed for optimal decision-making across various sectors, but it requires substantial expertise from operations research professionals. With the ad...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "framework",
        "fine-tuning",
        "LLM",
        "model",
        "arxiv",
        "research",
        "analysis",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development",
      "url": "https://arxiv.org/abs/2508.10108",
      "description": "arXiv:2508.10108v1 Announce Type: new \nAbstract: AI systems for software development are rapidly gaining prominence, yet significant challenges remain in ensuring their safety. To address this, Amazon launched the Trusted AI track of the Amazon Nova AI Challenge, a global competition among 10 univer...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "paper",
        "API",
        "LLM",
        "platform",
        "arxiv",
        "model",
        "alignment",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection",
      "url": "https://arxiv.org/abs/2508.10143",
      "description": "arXiv:2508.10143v1 Announce Type: new \nAbstract: The large spread of disinformation across digital platforms creates significant challenges to information integrity. This paper presents a multi-agent system that uses relation extraction to detect disinformation in news articles, focusing on titles a...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "prompt",
        "LLM",
        "platform",
        "prompt engineering",
        "arxiv",
        "model",
        "ICL",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges",
      "url": "https://arxiv.org/abs/2508.10146",
      "description": "arXiv:2508.10146v1 Announce Type: new \nAbstract: The emergence of Large Language Models (LLMs) has ushered in a transformative paradigm in artificial intelligence, Agentic AI, where intelligent agents exhibit goal-directed autonomy, contextual reasoning, and dynamic multi-agent coordination. This pa...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "memory",
        "framework",
        "LLM",
        "model",
        "reasoning",
        "arxiv",
        "research",
        "alignment",
        "analysis",
        "large language model",
        "context",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization",
      "url": "https://arxiv.org/abs/2508.10164",
      "description": "arXiv:2508.10164v1 Announce Type: new \nAbstract: Recent advances in Large Reasoning Models (LRMs) have demonstrated strong performance on complex tasks through long Chain-of-Thought (CoT) reasoning. However, their lengthy outputs increase computational costs and may lead to overthinking, raising cha...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "CoT",
        "paper",
        "framework",
        "chain-of-thought",
        "model",
        "arxiv",
        "analysis",
        "experiment",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems",
      "url": "https://arxiv.org/abs/2508.10177",
      "description": "arXiv:2508.10177v1 Announce Type: new \nAbstract: Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive capabilities but face significant limitations such as constrained exploration strategies and a severe execution bottleneck. Exploration is hindered by one-shot methods lacki...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "paper",
        "framework",
        "LLM",
        "model",
        "arxiv",
        "retrieval",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Why Cannot Large Language Models Ever Make True Correct Reasoning?",
      "url": "https://arxiv.org/abs/2508.10265",
      "description": "arXiv:2508.10265v1 Announce Type: new \nAbstract: Recently, with the application progress of AIGC tools based on large language models (LLMs), led by ChatGPT, many AI experts and more non-professionals are trumpeting the \"understanding ability\" and \"reasoning ability\" of the LLMs. The present author ...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "LLM",
        "model",
        "arxiv",
        "tool",
        "large language model",
        "reasoning",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Promoting Efficient Reasoning with Verifiable Stepwise Reward",
      "url": "https://arxiv.org/abs/2508.10293",
      "description": "arXiv:2508.10293v1 Announce Type: new \nAbstract: Large reasoning models (LRMs) have recently achieved significant progress in complex reasoning tasks, aided by reinforcement learning with verifiable rewards. However, LRMs often suffer from overthinking, expending excessive computation on simple prob...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "model",
        "arxiv",
        "analysis",
        "release",
        "step-by-step",
        "experiment",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Measuring Time Series Forecast Stability for Demand Planning",
      "url": "https://arxiv.org/abs/2508.10063",
      "description": "arXiv:2508.10063v1 Announce Type: new \nAbstract: Time series forecasting is a critical first step in generating demand plans for supply chains. Experiments on time series models typically focus on demonstrating improvements in forecast accuracy over existing/baseline solutions, quantified according ...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "study",
        "model",
        "arxiv",
        "product",
        "experiment",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "Constrained Decoding of Diffusion LLMs with Context-Free Grammars",
      "url": "https://arxiv.org/abs/2508.10111",
      "description": "arXiv:2508.10111v1 Announce Type: new \nAbstract: Large language models (LLMs) have shown promising performance across diverse domains. Many practical applications of LLMs, such as code completion and structured data extraction, require adherence to syntactic constraints specified by a formal languag...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "LLM",
        "model",
        "arxiv",
        "large language model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Less is More: Learning Graph Tasks with Just LLMs",
      "url": "https://arxiv.org/abs/2508.10115",
      "description": "arXiv:2508.10115v1 Announce Type: new \nAbstract: For large language models (LLMs), reasoning over graphs could help solve many problems. Prior work has tried to improve LLM graph reasoning by examining how best to serialize graphs as text and by combining GNNs and LLMs. However, the merits of such a...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "LLM",
        "chain-of-thought",
        "arxiv",
        "model",
        "research",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "From Intent to Execution: Multimodal Chain-of-Thought Reinforcement Learning for Precise CAD Code Generation",
      "url": "https://arxiv.org/abs/2508.10118",
      "description": "arXiv:2508.10118v1 Announce Type: new \nAbstract: Computer-Aided Design (CAD) plays a vital role in engineering and manufacturing, yet current CAD workflows require extensive domain expertise and manual modeling effort. Recent advances in large language models (LLMs) have made it possible to generate...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "multimodal",
        "CoT",
        "example",
        "framework",
        "LLM",
        "chain-of-thought",
        "arxiv",
        "model",
        "experiment",
        "release",
        "large language model",
        "vision",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts",
      "url": "https://arxiv.org/abs/2508.10123",
      "description": "arXiv:2508.10123v1 Announce Type: new \nAbstract: Advanced reasoning in LLMs on challenging domains like mathematical reasoning can be tackled using verifiable rewards based reinforced fine-tuning (ReFT). In standard ReFT frameworks, a behavior model generates multiple completions with answers per pr...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "fine-tuning",
        "LLM",
        "model",
        "arxiv",
        "analysis",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "rETF-semiSL: Semi-Supervised Learning for Neural Collapse in Temporal Data",
      "url": "https://arxiv.org/abs/2508.10147",
      "description": "arXiv:2508.10147v1 Announce Type: new \nAbstract: Deep neural networks for time series must capture complex temporal patterns, to effectively represent dynamic data. Self- and semi-supervised learning methods show promising results in pre-training large models, which -- when finetuned for classificat...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "embedding",
        "transformer",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Out-of-Distribution Detection using Counterfactual Distance",
      "url": "https://arxiv.org/abs/2508.10148",
      "description": "arXiv:2508.10148v1 Announce Type: new \nAbstract: Accurate and explainable out-of-distribution (OOD) detection is required to use machine learning systems safely. Previous work has shown that feature distance to decision boundaries can be used to identify OOD data effectively. In this paper, we build...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "embedding",
        "RAG",
        "paper",
        "image",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt",
        "prompt engineering",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "CoT",
        "framework",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "context",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "attention",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "framework",
        "LLM",
        "model",
        "retrieval",
        "vector",
        "knowledge base",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "fine-tuning",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "API",
        "retrieval",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "prompt",
        "LLM",
        "platform",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "xRFM: Accurate, scalable, and interpretable feature learning models for tabular data",
      "url": "https://arxiv.org/abs/2508.10053",
      "description": "arXiv:2508.10053v1 Announce Type: new \nAbstract: Inference from tabular data, collections of continuous and categorical variables organized into matrices, is a foundation for modern technology and science. Yet, in contrast to the explosive changes in the rest of AI, the best practice for these predi...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "RAG",
        "model",
        "arxiv",
        "product"
      ],
      "score": 0.8
    },
    {
      "title": "A Personalized Exercise Assistant using Reinforcement Learning (PEARL): Results from a four-arm Randomized-controlled Trial",
      "url": "https://arxiv.org/abs/2508.10060",
      "description": "arXiv:2508.10060v1 Announce Type: new \nAbstract: Consistent physical inactivity poses a major global health challenge. Mobile health (mHealth) interventions, particularly Just-in-Time Adaptive Interventions (JITAIs), offer a promising avenue for scalable, personalized physical activity (PA) promotio...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "RAG",
        "study",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "context",
        "tool",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "paper",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Improving and Evaluating Open Deep Research Agents",
      "url": "https://arxiv.org/abs/2508.10152",
      "description": "arXiv:2508.10152v1 Announce Type: new \nAbstract: We focus here on Deep Research Agents (DRAs), which are systems that can take a natural language prompt from a user, and then autonomously search for, and utilize, internet-based content to address the prompt. Recent DRAs have demonstrated impressive ...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "research",
        "model",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "OpenFPL: An open-source forecasting method rivaling state-of-the-art Fantasy Premier League services",
      "url": "https://arxiv.org/abs/2508.09992",
      "description": "arXiv:2508.09992v1 Announce Type: new \nAbstract: Fantasy Premier League engages the football community in selecting the Premier League players who will perform best from gameweek to gameweek. Access to accurate performance forecasts gives participants an edge over competitors by guiding expectations...",
      "published_date": "2025-08-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "model",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}