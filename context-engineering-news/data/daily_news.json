{
  "generated_at": "2025-08-01T20:05:38.823249",
  "total_items": 45,
  "items": [
    {
      "title": "Large Language Models in the Travel Domain: An Industrial Experience",
      "url": "https://arxiv.org/abs/2507.22910",
      "description": "arXiv:2507.22910v1 Announce Type: new \nAbstract: Online property booking platforms are widely used and rely heavily on consistent, up-to-date information about accommodation facilities, often sourced from third-party providers. However, these external data sources are frequently affected by incomple...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "LLM",
        "platform",
        "context",
        "arxiv",
        "product",
        "study",
        "model",
        "RAG",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing",
      "url": "https://arxiv.org/abs/2507.22911",
      "description": "arXiv:2507.22911v1 Announce Type: new \nAbstract: Electric power marketing customer service plays a critical role in addressing inquiries, complaints, and service requests. However, current systems, such as China's 95598 hotline, often struggle with slow response times, inflexible procedures, and lim...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "LLM",
        "GPT",
        "arxiv",
        "model",
        "augmented",
        "experiment",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms",
      "url": "https://arxiv.org/abs/2507.22912",
      "description": "arXiv:2507.22912v1 Announce Type: new \nAbstract: Illegal marketplaces have increasingly shifted to concealed parts of the internet, including the deep and dark web, as well as platforms such as Telegram, Reddit, and Pastebin. These channels enable the anonymous trade of illicit goods including drugs...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "platform",
        "transformer",
        "arxiv",
        "experiment",
        "vision",
        "model",
        "framework",
        "paper",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models",
      "url": "https://arxiv.org/abs/2507.22913",
      "description": "arXiv:2507.22913v1 Announce Type: new \nAbstract: Providing subject access to information resources is an essential function of any library management system. Large language models (LLMs) have been widely used in classification and summarization tasks, but their capability to perform subject analysis...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "LLM",
        "model",
        "analysis",
        "arxiv",
        "summarization",
        "library",
        "framework",
        "experiment",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs",
      "url": "https://arxiv.org/abs/2507.22914",
      "description": "arXiv:2507.22914v1 Announce Type: new \nAbstract: Knowledge graphs (KGs) are powerful tools for representing and reasoning over structured information. Their main components include schema, identity, and context. While schema and identity matching are well-established in ontology and entity matching ...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "tool",
        "reasoning",
        "context",
        "arxiv",
        "vector",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Theoretical Foundations and Mitigation of Hallucination in Large Language Models",
      "url": "https://arxiv.org/abs/2507.22915",
      "description": "arXiv:2507.22915v1 Announce Type: new \nAbstract: Hallucination in Large Language Models (LLMs) refers to the generation of content that is not faithful to the input or the real-world facts. This paper provides a rigorous treatment of hallucination in LLMs, including formal definitions and theoretica...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "retrieval",
        "LLM",
        "framework",
        "fine-tuning",
        "arxiv",
        "experiment",
        "model",
        "alignment",
        "augmented",
        "attention",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Reading Between the Timelines: RAG for Answering Diachronic Questions",
      "url": "https://arxiv.org/abs/2507.22917",
      "description": "arXiv:2507.22917v1 Announce Type: new \nAbstract: While Retrieval-Augmented Generation (RAG) excels at injecting static, factual knowledge into Large Language Models (LLMs), it exhibits a critical deficit in handling longitudinal queries that require tracking entities and phenomena across time. This ...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "retrieval",
        "LLM",
        "framework",
        "analysis",
        "augmented",
        "arxiv",
        "study",
        "model",
        "ICL",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Semantic Convergence: Investigating Shared Representations Across Scaled LLMs",
      "url": "https://arxiv.org/abs/2507.22918",
      "description": "arXiv:2507.22918v1 Announce Type: new \nAbstract: We investigate feature universality in Gemma-2 language models (Gemma-2-2B and Gemma-2-9B), asking whether models with a four-fold difference in scale still converge on comparable internal concepts. Using the Sparse Autoencoder (SAE) dictionary-learni...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "LLM",
        "analysis",
        "arxiv",
        "model",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations",
      "url": "https://arxiv.org/abs/2507.22919",
      "description": "arXiv:2507.22919v1 Announce Type: new \nAbstract: Objectives: With accurate estimates of expected safety results, clinical trials could be designed to avoid terminations and limit exposing participants to unnecessary risks. We evaluated methods for predicting serious adverse event (SAE) results in cl...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "transformer",
        "arxiv",
        "model",
        "RAG",
        "experiment",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey",
      "url": "https://arxiv.org/abs/2507.22920",
      "description": "arXiv:2507.22920v1 Announce Type: new \nAbstract: The rapid advancement of large language models (LLMs) has intensified the need for effective mechanisms to transform continuous multimodal data into discrete representations suitable for language-based processing. Discrete tokenization, with vector qu...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "LLM",
        "reasoning",
        "analysis",
        "API",
        "context",
        "arxiv",
        "multimodal",
        "vector",
        "research",
        "model",
        "alignment",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "FairReason: Balancing Reasoning and Social Bias in MLLMs",
      "url": "https://arxiv.org/abs/2507.23067",
      "description": "arXiv:2507.23067v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) already achieve state-of-the-art results across a wide range of tasks and modalities. To push their reasoning ability further, recent studies explore advanced prompting schemes and post-training fine-tuning. Al...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "LLM",
        "reasoning",
        "fine-tuning",
        "arxiv",
        "multimodal",
        "study",
        "research",
        "model",
        "prompt",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Moravec's Paradox: Towards an Auditory Turing Test",
      "url": "https://arxiv.org/abs/2507.23091",
      "description": "arXiv:2507.23091v1 Announce Type: new \nAbstract: This research work demonstrates that current AI systems fail catastrophically on auditory tasks that humans perform effortlessly. Drawing inspiration from Moravec's paradox (i.e., tasks simple for humans often prove difficult for machines, and vice ve...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "analysis",
        "audio",
        "context",
        "arxiv",
        "multimodal",
        "research",
        "model",
        "framework",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "Argumentatively Coherent Judgmental Forecasting",
      "url": "https://arxiv.org/abs/2507.23163",
      "description": "arXiv:2507.23163v1 Announce Type: new \nAbstract: Judgmental forecasting employs human opinions to make predictions about future events, rather than exclusively historical data as in quantitative forecasting. When these opinions form an argumentative structure around forecasts, it is useful to study ...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "LLM",
        "reasoning",
        "arxiv",
        "experiment",
        "study",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "How Far Are AI Scientists from Changing the World?",
      "url": "https://arxiv.org/abs/2507.23276",
      "description": "arXiv:2507.23276v1 Announce Type: new \nAbstract: The emergence of large language models (LLMs) is propelling automated scientific discovery to the next level, with LLM-based Artificial Intelligence (AI) Scientist systems now taking the lead in scientific research. Several influential works have alre...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "LLM",
        "API",
        "arxiv",
        "research",
        "model",
        "ICL",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "DSBC : Data Science task Benchmarking with Context engineering",
      "url": "https://arxiv.org/abs/2507.23336",
      "description": "arXiv:2507.23336v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) have significantly impacted data science workflows, giving rise to specialized data science agents designed to automate analytical tasks. Despite rapid adoption, systematic benchmarks evaluating the effi...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "instruction",
        "large language model",
        "LLM",
        "model",
        "paper",
        "API",
        "context",
        "arxiv",
        "research",
        "zero-shot",
        "framework",
        "prompt",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Neural Autoregressive Modeling of Brain Aging",
      "url": "https://arxiv.org/abs/2507.22954",
      "description": "arXiv:2507.22954v1 Announce Type: new \nAbstract: Brain aging synthesis is a critical task with broad applications in clinical and computational neuroscience. The ability to predict the future structural evolution of a subject's brain from an earlier MRI scan provides valuable insights into aging tra...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "image",
        "transformer",
        "arxiv",
        "model",
        "attention",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "LLM-Assisted Cheating Detection in Korean Language via Keystrokes",
      "url": "https://arxiv.org/abs/2507.22956",
      "description": "arXiv:2507.22956v1 Announce Type: new \nAbstract: This paper presents a keystroke-based framework for detecting LLM-assisted cheating in Korean, addressing key gaps in prior research regarding language coverage, cognitive context, and the granularity of LLM involvement. Our proposed dataset includes ...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "GPT",
        "context",
        "arxiv",
        "research",
        "model",
        "framework",
        "RAG",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Multi-Hazard Early Warning Systems for Agriculture with Featural-Temporal Explanations",
      "url": "https://arxiv.org/abs/2507.22962",
      "description": "arXiv:2507.22962v1 Announce Type: new \nAbstract: Climate extremes present escalating risks to agriculture intensifying the need for reliable multi-hazard early warning systems (EWS). The situation is evolving due to climate change and hence such systems should have the intelligent to continue to lea...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "research",
        "model",
        "framework",
        "attention",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Planning for Cooler Cities: A Multimodal AI Framework for Predicting and Mitigating Urban Heat Stress through Urban Landscape Transformation",
      "url": "https://arxiv.org/abs/2507.23000",
      "description": "arXiv:2507.23000v1 Announce Type: new \nAbstract: As extreme heat events intensify due to climate change and urbanization, cities face increasing challenges in mitigating outdoor heat stress. While traditional physical models such as SOLWEIG and ENVI-met provide detailed assessments of human-perceive...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "tool",
        "analysis",
        "context",
        "arxiv",
        "multimodal",
        "study",
        "model",
        "alignment",
        "framework",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead",
      "url": "https://arxiv.org/abs/2507.23009",
      "description": "arXiv:2507.23009v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have achieved remarkable results on a range of standardized tests originally designed to assess human cognitive and psychological traits, such as intelligence and personality. While these results are often interpreted as s...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "LLM",
        "paper",
        "context",
        "arxiv",
        "model",
        "framework",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Investigating the Invertibility of Multimodal Latent Spaces: Limitations of Optimization-Based Methods",
      "url": "https://arxiv.org/abs/2507.23010",
      "description": "arXiv:2507.23010v1 Announce Type: new \nAbstract: This paper investigates the inverse capabilities and broader utility of multimodal latent spaces within task-specific AI (Artificial Intelligence) models. While these models excel at their designed forward tasks (e.g., text-to-image generation, audio-...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "image",
        "audio",
        "arxiv",
        "multimodal",
        "experiment",
        "research",
        "model",
        "framework",
        "paper",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "KLLM: Fast LLM Inference with K-Means Quantization",
      "url": "https://arxiv.org/abs/2507.23035",
      "description": "arXiv:2507.23035v1 Announce Type: new \nAbstract: Large language model (LLM) inference poses significant challenges due to its intensive memory and computation demands. Weight and activation quantization (WAQ) offers a promising solution by reducing both memory footprint and arithmetic complexity. Ho...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "LLM",
        "arxiv",
        "experiment",
        "memory",
        "model",
        "framework",
        "RAG",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt",
        "prompt engineering",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "CoT",
        "audio",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "attention",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "LLM",
        "reasoning",
        "vector",
        "model",
        "framework",
        "RAG",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "LLM",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "API",
        "product",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "platform",
        "vector",
        "framework",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Unifying Post-hoc Explanations of Knowledge Graph Completions",
      "url": "https://arxiv.org/abs/2507.22951",
      "description": "arXiv:2507.22951v1 Announce Type: new \nAbstract: Post-hoc explainability for Knowledge Graph Completion (KGC) lacks formalization and consistent evaluations, hindering reproducibility and cross-study comparisons. This paper argues for a unified approach to post-hoc explainability in KGC. First, we p...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "study",
        "framework",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "Data Readiness for Scientific AI at Scale",
      "url": "https://arxiv.org/abs/2507.23018",
      "description": "arXiv:2507.23018v1 Announce Type: new \nAbstract: This paper examines how Data Readiness for AI (DRAI) principles apply to leadership-scale scientific datasets used to train foundation models. We analyze archetypal workflows across four representative domains - climate, nuclear fusion, bio/health, an...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "transformer",
        "arxiv",
        "model",
        "framework",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "Tractable Responsibility Measures for Ontology-Mediated Query Answering",
      "url": "https://arxiv.org/abs/2507.23191",
      "description": "arXiv:2507.23191v1 Announce Type: new \nAbstract: Recent work on quantitative approaches to explaining query answers employs responsibility measures to assign scores to facts in order to quantify their respective contributions to obtaining a given answer. In this paper, we study the complexity of com...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "study",
        "analysis",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification",
      "url": "https://arxiv.org/abs/2507.23197",
      "description": "arXiv:2507.23197v1 Announce Type: new \nAbstract: To handle complex instances, we revisit a divide-and-conquer approach to break down the complexity: instead of few complex BaB calls, we rely on many small {\\em partial} MILP calls. The crucial step is to select very few but very important ReLUs to tr...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "experiment",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "API",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Scientific Machine Learning with Kolmogorov-Arnold Networks",
      "url": "https://arxiv.org/abs/2507.22959",
      "description": "arXiv:2507.22959v1 Announce Type: new \nAbstract: The field of scientific machine learning, which originally utilized multilayer perceptrons (MLPs), is increasingly adopting Kolmogorov-Arnold Networks (KANs) for data encoding. This shift is driven by the limitations of MLPs, including poor interpreta...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "framework",
        "research"
      ],
      "score": 0.4
    },
    {
      "title": "Linking Actor Behavior to Process Performance Over Time",
      "url": "https://arxiv.org/abs/2507.23037",
      "description": "arXiv:2507.23037v1 Announce Type: new \nAbstract: Understanding how actor behavior influences process outcomes is a critical aspect of process mining. Traditional approaches often use aggregate and static process data, overlooking the temporal and causal dynamics that arise from individual actor beha...",
      "published_date": "2025-08-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "ReasonFlux - ReasonFlux Series - A family of LLM post-training algorithms focusing on data selection, reinforcement learning, and inference scaling",
      "url": "https://github.com/Gen-Verse/ReasonFlux",
      "description": "ReasonFlux Series - A family of LLM post-training algorithms focusing on data selection, reinforcement learning, and inference scaling",
      "published_date": "2025-02-10T11:04:39+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}