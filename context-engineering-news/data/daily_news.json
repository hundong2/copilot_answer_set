{
  "generated_at": "2025-10-10T20:05:39.237082",
  "total_items": 45,
  "items": [
    {
      "title": "Haystack Engineering: Context Engineering for Heterogeneous and Agentic Long-Context Evaluation",
      "url": "https://arxiv.org/abs/2510.07414",
      "description": "arXiv:2510.07414v1 Announce Type: new \nAbstract: Modern long-context large language models (LLMs) perform well on synthetic \"needle-in-a-haystack\" (NIAH) benchmarks, but such tests overlook how noisy contexts arise from biased retrieval and agentic workflows. We argue that haystack engineering is ne...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "large language model",
        "GPT",
        "reasoning",
        "LLM",
        "retrieval",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training Data",
      "url": "https://arxiv.org/abs/2510.07434",
      "description": "arXiv:2510.07434v1 Announce Type: new \nAbstract: Lemmatization is the task of transforming all words in a given text to their dictionary forms. While large language models (LLMs) have demonstrated their ability to achieve competitive results across a wide range of NLP tasks, there is no prior eviden...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "in-context",
        "fine-tuning",
        "paper",
        "large language model",
        "example",
        "LLM",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "LASER: An LLM-based ASR Scoring and Evaluation Rubric",
      "url": "https://arxiv.org/abs/2510.07437",
      "description": "arXiv:2510.07437v1 Announce Type: new \nAbstract: Standard ASR evaluation metrics like Word Error Rate (WER) tend to unfairly penalize morphological and syntactic nuances that do not significantly alter sentence semantics. We introduce an LLM-based scoring rubric LASER that leverages state-of-the-art...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "arxiv",
        "context",
        "in-context",
        "example",
        "LLM",
        "RAG",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Meaningful Pose-Based Sign Language Evaluation",
      "url": "https://arxiv.org/abs/2510.07453",
      "description": "arXiv:2510.07453v1 Announce Type: new \nAbstract: We present a comprehensive study on meaningfully evaluating sign language utterances in the form of human skeletal poses. The study covers keypoint distance-based, embedding-based, and back-translation-based metrics. We show tradeoffs between differen...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "tool",
        "arxiv",
        "retrieval",
        "study",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Populism Meets AI: Advancing Populism Research with LLMs",
      "url": "https://arxiv.org/abs/2510.07458",
      "description": "arXiv:2510.07458v1 Announce Type: new \nAbstract: Measuring the ideational content of populism remains a challenge. Traditional strategies based on textual analysis have been critical for building the field's foundations and providing a valid, objective indicator of populist framing. Yet these approa...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "CoT",
        "prompting",
        "analysis",
        "reasoning",
        "research",
        "LLM",
        "RAG",
        "prompt",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "MAPRO: Recasting Multi-Agent Prompt Optimization as Maximum a Posteriori Inference",
      "url": "https://arxiv.org/abs/2510.07475",
      "description": "arXiv:2510.07475v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated remarkable capabilities across diverse tasks, and LLM-based agents further extend these abilities to various practical workflows. While recent progress shows that multi-agent systems (MAS) can outperform ...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "framework",
        "large language model",
        "LLM",
        "product",
        "prompt",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "AsyncSpade: Efficient Test-Time Scaling with Asynchronous Sparse Decoding",
      "url": "https://arxiv.org/abs/2510.07486",
      "description": "arXiv:2510.07486v1 Announce Type: new \nAbstract: Test-time scaling (TTS) boosts LLM reasoning via long chain-of-thought (CoT), but the linear KV-cache growth amplifies the memory-bound bottleneck of LLM decoding. Query-aware page-level sparse decoding can achieve state-of-the-art performance under c...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "CoT",
        "attention",
        "paper",
        "framework",
        "memory",
        "reasoning",
        "chain-of-thought",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Can Lessons From Human Teams Be Applied to Multi-Agent Systems? The Role of Structure, Diversity, and Interaction Dynamics",
      "url": "https://arxiv.org/abs/2510.07488",
      "description": "arXiv:2510.07488v1 Announce Type: new \nAbstract: Multi-Agent Systems (MAS) with Large Language Model (LLM)-powered agents are gaining attention, yet fewer studies explore their team dynamics. Inspired by human team science, we propose a multi-agent framework to examine core aspects of team science: ...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "attention",
        "framework",
        "large language model",
        "reasoning",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Can Speech LLMs Think while Listening?",
      "url": "https://arxiv.org/abs/2510.07497",
      "description": "arXiv:2510.07497v1 Announce Type: new \nAbstract: Recent advances in speech large language models (speech LLMs) have enabled seamless spoken interactions, but these systems still struggle with complex reasoning tasks. Previously, chain-of-thought (CoT) prompting or fine-tuning has been to shown to si...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "CoT",
        "prompting",
        "fine-tuning",
        "large language model",
        "reasoning",
        "chain-of-thought",
        "LLM",
        "RAG",
        "prompt",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Truth-Aware Decoding: A Program-Logic Approach to Factual Language Generation",
      "url": "https://arxiv.org/abs/2510.07331",
      "description": "arXiv:2510.07331v1 Announce Type: new \nAbstract: This paper introduces Truth-Aware Decoding (TAD), a verification-oriented decoding scheme that aligns neural language generation with knowledge bases. Situated in the tradition of probabilistic program semantics for sequence models, TAD augments moder...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "paper",
        "knowledge base",
        "instruction",
        "RAG",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)",
      "url": "https://arxiv.org/abs/2510.07363",
      "description": "arXiv:2510.07363v1 Announce Type: new \nAbstract: The increasing integration of Industrial IoT (IIoT) exposes critical cyber-physical systems to sophisticated, multi-stage attacks that elude traditional defenses lacking contextual awareness. This paper introduces L2M-AID, a novel framework for Autono...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "paper",
        "framework",
        "large language model",
        "reasoning",
        "LLM",
        "RAG",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Position: AI Will Transform Neuropsychology Through Mental Health Digital Twins for Dynamic Mental Health Care, Especially for ADHD",
      "url": "https://arxiv.org/abs/2510.07409",
      "description": "arXiv:2510.07409v1 Announce Type: new \nAbstract: Static solutions don't serve a dynamic mind. Thus, we advocate a shift from static mental health diagnostic assessments to continuous, artificial intelligence (AI)-driven assessment. Focusing on Attention-Deficit/Hyperactivity Disorder (ADHD) as a cas...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "vision",
        "attention",
        "framework",
        "study",
        "research",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "ProSEA: Problem Solving via Exploration Agents",
      "url": "https://arxiv.org/abs/2510.07423",
      "description": "arXiv:2510.07423v1 Announce Type: new \nAbstract: Large language models (LLMs) have empowered AI agents to tackle increasingly complex tasks. However, most existing agents remain limited to static planning and brittle interactions, falling short of true collaboration or adaptive reasoning. We introdu...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "framework",
        "large language model",
        "reasoning",
        "LLM",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "TS-Agent: A Time Series Reasoning Agent with Iterative Statistical Insight Gathering",
      "url": "https://arxiv.org/abs/2510.07432",
      "description": "arXiv:2510.07432v1 Announce Type: new \nAbstract: Large language models (LLMs) have shown strong abilities in reasoning and problem solving, but recent studies reveal that they still struggle with time series reasoning tasks, where outputs are often affected by hallucination or knowledge leakage. In ...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "tool",
        "arxiv",
        "step-by-step",
        "large language model",
        "alignment",
        "reasoning",
        "LLM",
        "zero-shot",
        "image",
        "RAG",
        "embedding",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "ExpertAgent: Enhancing Personalized Education through Dynamic Planning and Retrieval-Augmented Long-Chain Reasoning",
      "url": "https://arxiv.org/abs/2510.07456",
      "description": "arXiv:2510.07456v1 Announce Type: new \nAbstract: The application of advanced generative artificial intelligence in education is often constrained by the lack of real-time adaptability, personalization, and reliability of the content. To address these challenges, we propose ExpertAgent - an intellige...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "arxiv",
        "framework",
        "large language model",
        "reasoning",
        "instruction",
        "retrieval",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Evaluation of LLMs for Process Model Analysis and Optimization",
      "url": "https://arxiv.org/abs/2510.07489",
      "description": "arXiv:2510.07489v1 Announce Type: new \nAbstract: In this paper, we report our experience with several LLMs for their ability to understand a process model in an interactive, conversational style, find syntactical and logical errors in it, and reason with it in depth through a natural language (NL) i...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "paper",
        "analysis",
        "GPT",
        "reasoning",
        "LLM",
        "zero-shot",
        "image",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Optimizing Ethical Risk Reduction for Medical Intelligent Systems with Constraint Programming",
      "url": "https://arxiv.org/abs/2510.07491",
      "description": "arXiv:2510.07491v1 Announce Type: new \nAbstract: Medical Intelligent Systems (MIS) are increasingly integrated into healthcare workflows, offering significant benefits but also raising critical safety and ethical concerns. According to the European Union AI Act, most MIS will be classified as high-r...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "study",
        "RAG",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Out-of-Distribution Generalization in Climate-Aware Yield Prediction with Earth Observation Data",
      "url": "https://arxiv.org/abs/2510.07350",
      "description": "arXiv:2510.07350v1 Announce Type: new \nAbstract: Climate change is increasingly disrupting agricultural systems, making accurate crop yield forecasting essential for food security. While deep learning models have shown promise in yield prediction using satellite and weather data, their ability to ge...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "arxiv",
        "model",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "ConCuR: Conciseness Makes State-of-the-Art Kernel Generation",
      "url": "https://arxiv.org/abs/2510.07356",
      "description": "arXiv:2510.07356v1 Announce Type: new \nAbstract: GPU kernel generation by LLMs has recently experienced rapid development, leveraging test-time scaling and reinforcement learning techniques. However, a key challenge for kernel generation is the scarcity of high-quality data, as most high-quality ker...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "fine-tuning",
        "reasoning",
        "API",
        "LLM",
        "RAG",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Encode, Think, Decode: Scaling test-time reasoning with recursive latent thoughts",
      "url": "https://arxiv.org/abs/2510.07358",
      "description": "arXiv:2510.07358v1 Announce Type: new \nAbstract: Most efforts to improve the reasoning capabilities of large language models (LLMs) involve either scaling the number of parameters and the size of training data, or scaling inference computation by letting models generate complex chains of thought. Mo...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "large language model",
        "reasoning",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Best-of-Both Worlds for linear contextual bandits with paid observations",
      "url": "https://arxiv.org/abs/2510.07424",
      "description": "arXiv:2510.07424v1 Announce Type: new \nAbstract: We study the problem of linear contextual bandits with paid observations, where at each round the learner selects an action in order to minimize its loss in a given context, and can then decide to pay a fixed cost to observe the loss of any arm. Build...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "analysis",
        "framework",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Learning to Route LLMs from Bandit Feedback: One Policy, Many Trade-offs",
      "url": "https://arxiv.org/abs/2510.07429",
      "description": "arXiv:2510.07429v1 Announce Type: new \nAbstract: Efficient use of large language models (LLMs) is critical for deployment at scale: without adaptive routing, systems either overpay for strong models or risk poor performance from weaker ones. Selecting the right LLM for each query is fundamentally an...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "experiment",
        "vision",
        "large language model",
        "vector",
        "LLM",
        "prompt",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "context window",
        "prompt engineering",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "framework",
        "reasoning",
        "chain-of-thought",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "context",
        "API",
        "LLM",
        "prompt",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "context",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "knowledge base",
        "framework",
        "reasoning",
        "vector",
        "LLM",
        "retrieval",
        "RAG",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "fine-tuning",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "API",
        "retrieval",
        "RAG",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "framework",
        "vector",
        "LLM",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "framework",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Base Models Know How to Reason, Thinking Models Learn When",
      "url": "https://arxiv.org/abs/2510.07364",
      "description": "arXiv:2510.07364v1 Announce Type: new \nAbstract: Why do thinking language models like DeepSeek R1 outperform their base counterparts? Despite consistent performance gains, it remains unclear to what extent thinking models learn entirely new reasoning capabilities or repurpose pre-existing base model...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "reasoning",
        "LLM",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Deep Learning Based Approach to Enhanced Recognition of Emotions and Behavioral Patterns of Autistic Children",
      "url": "https://arxiv.org/abs/2510.07320",
      "description": "arXiv:2510.07320v1 Announce Type: new \nAbstract: Autism Spectrum Disorder significantly influences the communication abilities, learning processes, behavior, and social interactions of individuals. Although early intervention and customized educational strategies are critical to improving outcomes, ...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "framework",
        "study",
        "research"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "API",
        "context",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Inconsistent Affective Reaction: Sentiment of Perception and Opinion in Urban Environments",
      "url": "https://arxiv.org/abs/2510.07359",
      "description": "arXiv:2510.07359v1 Announce Type: new \nAbstract: The ascension of social media platforms has transformed our understanding of urban environments, giving rise to nuanced variations in sentiment reaction embedded within human perception and opinion, and challenging existing multidimensional sentiment ...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "platform",
        "analysis",
        "image",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "Less is More: Strategic Expert Selection Outperforms Ensemble Complexity in Traffic Forecasting",
      "url": "https://arxiv.org/abs/2510.07426",
      "description": "arXiv:2510.07426v1 Announce Type: new \nAbstract: Traffic forecasting is fundamental to intelligent transportation systems, enabling congestion mitigation and emission reduction in increasingly complex urban environments. While recent graph neural network approaches have advanced spatial temporal mod...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "attention",
        "arxiv",
        "framework",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "MultiFair: Multimodal Balanced Fairness-Aware Medical Classification with Dual-Level Gradient Modulation",
      "url": "https://arxiv.org/abs/2510.07328",
      "description": "arXiv:2510.07328v1 Announce Type: new \nAbstract: Medical decision systems increasingly rely on data from multiple sources to ensure reliable and unbiased diagnosis. However, existing multimodal learning models fail to achieve this goal because they often ignore two critical challenges. First, variou...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "multimodal",
        "experiment",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Parameter-Free Federated TD Learning with Markov Noise in Heterogeneous Environments",
      "url": "https://arxiv.org/abs/2510.07436",
      "description": "arXiv:2510.07436v1 Announce Type: new \nAbstract: Federated learning (FL) can dramatically speed up reinforcement learning by distributing exploration and training across multiple agents. It can guarantee an optimal convergence rate that scales linearly in the number of agents, i.e., a rate of $\\tild...",
      "published_date": "2025-10-10T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}