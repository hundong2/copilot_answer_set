{
  "generated_at": "2026-02-19T20:10:31.014728",
  "total_items": 47,
  "items": [
    {
      "title": "The Perplexity Paradox: Why Code Compresses Better Than Math in LLM Prompts",
      "url": "https://arxiv.org/abs/2602.15843",
      "description": "arXiv:2602.15843v1 Announce Type: new \nAbstract: In \"Compress or Route?\" (Johnson, 2026), we found that code generation tolerates aggressive prompt compression (r >= 0.6) while chain-of-thought reasoning degrades gradually. That study was limited to HumanEval (164 problems), left the \"perplexity par...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "chain-of-thought",
        "study",
        "paper",
        "arxiv",
        "analysis",
        "reasoning",
        "LLM",
        "compression"
      ],
      "score": 1.0
    },
    {
      "title": "Language Model Representations for Efficient Few-Shot Tabular Classification",
      "url": "https://arxiv.org/abs/2602.15844",
      "description": "arXiv:2602.15844v1 Announce Type: new \nAbstract: The Web is a rich source of structured data in the form of tables, from product catalogs and knowledge bases to scientific datasets. However, the heterogeneity of the structure and semantics of these tables makes it challenging to build a unified meth...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "product",
        "few-shot",
        "RAG",
        "embedding",
        "arxiv",
        "knowledge base",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "KD4MT: A Survey of Knowledge Distillation for Machine Translation",
      "url": "https://arxiv.org/abs/2602.15845",
      "description": "arXiv:2602.15845v1 Announce Type: new \nAbstract: Knowledge Distillation (KD) as a research area has gained a lot of traction in recent years as a compression tool to address challenges related to ever-larger models in NLP. Remarkably, Machine Translation (MT) offers a much more nuanced take on this ...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "model",
        "paper",
        "arxiv",
        "tool",
        "API",
        "vision",
        "ICL",
        "LLM",
        "compression"
      ],
      "score": 1.0
    },
    {
      "title": "Gated Tree Cross-attention for Checkpoint-Compatible Syntax Injection in Decoder-Only LLMs",
      "url": "https://arxiv.org/abs/2602.15846",
      "description": "arXiv:2602.15846v1 Announce Type: new \nAbstract: Decoder-only large language models achieve strong broad performance but are brittle to minor grammatical perturbations, undermining reliability for downstream reasoning. However, directly injecting explicit syntactic structure into an existing checkpo...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "memory",
        "arxiv",
        "transformer",
        "attention",
        "model",
        "reasoning",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Do Personality Traits Interfere? Geometric Limitations of Steering in Large Language Models",
      "url": "https://arxiv.org/abs/2602.15847",
      "description": "arXiv:2602.15847v1 Announce Type: new \nAbstract: Personality steering in large language models (LLMs) commonly relies on injecting trait-specific steering vectors, implicitly assuming that personality traits can be controlled independently. In this work, we examine whether this assumption holds by a...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vector",
        "study",
        "arxiv",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Can LLMs Assess Personality? Validating Conversational AI for Trait Profiling",
      "url": "https://arxiv.org/abs/2602.15848",
      "description": "arXiv:2602.15848v1 Announce Type: new \nAbstract: This study validates Large Language Models (LLMs) as a dynamic alternative to questionnaire-based personality assessment. Using a within-subjects experiment (N=33), we compared Big Five personality scores derived from guided LLM conversations against ...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "experiment",
        "arxiv",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Preference Optimization for Review Question Generation Improves Writing Quality",
      "url": "https://arxiv.org/abs/2602.15849",
      "description": "arXiv:2602.15849v1 Announce Type: new \nAbstract: Peer review relies on substantive, evidence-based questions, yet existing LLM-based approaches often generate surface-level queries, drawing over 50\\% of their question tokens from a paper's first page. To bridge this gap, we develop IntelliReward, a ...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "model",
        "paper",
        "arxiv",
        "transformer",
        "API",
        "reasoning",
        "release",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Large Language Models for Assisting American College Applications",
      "url": "https://arxiv.org/abs/2602.15850",
      "description": "arXiv:2602.15850v1 Announce Type: new \nAbstract: American college applications require students to navigate fragmented admissions policies, repetitive and conditional forms, and ambiguous questions that often demand cross-referencing multiple sources. We present EZCollegeApp, a large language model ...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "arxiv",
        "model",
        "reasoning",
        "release",
        "augmented",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Narrative Theory-Driven LLM Methods for Automatic Story Generation and Understanding: A Survey",
      "url": "https://arxiv.org/abs/2602.15851",
      "description": "arXiv:2602.15851v1 Announce Type: new \nAbstract: Applications of narrative theories using large language models (LLMs) deliver promising use-cases in automatic story generation and understanding tasks. Our survey examines how natural language processing (NLP) research engages with fields of narrativ...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "prompt",
        "context",
        "research",
        "experiment",
        "arxiv",
        "analysis",
        "model",
        "prompting",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment",
      "url": "https://arxiv.org/abs/2602.16039",
      "description": "arXiv:2602.16039v1 Announce Type: new \nAbstract: The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they al...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "research",
        "study",
        "model",
        "arxiv",
        "instruction",
        "API",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination",
      "url": "https://arxiv.org/abs/2602.16050",
      "description": "arXiv:2602.16050v1 Announce Type: new \nAbstract: Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated ...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "retrieval",
        "model",
        "GPT",
        "arxiv",
        "API",
        "reasoning",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Improving Interactive In-Context Learning from Natural Language Feedback",
      "url": "https://arxiv.org/abs/2602.16066",
      "description": "arXiv:2602.16066v1 Announce Type: new \nAbstract: Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corp...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "context",
        "in-context",
        "arxiv",
        "analysis",
        "reasoning",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "GPSBench: Do Large Language Models Understand GPS Coordinates?",
      "url": "https://arxiv.org/abs/2602.16105",
      "description": "arXiv:2602.16105v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly deployed in applications that interact with the physical world, such as navigation, robotics, or mapping, making robust geospatial reasoning a critical capability. Despite that, LLMs' ability to reason abo...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "tool",
        "model",
        "reasoning",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage",
      "url": "https://arxiv.org/abs/2602.16192",
      "description": "arXiv:2602.16192v1 Announce Type: new \nAbstract: Driven by our mission of \"uplifting the world with memory,\" this paper explores the design concept of \"memory\" that is essential for achieving artificial superintelligence (ASI). Rather than proposing novel methods, we focus on several alternative app...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "experiment",
        "paper",
        "RAG",
        "memory",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents",
      "url": "https://arxiv.org/abs/2602.16246",
      "description": "arXiv:2602.16246v1 Announce Type: new \nAbstract: Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior age...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "product",
        "framework",
        "arxiv",
        "tool",
        "model",
        "reasoning",
        "vision",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Memes-as-Replies: Can Models Select Humorous Manga Panel Responses?",
      "url": "https://arxiv.org/abs/2602.15842",
      "description": "arXiv:2602.15842v1 Announce Type: new \nAbstract: Memes are a popular element of modern web communication, used not only as static artifacts but also as interactive replies within conversations. While computational research has focused on analyzing the intrinsic properties of memes, the dynamic and c...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "research",
        "arxiv",
        "analysis",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "IT-OSE: Exploring Optimal Sample Size for Industrial Data Augmentation",
      "url": "https://arxiv.org/abs/2602.15878",
      "description": "arXiv:2602.15878v1 Announce Type: new \nAbstract: In industrial scenarios, data augmentation is an effective approach to improve model performance. However, its benefits are not unidirectionally beneficial. There is no theoretical research or established estimation for the optimal sample size (OSS) i...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "experiment",
        "RAG",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "B-DENSE: Branching For Dense Ensemble Network Learning",
      "url": "https://arxiv.org/abs/2602.15971",
      "description": "arXiv:2602.15971v1 Announce Type: new \nAbstract: Inspired by non-equilibrium thermodynamics, diffusion models have achieved state-of-the-art performance in generative modeling. However, their iterative sampling nature results in high inference latency. While recent distillation techniques accelerate...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "framework",
        "RAG",
        "alignment",
        "image",
        "arxiv",
        "vision",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt engineering",
        "context window",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "audio",
        "reasoning",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "context",
        "model",
        "tool",
        "API",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "RAG",
        "reasoning",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "vector",
        "framework",
        "RAG",
        "knowledge base",
        "model",
        "reasoning",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "product",
        "retrieval",
        "RAG",
        "API",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "vector",
        "prompt",
        "platform",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Building Safe and Deployable Clinical Natural Language Processing under Temporal Leakage Constraints",
      "url": "https://arxiv.org/abs/2602.15852",
      "description": "arXiv:2602.15852v1 Announce Type: new \nAbstract: Clinical natural language processing (NLP) models have shown promise for supporting hospital discharge planning by leveraging narrative clinical documentation. However, note-based models are particularly vulnerable to temporal and lexical leakage, whe...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "study",
        "arxiv",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "A Koopman-Bayesian Framework for High-Fidelity, Perceptually Optimized Haptic Surgical Simulation",
      "url": "https://arxiv.org/abs/2602.15834",
      "description": "arXiv:2602.15834v1 Announce Type: new \nAbstract: We introduce a unified framework that combines nonlinear dynamics, perceptual psychophysics and high frequency haptic rendering to enhance realism in surgical simulation. The interaction of the surgical device with soft tissue is elevated to an augmen...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "arxiv",
        "augmented",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "BamaER: A Behavior-Aware Memory-Augmented Model for Exercise Recommendation",
      "url": "https://arxiv.org/abs/2602.15879",
      "description": "arXiv:2602.15879v1 Announce Type: new \nAbstract: Exercise recommendation focuses on personalized exercise selection conditioned on students' learning history, personal interests, and other individualized characteristics. Despite notable progress, most existing methods represent student learning sole...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "experiment",
        "RAG",
        "memory",
        "arxiv",
        "augmented",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Adaptive Semi-Supervised Training of P300 ERP-BCI Speller System with Minimum Calibration Effort",
      "url": "https://arxiv.org/abs/2602.15955",
      "description": "arXiv:2602.15955v1 Announce Type: new \nAbstract: A P300 ERP-based Brain-Computer Interface (BCI) speller is an assistive communication tool. It searches for the P300 event-related potential (ERP) elicited by target stimuli, distinguishing it from the neural responses to non-target stimuli embedded i...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "framework",
        "arxiv",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "R$^2$Energy: A Large-Scale Benchmark for Robust Renewable Energy Forecasting under Diverse and Extreme Conditions",
      "url": "https://arxiv.org/abs/2602.15961",
      "description": "arXiv:2602.15961v1 Announce Type: new \nAbstract: The rapid expansion of renewable energy, particularly wind and solar power, has made reliable forecasting critical for power system operations. While recent deep learning models have achieved strong average accuracy, the increasing frequency and inten...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "RAG",
        "arxiv",
        "API",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "model",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments",
      "url": "https://arxiv.org/abs/2602.16179",
      "description": "arXiv:2602.16179v1 Announce Type: new \nAbstract: We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce \\corecraft{}, the first environment in \\textsc{EnterpriseGym}, Surge AI's suite o...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "GPT",
        "arxiv",
        "tool"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "paper",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "Towards Efficient Constraint Handling in Neural Solvers for Routing Problems",
      "url": "https://arxiv.org/abs/2602.16012",
      "description": "arXiv:2602.16012v1 Announce Type: new \nAbstract: Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schem...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "Learning Personalized Agents from Human Feedback",
      "url": "https://arxiv.org/abs/2602.16173",
      "description": "arXiv:2602.16173v1 Announce Type: new \nAbstract: Modern AI agents are powerful but often fail to align with the idiosyncratic, evolving preferences of individual users. Prior approaches typically rely on static datasets, either training implicit preference models on interaction history or encoding u...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "memory",
        "arxiv",
        "analysis",
        "API",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Kalman-Inspired Runtime Stability and Recovery in Hybrid Reasoning Systems",
      "url": "https://arxiv.org/abs/2602.15855",
      "description": "arXiv:2602.15855v1 Announce Type: new \nAbstract: Hybrid reasoning systems that combine learned components with model-based inference are increasingly deployed in tool-augmented decision loops, yet their runtime behavior under partial observability and sustained evidence mismatch remains poorly under...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "experiment",
        "arxiv",
        "tool",
        "reasoning",
        "augmented",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Genetic Generalized Additive Models",
      "url": "https://arxiv.org/abs/2602.15877",
      "description": "arXiv:2602.15877v1 Announce Type: new \nAbstract: Generalized Additive Models (GAMs) balance predictive accuracy and interpretability, but manually configuring their structure is challenging. We propose using the multi-objective genetic algorithm NSGA-II to automatically optimize GAMs, jointly minimi...",
      "published_date": "2026-02-19T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "experiment",
        "arxiv",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Train AI models with Unsloth and Hugging Face Jobs for FREE",
      "url": "https://huggingface.co/blog/unsloth-jobs",
      "description": "...",
      "published_date": "2026-02-20T00:00:00",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model"
      ],
      "score": 0.2
    }
  ]
}