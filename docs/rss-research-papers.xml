<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>How Deep Is Representational Bias in LLMs? The Cases of Caste and Religion</title>
      <link>https://arxiv.org/abs/2508.03712</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03712</guid>
      <description>arXiv:2508.03712v1 Announce Type: new 
Abstract: Representational bias in large language models (LLMs) has predominantly been measured through single-response interactions and has focused on Global North-centric identities like race and gender. We expand on that research by conducting a systematic a...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, arxiv, GPT, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>prompt</category>
      <category>arxiv</category>
      <category>GPT</category>
    </item>
    <item>
      <title>FeynTune: Large Language Models for High-Energy Theory</title>
      <link>https://arxiv.org/abs/2508.03716</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03716</guid>
      <description>arXiv:2508.03716v1 Announce Type: new 
Abstract: We present specialized Large Language Models for theoretical High-Energy Physics, obtained as 20 fine-tuned variants of the 8-billion parameter Llama-3.1 model. Each variant was trained on arXiv abstracts (through August 2024) from different combinati...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, GPT, LLM, study, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>GPT</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Hierarchical Verification of Speculative Beams for Accelerating LLM Inference</title>
      <link>https://arxiv.org/abs/2508.03726</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03726</guid>
      <description>arXiv:2508.03726v1 Announce Type: new 
Abstract: Large language models (LLMs) have achieved remarkable success across diverse natural language processing tasks but face persistent challenges in inference efficiency due to their autoregressive nature. While speculative decoding and beam sampling offe...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, model, experiment, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>WINELL: Wikipedia Never-Ending Updating with LLM Agents</title>
      <link>https://arxiv.org/abs/2508.03728</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03728</guid>
      <description>arXiv:2508.03728v1 Announce Type: new 
Abstract: Wikipedia, a vast and continuously consulted knowledge base, faces significant challenges in maintaining up-to-date content due to its reliance on manual human editors. Inspired by the vision of continuous knowledge acquisition in NELL and fueled by a...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; knowledge base, arxiv, GPT, LLM, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>knowledge base</category>
      <category>arxiv</category>
      <category>GPT</category>
    </item>
    <item>
      <title>Majority Bit-Aware Watermarking For Large Language Models</title>
      <link>https://arxiv.org/abs/2508.03829</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03829</guid>
      <description>arXiv:2508.03829v1 Announce Type: new 
Abstract: The growing deployment of Large Language Models (LLMs) in real-world applications has raised concerns about their potential misuse in generating harmful or deceptive content. To address this issue, watermarking techniques have emerged as a promising s...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, analysis, model, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>analysis</category>
    </item>
    <item>
      <title>An Entity Linking Agent for Question Answering</title>
      <link>https://arxiv.org/abs/2508.03865</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03865</guid>
      <description>arXiv:2508.03865v1 Announce Type: new 
Abstract: Some Question Answering (QA) systems rely on knowledge bases (KBs) to provide accurate answers. Entity Linking (EL) plays a critical role in linking natural language mentions to KB entries. However, most existing EL methods are designed for long conte...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, knowledge base, tool, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>knowledge base</category>
      <category>tool</category>
    </item>
    <item>
      <title>MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems</title>
      <link>https://arxiv.org/abs/2508.03858</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03858</guid>
      <description>arXiv:2508.03858v1 Announce Type: new 
Abstract: Agentic AI systems capable of reasoning, planning, and executing actions present fundamentally distinct governance challenges compared to traditional AI models. Unlike conventional AI, these systems exhibit emergent and unexpected behaviors during run...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; product, arxiv, alignment, analysis, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>product</category>
      <category>arxiv</category>
      <category>alignment</category>
    </item>
    <item>
      <title>MOTIF: Multi-strategy Optimization via Turn-based Interactive Framework</title>
      <link>https://arxiv.org/abs/2508.03929</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03929</guid>
      <description>arXiv:2508.03929v1 Announce Type: new 
Abstract: Designing effective algorithmic components remains a fundamental obstacle in tackling NP-hard combinatorial optimization problems (COPs), where solvers often rely on carefully hand-crafted strategies. Despite recent advances in using large language mo...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, arxiv, prompting, LLM, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>prompt</category>
      <category>arxiv</category>
      <category>prompting</category>
    </item>
    <item>
      <title>Personalized Knowledge Transfer Through Generative AI: Contextualizing Learning to Individual Career Goals</title>
      <link>https://arxiv.org/abs/2508.04070</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.04070</guid>
      <description>arXiv:2508.04070v1 Announce Type: new 
Abstract: As artificial intelligence becomes increasingly integrated into digital learning environments, the personalization of learning content to reflect learners&amp;#x27; individual career goals offers promising potential to enhance engagement and long-term motivati...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, arxiv, study, analysis, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>arxiv</category>
      <category>study</category>
    </item>
    <item>
      <title>Latent Knowledge Scalpel: Precise and Massive Knowledge Editing for Large Language Models</title>
      <link>https://arxiv.org/abs/2508.03741</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03741</guid>
      <description>arXiv:2508.03741v1 Announce Type: new 
Abstract: Large Language Models (LLMs) often retain inaccurate or outdated information from pre-training, leading to incorrect predictions or biased outputs during inference. While existing model editing methods can address this challenge, they struggle with ed...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, study, paper, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>study</category>
    </item>
    <item>
      <title>GlaBoost: A multimodal Structured Framework for Glaucoma Risk Stratification</title>
      <link>https://arxiv.org/abs/2508.03750</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03750</guid>
      <description>arXiv:2508.03750v1 Announce Type: new 
Abstract: Early and accurate detection of glaucoma is critical to prevent irreversible vision loss. However, existing methods often rely on unimodal data and lack interpretability, limiting their clinical utility. In this paper, we present GlaBoost, a multimoda...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, image, transformer, embedding, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>image</category>
      <category>transformer</category>
    </item>
    <item>
      <title>LRTuckerRep: Low-rank Tucker Representation Model for Multi-dimensional Data Completion</title>
      <link>https://arxiv.org/abs/2508.03755</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03755</guid>
      <description>arXiv:2508.03755v1 Announce Type: new 
Abstract: Multi-dimensional data completion is a critical problem in computational sciences, particularly in domains such as computer vision, signal processing, and scientific computing. Existing methods typically leverage either global low-rank approximations ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, image, paper, model, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>image</category>
      <category>paper</category>
    </item>
    <item>
      <title>Provably Near-Optimal Distributionally Robust Reinforcement Learning in Online Settings</title>
      <link>https://arxiv.org/abs/2508.03768</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03768</guid>
      <description>arXiv:2508.03768v1 Announce Type: new 
Abstract: Reinforcement learning (RL) faces significant challenges in real-world deployments due to the sim-to-real gap, where policies trained in simulators often underperform in practice due to mismatches between training and deployment conditions. Distributi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, study, model, experiment, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>study</category>
      <category>model</category>
    </item>
    <item>
      <title>GTPO: Trajectory-Based Policy Optimization in Large Language Models</title>
      <link>https://arxiv.org/abs/2508.03772</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03772</guid>
      <description>arXiv:2508.03772v1 Announce Type: new 
Abstract: Policy-based optimizations are widely adopted today for the training and alignment of language models, where one of the most recent and effective approaches is Group-relative Policy Optimization (GRPO). In this paper, we reveals and analyze two major ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, alignment, paper, model, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>alignment</category>
      <category>paper</category>
    </item>
    <item>
      <title>Evo-MARL: Co-Evolutionary Multi-Agent Reinforcement Learning for Internalized Safety</title>
      <link>https://arxiv.org/abs/2508.03864</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03864</guid>
      <description>arXiv:2508.03864v1 Announce Type: new 
Abstract: Multi-agent systems (MAS) built on multimodal large language models exhibit strong collaboration and performance. However, their growing openness and interaction complexity pose serious risks, notably jailbreak and adversarial attacks. Existing defens...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, model, experiment, multimodal, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>model</category>
      <category>experiment</category>
    </item>
    <item>
      <title>The Emotional Baby Is Truly Deadly: Does your Multimodal Large Reasoning Model Have Emotional Flattery towards Humans?</title>
      <link>https://arxiv.org/abs/2508.03986</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03986</guid>
      <description>arXiv:2508.03986v1 Announce Type: new 
Abstract: We observe that MLRMs oriented toward human-centric service are highly susceptible to user emotional cues during the deep-thinking stage, often overriding safety protocols or built-in safety checks under high emotional intensity. Inspired by this key ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, arxiv, alignment, model, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>prompt</category>
      <category>arxiv</category>
      <category>alignment</category>
    </item>
    <item>
      <title>Galaxy: A Cognition-Centered Framework for Proactive, Privacy-Preserving, and Self-Evolving LLM Agents</title>
      <link>https://arxiv.org/abs/2508.03991</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03991</guid>
      <description>arXiv:2508.03991v1 Announce Type: new 
Abstract: Intelligent personal assistants (IPAs) such as Siri and Google Assistant are designed to enhance human capabilities and perform tasks on behalf of users. The emergence of LLM agents brings new opportunities for the development of IPAs. While responsiv...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, model, experiment, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>SEA: Self-Evolution Agent with Step-wise Reward for Computer Use</title>
      <link>https://arxiv.org/abs/2508.04037</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.04037</guid>
      <description>arXiv:2508.04037v1 Announce Type: new 
Abstract: Computer use agent is an emerging area in artificial intelligence that aims to operate the computers to achieve the user&amp;#x27;s tasks, which attracts a lot of attention from both industry and academia. However, the present agents&amp;#x27; performance is far from b...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, attention, paper, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>attention</category>
      <category>paper</category>
    </item>
    <item>
      <title>Privileged Contrastive Pretraining for Multimodal Affect Modelling</title>
      <link>https://arxiv.org/abs/2508.03729</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03729</guid>
      <description>arXiv:2508.03729v1 Announce Type: new 
Abstract: Affective Computing (AC) has made significant progress with the advent of deep learning, yet a persistent challenge remains: the reliable transfer of affective models from controlled laboratory settings (in-vitro) to uncontrolled real-world environmen...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, model, experiment, multimodal, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>model</category>
      <category>experiment</category>
    </item>
    <item>
      <title>U-PINet: End-to-End Hierarchical Physics-Informed Learning With Sparse Graph Coupling for 3D EM Scattering Modeling</title>
      <link>https://arxiv.org/abs/2508.03774</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.03774</guid>
      <description>arXiv:2508.03774v1 Announce Type: new 
Abstract: Electromagnetic (EM) scattering modeling is critical for radar remote sensing, however, its inherent complexity introduces significant computational challenges. Traditional numerical solvers offer high accuracy, but suffer from scalability issues and ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, model, experiment, framework, embedding | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 07 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>model</category>
      <category>experiment</category>
    </item>
  </channel>
</rss>