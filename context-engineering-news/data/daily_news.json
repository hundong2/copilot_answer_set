{
  "generated_at": "2025-08-07T20:05:51.665853",
  "total_items": 49,
  "items": [
    {
      "title": "How Deep Is Representational Bias in LLMs? The Cases of Caste and Religion",
      "url": "https://arxiv.org/abs/2508.03712",
      "description": "arXiv:2508.03712v1 Announce Type: new \nAbstract: Representational bias in large language models (LLMs) has predominantly been measured through single-response interactions and has focused on Global North-centric identities like race and gender. We expand on that research by conducting a systematic a...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "arxiv",
        "GPT",
        "LLM",
        "model",
        "RAG",
        "large language model",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "FeynTune: Large Language Models for High-Energy Theory",
      "url": "https://arxiv.org/abs/2508.03716",
      "description": "arXiv:2508.03716v1 Announce Type: new \nAbstract: We present specialized Large Language Models for theoretical High-Energy Physics, obtained as 20 fine-tuned variants of the 8-billion parameter Llama-3.1 model. Each variant was trained on arXiv abstracts (through August 2024) from different combinati...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "GPT",
        "LLM",
        "study",
        "model",
        "large language model",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "Intent Aware Context Retrieval for Multi-Turn Agricultural Question Answering",
      "url": "https://arxiv.org/abs/2508.03719",
      "description": "arXiv:2508.03719v1 Announce Type: new \nAbstract: Indian farmers often lack timely, accessible, and language-friendly agricultural advice, especially in rural areas with low literacy. To address this gap in accessibility, this paper presents a novel AI-powered agricultural chatbot, Krishi Sathi, desi...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval",
        "arxiv",
        "paper",
        "model",
        "RAG",
        "instruction",
        "augmented",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "Hierarchical Verification of Speculative Beams for Accelerating LLM Inference",
      "url": "https://arxiv.org/abs/2508.03726",
      "description": "arXiv:2508.03726v1 Announce Type: new \nAbstract: Large language models (LLMs) have achieved remarkable success across diverse natural language processing tasks but face persistent challenges in inference efficiency due to their autoregressive nature. While speculative decoding and beam sampling offe...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "model",
        "experiment",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "WINELL: Wikipedia Never-Ending Updating with LLM Agents",
      "url": "https://arxiv.org/abs/2508.03728",
      "description": "arXiv:2508.03728v1 Announce Type: new \nAbstract: Wikipedia, a vast and continuously consulted knowledge base, faces significant challenges in maintaining up-to-date content due to its reliance on manual human editors. Inspired by the vision of continuous knowledge acquisition in NELL and fueled by a...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "knowledge base",
        "arxiv",
        "GPT",
        "LLM",
        "paper",
        "model",
        "RAG",
        "instruction",
        "framework",
        "research",
        "ICL",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "GanitBench: A bi-lingual benchmark for evaluating mathematical reasoning in Vision Language Models",
      "url": "https://arxiv.org/abs/2508.03737",
      "description": "arXiv:2508.03737v1 Announce Type: new \nAbstract: Benchmarks for evaluating reasoning among Vision Language Models (VLMs) on several fields and domains are being curated more frequently over the last few years. However these are often monolingual, mostly available in English. Additionally there also ...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "arxiv",
        "image",
        "GPT",
        "model",
        "research",
        "RAG",
        "reasoning",
        "zero-shot",
        "chain-of-thought",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "AttnTrace: Attention-based Context Traceback for Long-Context LLMs",
      "url": "https://arxiv.org/abs/2508.03793",
      "description": "arXiv:2508.03793v1 Announce Type: new \nAbstract: Long-context large language models (LLMs), such as Gemini-2.5-Pro and Claude-Sonnet-4, are increasingly used to empower advanced AI systems, including retrieval-augmented generation (RAG) pipelines and autonomous agents. In these systems, an LLM recei...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "prompt",
        "retrieval",
        "arxiv",
        "LLM",
        "paper",
        "analysis",
        "model",
        "memory",
        "attention",
        "RAG",
        "instruction",
        "large language model",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Majority Bit-Aware Watermarking For Large Language Models",
      "url": "https://arxiv.org/abs/2508.03829",
      "description": "arXiv:2508.03829v1 Announce Type: new \nAbstract: The growing deployment of Large Language Models (LLMs) in real-world applications has raised concerns about their potential misuse in generating harmful or deceptive content. To address this issue, watermarking techniques have emerged as a promising s...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "analysis",
        "model",
        "experiment",
        "large language model",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models",
      "url": "https://arxiv.org/abs/2508.03860",
      "description": "arXiv:2508.03860v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are trained on vast and diverse internet corpora that often include inaccurate or misleading content. Consequently, LLMs can generate misinformation, making robust fact-checking essential. This review systematically analyz...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt",
        "retrieval",
        "arxiv",
        "prompting",
        "LLM",
        "analysis",
        "model",
        "RAG",
        "instruction",
        "framework",
        "large language model",
        "reasoning",
        "research",
        "augmented",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "An Entity Linking Agent for Question Answering",
      "url": "https://arxiv.org/abs/2508.03865",
      "description": "arXiv:2508.03865v1 Announce Type: new \nAbstract: Some Question Answering (QA) systems rely on knowledge bases (KBs) to provide accurate answers. Entity Linking (EL) plays a critical role in linking natural language mentions to KB entries. However, most existing EL methods are designed for long conte...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "knowledge base",
        "tool",
        "arxiv",
        "model",
        "experiment",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems",
      "url": "https://arxiv.org/abs/2508.03858",
      "description": "arXiv:2508.03858v1 Announce Type: new \nAbstract: Agentic AI systems capable of reasoning, planning, and executing actions present fundamentally distinct governance challenges compared to traditional AI models. Unlike conventional AI, these systems exhibit emergent and unexpected behaviors during run...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "product",
        "arxiv",
        "alignment",
        "analysis",
        "model",
        "RAG",
        "framework",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "MOTIF: Multi-strategy Optimization via Turn-based Interactive Framework",
      "url": "https://arxiv.org/abs/2508.03929",
      "description": "arXiv:2508.03929v1 Announce Type: new \nAbstract: Designing effective algorithmic components remains a fundamental obstacle in tackling NP-hard combinatorial optimization problems (COPs), where solvers often rely on carefully hand-crafted strategies. Despite recent advances in using large language mo...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "arxiv",
        "prompting",
        "LLM",
        "paper",
        "model",
        "experiment",
        "RAG",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?",
      "url": "https://arxiv.org/abs/2508.03963",
      "description": "arXiv:2508.03963v1 Announce Type: new \nAbstract: Uncovering hidden symbolic laws from time series data, as an aspiration dating back to Kepler's discovery of planetary motion, remains a core challenge in scientific discovery and artificial intelligence. While Large Language Models show promise in st...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "arxiv",
        "alignment",
        "LLM",
        "model",
        "framework",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Personalized Knowledge Transfer Through Generative AI: Contextualizing Learning to Individual Career Goals",
      "url": "https://arxiv.org/abs/2508.04070",
      "description": "arXiv:2508.04070v1 Announce Type: new \nAbstract: As artificial intelligence becomes increasingly integrated into digital learning environments, the personalization of learning content to reflect learners' individual career goals offers promising potential to enhance engagement and long-term motivati...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "arxiv",
        "study",
        "analysis",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "KG-Augmented Executable CoT for Mathematical Coding",
      "url": "https://arxiv.org/abs/2508.04072",
      "description": "arXiv:2508.04072v1 Announce Type: new \nAbstract: In recent years, large language models (LLMs) have excelled in natural language processing tasks but face significant challenges in complex reasoning tasks such as mathematical reasoning and code generation. To address these limitations, we propose KG...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "prompt",
        "retrieval",
        "arxiv",
        "prompting",
        "LLM",
        "analysis",
        "model",
        "augmented",
        "RAG",
        "framework",
        "large language model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "CX-Mind: A Pioneering Multimodal Large Language Model for Interleaved Reasoning in Chest X-ray via Curriculum-Guided Reinforcement Learning",
      "url": "https://arxiv.org/abs/2508.03733",
      "description": "arXiv:2508.03733v1 Announce Type: new \nAbstract: Chest X-ray (CXR) imaging is one of the most widely used diagnostic modalities in clinical practice, encompassing a broad spectrum of diagnostic tasks. Recent advancements have seen the extensive application of reasoning-based multimodal large languag...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "arxiv",
        "alignment",
        "image",
        "LLM",
        "model",
        "experiment",
        "RAG",
        "multimodal",
        "instruction",
        "framework",
        "large language model",
        "reasoning",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "Latent Knowledge Scalpel: Precise and Massive Knowledge Editing for Large Language Models",
      "url": "https://arxiv.org/abs/2508.03741",
      "description": "arXiv:2508.03741v1 Announce Type: new \nAbstract: Large Language Models (LLMs) often retain inaccurate or outdated information from pre-training, leading to incorrect predictions or biased outputs during inference. While existing model editing methods can address this challenge, they struggle with ed...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "study",
        "paper",
        "model",
        "experiment",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "GlaBoost: A multimodal Structured Framework for Glaucoma Risk Stratification",
      "url": "https://arxiv.org/abs/2508.03750",
      "description": "arXiv:2508.03750v1 Announce Type: new \nAbstract: Early and accurate detection of glaucoma is critical to prevent irreversible vision loss. However, existing methods often rely on unimodal data and lack interpretability, limiting their clinical utility. In this paper, we present GlaBoost, a multimoda...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "image",
        "transformer",
        "embedding",
        "paper",
        "analysis",
        "experiment",
        "model",
        "multimodal",
        "framework",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "LRTuckerRep: Low-rank Tucker Representation Model for Multi-dimensional Data Completion",
      "url": "https://arxiv.org/abs/2508.03755",
      "description": "arXiv:2508.03755v1 Announce Type: new \nAbstract: Multi-dimensional data completion is a critical problem in computational sciences, particularly in domains such as computer vision, signal processing, and scientific computing. Existing methods typically leverage either global low-rank approximations ...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "image",
        "paper",
        "model",
        "experiment",
        "RAG",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "LLM-Prior: A Framework for Knowledge-Driven Prior Elicitation and Aggregation",
      "url": "https://arxiv.org/abs/2508.03766",
      "description": "arXiv:2508.03766v1 Announce Type: new \nAbstract: The specification of prior distributions is fundamental in Bayesian inference, yet it remains a significant bottleneck. The prior elicitation process is often a manual, subjective, and unscalable task. We propose a novel framework which leverages Larg...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "tool",
        "arxiv",
        "LLM",
        "model",
        "RAG",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Provably Near-Optimal Distributionally Robust Reinforcement Learning in Online Settings",
      "url": "https://arxiv.org/abs/2508.03768",
      "description": "arXiv:2508.03768v1 Announce Type: new \nAbstract: Reinforcement learning (RL) faces significant challenges in real-world deployments due to the sim-to-real gap, where policies trained in simulators often underperform in practice due to mismatches between training and deployment conditions. Distributi...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "model",
        "experiment",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "GTPO: Trajectory-Based Policy Optimization in Large Language Models",
      "url": "https://arxiv.org/abs/2508.03772",
      "description": "arXiv:2508.03772v1 Announce Type: new \nAbstract: Policy-based optimizations are widely adopted today for the training and alignment of language models, where one of the most recent and effective approaches is Group-relative Policy Optimization (GRPO). In this paper, we reveals and analyze two major ...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "alignment",
        "paper",
        "model",
        "experiment",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt engineering",
        "prompt",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "CoT",
        "framework",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "context",
        "LLM",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "knowledge base",
        "retrieval",
        "vector",
        "LLM",
        "model",
        "RAG",
        "framework",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "tool",
        "model",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "product",
        "retrieval",
        "RAG",
        "API",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "vector",
        "LLM",
        "framework",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Evo-MARL: Co-Evolutionary Multi-Agent Reinforcement Learning for Internalized Safety",
      "url": "https://arxiv.org/abs/2508.03864",
      "description": "arXiv:2508.03864v1 Announce Type: new \nAbstract: Multi-agent systems (MAS) built on multimodal large language models exhibit strong collaboration and performance. However, their growing openness and interaction complexity pose serious risks, notably jailbreak and adversarial attacks. Existing defens...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "experiment",
        "multimodal",
        "framework",
        "large language model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "The Emotional Baby Is Truly Deadly: Does your Multimodal Large Reasoning Model Have Emotional Flattery towards Humans?",
      "url": "https://arxiv.org/abs/2508.03986",
      "description": "arXiv:2508.03986v1 Announce Type: new \nAbstract: We observe that MLRMs oriented toward human-centric service are highly susceptible to user emotional cues during the deep-thinking stage, often overriding safety protocols or built-in safety checks under high emotional intensity. Inspired by this key ...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "arxiv",
        "alignment",
        "model",
        "experiment",
        "multimodal",
        "framework",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Galaxy: A Cognition-Centered Framework for Proactive, Privacy-Preserving, and Self-Evolving LLM Agents",
      "url": "https://arxiv.org/abs/2508.03991",
      "description": "arXiv:2508.03991v1 Announce Type: new \nAbstract: Intelligent personal assistants (IPAs) such as Siri and Google Assistant are designed to enhance human capabilities and perform tasks on behalf of users. The emergence of LLM agents brings new opportunities for the development of IPAs. While responsiv...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "model",
        "experiment",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "SEA: Self-Evolution Agent with Step-wise Reward for Computer Use",
      "url": "https://arxiv.org/abs/2508.04037",
      "description": "arXiv:2508.04037v1 Announce Type: new \nAbstract: Computer use agent is an emerging area in artificial intelligence that aims to operate the computers to achieve the user's tasks, which attracts a lot of attention from both industry and academia. However, the present agents' performance is far from b...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "attention",
        "paper",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Privileged Contrastive Pretraining for Multimodal Affect Modelling",
      "url": "https://arxiv.org/abs/2508.03729",
      "description": "arXiv:2508.03729v1 Announce Type: new \nAbstract: Affective Computing (AC) has made significant progress with the advent of deep learning, yet a persistent challenge remains: the reliable transfer of affective models from controlled laboratory settings (in-vitro) to uncontrolled real-world environmen...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "experiment",
        "multimodal",
        "RAG",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "U-PINet: End-to-End Hierarchical Physics-Informed Learning With Sparse Graph Coupling for 3D EM Scattering Modeling",
      "url": "https://arxiv.org/abs/2508.03774",
      "description": "arXiv:2508.03774v1 Announce Type: new \nAbstract: Electromagnetic (EM) scattering modeling is critical for radar remote sensing, however, its inherent complexity introduces significant computational challenges. Traditional numerical solvers offer high accuracy, but suffer from scalability issues and ...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "experiment",
        "framework",
        "embedding"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "tool",
        "model",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "model",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Uncertainty-Aware GUI Agent: Adaptive Perception through Component Recommendation and Human-in-the-Loop Refinement",
      "url": "https://arxiv.org/abs/2508.04025",
      "description": "arXiv:2508.04025v1 Announce Type: new \nAbstract: Graphical user interface (GUI) agents have shown promise in automating mobile tasks but still struggle with input redundancy and decision ambiguity. In this paper, we present \\textbf{RecAgent}, an uncertainty-aware agent that addresses these issues th...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "experiment",
        "framework",
        "reasoning"
      ],
      "score": 0.6
    },
    {
      "title": "PILOT-C: Physics-Informed Low-Distortion Optimal Trajectory Compression",
      "url": "https://arxiv.org/abs/2508.03730",
      "description": "arXiv:2508.03730v1 Announce Type: new \nAbstract: Location-aware devices continuously generate massive volumes of trajectory data, creating demand for efficient compression. Line simplification is a common solution but typically assumes 2D trajectories and ignores time synchronization and motion cont...",
      "published_date": "2025-08-07T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "model",
        "RAG",
        "framework",
        "compression"
      ],
      "score": 0.6
    },
    {
      "title": "Vision Language Model Alignment in TRL ⚡️",
      "url": "https://huggingface.co/blog/trl-vlm-alignment",
      "description": "...",
      "published_date": "2025-08-07T00:00:00",
      "source": "Hugging Face Blog",
      "category": "multimodal_context",
      "keywords": [
        "model",
        "alignment",
        "vision"
      ],
      "score": 0.6
    },
    {
      "title": "Welcome GPT OSS, the new open-source model family from OpenAI!",
      "url": "https://huggingface.co/blog/welcome-openai-gpt-oss",
      "description": "...",
      "published_date": "2025-08-05T00:00:00",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "GPT",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}