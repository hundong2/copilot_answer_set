{
  "generated_at": "2025-07-30T20:05:15.360546",
  "total_items": 44,
  "items": [
    {
      "title": "Categorical Classification of Book Summaries Using Word Embedding Techniques",
      "url": "https://arxiv.org/abs/2507.21058",
      "description": "arXiv:2507.21058v1 Announce Type: new \nAbstract: In this study, book summaries and categories taken from book sites were classified using word embedding methods, natural language processing techniques and machine learning algorithms. In addition, one hot encoding, Word2Vec and Term Frequency - Inver...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "embedding",
        "arxiv",
        "vector",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Dialogic Social Learning for Artificial Agents: Enhancing LLM Ontology Acquisition through Mixed-Initiative Educational Interactions",
      "url": "https://arxiv.org/abs/2507.21065",
      "description": "arXiv:2507.21065v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in processing extensive offline datasets. However, they often face challenges in acquiring and integrating complex, knowledge online. Traditional AI training paradigms, predominant...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "study",
        "arxiv",
        "instruction",
        "model",
        "prompt engineering",
        "context",
        "prompt",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Product vs. Process: Exploring EFL Students' Editing of AI-Generated Text for Expository Writing",
      "url": "https://arxiv.org/abs/2507.21073",
      "description": "arXiv:2507.21073v1 Announce Type: new \nAbstract: Text generated by artificial intelligence (AI) chatbots is increasingly used in English as a foreign language (EFL) writing contexts, yet its impact on students' expository writing process and compositions remains understudied. This research examines ...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "analysis",
        "product",
        "instruction",
        "RAG",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ChatGPT Reads Your Tone and Responds Accordingly -- Until It Does Not -- Emotional Framing Induces Bias in LLM Outputs",
      "url": "https://arxiv.org/abs/2507.21083",
      "description": "arXiv:2507.21083v1 Announce Type: new \nAbstract: Large Language Models like GPT-4 adjust their responses not only based on the question asked, but also on how it is emotionally phrased. We systematically vary the emotional tone of 156 prompts - spanning controversial and everyday topics - and analyz...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "embedding",
        "arxiv",
        "GPT",
        "model",
        "prompt",
        "alignment",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Reviving Your MNEME: Predicting The Side Effects of LLM Unlearning and Fine-Tuning via Sparse Model Diffing",
      "url": "https://arxiv.org/abs/2507.21084",
      "description": "arXiv:2507.21084v1 Announce Type: new \nAbstract: Large language models (LLMs) are frequently fine-tuned or unlearned to adapt to new tasks or eliminate undesirable behaviors. While existing evaluation methods assess performance after such interventions, there remains no general approach for detectin...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "arxiv",
        "tool",
        "fine-tuning",
        "model",
        "alignment",
        "LLM",
        "example",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Multi-Amateur Contrastive Decoding for Text Generation",
      "url": "https://arxiv.org/abs/2507.21086",
      "description": "arXiv:2507.21086v1 Announce Type: new \nAbstract: Contrastive Decoding (CD) has emerged as an effective inference-time strategy for enhancing open-ended text generation by exploiting the divergence in output probabilities between a large expert language model and a smaller amateur model. Although CD ...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "paper",
        "model",
        "experiment",
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "QU-NLP at CheckThat! 2025: Multilingual Subjectivity in News Articles Detection using Feature-Augmented Transformer Models with Sequential Cross-Lingual Fine-Tuning",
      "url": "https://arxiv.org/abs/2507.21095",
      "description": "arXiv:2507.21095v1 Announce Type: new \nAbstract: This paper presents our approach to the CheckThat! 2025 Task 1 on subjectivity detection, where systems are challenged to distinguish whether a sentence from a news article expresses the subjective view of the author or presents an objective view on t...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "embedding",
        "arxiv",
        "ICL",
        "augmented",
        "paper",
        "analysis",
        "model",
        "transformer",
        "RAG",
        "fine-tuning",
        "context",
        "zero-shot"
      ],
      "score": 1.0
    },
    {
      "title": "Rewrite-to-Rank: Optimizing Ad Visibility via Retrieval-Aware Text Rewriting",
      "url": "https://arxiv.org/abs/2507.21099",
      "description": "arXiv:2507.21099v1 Announce Type: new \nAbstract: Search algorithms and user query relevance have given LLMs the ability to return relevant information, but the effect of content phrasing on ad visibility remains underexplored. We investigate how LLM-based rewriting of advertisements can improve thei...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "framework",
        "arxiv",
        "few-shot",
        "instruction",
        "fine-tuning",
        "model",
        "prompt engineering",
        "experiment",
        "prompt",
        "LLM",
        "retrieval",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "SynLang and Symbiotic Epistemology: A Manifesto for Conscious Human-AI Collaboration",
      "url": "https://arxiv.org/abs/2507.21067",
      "description": "arXiv:2507.21067v1 Announce Type: new \nAbstract: Current AI systems rely on opaque reasoning processes that hinder human oversight and collaborative potential. Conventional explainable AI approaches offer post-hoc justifications and often fail to establish genuine symbiotic collaboration. In this pa...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "embedding",
        "framework",
        "arxiv",
        "reasoning",
        "tool",
        "paper",
        "API",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Leveraging Generative AI to Enhance Synthea Module Development",
      "url": "https://arxiv.org/abs/2507.21123",
      "description": "arXiv:2507.21123v1 Announce Type: new \nAbstract: This paper explores the use of large language models (LLMs) to assist in the development of new disease modules for Synthea, an open-source synthetic health data generator. Incorporating LLMs into the module development process has the potential to re...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "paper",
        "model",
        "large language model",
        "RAG",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Measuring and Analyzing Intelligence via Contextual Uncertainty in Large Language Models using Information-Theoretic Metrics",
      "url": "https://arxiv.org/abs/2507.21129",
      "description": "arXiv:2507.21129v1 Announce Type: new \nAbstract: The remarkable capabilities of Large Language Models (LLMs) are now extensively documented on task-specific benchmarks, yet the internal mechanisms that produce these results are the subject of intense scientific inquiry. This paper contributes to thi...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "model",
        "large language model",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "INTEGRALBENCH: Benchmarking LLMs with Definite Integral Problems",
      "url": "https://arxiv.org/abs/2507.21130",
      "description": "arXiv:2507.21130v1 Announce Type: new \nAbstract: We present INTEGRALBENCH, a focused benchmark designed to evaluate Large Language Model (LLM) performance on definite integral problems. INTEGRALBENCH provides both symbolic and numerical ground truth solutions with manual difficulty annotations. Our ...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "arxiv",
        "reasoning",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Can You Trust an LLM with Your Life-Changing Decision? An Investigation into AI High-Stakes Responses",
      "url": "https://arxiv.org/abs/2507.21132",
      "description": "arXiv:2507.21132v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly consulted for high-stakes life advice, yet they lack standard safeguards against providing confident but misguided responses. This creates risks of sycophancy and over-confidence. This paper investigates t...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "analysis",
        "model",
        "experiment",
        "vector",
        "alignment",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "The Geometry of Harmfulness in LLMs through Subconcept Probing",
      "url": "https://arxiv.org/abs/2507.21141",
      "description": "arXiv:2507.21141v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) have intensified the need to understand and reliably curb their harmful behaviours. We introduce a multidimensional framework for probing and steering harmful content in model internals. For each of 55 d...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "arxiv",
        "tool",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Advancing Wildfire Risk Prediction via Morphology-Aware Curriculum Contrastive Learning",
      "url": "https://arxiv.org/abs/2507.21147",
      "description": "arXiv:2507.21147v1 Announce Type: new \nAbstract: Wildfires significantly impact natural ecosystems and human health, leading to biodiversity loss, increased hydrogeological risks, and elevated emissions of toxic substances. Climate change exacerbates these effects, particularly in regions with risin...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "paper",
        "analysis",
        "experiment",
        "model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Deep Reinforcement Learning for Real-Time Green Energy Integration in Data Centers",
      "url": "https://arxiv.org/abs/2507.21153",
      "description": "arXiv:2507.21153v1 Announce Type: new \nAbstract: This paper explores the implementation of a Deep Reinforcement Learning (DRL)-optimized energy management system for e-commerce data centers, aimed at enhancing energy efficiency, cost-effectiveness, and environmental sustainability. The proposed syst...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "study",
        "RAG",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "context window",
        "context",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "reasoning",
        "audio",
        "chain-of-thought",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "attention",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "reasoning",
        "knowledge base",
        "model",
        "vector",
        "RAG",
        "LLM",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "model",
        "fine-tuning",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "product",
        "API",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "platform",
        "vector",
        "prompt",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "framework",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Artificial intelligence for sustainable wine industry: AI-driven management in viticulture, wine production and enotourism",
      "url": "https://arxiv.org/abs/2507.21098",
      "description": "arXiv:2507.21098v1 Announce Type: new \nAbstract: This study examines the role of Artificial Intelligence (AI) in enhancing sustainability and efficiency within the wine industry. It focuses on AI-driven intelligent management in viticulture, wine production, and enotourism. As the wine industry face...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "analysis",
        "product",
        "vision",
        "study"
      ],
      "score": 0.8
    },
    {
      "title": "Task-Focused Consolidation with Spaced Recall: Making Neural Networks learn like college students",
      "url": "https://arxiv.org/abs/2507.21109",
      "description": "arXiv:2507.21109v1 Announce Type: new \nAbstract: Deep Neural Networks often suffer from a critical limitation known as Catastrophic Forgetting, where performance on past tasks degrades after learning new ones. This paper introduces a novel continual learning approach inspired by human learning strat...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "memory",
        "model",
        "retrieval"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "API",
        "model",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "iLSU-T: an Open Dataset for Uruguayan Sign Language Translation",
      "url": "https://arxiv.org/abs/2507.21104",
      "description": "arXiv:2507.21104v1 Announce Type: new \nAbstract: Automatic sign language translation has gained particular interest in the computer vision and computational linguistics communities in recent years. Given each sign language country particularities, machine translation requires local data to develop n...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "arxiv",
        "audio",
        "tool",
        "vision",
        "experiment",
        "multimodal"
      ],
      "score": 0.6
    },
    {
      "title": "NPO: Learning Alignment and Meta-Alignment through Structured Human Feedback",
      "url": "https://arxiv.org/abs/2507.21131",
      "description": "arXiv:2507.21131v1 Announce Type: new \nAbstract: We present NPO, an alignment-aware learning framework that operationalizes feedback-driven adaptation in human-in-the-loop decision systems. Unlike prior approaches that treat alignment as a static or post-hoc property, NPO introduces a formalization ...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "alignment",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Project Patti: Why can You Solve Diabolical Puzzles on one Sudoku Website but not Easy Puzzles on another Sudoku Website?",
      "url": "https://arxiv.org/abs/2507.21137",
      "description": "arXiv:2507.21137v1 Announce Type: new \nAbstract: In this paper we try to answer the question \"What constitutes Sudoku difficulty rating across different Sudoku websites?\" Using two distinct methods that can both solve every Sudoku puzzle, I propose two new metrics to characterize Sudoku difficulty. ...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "experiment"
      ],
      "score": 0.6
    },
    {
      "title": "Adaptive XAI in High Stakes Environments: Modeling Swift Trust with Multimodal Feedback in Human AI Teams",
      "url": "https://arxiv.org/abs/2507.21158",
      "description": "arXiv:2507.21158v1 Announce Type: new \nAbstract: Effective human-AI teaming heavily depends on swift trust, particularly in high-stakes scenarios such as emergency response, where timely and accurate decision-making is critical. In these time-sensitive and cognitively demanding settings, adaptive ex...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "arxiv",
        "RAG",
        "model",
        "multimodal"
      ],
      "score": 0.6
    },
    {
      "title": "A Study on Variants of Conventional, Fuzzy, and Nullspace-Based Independence Criteria for Improving Supervised and Unsupervised Learning",
      "url": "https://arxiv.org/abs/2507.21136",
      "description": "arXiv:2507.21136v1 Announce Type: new \nAbstract: Unsupervised and supervised learning methods conventionally use kernels to capture nonlinearities inherent in data structure. However experts have to ensure their proposed nonlinearity maximizes variability and capture inherent diversity of data. We r...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "research"
      ],
      "score": 0.6
    },
    {
      "title": "Handling Out-of-Distribution Data: A Survey",
      "url": "https://arxiv.org/abs/2507.21160",
      "description": "arXiv:2507.21160v1 Announce Type: new \nAbstract: In the field of Machine Learning (ML) and data-driven applications, one of the significant challenge is the change in data distribution between the training and deployment stages, commonly known as distribution shift. This paper outlines different mec...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "model",
        "research"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "paper",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Deep Unfolding for MIMO Signal Detection",
      "url": "https://arxiv.org/abs/2507.21152",
      "description": "arXiv:2507.21152v1 Announce Type: new \nAbstract: In this paper, we propose a deep unfolding neural network-based MIMO detector that incorporates complex-valued computations using Wirtinger calculus. The method, referred as Dynamic Partially Shrinkage Thresholding (DPST), enables efficient, interpret...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "OCSVM-Guided Representation Learning for Unsupervised Anomaly Detection",
      "url": "https://arxiv.org/abs/2507.21164",
      "description": "arXiv:2507.21164v1 Announce Type: new \nAbstract: Unsupervised anomaly detection (UAD) aims to detect anomalies without labeled data, a necessity in many machine learning applications where anomalous samples are rare or not available. Most state-of-the-art methods fall into two categories: reconstruc...",
      "published_date": "2025-07-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "image",
        "experiment",
        "model",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face",
      "url": "https://huggingface.co/blog/trackio",
      "description": "...",
      "published_date": "2025-07-29T00:00:00",
      "source": "Hugging Face Blog",
      "category": "tools_frameworks",
      "keywords": [
        "experiment",
        "library"
      ],
      "score": 0.2
    }
  ]
}