{
  "generated_at": "2025-08-04T20:06:06.537630",
  "total_items": 46,
  "items": [
    {
      "title": "PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems",
      "url": "https://arxiv.org/abs/2508.00079",
      "description": "arXiv:2508.00079v1 Announce Type: new \nAbstract: The discipline of physics stands as a cornerstone of human intellect, driving the evolution of technology and deepening our understanding of the fundamental principles of the cosmos. Contemporary literature includes some works centered on the task of ...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "LLM",
        "arxiv",
        "ICL",
        "paper",
        "analysis",
        "framework",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Do LLMs produce texts with \"human-like\" lexical diversity?",
      "url": "https://arxiv.org/abs/2508.00086",
      "description": "arXiv:2508.00086v1 Announce Type: new \nAbstract: The degree to which LLMs produce writing that is truly human-like remains unclear despite the extensive empirical attention that this question has received. The present study addresses this question from the perspective of lexical diversity. Specifica...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "LLM",
        "arxiv",
        "model",
        "vector",
        "study",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "Comparison of Large Language Models for Deployment Requirements",
      "url": "https://arxiv.org/abs/2508.00185",
      "description": "arXiv:2508.00185v1 Announce Type: new \nAbstract: Large Language Models (LLMs), such as Generative Pre-trained Transformers (GPTs) are revolutionizing the generation of human-like text, producing contextually relevant and syntactically correct content. Despite challenges like biases and hallucination...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "research",
        "transformer",
        "GPT",
        "LLM",
        "release",
        "fine-tuning",
        "arxiv",
        "API",
        "model",
        "context",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges",
      "url": "https://arxiv.org/abs/2508.00217",
      "description": "arXiv:2508.00217v1 Announce Type: new \nAbstract: Tables have gained significant attention in large language models (LLMs) and multimodal large language models (MLLMs) due to their complex and flexible structure. Unlike linear text inputs, tables are two-dimensional, encompassing formats that range f...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "research",
        "LLM",
        "arxiv",
        "paper",
        "multimodal",
        "retrieval",
        "context",
        "large language model",
        "attention",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform",
      "url": "https://arxiv.org/abs/2508.00220",
      "description": "arXiv:2508.00220v1 Announce Type: new \nAbstract: Wavelet transforms, a powerful mathematical tool, have been widely used in different domains, including Signal and Image processing, to unravel intricate patterns, enhance data representation, and extract meaningful features from data. Tangible result...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "RAG",
        "tool",
        "paper",
        "image",
        "arxiv",
        "embedding",
        "vector",
        "large language model",
        "compression"
      ],
      "score": 1.0
    },
    {
      "title": "Model Misalignment and Language Change: Traces of AI-Associated Language in Unscripted Spoken English",
      "url": "https://arxiv.org/abs/2508.00238",
      "description": "arXiv:2508.00238v1 Announce Type: new \nAbstract: In recent years, written language, particularly in science and education, has undergone remarkable shifts in word usage. These changes are widely attributed to the growing influence of Large Language Models (LLMs), which frequently rely on a distinct ...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "tool",
        "GPT",
        "LLM",
        "release",
        "alignment",
        "arxiv",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering",
      "url": "https://arxiv.org/abs/2508.00285",
      "description": "arXiv:2508.00285v1 Announce Type: new \nAbstract: Objective: Large Language Models (LLMs) demonstrate significant capabilities in medical text understanding and generation. However, their diagnostic reliability in complex clinical scenarios remains limited. This study aims to enhance LLMs' diagnostic...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "LLM",
        "fine-tuning",
        "alignment",
        "arxiv",
        "model",
        "study",
        "framework",
        "large language model",
        "attention",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench",
      "url": "https://arxiv.org/abs/2508.00081",
      "description": "arXiv:2508.00081v1 Announce Type: new \nAbstract: HealthBench, a benchmark designed to measure the capabilities of AI systems for health better (Arora et al., 2025), has advanced medical language model evaluation through physician-crafted dialogues and transparent rubrics. However, its reliance on ex...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "framework",
        "arxiv",
        "model",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence",
      "url": "https://arxiv.org/abs/2508.00116",
      "description": "arXiv:2508.00116v1 Announce Type: new \nAbstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact, do business, and conduct research. However, organizations struggle to apply AI successfully in industrial settings where the focus is on end-to-end operational processes. He...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "research",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "SHACL Validation under Graph Updates (Extended Paper)",
      "url": "https://arxiv.org/abs/2508.00137",
      "description": "arXiv:2508.00137v1 Announce Type: new \nAbstract: SHACL (SHApe Constraint Language) is a W3C standardized constraint language for RDF graphs. In this paper, we study SHACL validation in RDF graphs under updates. We present a SHACL-based update language that can capture intuitive and realistic modific...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "arxiv",
        "experiment",
        "paper",
        "analysis",
        "study",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization",
      "url": "https://arxiv.org/abs/2508.00222",
      "description": "arXiv:2508.00222v1 Announce Type: new \nAbstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly advanced the complex reasoning abilities of Large Language Models (LLMs). However, it struggles to break through the inherent capability boundaries of the base LLM, due to its inhe...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "LLM",
        "arxiv",
        "experiment",
        "model",
        "analysis",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion",
      "url": "https://arxiv.org/abs/2508.00037",
      "description": "arXiv:2508.00037v1 Announce Type: new \nAbstract: Networked urban systems facilitate the flow of people, resources, and services, and are essential for economic and social interactions. These systems often involve complex processes with unknown governing rules, observed by sensor-based time series. T...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "embedding",
        "transformer",
        "arxiv",
        "paper",
        "context",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings",
      "url": "https://arxiv.org/abs/2508.00039",
      "description": "arXiv:2508.00039v1 Announce Type: new \nAbstract: Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose safety risks to highway vehicles due to potential hang-ups. These crossings typically result from post-construction railway track maintenance activities or non-compliance wi...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "research",
        "transformer",
        "alignment",
        "arxiv",
        "API",
        "memory",
        "ICL",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting",
      "url": "https://arxiv.org/abs/2508.00040",
      "description": "arXiv:2508.00040v1 Announce Type: new \nAbstract: This work integrates Bayesian regime detection with conditional neural processes for 24-hour electricity price prediction in the German market. Our methodology integrates regime detection using a disentangled sticky hierarchical Dirichlet process hidd...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "RAG",
        "arxiv",
        "framework",
        "analysis",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages",
      "url": "https://arxiv.org/abs/2508.00041",
      "description": "arXiv:2508.00041v1 Announce Type: new \nAbstract: Federated fine-tuning enables Large Language Models (LLMs) to adapt to downstream tasks while preserving data privacy, but its resource-intensive nature limits deployment on edge devices. In this paper, we introduce Developmental Federated Tuning (Dev...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "RAG",
        "LLM",
        "fine-tuning",
        "arxiv",
        "paper",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains",
      "url": "https://arxiv.org/abs/2508.00046",
      "description": "arXiv:2508.00046v1 Announce Type: new \nAbstract: Mitigating partial observability is a necessary but challenging task for general reinforcement learning algorithms. To improve an algorithm's ability to mitigate partial observability, researchers need comprehensive benchmarks to gauge progress. Most ...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "research",
        "arxiv",
        "experiment",
        "memory",
        "library",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection",
      "url": "https://arxiv.org/abs/2508.00047",
      "description": "arXiv:2508.00047v1 Announce Type: new \nAbstract: Time-series anomaly detection plays a central role across a wide range of application domains. With the increasing proliferation of the Internet of Things (IoT) and smart manufacturing, time-series data has dramatically increased in both scale and dim...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "vision",
        "LLM",
        "arxiv",
        "experiment",
        "memory",
        "ICL",
        "model",
        "multimodal",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt",
        "context",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "chain-of-thought",
        "audio",
        "framework",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "context",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "LLM",
        "context",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "LLM",
        "knowledge base",
        "model",
        "vector",
        "retrieval",
        "framework",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "LLM",
        "fine-tuning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "product",
        "augmented",
        "API",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "LLM",
        "prompt",
        "vector",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "framework",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Hyperproperty-Constrained Secure Reinforcement Learning",
      "url": "https://arxiv.org/abs/2508.00106",
      "description": "arXiv:2508.00106v1 Announce Type: new \nAbstract: Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a domain-specific formal specification language known for its effectiveness in compactly representing security, opacity, and concurrency properties for robotics applications. This paper foc...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "research",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "context",
        "API",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Semiotic Complexity and Its Epistemological Implications for Modeling Culture",
      "url": "https://arxiv.org/abs/2508.00095",
      "description": "arXiv:2508.00095v1 Announce Type: new \nAbstract: Greater theorizing of methods in the computational humanities is needed for epistemological and interpretive clarity, and therefore the maturation of the field. In this paper, we frame such modeling work as engaging in translation work from a cultural...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "research",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Is neural semantic parsing good at ellipsis resolution, or isn't it?",
      "url": "https://arxiv.org/abs/2508.00121",
      "description": "arXiv:2508.00121v1 Announce Type: new \nAbstract: Neural semantic parsers have shown good overall performance for a variety of linguistic phenomena, reaching semantic matching scores of more than 90%. But how do such parsers perform on strongly context-sensitive phenomena, where large pieces of seman...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis",
      "url": "https://arxiv.org/abs/2508.00129",
      "description": "arXiv:2508.00129v1 Announce Type: new \nAbstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem that can greatly affect the results of a Multi-Criteria Decision Method against a particular set of alternatives. It is therefore useful to have a mechanism that allows one to m...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "library",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning",
      "url": "https://arxiv.org/abs/2508.00271",
      "description": "arXiv:2508.00271v1 Announce Type: new \nAbstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the principle of learning-by-doing, where expertise is developed through hands-on practice and continual self-improvement. MetaAgent starts with a minimal workflow, equipped only with...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "tool",
        "arxiv",
        "knowledge base",
        "model",
        "context",
        "reasoning"
      ],
      "score": 0.6
    },
    {
      "title": "Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization",
      "url": "https://arxiv.org/abs/2508.00078",
      "description": "arXiv:2508.00078v1 Announce Type: new \nAbstract: This study proposes a novel methodological framework integrating a LightGBM regression model and genetic algorithm (GA) optimization to systematically evaluate the contribution of COVID-19-related indicators to Bitcoin return prediction. The primary o...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "tool",
        "arxiv",
        "model",
        "analysis",
        "framework",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "Stress-Aware Resilient Neural Training",
      "url": "https://arxiv.org/abs/2508.00098",
      "description": "arXiv:2508.00098v1 Announce Type: new \nAbstract: This paper introduces Stress-Aware Learning, a resilient neural training paradigm in which deep neural networks dynamically adjust their optimization behavior - whether under stable training regimes or in settings with uncertain dynamics - based on th...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vision",
        "paper",
        "arxiv",
        "experiment",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection",
      "url": "https://arxiv.org/abs/2508.00117",
      "description": "arXiv:2508.00117v1 Announce Type: new \nAbstract: Liver diseases are a serious health concern in the world, which requires precise and timely diagnosis to enhance the survival chances of patients. The current literature implemented numerous machine learning and deep learning models to classify liver ...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "analysis",
        "framework",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "FACTORY: A Challenging Human-Verified Prompt Set for Long-Form Factuality",
      "url": "https://arxiv.org/abs/2508.00109",
      "description": "arXiv:2508.00109v1 Announce Type: new \nAbstract: Long-form factuality evaluation assesses the ability of models to generate accurate, comprehensive responses to short prompts. Existing benchmarks often lack human verification, leading to potential quality issues. To address this limitation, we intro...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "prompt",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Co-Producing AI: Toward an Augmented, Participatory Lifecycle",
      "url": "https://arxiv.org/abs/2508.00138",
      "description": "arXiv:2508.00138v1 Announce Type: new \nAbstract: Despite efforts to mitigate the inherent risks and biases of artificial intelligence (AI) algorithms, these algorithms can disproportionately impact culturally marginalized groups. A range of approaches has been proposed to address or reduce these ris...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "product",
        "arxiv",
        "augmented",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation",
      "url": "https://arxiv.org/abs/2508.00143",
      "description": "arXiv:2508.00143v1 Announce Type: new \nAbstract: Humans can be notoriously imperfect evaluators. They are often biased, unreliable, and unfit to define \"ground truth.\" Yet, given the surging need to produce large amounts of training data in educational applications using AI, traditional inter-rater ...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "example",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power",
      "url": "https://arxiv.org/abs/2508.00159",
      "description": "arXiv:2508.00159v1 Announce Type: new \nAbstract: Power is a key concept in AI safety: power-seeking as an instrumental goal, sudden or gradual disempowerment of humans, power balance in human-AI interaction and international AI governance. At the same time, power as the ability to pursue diverse goa...",
      "published_date": "2025-08-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "ReasonFlux - ReasonFlux Series - A family of LLM post-training algorithms focusing on data selection, reinforcement learning, and inference scaling",
      "url": "https://github.com/Gen-Verse/ReasonFlux",
      "description": "ReasonFlux Series - A family of LLM post-training algorithms focusing on data selection, reinforcement learning, and inference scaling",
      "published_date": "2025-02-10T11:04:39+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}