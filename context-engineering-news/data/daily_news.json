{
  "generated_at": "2025-10-01T20:06:17.392406",
  "total_items": 49,
  "items": [
    {
      "title": "Cyclic Ablation: Testing Concept Localization against Functional Regeneration in AI",
      "url": "https://arxiv.org/abs/2509.25220",
      "description": "arXiv:2509.25220v1 Announce Type: new \nAbstract: Safety and controllability are critical for large language models. A central question is whether undesirable behaviors like deception are localized functions that can be removed, or if they are deeply intertwined with a model's core cognitive abilitie...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "large language model",
        "GPT",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "From Internal Representations to Text Quality: A Geometric Approach to LLM Evaluation",
      "url": "https://arxiv.org/abs/2509.25359",
      "description": "arXiv:2509.25359v1 Announce Type: new \nAbstract: This paper bridges internal and external analysis approaches to large language models (LLMs) by demonstrating that geometric properties of internal model representations serve as reliable proxies for evaluating generated text quality. We validate a se...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "large language model",
        "LLM",
        "analysis",
        "paper",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Generative Value Conflicts Reveal LLM Priorities",
      "url": "https://arxiv.org/abs/2509.25369",
      "description": "arXiv:2509.25369v1 Announce Type: new \nAbstract: Past work seeks to align large language model (LLM)-based assistants with a target set of values, but such assistants are frequently forced to make tradeoffs between values when deployed. In response to the scarcity of value conflict in existing align...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "alignment",
        "model",
        "prompt",
        "prompting",
        "large language model",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "From Faithfulness to Correctness: Generative Reward Models that Think Critically",
      "url": "https://arxiv.org/abs/2509.25409",
      "description": "arXiv:2509.25409v1 Announce Type: new \nAbstract: Through reinforcement learning with verifiable rewards (RLVR), large language models have achieved substantial progress in domains with easily verifiable outcomes, such as mathematics and coding. However, when applied to more complex tasks like open-d...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "alignment",
        "experiment",
        "RAG",
        "model",
        "reasoning",
        "large language model",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "SimulRAG: Simulator-based RAG for Grounding LLMs in Long-form Scientific QA",
      "url": "https://arxiv.org/abs/2509.25459",
      "description": "arXiv:2509.25459v1 Announce Type: new \nAbstract: Large language models (LLMs) show promise in solving scientific problems. They can help generate long-form answers for scientific questions, which are crucial for comprehensive understanding of complex phenomena that require detailed explanations span...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "experiment",
        "RAG",
        "context",
        "model",
        "large language model",
        "LLM",
        "framework",
        "augmented",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "The Rise of AfricaNLP: Contributions, Contributors, and Community Impact (2005-2025)",
      "url": "https://arxiv.org/abs/2509.25477",
      "description": "arXiv:2509.25477v1 Announce Type: new \nAbstract: Natural Language Processing (NLP) is undergoing constant transformation, as Large Language Models (LLMs) are driving daily breakthroughs in research and practice. In this regard, tracking the progress of NLP research and automatically analyzing the co...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "model",
        "research",
        "large language model",
        "LLM",
        "paper",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Not Wrong, But Untrue: LLM Overconfidence in Document-Based Queries",
      "url": "https://arxiv.org/abs/2509.25498",
      "description": "arXiv:2509.25498v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly used in newsroom workflows, but their tendency to hallucinate poses risks to core journalistic practices of sourcing, attribution, and accuracy. We evaluate three widely used tools - ChatGPT, Gemini, and N...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "GPT",
        "tool",
        "context",
        "prompt",
        "model",
        "LLM",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "MixtureVitae: Open Web-Scale Pretraining Dataset With High Quality Instruction and Reasoning Data Built from Permissive-First Text Sources",
      "url": "https://arxiv.org/abs/2509.25531",
      "description": "arXiv:2509.25531v1 Announce Type: new \nAbstract: We present MixtureVitae, an open-access pretraining corpus built to minimize legal risk while providing strong model performance. MixtureVitae follows a risk-mitigated sourcing strategy that combines public-domain and permissively licensed text (e.g.,...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "API",
        "release",
        "experiment",
        "model",
        "reasoning",
        "research",
        "LLM",
        "instruction",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Blueprint-Bench: Comparing spatial intelligence of LLMs, agents and image models",
      "url": "https://arxiv.org/abs/2509.25229",
      "description": "arXiv:2509.25229v1 Announce Type: new \nAbstract: We introduce Blueprint-Bench, a benchmark designed to evaluate spatial reasoning capabilities in AI models through the task of converting apartment photographs into accurate 2D floor plans. While the input modality (photographs) is well within the tra...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "GPT",
        "release",
        "model",
        "multimodal",
        "reasoning",
        "LLM",
        "image",
        "framework",
        "instruction",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "A Formal Comparison Between Chain-of-Thought and Latent Thought",
      "url": "https://arxiv.org/abs/2509.25239",
      "description": "arXiv:2509.25239v1 Announce Type: new \nAbstract: Chain-of-Thought (CoT) elicits reasoning in large language models by explicitly generating intermediate steps in natural language. In contrast, Latent Thought in looped models operates directly in the continuous latent space, enabling computation beyo...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "RAG",
        "model",
        "transformer",
        "reasoning",
        "large language model",
        "analysis",
        "arxiv",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "Neo-Grounded Theory: A Methodological Innovation Integrating High-Dimensional Vector Clustering and Multi-Agent Collaboration for Qualitative Research",
      "url": "https://arxiv.org/abs/2509.25244",
      "description": "arXiv:2509.25244v1 Announce Type: new \nAbstract: Purpose: Neo Grounded Theory (NGT) integrates vector clustering with multi agent systems to resolve qualitative research's scale depth paradox, enabling analysis of massive datasets in hours while preserving interpretive rigor. Methods: We compared NG...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "study",
        "experiment",
        "research",
        "analysis",
        "framework",
        "vector",
        "arxiv",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Memory Management and Contextual Consistency for Long-Running Low-Code Agents",
      "url": "https://arxiv.org/abs/2509.25250",
      "description": "arXiv:2509.25250v1 Announce Type: new \nAbstract: The rise of AI-native Low-Code/No-Code (LCNC) platforms enables autonomous agents capable of executing complex, long-duration business processes. However, a fundamental challenge remains: memory management. As agents operate over extended periods, the...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "platform",
        "experiment",
        "RAG",
        "context",
        "memory",
        "framework",
        "paper",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Fact Grounded Attention: Eliminating Hallucination in Large Language Models Through Attention Level Knowledge Integration",
      "url": "https://arxiv.org/abs/2509.25252",
      "description": "arXiv:2509.25252v1 Announce Type: new \nAbstract: \"The greatest enemy of knowledge is not ignorance, it is the illusion of knowledge.\" Large Language Models have conquered natural language but remain prisoners of their own probabilistic nature--confidently hallucinating facts they never truly knew. W...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "ICL",
        "attention",
        "knowledge base",
        "experiment",
        "model",
        "transformer",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Language Model Planning from an Information Theoretic Perspective",
      "url": "https://arxiv.org/abs/2509.25260",
      "description": "arXiv:2509.25260v1 Announce Type: new \nAbstract: The extent to which decoder-only language models (LMs) engage in planning, that is, organizing intermediate computations to support coherent long-range generation, remains an open and important question, with implications for interpretability, reliabi...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "model",
        "transformer",
        "analysis",
        "framework",
        "vector",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration",
      "url": "https://arxiv.org/abs/2509.25271",
      "description": "arXiv:2509.25271v1 Announce Type: new \nAbstract: Existing safety evaluation methods for large language models (LLMs) suffer from inherent limitations, including evaluator bias and detection failures arising from model homogeneity, which collectively undermine the robustness of risk evaluation proces...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "RAG",
        "context",
        "model",
        "reasoning",
        "large language model",
        "LLM",
        "framework",
        "paper",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "RL in the Wild: Characterizing RLVR Training in LLM Deployment",
      "url": "https://arxiv.org/abs/2509.25279",
      "description": "arXiv:2509.25279v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are now widely used across many domains. With their rapid development, Reinforcement Learning with Verifiable Rewards (RLVR) has surged in recent months to enhance their reasoning and understanding abilities. However, its ...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "API",
        "study",
        "model",
        "reasoning",
        "large language model",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Toward Causal-Visual Programming: Enhancing Agentic Reasoning in Low-Code Environments",
      "url": "https://arxiv.org/abs/2509.25282",
      "description": "arXiv:2509.25282v1 Announce Type: new \nAbstract: Large language model (LLM) agents are increasingly capable of orchestrating complex tasks in low-code environments. However, these agents often exhibit hallucinations and logical inconsistencies because their inherent reasoning mechanisms rely on prob...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "experiment",
        "model",
        "reasoning",
        "large language model",
        "LLM",
        "framework",
        "paper",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "VLHSA: Vision-Language Hierarchical Semantic Alignment for Jigsaw Puzzle Solving with Eroded Gaps",
      "url": "https://arxiv.org/abs/2509.25202",
      "description": "arXiv:2509.25202v1 Announce Type: new \nAbstract: Jigsaw puzzle solving remains challenging in computer vision, requiring an understanding of both local fragment details and global spatial relationships. While most traditional approaches only focus on visual cues like edge matching and visual coheren...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "arxiv",
        "alignment",
        "experiment",
        "RAG",
        "context",
        "model",
        "multimodal",
        "reasoning",
        "framework",
        "vision",
        "cross-modal"
      ],
      "score": 1.0
    },
    {
      "title": "Spectral Logit Sculpting: Adaptive Low-Rank Logit Transformation for Controlled Text Generation",
      "url": "https://arxiv.org/abs/2509.25204",
      "description": "arXiv:2509.25204v1 Announce Type: new \nAbstract: Entropy-based inference methods have gained traction for improving the reliability of Large Language Models (LLMs). However, many existing approaches, such as entropy minimization techniques, suffer from high computational overhead and fail to leverag...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "RAG",
        "context",
        "model",
        "reasoning",
        "large language model",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Hyperbolic Optimization",
      "url": "https://arxiv.org/abs/2509.25206",
      "description": "arXiv:2509.25206v1 Announce Type: new \nAbstract: This work explores optimization methods on hyperbolic manifolds. Building on Riemannian optimization principles, we extend the Hyperbolic Stochastic Gradient Descent (a specialization of Riemannian SGD) to a Hyperbolic Adam optimizer. While these meth...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "study",
        "RAG",
        "model",
        "arxiv",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Multi-level Diagnosis and Evaluation for Robust Tabular Feature Engineering with Large Language Models",
      "url": "https://arxiv.org/abs/2509.25207",
      "description": "arXiv:2509.25207v1 Announce Type: new \nAbstract: Recent advancements in large language models (LLMs) have shown promise in feature engineering for tabular data, but concerns about their reliability persist, especially due to variability in generated outputs. We introduce a multi-level diagnosis and ...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "model",
        "large language model",
        "LLM",
        "framework",
        "few-shot",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "STCast: Adaptive Boundary Alignment for Global and Regional Weather Forecasting",
      "url": "https://arxiv.org/abs/2509.25210",
      "description": "arXiv:2509.25210v1 Announce Type: new \nAbstract: To gain finer regional forecasts, many works have explored the regional integration from the global atmosphere, e.g., by solving boundary equations in physics-based methods or cropping regions from global forecasts in data-driven methods. However, the...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "alignment",
        "attention",
        "experiment",
        "model",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "LEMs: A Primer On Large Execution Models",
      "url": "https://arxiv.org/abs/2509.25211",
      "description": "arXiv:2509.25211v1 Announce Type: new \nAbstract: This paper introduces Large Execution Models (LEMs), a novel deep learning framework that extends transformer-based architectures to address complex execution problems with flexible time boundaries and multiple execution constraints. Building upon rec...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "RAG",
        "context",
        "transformer",
        "model",
        "framework",
        "paper",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles guide inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles guide inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt",
        "prompt engineering",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "audio",
        "framework",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "tool",
        "context",
        "prompt",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "knowledge base",
        "RAG",
        "model",
        "reasoning",
        "LLM",
        "framework",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "LLM",
        "model",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "retrieval",
        "product",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "prompt",
        "LLM",
        "framework",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "The Causal Abstraction Network: Theory and Learning",
      "url": "https://arxiv.org/abs/2509.25236",
      "description": "arXiv:2509.25236v1 Announce Type: new \nAbstract: Causal artificial intelligence aims to enhance explainability, trustworthiness, and robustness in AI by leveraging structural causal models (SCMs). In this pursuit, recent advances formalize network sheaves of causal knowledge. Pushing in the same dir...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "arxiv",
        "model",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "Six Sigma For Neural Networks: Taguchi-based optimization",
      "url": "https://arxiv.org/abs/2509.25213",
      "description": "arXiv:2509.25213v1 Announce Type: new \nAbstract: The optimization of hyperparameters in convolutional neural networks (CNNs) remains a challenging and computationally expensive process, often requiring extensive trial-and-error approaches or exhaustive grid searches. This study introduces the applic...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "experiment",
        "image",
        "framework",
        "analysis",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "context",
        "API",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Beyond WER: Probing Whisper's Sub-token Decoder Across Diverse Language Resource Levels",
      "url": "https://arxiv.org/abs/2509.25516",
      "description": "arXiv:2509.25516v1 Announce Type: new \nAbstract: While large multilingual automatic speech recognition (ASR) models achieve remarkable performance, the internal mechanisms of the end-to-end pipeline, particularly concerning fairness and efficacy across languages, remain underexplored. This paper int...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "paper",
        "arxiv",
        "analysis"
      ],
      "score": 0.6
    },
    {
      "title": "SOLD: SELFIES-based Objective-driven Latent Diffusion",
      "url": "https://arxiv.org/abs/2509.25198",
      "description": "arXiv:2509.25198v1 Announce Type: new \nAbstract: Recently, machine learning has made a significant impact on de novo drug design. However, current approaches to creating novel molecules conditioned on a target protein typically rely on generating molecules directly in the 3D conformational space, wh...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "transformer",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Polynomial Contrastive Learning for Privacy-Preserving Representation Learning on Graphs",
      "url": "https://arxiv.org/abs/2509.25205",
      "description": "arXiv:2509.25205v1 Announce Type: new \nAbstract: Self-supervised learning (SSL) has emerged as a powerful paradigm for learning representations on graph data without requiring manual labels. However, leading SSL methods like GRACE are fundamentally incompatible with privacy-preserving technologies s...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "framework",
        "experiment"
      ],
      "score": 0.6
    },
    {
      "title": "DPSformer: A long-tail-aware model for improving heavy rainfall prediction",
      "url": "https://arxiv.org/abs/2509.25208",
      "description": "arXiv:2509.25208v1 Announce Type: new \nAbstract: Accurate and timely forecasting of heavy rainfall remains a critical challenge for modern society. Precipitation exhibits a highly imbalanced distribution: most observations record no or light rain, while heavy rainfall events are rare. Such an imbala...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "tool",
        "arxiv",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Introducing RTEB: A New Standard for Retrieval Evaluation",
      "url": "https://huggingface.co/blog/rteb",
      "description": "...",
      "published_date": "2025-10-01T00:00:00",
      "source": "Hugging Face Blog",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "paper",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Emotion-Aligned Generation in Diffusion Text to Speech Models via Preference-Guided Optimization",
      "url": "https://arxiv.org/abs/2509.25416",
      "description": "arXiv:2509.25416v1 Announce Type: new \nAbstract: Emotional text-to-speech seeks to convey affect while preserving intelligibility and prosody, yet existing methods rely on coarse labels or proxy classifiers and receive only utterance-level feedback. We introduce Emotion-Aware Stepwise Preference Opt...",
      "published_date": "2025-10-01T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "experiment",
        "model",
        "framework",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Accelerating Qwen3-8B Agent on Intel® Core™ Ultra with Depth-Pruned Draft Models",
      "url": "https://huggingface.co/blog/intel-qwen3-agent",
      "description": "...",
      "published_date": "2025-09-29T00:00:00",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model"
      ],
      "score": 0.2
    }
  ]
}