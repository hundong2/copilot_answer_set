{
  "generated_at": "2025-09-19T20:05:59.742584",
  "total_items": 47,
  "items": [
    {
      "title": "Tokenization Strategies for Low-Resource Agglutinative Languages in Word2Vec: Case Study on Turkish and Finnish",
      "url": "https://arxiv.org/abs/2509.14238",
      "description": "arXiv:2509.14238v1 Announce Type: new \nAbstract: Tokenization plays a critical role in processing agglutinative languages, where a single word can encode multiple morphemes carrying syntactic and semantic information. This study evaluates the impact of various tokenization strategies - word-level, c...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "ICL",
        "study",
        "model",
        "embedding",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Advancing Conversational AI with Shona Slang: A Dataset and Hybrid Model for Digital Inclusion",
      "url": "https://arxiv.org/abs/2509.14249",
      "description": "arXiv:2509.14249v1 Announce Type: new \nAbstract: African languages remain underrepresented in natural language processing (NLP), with most corpora limited to formal registers that fail to capture the vibrancy of everyday communication. This work addresses this gap for Shona, a Bantu language spoken ...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "ICL",
        "arxiv",
        "augmented",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "The meaning of prompts and the prompts of meaning: Semiotic reflections and modelling",
      "url": "https://arxiv.org/abs/2509.14250",
      "description": "arXiv:2509.14250v1 Announce Type: new \nAbstract: This paper explores prompts and prompting in large language models (LLMs) as dynamic semiotic phenomena, drawing on Peirce's triadic model of signs, his nine sign types, and the Dynacom model of communication. The aim is to reconceptualize prompting n...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompting",
        "arxiv",
        "prompt",
        "large language model",
        "paper",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "LLM-JEPA: Large Language Models Meet Joint Embedding Predictive Architectures",
      "url": "https://arxiv.org/abs/2509.14252",
      "description": "arXiv:2509.14252v1 Announce Type: new \nAbstract: Large Language Model (LLM) pretraining, finetuning, and evaluation rely on input-space reconstruction and generative capabilities. Yet, it has been observed in vision that embedding-space training objectives, e.g., with Joint Embedding Predictive Arch...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "large language model",
        "vision",
        "embedding",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Hallucination Detection with the Internal Layers of LLMs",
      "url": "https://arxiv.org/abs/2509.14254",
      "description": "arXiv:2509.14254v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have succeeded in a variety of natural language processing tasks [Zha+25]. However, they have notable limitations. LLMs tend to generate hallucinations, a seemingly plausible yet factually unsupported output [Hua+24], whic...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "large language model",
        "LLM",
        "analysis",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Opening the Black Box: Interpretable LLMs via Semantic Resonance Architecture",
      "url": "https://arxiv.org/abs/2509.14255",
      "description": "arXiv:2509.14255v1 Announce Type: new \nAbstract: Large language models (LLMs) achieve remarkable performance but remain difficult to interpret. Mixture-of-Experts (MoE) models improve efficiency through sparse activation, yet typically rely on opaque, learned gating functions. While similarity-based...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "RAG",
        "arxiv",
        "large language model",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "JU-NLP at Touch\\'e: Covert Advertisement in Conversational AI-Generation and Detection Strategies",
      "url": "https://arxiv.org/abs/2509.14256",
      "description": "arXiv:2509.14256v1 Announce Type: new \nAbstract: This paper proposes a comprehensive framework for the generation of covert advertisements within Conversational AI systems, along with robust techniques for their detection. It explores how subtle promotional content can be crafted within AI-generated...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "prompting",
        "RAG",
        "arxiv",
        "large language model",
        "paper",
        "framework",
        "model",
        "prompt",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "From Correction to Mastery: Reinforced Distillation of Large Language Model Agents",
      "url": "https://arxiv.org/abs/2509.14257",
      "description": "arXiv:2509.14257v1 Announce Type: new \nAbstract: Large Language Model agents excel at solving complex tasks through iterative reasoning and tool use, but typically depend on ultra-large, costly backbones. Existing distillation approaches train smaller students to imitate full teacher trajectories, y...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "RAG",
        "arxiv",
        "large language model",
        "reasoning",
        "framework",
        "tool",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Persuasive or Neutral? A Field Experiment on Generative AI in Online Travel Planning",
      "url": "https://arxiv.org/abs/2509.14259",
      "description": "arXiv:2509.14259v1 Announce Type: new \nAbstract: Generative AI (GenAI) offers new opportunities for customer support in online travel agencies, yet little is known about how its design influences user engagement, purchase behavior, and user experience. We report results from a randomized field exper...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "experiment",
        "instruction",
        "arxiv",
        "prompt",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Unified Crew Planning and Replanning Optimization in Multi-Line Metro Systems Considering Workforce Heterogeneity",
      "url": "https://arxiv.org/abs/2509.14251",
      "description": "arXiv:2509.14251v1 Announce Type: new \nAbstract: Metro crew planning is a key component of smart city development as it directly impacts the operational efficiency and service reliability of public transportation. With the rapid expansion of metro networks, effective multi-line scheduling and emerge...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "API",
        "attention",
        "framework",
        "model",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing",
      "url": "https://arxiv.org/abs/2509.14289",
      "description": "arXiv:2509.14289v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly used to automate or augment penetration testing, but their effectiveness and reliability across attack phases remain unclear. We present a comprehensive evaluation of multiple LLM-based agents, from single...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "arxiv",
        "large language model",
        "model",
        "tool",
        "memory",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents",
      "url": "https://arxiv.org/abs/2509.14382",
      "description": "arXiv:2509.14382v1 Announce Type: new \nAbstract: Web agents powered by large language models (LLMs) can autonomously perform complex, multistep tasks in dynamic web environments. However, current evaluations mostly focus on the overall success while overlooking intermediate errors. This limits insig...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "large language model",
        "framework",
        "study",
        "analysis",
        "tool",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "VCBench: Benchmarking LLMs in Venture Capital",
      "url": "https://arxiv.org/abs/2509.14448",
      "description": "arXiv:2509.14448v1 Announce Type: new \nAbstract: Benchmarks such as SWE-bench and ARC-AGI demonstrate how shared datasets accelerate progress toward artificial general intelligence (AGI). We introduce VCBench, the first benchmark for predicting founder success in venture capital (VC), a domain where...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "GPT",
        "large language model",
        "API",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction",
      "url": "https://arxiv.org/abs/2509.14507",
      "description": "arXiv:2509.14507v1 Announce Type: new \nAbstract: Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that simplifies database access for non-technical users by converting natural language queries into SQL commands. Recent advancements, particularly those integrating Retrieval-Augm...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "experiment",
        "fine-tuning",
        "RAG",
        "retrieval",
        "arxiv",
        "CoT",
        "reasoning",
        "augmented",
        "chain-of-thought",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Rationality Check! Benchmarking the Rationality of Large Language Models",
      "url": "https://arxiv.org/abs/2509.14546",
      "description": "arXiv:2509.14546v1 Announce Type: new \nAbstract: Large language models (LLMs), a recent advance in deep learning and machine intelligence, have manifested astonishing capacities, now considered among the most promising for artificial general intelligence. With human-like capabilities, LLMs have been...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "large language model",
        "LLM",
        "tool",
        "analysis",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration",
      "url": "https://arxiv.org/abs/2509.14547",
      "description": "arXiv:2509.14547v1 Announce Type: new \nAbstract: Recent studies have shown that carefully designed workflows coordinating large language models(LLMs) significantly enhance task-solving capabilities compared to using a single model. While an increasing number of works focus on autonomous workflow con...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "RAG",
        "arxiv",
        "large language model",
        "framework",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "SynBench: A Benchmark for Differentially Private Text Generation",
      "url": "https://arxiv.org/abs/2509.14594",
      "description": "arXiv:2509.14594v1 Announce Type: new \nAbstract: Data-driven decision support in high-stakes domains like healthcare and finance faces significant barriers to data sharing due to regulatory, institutional, and privacy concerns. While recent generative AI models, such as large language models, have s...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "arxiv",
        "large language model",
        "framework",
        "study",
        "model",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Discovering New Theorems via LLMs with In-Context Proof Learning in Lean",
      "url": "https://arxiv.org/abs/2509.14274",
      "description": "arXiv:2509.14274v1 Announce Type: new \nAbstract: Large Language Models have demonstrated significant promise in formal theorem proving. However, previous works mainly focus on solving existing problems. In this paper, we focus on the ability of LLMs to find novel theorems. We propose Conjecturing-Pr...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "large language model",
        "in-context",
        "framework",
        "model",
        "paper",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "A Neural Network for the Identical Kuramoto Equation: Architectural Considerations and Performance Evaluation",
      "url": "https://arxiv.org/abs/2509.14384",
      "description": "arXiv:2509.14384v1 Announce Type: new \nAbstract: In this paper, we investigate the efficiency of Deep Neural Networks (DNNs) to approximate the solution of a nonlocal conservation law derived from the identical-oscillator Kuramoto model, focusing on the evaluation of an architectural choice and its ...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "model",
        "paper",
        "analysis",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Disproving the Feasibility of Learned Confidence Calibration Under Binary Supervision: An Information-Theoretic Impossibility",
      "url": "https://arxiv.org/abs/2509.14386",
      "description": "arXiv:2509.14386v1 Announce Type: new \nAbstract: We prove a fundamental impossibility theorem: neural networks cannot simultaneously learn well-calibrated confidence estimates with meaningful diversity when trained using binary correct/incorrect supervision. Through rigorous mathematical analysis an...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "RAG",
        "arxiv",
        "vision",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs",
      "url": "https://arxiv.org/abs/2509.14391",
      "description": "arXiv:2509.14391v1 Announce Type: new \nAbstract: Extending LLM context windows is crucial for long range tasks. RoPE-based position interpolation (PI) methods like linear and frequency-aware scaling extend input lengths without retraining, while post-training quantization (PTQ) enables practical dep...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "fine-tuning",
        "arxiv",
        "context window",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Hashing-Baseline: Rethinking Hashing in the Age of Pretrained Models",
      "url": "https://arxiv.org/abs/2509.14427",
      "description": "arXiv:2509.14427v1 Announce Type: new \nAbstract: Information retrieval with compact binary embeddings, also referred to as hashing, is crucial for scalable fast search applications, yet state-of-the-art hashing methods require expensive, scenario-specific training. In this work, we introduce Hashing...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG",
        "retrieval",
        "arxiv",
        "image",
        "vision",
        "embedding",
        "audio",
        "analysis",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "FedAVOT: Exact Distribution Alignment in Federated Learning via Masked Optimal Transport",
      "url": "https://arxiv.org/abs/2509.14444",
      "description": "arXiv:2509.14444v1 Announce Type: new \nAbstract: Federated Learning (FL) allows distributed model training without sharing raw data, but suffers when client participation is partial. In practice, the distribution of available users (\\emph{availability distribution} $q$) rarely aligns with the distri...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "RAG",
        "arxiv",
        "alignment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "BEACON: Behavioral Malware Classification with Large Language Model Embeddings and Deep Learning",
      "url": "https://arxiv.org/abs/2509.14519",
      "description": "arXiv:2509.14519v1 Announce Type: new \nAbstract: Malware is becoming increasingly complex and widespread, making it essential to develop more effective and timely detection methods. Traditional static analysis often fails to defend against modern threats that employ code obfuscation, polymorphism, a...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "arxiv",
        "large language model",
        "framework",
        "model",
        "embedding",
        "analysis",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context window",
        "context",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "reasoning",
        "framework",
        "chain-of-thought",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "model",
        "prompt",
        "tool",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "reasoning",
        "framework",
        "vector",
        "model",
        "LLM",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "fine-tuning",
        "tool",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "product",
        "RAG",
        "retrieval",
        "API",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "framework",
        "vector",
        "prompt",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "framework",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond the high score: Prosocial ability profiles of multi-agent populations",
      "url": "https://arxiv.org/abs/2509.14485",
      "description": "arXiv:2509.14485v1 Announce Type: new \nAbstract: The development and evaluation of social capabilities in AI agents require complex environments where competitive and cooperative behaviours naturally emerge. While game-theoretic properties can explain why certain teams or agent populations outperfor...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "framework",
        "paper",
        "analysis",
        "research"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "tool",
        "model",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "CrossPT: Exploring Cross-Task Transferability through Multi-Task Prompt Tuning",
      "url": "https://arxiv.org/abs/2509.14253",
      "description": "arXiv:2509.14253v1 Announce Type: new \nAbstract: Prompt tuning offers a parameter-efficient way to adapt large pre-trained language models to new tasks, but most existing approaches are designed for single-task settings, failing to share knowledge across related tasks. We propose Cross-task Prompt T...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "attention",
        "framework",
        "prompt",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "H-Alpha Anomalyzer: An Explainable Anomaly Detector for Solar H-Alpha Observations",
      "url": "https://arxiv.org/abs/2509.14472",
      "description": "arXiv:2509.14472v1 Announce Type: new \nAbstract: The plethora of space-borne and ground-based observatories has provided astrophysicists with an unprecedented volume of data, which can only be processed at scale using advanced computing algorithms. Consequently, ensuring the quality of data fed into...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "release",
        "arxiv",
        "study",
        "analysis",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Decentralized Optimization with Topology-Independent Communication",
      "url": "https://arxiv.org/abs/2509.14488",
      "description": "arXiv:2509.14488v1 Announce Type: new \nAbstract: Distributed optimization requires nodes to coordinate, yet full synchronization scales poorly. When $n$ nodes collaborate through $m$ pairwise regularizers, standard methods demand $\\mathcal{O}(m)$ communications per iteration. This paper proposes ran...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "paper",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "From Mimicry to True Intelligence (TI) - A New Paradigm for Artificial General Intelligence",
      "url": "https://arxiv.org/abs/2509.14474",
      "description": "arXiv:2509.14474v1 Announce Type: new \nAbstract: The debate around Artificial General Intelligence (AGI) remains open due to two fundamentally different goals: replicating human-like performance versus replicating human-like cognitive processes. We argue that current performance-based definitions ar...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "framework",
        "product",
        "research"
      ],
      "score": 0.4
    },
    {
      "title": "Predicting Case Suffixes With Activity Start and End Times: A Sweep-Line Based Approach",
      "url": "https://arxiv.org/abs/2509.14536",
      "description": "arXiv:2509.14536v1 Announce Type: new \nAbstract: Predictive process monitoring techniques support the operational decision making by predicting future states of ongoing cases of a business process. A subset of these techniques predict the remaining sequence of activities of an ongoing case (case suf...",
      "published_date": "2025-09-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}