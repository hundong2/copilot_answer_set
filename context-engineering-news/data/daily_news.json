{
  "generated_at": "2026-02-04T20:10:23.792777",
  "total_items": 48,
  "items": [
    {
      "title": "The Hypocrisy Gap: Quantifying Divergence Between Internal Belief and Chain-of-Thought Explanation via Sparse Autoencoders",
      "url": "https://arxiv.org/abs/2602.02496",
      "description": "arXiv:2602.02496v1 Announce Type: new \nAbstract: Large Language Models (LLMs) frequently exhibit unfaithful behavior, producing a final answer that differs significantly from their internal chain of thought (CoT) reasoning in order to appease the user they are conversing with. In order to better det...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "large language model",
        "chain-of-thought",
        "CoT",
        "arxiv",
        "LLM",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "STEMVerse: A Dual-Axis Diagnostic Framework for STEM Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2602.02497",
      "description": "arXiv:2602.02497v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) achieve significant breakthroughs in complex reasoning tasks, evaluating their proficiency in science, technology, engineering, and mathematics (STEM) has become a primary method for measuring machine intelligence. Howe...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "large language model",
        "reasoning",
        "RAG",
        "framework",
        "arxiv",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Test-Time Detoxification without Training or Learning Anything",
      "url": "https://arxiv.org/abs/2602.02498",
      "description": "arXiv:2602.02498v1 Announce Type: new \nAbstract: Large language models can produce toxic or inappropriate text even for benign inputs, creating risks when deployed at scale. Detoxification is therefore important for safety and user trust, particularly when we want to reduce harmful content without s...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "large language model",
        "prompt",
        "RAG",
        "arxiv",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "ROSA-Tuning: Enhancing Long-Context Modeling via Suffix Matching",
      "url": "https://arxiv.org/abs/2602.02499",
      "description": "arXiv:2602.02499v1 Announce Type: new \nAbstract: Long-context capability and computational efficiency are among the central challenges facing today's large language models. Existing efficient attention methods reduce computational complexity, but they typically suffer from a limited coverage of the ...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "large language model",
        "memory",
        "RAG",
        "example",
        "retrieval",
        "paper",
        "arxiv",
        "attention",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Graph-Augmented Reasoning with Large Language Models for Tobacco Pest and Disease Management",
      "url": "https://arxiv.org/abs/2602.02635",
      "description": "arXiv:2602.02635v1 Announce Type: new \nAbstract: This paper proposes a graph-augmented reasoning framework for tobacco pest and disease management that integrates structured domain knowledge into large language models. Building on GraphRAG, we construct a domain-specific knowledge graph and retrieve...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "large language model",
        "reasoning",
        "fine-tuning",
        "RAG",
        "transformer",
        "paper",
        "retrieval",
        "framework",
        "arxiv",
        "augmented",
        "LLM",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Monotonicity as an Architectural Bias for Robust Language Models",
      "url": "https://arxiv.org/abs/2602.02686",
      "description": "arXiv:2602.02686v1 Announce Type: new \nAbstract: Large language models (LLMs) are known to exhibit brittle behavior under adversarial prompts and jailbreak attacks, even after extensive alignment and fine-tuning. This fragility reflects a broader challenge of modern neural language models: small, ca...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "alignment",
        "summarization",
        "large language model",
        "reasoning",
        "model",
        "fine-tuning",
        "prompt",
        "RAG",
        "transformer",
        "arxiv",
        "LLM",
        "attention",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "InfMem: Learning System-2 Memory Control for Long-Context Agent",
      "url": "https://arxiv.org/abs/2602.02704",
      "description": "arXiv:2602.02704v1 Announce Type: new \nAbstract: Reasoning over ultra-long documents requires synthesizing sparse evidence scattered across distant segments under strict memory constraints. While streaming agents enable scalable processing, their passive memory update strategy often fails to preserv...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "reasoning",
        "memory",
        "RAG",
        "retrieval",
        "arxiv",
        "context",
        "compression"
      ],
      "score": 1.0
    },
    {
      "title": "Predicting first-episode homelessness among US Veterans using longitudinal EHR data: time-varying models and social risk factors",
      "url": "https://arxiv.org/abs/2602.02731",
      "description": "arXiv:2602.02731v1 Announce Type: new \nAbstract: Homelessness among US veterans remains a critical public health challenge, yet risk prediction offers a pathway for proactive intervention. In this retrospective prognostic study, we analyzed electronic health record (EHR) data from 4,276,403 Veterans...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "model",
        "large language model",
        "transformer",
        "arxiv",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes",
      "url": "https://arxiv.org/abs/2602.00053",
      "description": "arXiv:2602.00053v1 Announce Type: new \nAbstract: Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing req...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "model",
        "product",
        "RAG",
        "paper",
        "analysis",
        "arxiv",
        "API",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models",
      "url": "https://arxiv.org/abs/2602.00190",
      "description": "arXiv:2602.00190v1 Announce Type: new \nAbstract: Deep learning agents can achieve high performance in complex game domains without often understanding the underlying causal game mechanics. To address this, we investigate Causal Induction: the ability to infer governing laws from observational data, ...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "model",
        "large language model",
        "prompt",
        "framework",
        "arxiv",
        "LLM",
        "embedding",
        "context",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Localizing and Correcting Errors for LLM-based Planners",
      "url": "https://arxiv.org/abs/2602.00276",
      "description": "arXiv:2602.00276v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated strong reasoning capabilities on math and coding, but frequently fail on symbolic classical planning tasks. Our studies, as well as prior work, show that LLM-generated plans routinely violate domain const...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "instruction",
        "model",
        "large language model",
        "reasoning",
        "ICL",
        "demonstration",
        "example",
        "arxiv",
        "in-context",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
      "url": "https://arxiv.org/abs/2602.00298",
      "description": "arXiv:2602.00298v1 Announce Type: new \nAbstract: Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluatin...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "instruction",
        "alignment",
        "large language model",
        "model",
        "research",
        "ICL",
        "fine-tuning",
        "prompt",
        "RAG",
        "GPT",
        "paper",
        "arxiv",
        "LLM",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Autonomous Data Processing using Meta-Agents",
      "url": "https://arxiv.org/abs/2602.00307",
      "description": "arXiv:2602.00307v1 Announce Type: new \nAbstract: Traditional data processing pipelines are typically static and handcrafted for specific tasks, limiting their adaptability to evolving requirements. While general-purpose agents and coding assistants can generate code for well-understood data pipeline...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "RAG",
        "framework",
        "arxiv",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?",
      "url": "https://arxiv.org/abs/2602.00327",
      "description": "arXiv:2602.00327v1 Announce Type: new \nAbstract: We explore the use of large language models (LLMs) for next-utterance prediction in human dialogue. Despite recent advances in LLMs demonstrating their ability to engage in natural conversations with users, we show that even leading models surprisingl...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "large language model",
        "research",
        "multimodal",
        "arxiv",
        "LLM",
        "context",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants",
      "url": "https://arxiv.org/abs/2602.00353",
      "description": "arXiv:2602.00353v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly applied in mental health support systems, where reliable recognition of high-risk states such as suicidal ideation and self-harm is safety-critical. However, existing evaluations primarily rely on aggregat...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "large language model",
        "research",
        "analysis",
        "arxiv",
        "API",
        "LLM",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "Position: Agentic Evolution is the Path to Evolving LLMs",
      "url": "https://arxiv.org/abs/2602.00359",
      "description": "arXiv:2602.00359v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) move from curated training sets into open-ended real-world environments, a fundamental limitation emerges: static training cannot keep pace with continual deployment environment change. Scaling training-time and inferen...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "model",
        "large language model",
        "vision",
        "fine-tuning",
        "memory",
        "framework",
        "arxiv",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Augmenting Parameter-Efficient Pre-trained Language Models with Large Language Models",
      "url": "https://arxiv.org/abs/2602.02501",
      "description": "arXiv:2602.02501v1 Announce Type: new \nAbstract: Training AI models in cybersecurity with help of vast datasets offers significant opportunities to mimic real-world behaviors effectively. However, challenges like data drift and scarcity of labelled data lead to frequent updates of models and the ris...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "large language model",
        "tool",
        "fine-tuning",
        "analysis",
        "arxiv",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Learning ORDER-Aware Multimodal Representations for Composite Materials Design",
      "url": "https://arxiv.org/abs/2602.02513",
      "description": "arXiv:2602.02513v1 Announce Type: new \nAbstract: Artificial intelligence (AI) has shown remarkable success in materials discovery and property prediction, particularly for crystalline and polymer systems where material properties and structures are dominated by discrete graph representations. Such g...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "alignment",
        "multimodal",
        "retrieval",
        "framework",
        "arxiv",
        "image",
        "cross-modal"
      ],
      "score": 1.0
    },
    {
      "title": "GraphDancer: Training LLMs to Explore and Reason over Graphs via Curriculum Reinforcement Learning",
      "url": "https://arxiv.org/abs/2602.02518",
      "description": "arXiv:2602.02518v1 Announce Type: new \nAbstract: Large language models (LLMs) increasingly rely on external knowledge to improve factuality, yet many real-world knowledge sources are organized as heterogeneous graphs rather than plain text. Reasoning over such graph-structured knowledge poses two ke...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "large language model",
        "reasoning",
        "GPT",
        "retrieval",
        "framework",
        "arxiv",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Scaled Dot-Product Attention implements projection of inputs onto a common surface",
      "url": "https://arxiv.org/abs/2602.02521",
      "description": "arXiv:2602.02521v1 Announce Type: new \nAbstract: Scaled dot-product attention (SDPA) is a fundamental component responsible for the success of large-language models and other nonlinear signal processing applications. The rationale for SDPA has been based upon \"query, key, value\" concepts borrowed fr...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "model",
        "product",
        "attention",
        "vector",
        "arxiv",
        "embedding",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "IMU-1: Sample-Efficient Pre-training of Small Language Models",
      "url": "https://arxiv.org/abs/2602.02522",
      "description": "arXiv:2602.02522v1 Announce Type: new \nAbstract: We present IMU-1, a 430M-parameter language model trained on 72B tokens that approaches the benchmark performance of models trained on 56x more data. We describe a validated training recipe combining recent architectural interventions (QK-norm attenti...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "model",
        "release",
        "product",
        "arxiv",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "TabularMath: Evaluating Computational Extrapolation in Tabular Learning via Program-Verified Synthesis",
      "url": "https://arxiv.org/abs/2602.02523",
      "description": "arXiv:2602.02523v1 Announce Type: new \nAbstract: Standard tabular benchmarks mainly focus on the evaluation of a model's capability to interpolate values inside a data manifold, where models good at performing local statistical smoothing are rewarded. However, there exists a very large category of h...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "model",
        "release",
        "context",
        "ICL",
        "GPT",
        "arxiv",
        "in-context",
        "example"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "context window",
        "prompt engineering",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "audio",
        "chain-of-thought",
        "framework",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "prompt",
        "API",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "RAG",
        "reasoning",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "framework",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "reasoning",
        "knowledge base",
        "RAG",
        "vector",
        "retrieval",
        "framework",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "product",
        "RAG",
        "retrieval",
        "API",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "vector",
        "framework",
        "LLM",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "Time-Critical Multimodal Medical Transportation: Organs, Patients, and Medical Supplies",
      "url": "https://arxiv.org/abs/2602.02736",
      "description": "arXiv:2602.02736v1 Announce Type: new \nAbstract: Timely transportation of organs, patients, and medical supplies is critical to modern healthcare, particularly in emergencies and transplant scenarios where even short delays can severely impact outcomes. Traditional ground-based vehicles such as ambu...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "model",
        "ICL",
        "RAG",
        "multimodal",
        "arxiv",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "Sparse Adapter Fusion for Continual Learning in NLP",
      "url": "https://arxiv.org/abs/2602.02502",
      "description": "arXiv:2602.02502v1 Announce Type: new \nAbstract: Continual learning in natural language processing plays a crucial role in adapting to evolving data and preventing catastrophic forgetting. Despite significant progress, existing methods still face challenges, such as inefficient parameter reuse acros...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "arxiv",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "API",
        "context",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3â€™s Top Model",
      "url": "https://huggingface.co/blog/nvidia/nemotron-colembed-v2",
      "description": "...",
      "published_date": "2026-02-04T15:00:40",
      "source": "Hugging Face Blog",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "retrieval",
        "multimodal"
      ],
      "score": 0.6
    },
    {
      "title": "WideSeek: Advancing Wide Research via Multi-Agent Scaling",
      "url": "https://arxiv.org/abs/2602.02636",
      "description": "arXiv:2602.02636v1 Announce Type: new \nAbstract: Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for retrieving and synthesizing comprehensive information under complex constraints in parallel. However, progress in this field is impeded by the lack of dedica...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "research",
        "experiment"
      ],
      "score": 0.6
    },
    {
      "title": "Learning to Price: Interpretable Attribute-Level Models for Dynamic Markets",
      "url": "https://arxiv.org/abs/2602.00188",
      "description": "arXiv:2602.00188v1 Announce Type: new \nAbstract: Dynamic pricing in high-dimensional markets poses fundamental challenges of scalability, uncertainty, and interpretability. Existing low-rank bandit formulations learn efficiently but rely on latent features that obscure how individual product attribu...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "model",
        "arxiv",
        "API",
        "product"
      ],
      "score": 0.6
    },
    {
      "title": "The \"Robert Boulton\" Singularity: Semantic Tunneling and Manifold Unfolding in Recursive AI",
      "url": "https://arxiv.org/abs/2602.02526",
      "description": "arXiv:2602.02526v1 Announce Type: new \nAbstract: The stability of generative artificial intelligence trained on recursive synthetic data is conventionally monitored via Perplexity (PPL). We demonstrate that PPL is a deceptive metric in context-stabilized regimes (L=128). Using a rigorous sliding-win...",
      "published_date": "2026-02-04T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "model",
        "framework",
        "arxiv",
        "template",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "H Company's new Holo2 model takes the lead in UI Localization",
      "url": "https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b",
      "description": "...",
      "published_date": "2026-02-03T17:40:14",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model",
        "company"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Training Design for Text-to-Image Models: Lessons from Ablations",
      "url": "https://huggingface.co/blog/Photoroom/prx-part2",
      "description": "...",
      "published_date": "2026-02-03T11:25:53",
      "source": "Hugging Face Blog",
      "category": "multimodal_context",
      "keywords": [
        "model",
        "image"
      ],
      "score": 0.2
    }
  ]
}