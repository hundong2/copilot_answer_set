{
  "generated_at": "2026-01-30T20:08:06.259853",
  "total_items": 46,
  "items": [
    {
      "title": "DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents",
      "url": "https://arxiv.org/abs/2601.20975",
      "description": "arXiv:2601.20975v1 Announce Type: new \nAbstract: We introduce DeepSearchQA, a 900-prompt benchmark for evaluating agents on difficult multi-step information-seeking tasks across 17 different fields. Unlike traditional benchmarks that target single answer retrieval or broad-spectrum factuality, DeepS...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "research",
        "arxiv",
        "RAG",
        "tool",
        "retrieval",
        "prompt",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "asr_eval: Algorithms and tools for multi-reference and streaming speech recognition evaluation",
      "url": "https://arxiv.org/abs/2601.20992",
      "description": "arXiv:2601.20992v1 Announce Type: new \nAbstract: We propose several improvements to the speech recognition evaluation. First, we propose a string alignment algorithm that supports both multi-reference labeling, arbitrary-length insertions and better word alignment. This is especially useful for non-...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "ICL",
        "arxiv",
        "alignment",
        "tool",
        "fine-tuning",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "UrduBench: An Urdu Reasoning Benchmark using Contextually Ensembled Translations with Human-in-the-Loop",
      "url": "https://arxiv.org/abs/2601.21000",
      "description": "arXiv:2601.21000v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) have led to strong reasoning capabilities; however, evaluating such models in low-resource languages remains challenging due to the lack of standardized benchmarks. In particular, Urdu reasoning evaluati...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompting",
        "instruction",
        "framework",
        "model",
        "ICL",
        "arxiv",
        "RAG",
        "LLM",
        "alignment",
        "release",
        "large language model",
        "experiment",
        "analysis",
        "paper",
        "prompt",
        "context",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Position-invariant Fine-tuning of Speech Enhancement Models with Self-supervised Speech Representations",
      "url": "https://arxiv.org/abs/2601.21084",
      "description": "arXiv:2601.21084v1 Announce Type: new \nAbstract: Integrating front-end speech enhancement (SE) models with self-supervised learning (SSL)-based speech models is effective for downstream tasks in noisy conditions. SE models are commonly fine-tuned using SSL representations with mean squared error (MS...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "embedding",
        "experiment",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "ChunkWise LoRA: Adaptive Sequence Partitioning for Memory-Efficient Low-Rank Adaptation and Accelerated LLM Inference",
      "url": "https://arxiv.org/abs/2601.21109",
      "description": "arXiv:2601.21109v1 Announce Type: new \nAbstract: Recent advances in low-rank adaptation (LoRA) have enabled efficient fine-tuning of large language models (LLMs) with minimal additional parameters. However, existing LoRA methods apply static rank configurations uniformly across all input tokens, ign...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "model",
        "arxiv",
        "LLM",
        "transformer",
        "large language model",
        "experiment",
        "memory",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "Multi-task Code LLMs: Data Mix or Model Merge?",
      "url": "https://arxiv.org/abs/2601.21115",
      "description": "arXiv:2601.21115v1 Announce Type: new \nAbstract: Recent research advocates deploying smaller, specialized code LLMs in agentic frameworks alongside frontier models, sparking interest in efficient strategies for multi-task learning that balance performance, constraints, and costs. We compare two appr...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "model",
        "research",
        "arxiv",
        "LLM",
        "experiment",
        "analysis",
        "fine-tuning",
        "summarization"
      ],
      "score": 1.0
    },
    {
      "title": "Large Language Models Naively Recover Ethnicity from Individual Records",
      "url": "https://arxiv.org/abs/2601.21132",
      "description": "arXiv:2601.21132v1 Announce Type: new \nAbstract: I demonstrate that large language models can infer ethnicity from names with accuracy exceeding that of Bayesian Improved Surname Geocoding (BISG) without additional training data, enabling inference outside the United States and to contextually appro...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "GPT",
        "arxiv",
        "LLM",
        "transformer",
        "large language model",
        "context",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Output-Space Search: Targeting LLM Generations in a Frozen Encoder-Defined Output Space",
      "url": "https://arxiv.org/abs/2601.21169",
      "description": "arXiv:2601.21169v1 Announce Type: new \nAbstract: We introduce Output-Space Search (OS-Search), which turns LLM generation into endpoint search. An outer loop selects a target z* in a frozen encoder-defined 3D output space Z, and a retrieval-grounded policy trained with sequence-level RL generates ou...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "retrieval",
        "prompt",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "From Linear Input to Hierarchical Structure: Function Words as Statistical Cues for Language Learning",
      "url": "https://arxiv.org/abs/2601.21191",
      "description": "arXiv:2601.21191v1 Announce Type: new \nAbstract: What statistical conditions support learning hierarchical structure from linear input? In this paper, we address this question by focusing on the statistical distribution of function words. Function words have long been argued to play a crucial role i...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "alignment",
        "experiment",
        "analysis",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning",
      "url": "https://arxiv.org/abs/2601.20014",
      "description": "arXiv:2601.20014v1 Announce Type: new \nAbstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "arxiv",
        "LLM",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Insight Agents: An LLM-Based Multi-Agent System for Data Insights",
      "url": "https://arxiv.org/abs/2601.20048",
      "description": "arXiv:2601.20048v1 Announce Type: new \nAbstract: Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Ins...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "arxiv",
        "RAG",
        "LLM",
        "tool",
        "retrieval",
        "API",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Should I Have Expressed a Different Intent? Counterfactual Generation for LLM-Based Autonomous Control",
      "url": "https://arxiv.org/abs/2601.20090",
      "description": "arXiv:2601.20090v2 Announce Type: new \nAbstract: Large language model (LLM)-powered agents can translate high-level user intents into plans and actions in an environment. Yet after observing an outcome, users may wonder: What if I had phrased my intent differently? We introduce a framework that enab...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "model",
        "arxiv",
        "RAG",
        "LLM",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Towards Intelligent Urban Park Development Monitoring: LLM Agents for Multi-Modal Information Fusion and Analysis",
      "url": "https://arxiv.org/abs/2601.20206",
      "description": "arXiv:2601.20206v1 Announce Type: new \nAbstract: As an important part of urbanization, the development monitoring of newly constructed parks is of great significance for evaluating the effect of urban planning and optimizing resource allocation. However, traditional change detection methods based on...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "image",
        "GPT",
        "arxiv",
        "LLM",
        "alignment",
        "tool",
        "analysis",
        "reasoning",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning",
      "url": "https://arxiv.org/abs/2601.20221",
      "description": "arXiv:2601.20221v1 Announce Type: new \nAbstract: Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning tra...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "model",
        "arxiv",
        "augmented",
        "vision",
        "large language model",
        "tool",
        "retrieval",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Endogenous Reprompting: Self-Evolving Cognitive Alignment for Unified Multimodal Models",
      "url": "https://arxiv.org/abs/2601.20305",
      "description": "arXiv:2601.20305v1 Announce Type: new \nAbstract: Unified Multimodal Models (UMMs) exhibit strong understanding, yet this capability often fails to effectively guide generation. We identify this as a Cognitive Gap: the model lacks the understanding of how to enhance its own generation process. To bri...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompting",
        "instruction",
        "framework",
        "model",
        "arxiv",
        "RAG",
        "alignment",
        "experiment",
        "prompt",
        "reasoning",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "ECG-Agent: On-Device Tool-Calling Agent for ECG Multi-Turn Dialogue",
      "url": "https://arxiv.org/abs/2601.20323",
      "description": "arXiv:2601.20323v1 Announce Type: new \nAbstract: Recent advances in Multimodal Large Language Models have rapidly expanded to electrocardiograms, focusing on classification, report generation, and single-turn QA tasks. However, these models fall short in real-world scenarios, lacking multi-turn conv...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "arxiv",
        "LLM",
        "large language model",
        "tool",
        "experiment",
        "API",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "AMA: Adaptive Memory via Multi-Agent Collaboration",
      "url": "https://arxiv.org/abs/2601.20352",
      "description": "arXiv:2601.20352v1 Announce Type: new \nAbstract: The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from si...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "model",
        "research",
        "arxiv",
        "RAG",
        "LLM",
        "large language model",
        "experiment",
        "memory",
        "retrieval",
        "API",
        "context",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Rethinking LLM-Driven Heuristic Design: Generating Efficient and Specialized Solvers via Dynamics-Aware Optimization",
      "url": "https://arxiv.org/abs/2601.20868",
      "description": "arXiv:2601.20868v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have advanced the field of Combinatorial Optimization through automated heuristic generation. Instead of relying on manual design, this LLM-Driven Heuristic Design (LHD) process leverages LLMs to iteratively generate and r...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "model",
        "arxiv",
        "RAG",
        "LLM",
        "library",
        "large language model",
        "experiment",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins",
      "url": "https://arxiv.org/abs/2601.20906",
      "description": "arXiv:2601.20906v1 Announce Type: new \nAbstract: Precision oncology requires forecasting clinical events and trajectories, yet modeling sparse, multi-modal clinical time series remains a critical challenge. We introduce TwinWeaver, an open-source framework that serializes longitudinal patient histor...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "framework",
        "model",
        "arxiv",
        "RAG",
        "LLM",
        "large language model",
        "fine-tuning",
        "zero-shot",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Noisy but Valid: Robust Statistical Evaluation of LLMs with Imperfect Judges",
      "url": "https://arxiv.org/abs/2601.20913",
      "description": "arXiv:2601.20913v1 Announce Type: new \nAbstract: Reliable certification of Large Language Models (LLMs)-verifying that failure rates are below a safety threshold-is critical yet challenging. While \"LLM-as-a-Judge\" offers scalability, judge imperfections, noise, and bias can invalidate statistical gu...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "model",
        "arxiv",
        "RAG",
        "LLM",
        "large language model",
        "tool",
        "experiment",
        "RLHF"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt",
        "context",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "CoT",
        "audio",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "LLM",
        "tool",
        "API",
        "prompt",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "RAG",
        "reasoning",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "framework",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "model",
        "RAG",
        "knowledge base",
        "LLM",
        "retrieval",
        "reasoning",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval",
        "API",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "LLM",
        "platform",
        "prompt",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "EnsembleLink: Accurate Record Linkage Without Training Data",
      "url": "https://arxiv.org/abs/2601.21138",
      "description": "arXiv:2601.21138v1 Announce Type: new \nAbstract: Record linkage, the process of matching records that refer to the same entity across datasets, is essential to empirical social science but remains methodologically underdeveloped. Researchers treat it as a preprocessing step, applying ad hoc rules wi...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "research",
        "arxiv",
        "RAG",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "Finetune-Informed Pretraining Boosts Downstream Performance",
      "url": "https://arxiv.org/abs/2601.20884",
      "description": "arXiv:2601.20884v1 Announce Type: new \nAbstract: Multimodal pretraining is effective for building general-purpose representations, but in many practical deployments, only one modality is heavily used during downstream fine-tuning. Standard pretraining strategies treat all modalities uniformly, which...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "model",
        "arxiv",
        "vision",
        "fine-tuning",
        "multimodal"
      ],
      "score": 0.8
    },
    {
      "title": "A generative machine learning model for designing metal hydrides applied to hydrogen storage",
      "url": "https://arxiv.org/abs/2601.20892",
      "description": "arXiv:2601.20892v1 Announce Type: new \nAbstract: Developing new metal hydrides is a critical step toward efficient hydrogen storage in carbon-neutral energy systems. However, existing materials databases, such as the Materials Project, contain a limited number of well-characterized hydrides, which c...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "model",
        "arxiv",
        "RAG",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "Is Parameter Isolation Better for Prompt-Based Continual Learning?",
      "url": "https://arxiv.org/abs/2601.20894",
      "description": "arXiv:2601.20894v1 Announce Type: new \nAbstract: Prompt-based continual learning methods effectively mitigate catastrophic forgetting. However, most existing methods assign a fixed set of prompts to each task, completely isolating knowledge across tasks and resulting in suboptimal parameter utilizat...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "RAG",
        "analysis",
        "prompt"
      ],
      "score": 0.8
    },
    {
      "title": "Faster Predictive Coding Networks via Better Initialization",
      "url": "https://arxiv.org/abs/2601.20895",
      "description": "arXiv:2601.20895v1 Announce Type: new \nAbstract: Research aimed at scaling up neuroscience inspired learning algorithms for neural networks is accelerating. Recently, a key research area has been the study of energy-based learning algorithms such as predictive coding, due to their versatility and ma...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "experiment",
        "research"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "API",
        "model",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints",
      "url": "https://arxiv.org/abs/2601.20021",
      "description": "arXiv:2601.20021v1 Announce Type: new \nAbstract: Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verif...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "NeuroAI and Beyond",
      "url": "https://arxiv.org/abs/2601.19955",
      "description": "arXiv:2601.19955v1 Announce Type: new \nAbstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two...",
      "published_date": "2026-01-30T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "We Got Claude to Build CUDA Kernels and teach open models!",
      "url": "https://huggingface.co/blog/upskill",
      "description": "...",
      "published_date": "2026-01-28T00:00:00",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model"
      ],
      "score": 0.2
    }
  ]
}