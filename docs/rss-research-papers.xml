<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>DrDiff: Dynamic Routing Diffusion with Hierarchical Attention for Breaking the Efficiency-Quality Trade-off</title>
      <link>https://arxiv.org/abs/2509.02785</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02785</guid>
      <description>arXiv:2509.02785v1 Announce Type: new 
Abstract: This paper introduces DrDiff, a novel framework for long-text generation that overcomes the efficiency-quality trade-off through three core technologies. First, we design a dynamic expert scheduling mechanism that intelligently allocates computational...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, model, experiment, attention, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>model</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Clustering Discourses: Racial Biases in Short Stories about Women Generated by Large Language Models</title>
      <link>https://arxiv.org/abs/2509.02834</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02834</guid>
      <description>arXiv:2509.02834v1 Announce Type: new 
Abstract: This study investigates how large language models, in particular LLaMA 3.2-3B, construct narratives about Black and white women in short stories generated in Portuguese. From 2100 texts, we applied computational methods to group semantically similar s...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, arxiv, model, analysis, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>IDEAlign: Comparing Large Language Models to Human Experts in Open-ended Interpretive Annotations</title>
      <link>https://arxiv.org/abs/2509.02855</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02855</guid>
      <description>arXiv:2509.02855v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly applied to open-ended, interpretive annotation tasks, such as thematic analysis by researchers or generating feedback on student work by teachers. These tasks involve free-text annotations requiring expert...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, arxiv, prompt, instruction, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>arxiv</category>
      <category>prompt</category>
    </item>
    <item>
      <title>Advancing Minority Stress Detection with Transformers: Insights from the Social Media Datasets</title>
      <link>https://arxiv.org/abs/2509.02908</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02908</guid>
      <description>arXiv:2509.02908v1 Announce Type: new 
Abstract: Individuals from sexual and gender minority groups experience disproportionately high rates of poor health outcomes and mental disorders compared to their heterosexual and cisgender counterparts, largely as a consequence of minority stress as describe...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; few-shot, ICL, study, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>few-shot</category>
      <category>ICL</category>
      <category>study</category>
    </item>
    <item>
      <title>English Pronunciation Evaluation without Complex Joint Training: LoRA Fine-tuned Speech Multimodal LLM</title>
      <link>https://arxiv.org/abs/2509.02915</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02915</guid>
      <description>arXiv:2509.02915v1 Announce Type: new 
Abstract: This study demonstrates that a Multimodal Large Language Model (MLLM) adapted via Low-Rank Adaptation (LoRA) can perform both Automatic Pronunciation Assessment (APA) and Mispronunciation Detection and Diagnosis (MDD) simultaneously. Leveraging Micros...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, arxiv, model, research, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>ProMQA-Assembly: Multimodal Procedural QA Dataset on Assembly</title>
      <link>https://arxiv.org/abs/2509.02949</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02949</guid>
      <description>arXiv:2509.02949v1 Announce Type: new 
Abstract: Assistants on assembly tasks have a large potential to benefit humans from everyday tasks to industrial settings. However, no testbeds support application-oriented system evaluation in a practical setting, especially in assembly. To foster the develop...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; ICL, arxiv, instruction, model, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>ICL</category>
      <category>arxiv</category>
      <category>instruction</category>
    </item>
    <item>
      <title>The Future of Artificial Intelligence and the Mathematical and Physical Sciences (AI+MPS)</title>
      <link>https://arxiv.org/abs/2509.02661</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02661</guid>
      <description>arXiv:2509.02661v1 Announce Type: new 
Abstract: This community paper developed out of the NSF Workshop on the Future of Artificial Intelligence (AI) and the Mathematical and Physics Sciences (MPS), which was held in March 2025 with the goal of understanding how the MPS domains (Astronomy, Chemistry...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, research, RAG, paper, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>research</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics</title>
      <link>https://arxiv.org/abs/2509.02751</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02751</guid>
      <description>arXiv:2509.02751v1 Announce Type: new 
Abstract: With advances in large language models (LLMs), researchers are creating new systems that can perform AI-driven analytics over large unstructured datasets. Recent work has explored executing such analytics queries using semantic operators -- a declarat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, model, large language model, tool, vision | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>model</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Do LLM Modules Generalize? A Study on Motion Generation for Autonomous Driving</title>
      <link>https://arxiv.org/abs/2509.02754</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02754</guid>
      <description>arXiv:2509.02754v1 Announce Type: new 
Abstract: Recent breakthroughs in large language models (LLMs) have not only advanced natural language processing but also inspired their application in domains with structurally similar problems--most notably, autonomous driving motion generation. Both domains...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, study, arxiv, model, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>study</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Latent Variable Modeling in Multi-Agent Reinforcement Learning via Expectation-Maximization for UAV-Based Wildlife Protection</title>
      <link>https://arxiv.org/abs/2509.02579</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02579</guid>
      <description>arXiv:2509.02579v1 Announce Type: new 
Abstract: Protecting endangered wildlife from illegal poaching presents a critical challenge, particularly in vast and partially observable environments where real-time response is essential. This paper introduces a novel Expectation-Maximization (EM) based lat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; ICL, arxiv, model, experiment, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>ICL</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Preference Robustness for DPO with Applications to Public Health</title>
      <link>https://arxiv.org/abs/2509.02709</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02709</guid>
      <description>arXiv:2509.02709v1 Announce Type: new 
Abstract: We study an LLM fine-tuning task for designing reward functions for sequential resource allocation problems in public health, guided by human preferences expressed in natural language. This setting presents a challenging testbed for alignment due to c...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, arxiv, experiment, LLM, fine-tuning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>LExI: Layer-Adaptive Active Experts for Efficient MoE Model Inference</title>
      <link>https://arxiv.org/abs/2509.02753</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02753</guid>
      <description>arXiv:2509.02753v1 Announce Type: new 
Abstract: Mixture-of-Experts (MoE) models scale efficiently by activating only a subset of experts per token, offering a computationally sparse alternative to dense architectures. While prior post-training optimizations, such as inter- and intra-expert pruning,...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; memory, arxiv, model, experiment, example | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>memory</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Can Media Act as a Soft Regulator of Safe AI Development? A Game Theoretical Analysis</title>
      <link>https://arxiv.org/abs/2509.02650</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02650</guid>
      <description>arXiv:2509.02650v1 Announce Type: new 
Abstract: When developers of artificial intelligence (AI) products need to decide between profit and safety for the users, they likely choose profit. Untrustworthy AI technology must come packaged with tangible negative consequences. Here, we envisage those con...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, analysis, product, RAG, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>analysis</category>
      <category>product</category>
    </item>
    <item>
      <title>Accountability Framework for Healthcare AI Systems: Towards Joint Accountability in Decision Making</title>
      <link>https://arxiv.org/abs/2509.03286</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.03286</guid>
      <description>arXiv:2509.03286v1 Announce Type: new 
Abstract: AI is transforming the healthcare domain and is increasingly helping practitioners to make health-related decisions. Therefore, accountability becomes a crucial concern for critical AI-driven decisions. Although regulatory bodies, such as the EU commi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, arxiv, analysis, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>arxiv</category>
      <category>analysis</category>
    </item>
    <item>
      <title>The Lifecycle Principle: Stabilizing Dynamic Neural Networks with State Memory</title>
      <link>https://arxiv.org/abs/2509.02575</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02575</guid>
      <description>arXiv:2509.02575v1 Announce Type: new 
Abstract: I investigate a stronger form of regularization by deactivating neurons for extended periods, a departure from the temporary changes of methods like Dropout. However, this long-term dynamism introduces a critical challenge: severe training instability...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; memory, arxiv, image, analysis, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>memory</category>
      <category>arxiv</category>
      <category>image</category>
    </item>
    <item>
      <title>Structured Basis Function Networks: Loss-Centric Multi-Hypothesis Ensembles with Controllable Diversity</title>
      <link>https://arxiv.org/abs/2509.02792</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02792</guid>
      <description>arXiv:2509.02792v1 Announce Type: new 
Abstract: Existing approaches to predictive uncertainty rely either on multi-hypothesis prediction, which promotes diversity but lacks principled aggregation, or on ensemble learning, which improves accuracy but rarely captures the structured ambiguity. This im...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, arxiv, study, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>arxiv</category>
      <category>study</category>
    </item>
    <item>
      <title>Decoding the Rule Book: Extracting Hidden Moderation Criteria from Reddit Communities</title>
      <link>https://arxiv.org/abs/2509.02926</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02926</guid>
      <description>arXiv:2509.02926v1 Announce Type: new 
Abstract: Effective content moderation systems require explicit classification criteria, yet online communities like subreddits often operate with diverse, implicit standards. This work introduces a novel approach to identify and extract these implicit criteria...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Key Principles in Cross-Domain Hyper-Heuristic Performance</title>
      <link>https://arxiv.org/abs/2509.02782</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02782</guid>
      <description>arXiv:2509.02782v1 Announce Type: new 
Abstract: Cross-domain selection hyper-heuristics aim to distill decades of research on problem-specific heuristic search algorithms into adaptable general-purpose search strategies. In this respect, existing selection hyper-heuristics primarily focus on an ada...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; company, research, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>company</category>
      <category>research</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Uncertainty-driven Adaptive Exploration</title>
      <link>https://arxiv.org/abs/2509.03219</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.03219</guid>
      <description>arXiv:2509.03219v1 Announce Type: new 
Abstract: Adaptive exploration methods propose ways to learn complex policies via alternating between exploration and exploitation. An important question for such methods is to determine the appropriate moment to switch between exploration and exploitation and ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Beyond Synthetic Augmentation: Group-Aware Threshold Calibration for Robust Balanced Accuracy in Imbalanced Learning</title>
      <link>https://arxiv.org/abs/2509.02592</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.02592</guid>
      <description>arXiv:2509.02592v1 Announce Type: new 
Abstract: Class imbalance remains a fundamental challenge in machine learning, with traditional solutions often creating as many problems as they solve. We demonstrate that group-aware threshold calibration--setting different decision thresholds for different d...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, model, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>augmented</category>
      <category>model</category>
      <category>arxiv</category>
    </item>
  </channel>
</rss>