{
  "generated_at": "2026-02-10T20:16:19.980547",
  "total_items": 49,
  "items": [
    {
      "title": "Does Visual Rendering Bypass Tokenization? Investigating Script-Tokenizer Misalignment in Pixel-Based Language Models",
      "url": "https://arxiv.org/abs/2602.06973",
      "description": "arXiv:2602.06973v1 Announce Type: new \nAbstract: While pixel-based language modeling aims to bypass the sub-word tokenization bottleneck by rendering text as images, recent multimodal variants such as DualGPT reintroduce text tokenizers to improve autoregressive performance. We investigate a fundame...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "multimodal",
        "GPT",
        "image",
        "model",
        "arxiv",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "BiomechAgent: AI-Assisted Biomechanical Analysis Through Code-Generating Agents",
      "url": "https://arxiv.org/abs/2602.06975",
      "description": "arXiv:2602.06975v1 Announce Type: new \nAbstract: Markerless motion capture is making quantitative movement analysis increasingly accessible, yet analyzing the resulting data remains a barrier for clinicians without programming expertise. We present BiomechAgent, a code-generating AI agent that enabl...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "retrieval",
        "model",
        "reasoning",
        "analysis",
        "prompt",
        "arxiv",
        "LLM",
        "tool",
        "instruction"
      ],
      "score": 1.0
    },
    {
      "title": "Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks",
      "url": "https://arxiv.org/abs/2602.06976",
      "description": "arXiv:2602.06976v1 Announce Type: new \nAbstract: The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive fi...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "paper",
        "augmented",
        "retrieval",
        "model",
        "analysis",
        "framework",
        "arxiv",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Free Energy Mixer",
      "url": "https://arxiv.org/abs/2602.07160",
      "description": "arXiv:2602.07160v1 Announce Type: new \nAbstract: Standard attention stores keys/values losslessly but reads them via a per-head convex average, blocking channel-wise selection. We propose the Free Energy Mixer (FEM): a free-energy (log-sum-exp) read that applies a value-driven, per-channel log-linea...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "vision",
        "arxiv",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "Your Language Model Secretly Contains Personality Subnetworks",
      "url": "https://arxiv.org/abs/2602.07164",
      "description": "arXiv:2602.07164v1 Announce Type: new \nAbstract: Humans shift between different personas depending on social context. Large Language Models (LLMs) demonstrate a similar flexibility in adopting different personas and behaviors. Existing approaches, however, typically adapt such behavior through exter...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "retrieval",
        "prompting",
        "augmented",
        "fine-tuning",
        "model",
        "prompt",
        "arxiv",
        "alignment",
        "context",
        "LLM",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI",
      "url": "https://arxiv.org/abs/2602.07176",
      "description": "arXiv:2602.07176v1 Announce Type: new \nAbstract: Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, a...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "multimodal",
        "paper",
        "platform",
        "framework",
        "arxiv",
        "context",
        "tool",
        "instruction",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Can LLMs Discern the Traits Influencing Your Preferences? Evaluating Personality-Driven Preference Alignment in LLMs",
      "url": "https://arxiv.org/abs/2602.07181",
      "description": "arXiv:2602.07181v1 Announce Type: new \nAbstract: User preferences are increasingly used to personalize Large Language Model (LLM) responses, yet how to reliably leverage preference signals for answer generation remains under-explored. In practice, preferences can be noisy, incomplete, or even mislea...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "model",
        "experiment",
        "framework",
        "alignment",
        "arxiv",
        "LLM",
        "study",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Long-Context Long-Form Question Answering for Legal Domain",
      "url": "https://arxiv.org/abs/2602.07190",
      "description": "arXiv:2602.07190v1 Announce Type: new \nAbstract: Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent c...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "retrieval",
        "experiment",
        "arxiv",
        "context",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Equipping LLM with Directional Multi-Talker Speech Understanding Capabilities",
      "url": "https://arxiv.org/abs/2602.07211",
      "description": "arXiv:2602.07211v1 Announce Type: new \nAbstract: Recent studies have demonstrated that prompting large language models (LLM) with audio encodings enables effective speech understanding capabilities. However, most speech LLMs are trained on single-channel, single-talker data, which makes it challengi...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "prompting",
        "model",
        "audio",
        "prompt",
        "experiment",
        "arxiv",
        "LLM",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation",
      "url": "https://arxiv.org/abs/2602.07032",
      "description": "arXiv:2602.07032v1 Announce Type: new \nAbstract: Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machi...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "paper",
        "example",
        "fine-tuning",
        "model",
        "reasoning",
        "prompt",
        "experiment",
        "arxiv",
        "context",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "ST-Raptor: An Agentic System for Semi-Structured Table QA",
      "url": "https://arxiv.org/abs/2602.07034",
      "description": "arXiv:2602.07034v1 Announce Type: new \nAbstract: Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "multimodal",
        "demonstration",
        "model",
        "analysis",
        "experiment",
        "arxiv",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
      "url": "https://arxiv.org/abs/2602.07035",
      "description": "arXiv:2602.07035v1 Announce Type: new \nAbstract: Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, thei...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "large language model",
        "paper",
        "API",
        "fine-tuning",
        "model",
        "reasoning",
        "experiment",
        "framework",
        "arxiv",
        "LLM",
        "tool",
        "instruction",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
      "url": "https://arxiv.org/abs/2602.07153",
      "description": "arXiv:2602.07153v1 Announce Type: new \nAbstract: End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drift...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "demonstration",
        "model",
        "experiment",
        "framework",
        "vision",
        "arxiv",
        "context",
        "instruction",
        "zero-shot"
      ],
      "score": 1.0
    },
    {
      "title": "Is there \"Secret Sauce'' in Large Language Model Development?",
      "url": "https://arxiv.org/abs/2602.07238",
      "description": "arXiv:2602.07238v1 Announce Type: new \nAbstract: Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-dat...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "large language model",
        "model",
        "arxiv",
        "release",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Attractor Patch Networks: Reducing Catastrophic Forgetting with Routed Low-Rank Patch Experts",
      "url": "https://arxiv.org/abs/2602.06993",
      "description": "arXiv:2602.06993v1 Announce Type: new \nAbstract: Transformers achieve strong language modeling accuracy, yet their position-wise feed-forward networks (FFNs) are dense, globally shared, and typically updated end to end. These properties create two practical tensions. First, dense FFNs spend the same...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "fine-tuning",
        "model",
        "experiment",
        "transformer",
        "arxiv",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Neural Sabermetrics with World Model: Play-by-play Predictive Modeling with Large Language Model",
      "url": "https://arxiv.org/abs/2602.07030",
      "description": "arXiv:2602.07030v1 Announce Type: new \nAbstract: Classical sabermetrics has profoundly shaped baseball analytics by summarizing long histories of play into compact statistics. While these metrics are invaluable for valuation and retrospective analysis, they do not define a generative model of how ba...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "model",
        "analysis",
        "arxiv",
        "framework",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "TransConv-DDPM: Enhanced Diffusion Model for Generating Time-Series Data in Healthcare",
      "url": "https://arxiv.org/abs/2602.07033",
      "description": "arXiv:2602.07033v1 Announce Type: new \nAbstract: The lack of real-world data in clinical fields poses a major obstacle in training effective AI models for diagnostic and preventive tools in medicine. Generative AI has shown promise in increasing data volume and enhancing model training, particularly...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "model",
        "transformer",
        "arxiv",
        "vision",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization",
      "url": "https://arxiv.org/abs/2602.07054",
      "description": "arXiv:2602.07054v1 Announce Type: new \nAbstract: Emotion understanding is essential for building socially intelligent agents. Although recent multimodal large language models have shown strong performance on this task, two key challenges remain - spurious associations between emotions and irrelevant...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "multimodal",
        "release",
        "large language model",
        "ICL",
        "model",
        "reasoning",
        "audio",
        "prompt",
        "experiment",
        "framework",
        "arxiv",
        "LLM",
        "zero-shot"
      ],
      "score": 1.0
    },
    {
      "title": "Video-based Music Generation",
      "url": "https://arxiv.org/abs/2602.07063",
      "description": "arXiv:2602.07063v1 Announce Type: new \nAbstract: As the volume of video content on the internet grows rapidly, finding a suitable soundtrack remains a significant challenge. This thesis presents EMSYNC (EMotion and SYNChronization), a fast, free, and automatic solution that generates music tailored ...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "product",
        "model",
        "arxiv",
        "alignment",
        "API",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Hybrid Dual-Path Linear Transformations for Efficient Transformer Architectures",
      "url": "https://arxiv.org/abs/2602.07070",
      "description": "arXiv:2602.07070v1 Announce Type: new \nAbstract: Standard Transformer architectures rely heavily on dense linear transformations, treating feature projection as a monolithic, full-rank operation. We argue that this formulation is inefficient and lacks the structural inductive bias necessary for dist...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "cross-modal",
        "experiment",
        "transformer",
        "arxiv",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "The Optimal Token Baseline: Variance Reduction for Long-Horizon LLM-RL",
      "url": "https://arxiv.org/abs/2602.07078",
      "description": "arXiv:2602.07078v1 Announce Type: new \nAbstract: Reinforcement Learning (RL) for Large Language Models (LLMs) often suffers from training collapse in long-horizon tasks due to exploding gradient variance. To mitigate this, a baseline is commonly introduced for advantage computation; however, traditi...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "large language model",
        "model",
        "reasoning",
        "arxiv",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Attention-Driven Framework for Non-Rigid Medical Image Registration",
      "url": "https://arxiv.org/abs/2602.07088",
      "description": "arXiv:2602.07088v1 Announce Type: new \nAbstract: Deformable medical image registration is a fundamental task in medical image analysis with applications in disease diagnosis, treatment planning, and image-guided interventions. Despite significant advances in deep learning based registration methods,...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "image",
        "analysis",
        "experiment",
        "framework",
        "alignment",
        "arxiv",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "context window",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "audio",
        "framework",
        "CoT",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "prompt",
        "context",
        "tool",
        "API",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "vector",
        "RAG",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "knowledge base",
        "retrieval",
        "model",
        "reasoning",
        "vector",
        "framework",
        "LLM",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "product",
        "augmented",
        "retrieval",
        "API",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "prompt",
        "vector",
        "framework",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model",
      "url": "https://arxiv.org/abs/2602.07120",
      "description": "arXiv:2602.07120v1 Announce Type: new \nAbstract: Modern language models (LMs) tend to memorize portions of their training data and emit verbatim spans. When the underlying sources are sensitive or copyright-protected, such reproduction raises issues of consent and compensation for creators and compl...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "product",
        "model",
        "framework",
        "arxiv",
        "RAG"
      ],
      "score": 0.8
    },
    {
      "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
      "url": "https://arxiv.org/abs/2602.07040",
      "description": "arXiv:2602.07040v1 Announce Type: new \nAbstract: We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improv...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "GPT",
        "model",
        "analysis",
        "framework",
        "arxiv",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "TACIT: Transformation-Aware Capturing of Implicit Thought",
      "url": "https://arxiv.org/abs/2602.07061",
      "description": "arXiv:2602.07061v1 Announce Type: new \nAbstract: We present TACIT (Transformation-Aware Capturing of Implicit Thought), a diffusion-based transformer for interpretable visual reasoning. Unlike language-based reasoning systems, TACIT operates entirely in pixel space using rectified flow, enabling dir...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "image",
        "model",
        "reasoning",
        "analysis",
        "transformer",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "model",
        "API",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents",
      "url": "https://arxiv.org/abs/2602.07187",
      "description": "arXiv:2602.07187v1 Announce Type: new \nAbstract: Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe ...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "model",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View",
      "url": "https://arxiv.org/abs/2602.07253",
      "description": "arXiv:2602.07253v1 Announce Type: new \nAbstract: Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain l...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "large language model",
        "model",
        "reasoning",
        "arxiv",
        "vision"
      ],
      "score": 0.6
    },
    {
      "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective",
      "url": "https://arxiv.org/abs/2602.07259",
      "description": "arXiv:2602.07259v1 Announce Type: new \nAbstract: As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety fra...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "framework",
        "alignment",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Lagged backward-compatible physics-informed neural networks for unsaturated soil consolidation analysis",
      "url": "https://arxiv.org/abs/2602.07031",
      "description": "arXiv:2602.07031v1 Announce Type: new \nAbstract: This study develops a Lagged Backward-Compatible Physics-Informed Neural Network (LBC-PINN) for simulating and inverting one-dimensional unsaturated soil consolidation under long-term loading. To address the challenges of coupled air and water pressur...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "analysis",
        "framework",
        "arxiv",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
      "url": "https://arxiv.org/abs/2602.07055",
      "description": "arXiv:2602.07055v1 Announce Type: new \nAbstract: Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We prop...",
      "published_date": "2026-02-10T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "multimodal",
        "model",
        "prompt",
        "arxiv",
        "vision"
      ],
      "score": 0.4
    },
    {
      "title": "Transformers.js v4 Preview: Now Available on NPM!",
      "url": "https://huggingface.co/blog/transformersjs-v4",
      "description": "...",
      "published_date": "2026-02-09T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "transformer"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}