<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Comparative Analysis of LoRA-Adapted Embedding Models for Clinical Cardiology Text Representation</title>
      <link>https://arxiv.org/abs/2511.19739</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.19739</guid>
      <description>arXiv:2511.19739v1 Announce Type: new 
Abstract: Domain-specific text embeddings are critical for clinical natural language processing, yet systematic comparisons across model architectures remain limited. This study evaluates ten transformer-based embedding models adapted for cardiology through Low...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, study, fine-tuning, arxiv, embedding | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>study</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>Breaking Bad: Norms for Valence, Arousal, and Dominance for over 10k English Multiword Expressions</title>
      <link>https://arxiv.org/abs/2511.19816</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.19816</guid>
      <description>arXiv:2511.19816v1 Announce Type: new 
Abstract: Factor analysis studies have shown that the primary dimensions of word meaning are Valence (V), Arousal (A), and Dominance (D). Existing lexicons such as the NRC VAD Lexicon, published in 2018, include VAD association ratings for words. Here, we prese...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, RAG, arxiv, ICL, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>RAG</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Language-Independent Sentiment Labelling with Distant Supervision: A Case Study for English, Sepedi and Setswana</title>
      <link>https://arxiv.org/abs/2511.19818</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.19818</guid>
      <description>arXiv:2511.19818v1 Announce Type: new 
Abstract: Sentiment analysis is a helpful task to automatically analyse opinions and emotions on various topics in areas such as AI for Social Good, AI in Education or marketing. While many of the sentiment analysis systems are developed for English, many Afric...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, study, RAG, arxiv, vision | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>study</category>
      <category>RAG</category>
    </item>
    <item>
      <title>AppSelectBench: Application-Level Tool Selection Benchmark</title>
      <link>https://arxiv.org/abs/2511.19957</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.19957</guid>
      <description>arXiv:2511.19957v1 Announce Type: new 
Abstract: Computer Using Agents (CUAs) are increasingly equipped with external tools, enabling them to perform complex and realistic tasks. For CUAs to operate effectively, application selection, which refers to deciding which application to use before invoking...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, zero-shot, study, reasoning, few-shot | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>zero-shot</category>
      <category>study</category>
    </item>
    <item>
      <title>Hybrid Neuro-Symbolic Models for Ethical AI in Risk-Sensitive Domains</title>
      <link>https://arxiv.org/abs/2511.17644</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.17644</guid>
      <description>arXiv:2511.17644v1 Announce Type: new 
Abstract: Artificial intelligence deployed in risk-sensitive domains such as healthcare, finance, and security must not only achieve predictive accuracy but also ensure transparency, ethical alignment, and compliance with regulatory expectations. Hybrid neuro s...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, framework, arxiv, embedding, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>framework</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>QuickLAP: Quick Language-Action Preference Learning for Autonomous Driving Agents</title>
      <link>https://arxiv.org/abs/2511.17855</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.17855</guid>
      <description>arXiv:2511.17855v1 Announce Type: new 
Abstract: Robots must learn from both what people do and what they say, but either modality alone is often incomplete: physical corrections are grounded but ambiguous in intent, while language expresses high-level goals but lacks physical grounding. We introduc...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, study, attention, large language model, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>study</category>
      <category>attention</category>
    </item>
    <item>
      <title>Hidden markov model to predict tourists visited place</title>
      <link>https://arxiv.org/abs/2511.19465</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.19465</guid>
      <description>arXiv:2511.19465v1 Announce Type: new 
Abstract: Nowadays, social networks are becoming a popular way of analyzing tourist behavior, thanks to the digital traces left by travelers during their stays on these networks. The massive amount of data generated; by the propensity of tourists to share comme...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, arxiv, context, model, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>arxiv</category>
      <category>context</category>
    </item>
    <item>
      <title>Quantifying Modality Contributions via Disentangling Multimodal Representations</title>
      <link>https://arxiv.org/abs/2511.19470</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.19470</guid>
      <description>arXiv:2511.19470v1 Announce Type: new 
Abstract: Quantifying modality contributions in multimodal models remains a challenge, as existing approaches conflate the notion of contribution itself. Prior work relies on accuracy-based approaches, interpreting performance drops after removing a modality as...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, attention, framework, arxiv, embedding | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>attention</category>
      <category>framework</category>
    </item>
    <item>
      <title>Exploiting the Experts: Unauthorized Compression in MoE-LLMs</title>
      <link>https://arxiv.org/abs/2511.19480</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.19480</guid>
      <description>arXiv:2511.19480v1 Announce Type: new 
Abstract: Mixture-of-Experts (MoE) architectures are increasingly adopted in large language models (LLMs) for their scalability and efficiency. However, their modular structure introduces a unique vulnerability: adversaries can attempt to compress or repurpose ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, LLM, study, fine-tuning, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>LLM</category>
      <category>study</category>
    </item>
    <item>
      <title>Quality analysis and evaluation prediction of RAG retrieval based on machine learning algorithms</title>
      <link>https://arxiv.org/abs/2511.19481</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.19481</guid>
      <description>arXiv:2511.19481v1 Announce Type: new 
Abstract: With the rapid evolution of large language models, retrieval enhanced generation technology has been widely used due to its ability to integrate external knowledge to improve output accuracy. However, the performance of the system is highly dependent ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, RAG, large language model, retrieval, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>RAG</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Efficient Inference Using Large Language Models with Limited Human Data: Fine-Tuning then Rectification</title>
      <link>https://arxiv.org/abs/2511.19486</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.19486</guid>
      <description>arXiv:2511.19486v1 Announce Type: new 
Abstract: Driven by recent advances in artificial intelligence (AI), a growing body of work demonstrates the potential of using large language models (LLMs) to generate human-like responses in market research and social science applications. Two primary approac...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, LLM, RAG, fine-tuning, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>LLM</category>
      <category>RAG</category>
    </item>
    <item>
      <title>The Generalized Proximity Forest</title>
      <link>https://arxiv.org/abs/2511.19487</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.19487</guid>
      <description>arXiv:2511.19487v1 Announce Type: new 
Abstract: Recent work has demonstrated the utility of Random Forest (RF) proximities for various supervised machine learning tasks, including outlier detection, missing data imputation, and visualization. However, the utility of the RF proximities depends upon ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, framework, arxiv, context, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>framework</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Fluid Grey 2: How Well Does Generative Adversarial Network Learn Deeper Topology Structure in Architecture That Matches Images?</title>
      <link>https://arxiv.org/abs/2511.17643</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.17643</guid>
      <description>arXiv:2511.17643v1 Announce Type: new 
Abstract: Taking into account the regional characteristics of intrinsic and extrinsic properties of space is an essential issue in architectural design and urban renewal, which is often achieved step by step using image and graph-based GANs. However, each model...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, arxiv, image, model, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>arxiv</category>
      <category>image</category>
    </item>
    <item>
      <title>Leibniz&amp;#x27;s Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation</title>
      <link>https://arxiv.org/abs/2511.17541</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.17541</guid>
      <description>arXiv:2511.17541v1 Announce Type: new 
Abstract: This paper develops a mathematically rigorous, philosophically grounded framework for evaluating artificial memory systems, rooted in the metaphysical structure of Leibniz&amp;#x27;s Monadology. Building on a previously formalized metric, the Artificial Age Sc...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, framework, memory, arxiv, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 26 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>framework</category>
      <category>memory</category>
    </item>
  </channel>
</rss>