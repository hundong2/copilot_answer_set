{
  "generated_at": "2025-09-08T20:05:36.733931",
  "total_items": 47,
  "items": [
    {
      "title": "INSEva: A Comprehensive Chinese Benchmark for Large Language Models in Insurance",
      "url": "https://arxiv.org/abs/2509.04455",
      "description": "arXiv:2509.04455v1 Announce Type: new \nAbstract: Insurance, as a critical component of the global financial system, demands high standards of accuracy and reliability in AI applications. While existing benchmarks evaluate AI capabilities across various domains, they often fail to capture the unique ...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "arxiv",
        "RAG",
        "model",
        "example",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Mentalic Net: Development of RAG-based Conversational AI and Evaluation Framework for Mental Health Support",
      "url": "https://arxiv.org/abs/2509.04456",
      "description": "arXiv:2509.04456v1 Announce Type: new \nAbstract: The emergence of large language models (LLMs) has unlocked boundless possibilities, along with significant challenges. In response, we developed a mental health support chatbot designed to augment professional healthcare, with a strong emphasis on saf...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "arxiv",
        "framework",
        "prompt engineering",
        "RAG",
        "model",
        "large language model",
        "LLM",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Do MLLMs Really Understand the Charts?",
      "url": "https://arxiv.org/abs/2509.04457",
      "description": "arXiv:2509.04457v1 Announce Type: new \nAbstract: Although Multimodal Large Language Models (MLLMs) have demonstrated increasingly impressive performance in chart understanding, most of them exhibit alarming hallucinations and significant performance degradation when handling non-annotated charts. Th...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "arxiv",
        "reasoning",
        "model",
        "ICL",
        "GPT",
        "large language model",
        "LLM",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Predicting Failures of LLMs to Link Biomedical Ontology Terms to Identifiers Evidence Across Models and Ontologies",
      "url": "https://arxiv.org/abs/2509.04458",
      "description": "arXiv:2509.04458v1 Announce Type: new \nAbstract: Large language models often perform well on biomedical NLP tasks but may fail to link ontology terms to their correct identifiers. We investigate why these failures occur by analyzing predictions across two major ontologies, Human Phenotype Ontology a...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "GPT",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis",
      "url": "https://arxiv.org/abs/2509.04459",
      "description": "arXiv:2509.04459v1 Announce Type: new \nAbstract: The advent of Multimodal Large Language Models (MLLMs) has significantly advanced the state-of-the-art in multimodal machine learning, yet their substantial computational demands present a critical barrier to real-world deployment. Conversely, smaller...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "API",
        "experiment",
        "RAG",
        "model",
        "large language model",
        "LLM",
        "prompt",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "CoCoNUTS: Concentrating on Content while Neglecting Uninformative Textual Styles for AI-Generated Peer Review Detection",
      "url": "https://arxiv.org/abs/2509.04460",
      "description": "arXiv:2509.04460v1 Announce Type: new \nAbstract: The growing integration of large language models (LLMs) into the peer review process presents potential risks to the fairness and reliability of scholarly evaluation. While LLMs offer valuable assistance for reviewers with language refinement, there i...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "arxiv",
        "framework",
        "model",
        "ICL",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media",
      "url": "https://arxiv.org/abs/2509.04461",
      "description": "arXiv:2509.04461v1 Announce Type: new \nAbstract: Personality prediction from social media posts is a critical task that implies diverse applications in psychology and sociology. The Myers Briggs Type Indicator (MBTI), a popular personality inventory, has been traditionally predicted by machine learn...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "arxiv",
        "paper",
        "context",
        "experiment",
        "framework",
        "RAG",
        "model",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Benchmarking GPT-5 for biomedical natural language processing",
      "url": "https://arxiv.org/abs/2509.04462",
      "description": "arXiv:2509.04462v1 Announce Type: new \nAbstract: The rapid expansion of biomedical literature has heightened the need for scalable natural language processing (NLP) solutions. While GPT-4 substantially narrowed the gap with task-specific systems, especially in question answering, its performance acr...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "retrieval",
        "augmented",
        "arxiv",
        "prompting",
        "API",
        "reasoning",
        "RAG",
        "summarization",
        "GPT",
        "model",
        "template",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Can Multiple Responses from an LLM Reveal the Sources of Its Uncertainty?",
      "url": "https://arxiv.org/abs/2509.04464",
      "description": "arXiv:2509.04464v1 Announce Type: new \nAbstract: Large language models (LLMs) have delivered significant breakthroughs across diverse domains but can still produce unreliable or misleading outputs, posing critical challenges for real-world applications. While many recent studies focus on quantifying...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "experiment",
        "framework",
        "model",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management",
      "url": "https://arxiv.org/abs/2509.04505",
      "description": "arXiv:2509.04505v1 Announce Type: new \nAbstract: The integration of Artificial Intelligence (AI) into construction project management (CPM) is accelerating, with Large Language Models (LLMs) emerging as accessible decision-support tools. This study aims to critically evaluate the ethical viability a...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "study",
        "research",
        "context",
        "reasoning",
        "framework",
        "model",
        "large language model",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents",
      "url": "https://arxiv.org/abs/2509.04642",
      "description": "arXiv:2509.04642v1 Announce Type: new \nAbstract: Building reliable LLM agents requires decisions at two levels: the graph (which modules exist and how information flows) and the configuration of each node (models, prompts, tools, control knobs). Most existing optimizers tune configurations while hol...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "framework",
        "RAG",
        "model",
        "LLM",
        "prompt",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization",
      "url": "https://arxiv.org/abs/2509.04646",
      "description": "arXiv:2509.04646v1 Announce Type: new \nAbstract: Modeling & Simulation (M&amp;S) approaches such as agent-based models hold significant potential to support decision-making activities in health, with recent examples including the adoption of vaccines, and a vast literature on healthy eating behavior...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "arxiv",
        "step-by-step",
        "framework",
        "model",
        "summarization",
        "example",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "An Approach to Grounding AI Model Evaluations in Human-derived Criteria",
      "url": "https://arxiv.org/abs/2509.04676",
      "description": "arXiv:2509.04676v1 Announce Type: new \nAbstract: In the rapidly evolving field of artificial intelligence (AI), traditional benchmarks can fall short in attempting to capture the nuanced capabilities of AI models. We focus on the case of physical world modeling and propose a novel approach to augmen...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "research",
        "context",
        "API",
        "reasoning",
        "framework",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning",
      "url": "https://arxiv.org/abs/2509.04731",
      "description": "arXiv:2509.04731v1 Announce Type: new \nAbstract: The convergence of Language models, Agent models, and World models represents a critical frontier for artificial intelligence. While recent progress has focused on scaling Language and Agent models, the development of sophisticated, explicit World Mod...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "research",
        "framework",
        "RAG",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking",
      "url": "https://arxiv.org/abs/2509.04791",
      "description": "arXiv:2509.04791v1 Announce Type: new \nAbstract: Large language models (LLMs) excel at processing information reactively but lack the ability to systemically explore hypothetical futures. They cannot ask, \"what if we take this action? how will it affect the final outcome\" and forecast its potential ...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "API",
        "experiment",
        "framework",
        "reasoning",
        "RAG",
        "model",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models",
      "url": "https://arxiv.org/abs/2509.04809",
      "description": "arXiv:2509.04809v1 Announce Type: new \nAbstract: Explainable Reinforcement Learning (XRL) has emerged as a promising approach in improving the transparency of Reinforcement Learning (RL) agents. However, there remains a gap between complex RL policies and domain experts, due to the limited comprehen...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "context",
        "framework",
        "RAG",
        "model",
        "large language model",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory",
      "url": "https://arxiv.org/abs/2509.04847",
      "description": "arXiv:2509.04847v1 Announce Type: new \nAbstract: Language models are increasingly deployed in interactive online environments, from personal chat assistants to domain-specific agents, raising questions about their cooperative and competitive behavior in multi-party settings. While prior work has exa...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "paper",
        "study",
        "research",
        "context",
        "API",
        "experiment",
        "framework",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Cloning a Conversational Voice AI Agent from Call\\,Recording Datasets for Telesales",
      "url": "https://arxiv.org/abs/2509.04871",
      "description": "arXiv:2509.04871v1 Announce Type: new \nAbstract: Recent advances in language and speech modelling have made it possible to build autonomous voice assistants that understand and generate human dialogue in real time. These systems are increasingly being deployed in domains such as customer service and...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "study",
        "research",
        "product",
        "prompt engineering",
        "model",
        "large language model",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration",
      "url": "https://arxiv.org/abs/2509.04876",
      "description": "arXiv:2509.04876v1 Announce Type: new \nAbstract: This paper introduces OSC (Orchestrating Cognitive Synergy), a knowledge-aware adaptive collaboration framework designed to enhance cognitive synergy in multi-agent systems with large language models. While prior work has advanced agent selection and ...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "paper",
        "experiment",
        "framework",
        "reasoning",
        "model",
        "large language model",
        "LLM",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Q-SafeML: Safety Assessment of Quantum Machine Learning via Quantum Distance Metrics",
      "url": "https://arxiv.org/abs/2509.04536",
      "description": "arXiv:2509.04536v1 Announce Type: new \nAbstract: The rise of machine learning in safety-critical systems has paralleled advancements in quantum computing, leading to the emerging field of Quantum Machine Learning (QML). While safety monitoring has progressed in classical ML, existing methods are not...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "context",
        "experiment",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Bootstrapping Task Spaces for Self-Improvement",
      "url": "https://arxiv.org/abs/2509.04575",
      "description": "arXiv:2509.04575v1 Announce Type: new \nAbstract: Progress in many task domains emerges from repeated revisions to previous solution attempts. Training agents that can reliably self-improve over such sequences at inference-time is a natural target for reinforcement learning (RL), yet the naive approa...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "vision",
        "RAG",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Measuring the Measures: Discriminative Capacity of Representational Similarity Metrics Across Model Families",
      "url": "https://arxiv.org/abs/2509.04622",
      "description": "arXiv:2509.04622v1 Announce Type: new \nAbstract: Representational similarity metrics are fundamental tools in neuroscience and AI, yet we lack systematic comparisons of their discriminative power across model families. We introduce a quantitative framework to evaluate representational similarity mea...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "transformer",
        "arxiv",
        "alignment",
        "vision",
        "framework",
        "model",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt",
        "context window",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "framework",
        "reasoning",
        "chain-of-thought",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "model",
        "LLM",
        "prompt",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "context",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "vector",
        "knowledge base",
        "reasoning",
        "framework",
        "RAG",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "fine-tuning",
        "LLM",
        "tool",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "product",
        "API",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "platform",
        "framework",
        "LLM",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "framework",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Emotionally-Aware Agents for Dispute Resolution",
      "url": "https://arxiv.org/abs/2509.04465",
      "description": "arXiv:2509.04465v1 Announce Type: new \nAbstract: In conflict, people use emotional expressions to shape their counterparts' thoughts, feelings, and actions. This paper explores whether automatic text emotion recognition offers insight into this influence in the context of dispute resolution. Prior w...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "context",
        "arxiv",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "i-Mask: An Intelligent Mask for Breath-Driven Activity Recognition",
      "url": "https://arxiv.org/abs/2509.04544",
      "description": "arXiv:2509.04544v1 Announce Type: new \nAbstract: The patterns of inhalation and exhalation contain important physiological signals that can be used to anticipate human behavior, health trends, and vital parameters. Human activity recognition (HAR) is fundamentally connected to these vital signs, pro...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "RAG",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "Toward Faithfulness-guided Ensemble Interpretation of Neural Network",
      "url": "https://arxiv.org/abs/2509.04588",
      "description": "arXiv:2509.04588v1 Announce Type: new \nAbstract: Interpretable and faithful explanations for specific neural inferences are crucial for understanding and evaluating model behavior. Our work introduces \\textbf{F}aithfulness-guided \\textbf{E}nsemble \\textbf{I}nterpretation (\\textbf{FEI}), an innovativ...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "research",
        "experiment",
        "framework",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "context",
        "tool",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Split Conformal Prediction in the Function Space with Neural Operators",
      "url": "https://arxiv.org/abs/2509.04623",
      "description": "arXiv:2509.04623v1 Announce Type: new \nAbstract: Uncertainty quantification for neural operators remains an open problem in the infinite-dimensional setting due to the lack of finite-sample coverage guarantees over functional outputs. While conformal prediction offers finite-sample guarantees in fin...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "RAG"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Finance-Grounded Optimization For Algorithmic Trading",
      "url": "https://arxiv.org/abs/2509.04541",
      "description": "arXiv:2509.04541v1 Announce Type: new \nAbstract: Deep Learning is evolving fast and integrates into various domains. Finance is a challenging field for deep learning, especially in the case of interpretable artificial intelligence (AI). Although classical approaches perform very well with natural la...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "vision",
        "study"
      ],
      "score": 0.4
    },
    {
      "title": "Instance-Wise Adaptive Sampling for Dataset Construction in Approximating Inverse Problem Solutions",
      "url": "https://arxiv.org/abs/2509.04583",
      "description": "arXiv:2509.04583v1 Announce Type: new \nAbstract: We propose an instance-wise adaptive sampling framework for constructing compact and informative training datasets for supervised learning of inverse problem solutions. Typical learning-based approaches aim to learn a general-purpose inverse map from ...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Quantum-Enhanced Multi-Task Learning with Learnable Weighting for Pharmacokinetic and Toxicity Prediction",
      "url": "https://arxiv.org/abs/2509.04601",
      "description": "arXiv:2509.04601v1 Announce Type: new \nAbstract: Prediction for ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity) plays a crucial role in drug discovery and development, accelerating the screening and optimization of new drugs. Existing methods primarily rely on single-task learn...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "framework",
        "arxiv",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Fundamental bounds on efficiency-confidence trade-off for transductive conformal prediction",
      "url": "https://arxiv.org/abs/2509.04631",
      "description": "arXiv:2509.04631v1 Announce Type: new \nAbstract: Transductive conformal prediction addresses the simultaneous prediction for multiple data points. Given a desired confidence level, the objective is to construct a prediction set that includes the true outcomes with the prescribed confidence. We demon...",
      "published_date": "2025-09-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}