<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Context Engineering Daily</title>
    <link>https://your-username.github.io/context-engineering-news</link>
    <description>Daily news and research updates in AI Context Engineering, Prompt Engineering, RAG, and LLM development</description>
    <language>en-us</language>
    <copyright>Copyright 2026 Context Engineering Daily</copyright>
    <generator>Context Engineering News Generator</generator>
    <lastBuildDate>Fri, 23 Jan 2026 20:06:22 +0000</lastBuildDate>
    <atom:link href="https://your-username.github.io/context-engineering-news/rss.xml" rel="self" type="application/rss+xml"/>
    <category>Technology</category>
    <category>Artificial Intelligence</category>
    <category>Machine Learning</category>
    <item>
      <title>AfriEconQA: A Benchmark Dataset for African Economic Analysis based on World Bank Reports</title>
      <link>https://arxiv.org/abs/2601.15297</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15297</guid>
      <description>arXiv:2601.15297v1 Announce Type: new 
Abstract: We introduce AfriEconQA, a specialized benchmark dataset for African economic analysis grounded in a comprehensive corpus of 236 World Bank reports. The task of AfriEconQA is to answer complex economic queries that require high-precision numerical rea...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; large language model, GPT, model, LLM, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>large language model</category>
      <category>GPT</category>
      <category>model</category>
    </item>
    <item>
      <title>Embedding Retrofitting: Data Engineering for better RAG</title>
      <link>https://arxiv.org/abs/2601.15298</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15298</guid>
      <description>arXiv:2601.15298v1 Announce Type: new 
Abstract: Embedding retrofitting adjusts pre-trained word vectors using knowledge graph constraints to improve domain-specific retrieval. However, the effectiveness of retrofitting depends critically on knowledge graph quality, which in turn depends on text pre...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, RAG, vector, embedding, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>paper</category>
      <category>RAG</category>
      <category>vector</category>
    </item>
    <item>
      <title>MALTopic: Multi-Agent LLM Topic Modeling Framework</title>
      <link>https://arxiv.org/abs/2601.15299</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15299</guid>
      <description>arXiv:2601.15299v1 Announce Type: new 
Abstract: Topic modeling is a crucial technique for extracting latent themes from unstructured text data, particularly valuable in analyzing survey responses. However, traditional methods often only consider free-text responses and do not natively incorporate s...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, LLM, RAG, arxiv, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>LLM</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Intelligence Degradation in Long-Context LLMs: Critical Threshold Determination via Natural Length Distribution Analysis</title>
      <link>https://arxiv.org/abs/2601.15300</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15300</guid>
      <description>arXiv:2601.15300v1 Announce Type: new 
Abstract: Large Language Models (LLMs) exhibit catastrophic performance degradation when processing contexts approaching certain critical thresholds, even when information remains relevant. This intelligence degradation-defined as over 30% drop in task performa...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; large language model, model, LLM, paper, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>large language model</category>
      <category>model</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Can We Trust LLM Detectors?</title>
      <link>https://arxiv.org/abs/2601.15301</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15301</guid>
      <description>arXiv:2601.15301v1 Announce Type: new 
Abstract: The rapid adoption of LLMs has increased the need for reliable AI text detection, yet existing detectors often fail outside controlled benchmarks. We systematically evaluate 2 dominant paradigms (training-free and supervised) and show that both are br...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, LLM, experiment, embedding, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>framework</category>
      <category>LLM</category>
      <category>experiment</category>
    </item>
    <item>
      <title>ICPO: Illocution-Calibrated Policy Optimization for Multi-Turn Conversation</title>
      <link>https://arxiv.org/abs/2601.15330</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15330</guid>
      <description>arXiv:2601.15330v1 Announce Type: new 
Abstract: Large Language Models (LLMs) in multi-turn conversations often suffer from a ``lost-in-conversation&amp;#x27;&amp;#x27; phenomenon, where they struggle to recover from early incorrect assumptions, particularly when users provide ambiguous initial instructions. We find ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, prompt, large language model, model, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Prompt Engineering</category>
      <category>framework</category>
      <category>prompt</category>
      <category>large language model</category>
    </item>
    <item>
      <title>RECAP: A Resource-Efficient Method for Adversarial Prompting in Large Language Models</title>
      <link>https://arxiv.org/abs/2601.15331</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15331</guid>
      <description>arXiv:2601.15331v1 Announce Type: new 
Abstract: The deployment of large language models (LLMs) has raised security concerns due to their susceptibility to producing harmful or policy-violating outputs when exposed to adversarial prompts. While alignment and guardrails mitigate common misuse, they r...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, large language model, model, LLM, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Prompt Engineering</category>
      <category>prompt</category>
      <category>large language model</category>
      <category>model</category>
    </item>
    <item>
      <title>No Reliable Evidence of Self-Reported Sentience in Small Large Language Models</title>
      <link>https://arxiv.org/abs/2601.15334</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15334</guid>
      <description>arXiv:2601.15334v1 Announce Type: new 
Abstract: Whether language models possess sentience has no empirical answer. But whether they believe themselves to be sentient can, in principle, be tested. We do so by querying several open-weights models about their own consciousness, and then verifying thei...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; large language model, GPT, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>large language model</category>
      <category>GPT</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>From Quotes to Concepts: Axial Coding of Political Debates with Ensemble LMs</title>
      <link>https://arxiv.org/abs/2601.15338</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15338</guid>
      <description>arXiv:2601.15338v1 Announce Type: new 
Abstract: Axial coding is a commonly used qualitative analysis method that enhances document understanding by organizing sentence-level open codes into broader categories. In this paper, we operationalize axial coding with large language models (LLMs). Extendin...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; large language model, model, LLM, paper, embedding | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>large language model</category>
      <category>model</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Gated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models</title>
      <link>https://arxiv.org/abs/2601.15305</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15305</guid>
      <description>arXiv:2601.15305v1 Announce Type: new 
Abstract: The computational burden of attention in long-context language models has motivated two largely independent lines of work: sparse attention mechanisms that reduce complexity by attending to selected tokens, and gated attention variants that improve tr...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, attention, experiment, arxiv, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>attention</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Uncovering Latent Bias in LLM-Based Emergency Department Triage Through Proxy Variables</title>
      <link>https://arxiv.org/abs/2601.15306</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15306</guid>
      <description>arXiv:2601.15306v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have enabled their integration into clinical decision-making; however, hidden biases against patients across racial, social, economic, and clinical backgrounds persist. In this study, we investigate bias...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; large language model, model, LLM, arxiv, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>large language model</category>
      <category>model</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Aeon: High-Performance Neuro-Symbolic Memory Management for Long-Horizon LLM Agents</title>
      <link>https://arxiv.org/abs/2601.15311</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15311</guid>
      <description>arXiv:2601.15311v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are fundamentally constrained by the quadratic computational cost of self-attention and the &amp;quot;Lost in the Middle&amp;quot; phenomenon, where reasoning capabilities degrade as context windows expand. Existing solutions, primarily &amp;quot;Fl...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; large language model, model, LLM, attention, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>large language model</category>
      <category>model</category>
      <category>LLM</category>
    </item>
    <item>
      <title>The Paradigm Shift: A Comprehensive Survey on Large Vision Language Models for Multimodal Fake News Detection</title>
      <link>https://arxiv.org/abs/2601.15316</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15316</guid>
      <description>arXiv:2601.15316v1 Announce Type: new 
Abstract: In recent years, the rapid evolution of large vision-language models (LVLMs) has driven a paradigm shift in multimodal fake news detection (MFND), transforming it from traditional feature-engineering approaches to unified, end-to-end multimodal reason...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, model, image, reasoning, vision | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Multimodal Context</category>
      <category>framework</category>
      <category>model</category>
      <category>image</category>
    </item>
    <item>
      <title>Replayable Financial Agents: A Determinism-Faithfulness Assurance Harness for Tool-Using LLM Agents</title>
      <link>https://arxiv.org/abs/2601.15322</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15322</guid>
      <description>arXiv:2601.15322v1 Announce Type: new 
Abstract: LLM agents struggle with regulatory audit replay: when asked to reproduce a flagged transaction decision with identical inputs, most deployments fail to return consistent results. This paper introduces the Determinism-Faithfulness Assurance Harness (D...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, LLM, paper, experiment, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>LLM</category>
      <category>paper</category>
    </item>
    <item>
      <title>Prometheus Mind: Retrofitting Memory to Frozen Language Models</title>
      <link>https://arxiv.org/abs/2601.15324</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15324</guid>
      <description>arXiv:2601.15324v1 Announce Type: new 
Abstract: Adding memory to pretrained language models typically requires architectural changes or weight modification. We present Prometheus Mind, which retrofits memory to a frozen Qwen3-4B using 11 modular adapters (530MB, 7% overhead) -- fully reversible by ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, transformer, retrieval, arxiv, memory | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>model</category>
      <category>transformer</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>Logic Programming on Knowledge Graph Networks And its Application in Medical Domain</title>
      <link>https://arxiv.org/abs/2601.15347</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15347</guid>
      <description>arXiv:2601.15347v1 Announce Type: new 
Abstract: The rash development of knowledge graph research has brought big driving force to its application in many areas, including the medicine and healthcare domain. However, we have found that the application of some major information processing techniques ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; example, reasoning, paper, vector, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>example</category>
      <category>reasoning</category>
      <category>paper</category>
    </item>
    <item>
      <title>GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation</title>
      <link>https://arxiv.org/abs/2601.15392</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15392</guid>
      <description>arXiv:2601.15392v1 Announce Type: new 
Abstract: Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene ex...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, model, image, API, vector | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>model</category>
      <category>image</category>
    </item>
    <item>
      <title>Beyond Prompting: Efficient and Robust Contextual Biasing for Speech LLMs via Logit-Space Integration (LOGIC)</title>
      <link>https://arxiv.org/abs/2601.15397</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15397</guid>
      <description>arXiv:2601.15397v1 Announce Type: new 
Abstract: The rapid emergence of new entities -- driven by cultural shifts, evolving trends, and personalized user data -- poses a significant challenge for existing Speech Large Language Models (Speech LLMs). While these models excel at general conversational ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, prompt, large language model, model, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Prompt Engineering</category>
      <category>framework</category>
      <category>prompt</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Empowering LLMs for Structure-Based Drug Design via Exploration-Augmented Latent Inference</title>
      <link>https://arxiv.org/abs/2601.15333</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15333</guid>
      <description>arXiv:2601.15333v1 Announce Type: new 
Abstract: Large Language Models (LLMs) possess strong representation and reasoning capabilities, but their application to structure-based drug design (SBDD) is limited by insufficient understanding of protein structures and unpredictable molecular generation. T...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, large language model, model, LLM, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>large language model</category>
      <category>model</category>
    </item>
    <item>
      <title>Language Models Entangle Language and Culture</title>
      <link>https://arxiv.org/abs/2601.15337</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15337</guid>
      <description>arXiv:2601.15337v1 Announce Type: new 
Abstract: Users should not be systemically disadvantaged by the language they use for interacting with LLMs; i.e. users across languages should get responses of similar quality irrespective of language used. In this work, we create a set of real-world open-ende...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, LLM, arxiv, context, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>LLM</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>You Need Better Attention Priors</title>
      <link>https://arxiv.org/abs/2601.15380</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15380</guid>
      <description>arXiv:2601.15380v1 Announce Type: new 
Abstract: We generalize the attention mechanism by viewing it through the lens of Entropic Optimal Transport, revealing that standard attention corresponds to a transport problem regularized by an implicit uniform prior. We introduce Generalized Optimal transpo...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, embedding, attention | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>arxiv</category>
      <category>embedding</category>
      <category>attention</category>
    </item>
    <item>
      <title>FedUMM: A General Framework for Federated Learning with Unified Multimodal Models</title>
      <link>https://arxiv.org/abs/2601.15390</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15390</guid>
      <description>arXiv:2601.15390v1 Announce Type: new 
Abstract: Unified multimodal models (UMMs) are emerging as strong foundation models that can do both generation and understanding tasks in a single architecture. However, they are typically trained in centralized settings where all training and downstream datas...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, paper, fine-tuning, research, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>paper</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>Attention-Informed Surrogates for Navigating Power-Performance Trade-offs in HPC</title>
      <link>https://arxiv.org/abs/2601.15399</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15399</guid>
      <description>arXiv:2601.15399v1 Announce Type: new 
Abstract: High-Performance Computing (HPC) schedulers must balance user performance with facility-wide resource constraints. The task boils down to selecting the optimal number of nodes for a given job. We present a surrogate-assisted multi-objective Bayesian o...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, attention, embedding, arxiv, product | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Industry News</category>
      <category>model</category>
      <category>attention</category>
      <category>embedding</category>
    </item>
    <item>
      <title>Context-Engineering - &amp;quot;Context engineering is the delicate art and science of filling the context window with just the right information for the next step.&amp;quot; â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.</title>
      <link>https://github.com/davidkimai/Context-Engineering</link>
      <guid isPermaLink="false">https://github.com/davidkimai/Context-Engineering</guid>
      <description>&amp;quot;Context engineering is the delicate art and science of filling the context window with just the right information for the next step.&amp;quot; â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context window, prompt, prompt engineering, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 29 Jun 2025 00:16:36 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>context window</category>
      <category>prompt</category>
      <category>prompt engineering</category>
    </item>
    <item>
      <title>ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.</title>
      <link>https://github.com/FunAudioLLM/ThinkSound</link>
      <guid isPermaLink="false">https://github.com/FunAudioLLM/ThinkSound</guid>
      <description>[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; chain-of-thought, audio, reasoning, CoT, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 27 Jun 2025 02:27:00 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>chain-of-thought</category>
      <category>audio</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>mcp-context-forge - A Model Context Protocol (MCP) Gateway &amp;amp; Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).</title>
      <link>https://github.com/IBM/mcp-context-forge</link>
      <guid isPermaLink="false">https://github.com/IBM/mcp-context-forge</guid>
      <description>A Model Context Protocol (MCP) Gateway &amp;amp; Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, model, LLM, context, tool | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 08 May 2025 08:16:59 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>prompt</category>
      <category>model</category>
      <category>LLM</category>
    </item>
    <item>
      <title>PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG</title>
      <link>https://github.com/VectifyAI/PageIndex</link>
      <guid isPermaLink="false">https://github.com/VectifyAI/PageIndex</guid>
      <description>ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, RAG, vector | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 01 Apr 2025 10:53:54 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>reasoning</category>
      <category>RAG</category>
      <category>vector</category>
    </item>
    <item>
      <title>Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code</title>
      <link>https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-</link>
      <guid isPermaLink="false">https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-</guid>
      <description>A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; chain-of-thought, framework, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 18 Feb 2025 15:45:30 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>chain-of-thought</category>
      <category>framework</category>
      <category>context</category>
    </item>
    <item>
      <title>airweave - Open-source context retrieval layer for AI agents</title>
      <link>https://github.com/airweave-ai/airweave</link>
      <guid isPermaLink="false">https://github.com/airweave-ai/airweave</guid>
      <description>Open-source context retrieval layer for AI agents&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; retrieval, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 24 Dec 2024 10:00:06 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>retrieval</category>
      <category>context</category>
    </item>
    <item>
      <title>LightRAG - [EMNLP2025] &amp;quot;LightRAG: Simple and Fast Retrieval-Augmented Generation&amp;quot;</title>
      <link>https://github.com/HKUDS/LightRAG</link>
      <guid isPermaLink="false">https://github.com/HKUDS/LightRAG</guid>
      <description>[EMNLP2025] &amp;quot;LightRAG: Simple and Fast Retrieval-Augmented Generation&amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, retrieval, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 02 Oct 2024 11:57:54 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>retrieval</category>
      <category>RAG</category>
    </item>
    <item>
      <title>KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&amp;amp;A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.</title>
      <link>https://github.com/OpenSPG/KAG</link>
      <guid isPermaLink="false">https://github.com/OpenSPG/KAG</guid>
      <description>KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&amp;amp;A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, model, LLM, reasoning, vector | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sat, 21 Sep 2024 13:56:44 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>framework</category>
      <category>model</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.</title>
      <link>https://github.com/Kiln-AI/Kiln</link>
      <guid isPermaLink="false">https://github.com/Kiln-AI/Kiln</guid>
      <description>Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, fine-tuning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 23 Jul 2024 23:10:13 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>RAG</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system</title>
      <link>https://github.com/microsoft/graphrag</link>
      <guid isPermaLink="false">https://github.com/microsoft/graphrag</guid>
      <description>A modular graph-based Retrieval-Augmented Generation (RAG) system&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, retrieval, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 27 Mar 2024 17:57:52 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>retrieval</category>
      <category>RAG</category>
    </item>
    <item>
      <title>R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.</title>
      <link>https://github.com/SciPhi-AI/R2R</link>
      <guid isPermaLink="false">https://github.com/SciPhi-AI/R2R</guid>
      <description>SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, RAG, retrieval, product, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 12 Feb 2024 03:24:27 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>RAG</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.</title>
      <link>https://github.com/openlit/openlit</link>
      <guid isPermaLink="false">https://github.com/openlit/openlit</guid>
      <description>Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, LLM, platform, vector, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 23 Jan 2024 17:40:59 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>prompt</category>
      <category>LLM</category>
      <category>platform</category>
    </item>
    <item>
      <title>DeepSurvey-Bench: Evaluating Academic Value of Automatically Generated Scientific Survey</title>
      <link>https://arxiv.org/abs/2601.15307</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15307</guid>
      <description>arXiv:2601.15307v1 Announce Type: new 
Abstract: The rapid development of automated scientific survey generation technology has made it increasingly important to establish a comprehensive benchmark to evaluate the quality of generated surveys.Nearly all existing evaluation benchmarks rely on flawed ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; API, experiment, research, arxiv, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>API</category>
      <category>experiment</category>
      <category>research</category>
    </item>
    <item>
      <title>CASL: Concept-Aligned Sparse Latents for Interpreting Diffusion Models</title>
      <link>https://arxiv.org/abs/2601.15441</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15441</guid>
      <description>arXiv:2601.15441v1 Announce Type: new 
Abstract: Internal activations of diffusion models encode rich semantic information, but interpreting such representations remains challenging. While Sparse Autoencoders (SAEs) have shown promise in disentangling latent representations, existing SAE-based metho...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, image, experiment, alignment, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>image</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Learning from Synthetic Data: Limitations of ERM</title>
      <link>https://arxiv.org/abs/2601.15468</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15468</guid>
      <description>arXiv:2601.15468v1 Announce Type: new 
Abstract: The prevalence and low cost of LLMs have led to a rise of synthetic content. From review sites to court documents, ``natural&amp;#x27;&amp;#x27; content has been contaminated by data points that appear similar to natural data, but are in fact LLM-generated. In this wor...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, example, LLM, arxiv, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>example</category>
      <category>LLM</category>
    </item>
    <item>
      <title>fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!</title>
      <link>https://github.com/tadata-org/fastapi_mcp</link>
      <guid isPermaLink="false">https://github.com/tadata-org/fastapi_mcp</guid>
      <description>Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; API, model, tool, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sat, 08 Mar 2025 11:15:43 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>API</category>
      <category>model</category>
      <category>tool</category>
    </item>
    <item>
      <title>cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.</title>
      <link>https://github.com/nvidia-cosmos/cosmos-reason1</link>
      <guid isPermaLink="false">https://github.com/nvidia-cosmos/cosmos-reason1</guid>
      <description>Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, chain-of-thought, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 02 Mar 2025 15:23:55 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>reasoning</category>
      <category>chain-of-thought</category>
      <category>model</category>
    </item>
    <item>
      <title>Entropy-Tree: Tree-Based Decoding with Entropy-Guided Exploration</title>
      <link>https://arxiv.org/abs/2601.15296</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15296</guid>
      <description>arXiv:2601.15296v1 Announce Type: new 
Abstract: Large language models achieve strong reasoning performance, yet existing decoding strategies either explore blindly (random sampling) or redundantly (independent multi-sampling). We propose Entropy-Tree, a tree-based decoding method that exploits entr...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, large language model, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Chain Of Thought</category>
      <category>reasoning</category>
      <category>large language model</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Improving MoE Compute Efficiency by Composing Weight and Data Sparsity</title>
      <link>https://arxiv.org/abs/2601.15370</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15370</guid>
      <description>arXiv:2601.15370v1 Announce Type: new 
Abstract: Mixture-of-Experts layers achieve compute efficiency through weight sparsity: each token activates only a subset of experts. Data sparsity, where each expert processes only a subset of tokens, offers a complementary axis. Expert-choice routing impleme...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vision, arxiv, model, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>vision</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Lattice: A Confidence-Gated Hybrid System for Uncertainty-Aware Sequential Prediction with Behavioral Archetypes</title>
      <link>https://arxiv.org/abs/2601.15423</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2601.15423</guid>
      <description>arXiv:2601.15423v1 Announce Type: new 
Abstract: We introduce Lattice, a hybrid sequential prediction system that conditionally activates learned behavioral structure using binary confidence gating. The system clusters behavior windows into behavioral archetypes and uses binary confidence gating to ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; transformer, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 23 Jan 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>transformer</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>excel-mcp-server - A Model Context Protocol server for Excel file manipulation</title>
      <link>https://github.com/haris-musa/excel-mcp-server</link>
      <guid isPermaLink="false">https://github.com/haris-musa/excel-mcp-server</guid>
      <description>A Model Context Protocol server for Excel file manipulation&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Feb 2025 06:39:48 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Industry News</category>
      <category>model</category>
      <category>context</category>
    </item>
    <item>
      <title>mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns</title>
      <link>https://github.com/lastmile-ai/mcp-agent</link>
      <guid isPermaLink="false">https://github.com/lastmile-ai/mcp-agent</guid>
      <description>Build effective agents using Model Context Protocol and simple workflow patterns&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 18 Dec 2024 01:55:10 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Industry News</category>
      <category>model</category>
      <category>context</category>
    </item>
    <item>
      <title>AlphaCodium - Official implementation for the paper: &amp;quot;Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering&amp;quot;&amp;quot;</title>
      <link>https://github.com/Codium-ai/AlphaCodium</link>
      <guid isPermaLink="false">https://github.com/Codium-ai/AlphaCodium</guid>
      <description>Official implementation for the paper: &amp;quot;Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering&amp;quot;&amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, prompt engineering, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 14 Jan 2024 15:17:18 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>prompt</category>
      <category>prompt engineering</category>
      <category>paper</category>
    </item>
    <item>
      <title>optillm - Optimizing inference proxy for LLMs</title>
      <link>https://github.com/algorithmicsuperintelligence/optillm</link>
      <guid isPermaLink="false">https://github.com/algorithmicsuperintelligence/optillm</guid>
      <description>Optimizing inference proxy for LLMs&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 22 Aug 2024 19:46:07 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>LLM</category>
    </item>
  </channel>
</rss>