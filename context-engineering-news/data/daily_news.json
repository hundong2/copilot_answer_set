{
  "generated_at": "2025-11-13T20:06:14.620143",
  "total_items": 46,
  "items": [
    {
      "title": "GMTRouter: Personalized LLM Router over Multi-turn User Interactions",
      "url": "https://arxiv.org/abs/2511.08590",
      "description": "arXiv:2511.08590v1 Announce Type: new \nAbstract: Large Language Model (LLM) routing has demonstrated strong capability in balancing response quality with computational cost. As users exhibit diverse preferences, personalization has attracted increasing attention in LLM routing, since even identical ...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "fine-tuning",
        "model",
        "attention",
        "ICL",
        "large language model",
        "LLM",
        "few-shot",
        "arxiv",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "The Collective Turing Test: Large Language Models Can Generate Realistic Multi-User Discussions",
      "url": "https://arxiv.org/abs/2511.08592",
      "description": "arXiv:2511.08592v1 Announce Type: new \nAbstract: Large Language Models (LLMs) offer new avenues to simulate online communities and social media. Potential applications range from testing the design of content recommendation algorithms to estimating the effects of content policies and interventions. ...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "model",
        "large language model",
        "LLM",
        "study",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Knowledge Graph Analysis of Legal Understanding and Violations in LLMs",
      "url": "https://arxiv.org/abs/2511.08593",
      "description": "arXiv:2511.08593v1 Announce Type: new \nAbstract: The rise of Large Language Models (LLMs) offers transformative potential for interpreting complex legal frameworks, such as Title 18 Section 175 of the US Code, which governs biological weapons. These systems hold promise for advancing legal analysis ...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "instruction",
        "analysis",
        "model",
        "research",
        "RAG",
        "reasoning",
        "large language model",
        "LLM",
        "augmented",
        "experiment",
        "arxiv",
        "framework",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Diverse Preference Learning for Capabilities and Alignment",
      "url": "https://arxiv.org/abs/2511.08594",
      "description": "arXiv:2511.08594v1 Announce Type: new \nAbstract: The ability of LLMs to represent diverse perspectives is critical as they increasingly impact society. However, recent studies reveal that alignment algorithms such as RLHF and DPO significantly reduce the diversity of LLM outputs. Not only do aligned...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "LLM",
        "alignment",
        "arxiv",
        "RLHF"
      ],
      "score": 1.0
    },
    {
      "title": "Chopping Trees: Semantic Similarity Based Dynamic Pruning for Tree-of-Thought Reasoning",
      "url": "https://arxiv.org/abs/2511.08595",
      "description": "arXiv:2511.08595v1 Announce Type: new \nAbstract: Tree-of-Thought (ToT) reasoning boosts the problem-solving abilities of Large Language Models (LLMs) but is computationally expensive due to semantic redundancy, where distinct branches explore equivalent reasoning paths. We introduce Semantic Similar...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "model",
        "ICL",
        "reasoning",
        "large language model",
        "LLM",
        "arxiv",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "What About the Scene with the Hitler Reference? HAUNT: A Framework to Probe LLMs' Self-consistency Via Adversarial Nudge",
      "url": "https://arxiv.org/abs/2511.08596",
      "description": "arXiv:2511.08596v1 Announce Type: new \nAbstract: Hallucinations pose a critical challenge to the real-world deployment of large language models (LLMs) in high-stakes domains. In this paper, we present a framework for stress testing factual fidelity in LLMs in the presence of adversarial nudge. Our f...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "model",
        "large language model",
        "paper",
        "LLM",
        "arxiv",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Self-HarmLLM: Can Large Language Model Harm Itself?",
      "url": "https://arxiv.org/abs/2511.08597",
      "description": "arXiv:2511.08597v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are generally equipped with guardrails to block the generation of harmful responses. However, existing defenses always assume that an external attacker crafts the harmful query, and the possibility of a model's own output ...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "GPT",
        "model",
        "zero-shot",
        "vector",
        "RAG",
        "large language model",
        "LLM",
        "study",
        "few-shot",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "OKBench: Democratizing LLM Evaluation with Fully Automated, On-Demand, Open Knowledge Benchmarking",
      "url": "https://arxiv.org/abs/2511.08598",
      "description": "arXiv:2511.08598v1 Announce Type: new \nAbstract: Knowledge-intensive question answering is central to large language models (LLMs) and is typically assessed using static benchmarks derived from sources like Wikipedia and textbooks. However, these benchmarks fail to capture evolving knowledge in a dy...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "API",
        "large language model",
        "LLM",
        "augmented",
        "arxiv",
        "framework",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Retrieval-Augmented Generation of Pediatric Speech-Language Pathology vignettes: A Proof-of-Concept Study",
      "url": "https://arxiv.org/abs/2511.08600",
      "description": "arXiv:2511.08600v1 Announce Type: new \nAbstract: Clinical vignettes are essential educational tools in speech-language pathology (SLP), but manual creation is time-intensive. While general-purpose large language models (LLMs) can generate text, they lack domain-specific knowledge, leading to halluci...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "GPT",
        "knowledge base",
        "tool",
        "model",
        "research",
        "prompt",
        "RAG",
        "large language model",
        "LLM",
        "augmented",
        "study",
        "template",
        "vision",
        "arxiv",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Analysing Environmental Efficiency in AI for X-Ray Diagnosis",
      "url": "https://arxiv.org/abs/2511.07436",
      "description": "arXiv:2511.07436v1 Announce Type: new \nAbstract: The integration of AI tools into medical applications has aimed to improve the efficiency of diagnosis. The emergence of large language models (LLMs), such as ChatGPT and Claude, has expanded this integration even further. Because of LLM versatility a...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "knowledge base",
        "tool",
        "model",
        "API",
        "large language model",
        "LLM",
        "paper",
        "study",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Agentic Educational Content Generation for African Languages on Edge Devices",
      "url": "https://arxiv.org/abs/2511.07437",
      "description": "arXiv:2511.07437v1 Announce Type: new \nAbstract: Addressing educational inequity in Sub-Saharan Africa, this research presents an autonomous agent-orchestrated framework for decentralized, culturally adaptive educational content generation on edge devices. The system leverages four specialized agent...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "RAG",
        "platform",
        "experiment",
        "context",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond Correctness: Confidence-Aware Reward Modeling for Enhancing Large Language Model Reasoning",
      "url": "https://arxiv.org/abs/2511.07483",
      "description": "arXiv:2511.07483v1 Announce Type: new \nAbstract: Recent advancements in large language models (LLMs) have shifted the post-training paradigm from traditional instruction tuning and human preference alignment toward reinforcement learning (RL) focused on reasoning capabilities. However, numerous tech...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "instruction",
        "model",
        "release",
        "reasoning",
        "large language model",
        "LLM",
        "alignment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Procedural Knowledge Improves Agentic LLM Workflows",
      "url": "https://arxiv.org/abs/2511.07568",
      "description": "arXiv:2511.07568v1 Announce Type: new \nAbstract: Large language models (LLMs) often struggle when performing agentic tasks without substantial tool support, prom-pt engineering, or fine tuning. Despite research showing that domain-dependent, procedural knowledge can dramatically increase planning ef...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "tool",
        "model",
        "research",
        "RAG",
        "large language model",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Think Before You Retrieve: Learning Test-Time Adaptive Search with Small Language Models",
      "url": "https://arxiv.org/abs/2511.07581",
      "description": "arXiv:2511.07581v1 Announce Type: new \nAbstract: Effective information retrieval requires reasoning over partial evidence and refining strategies as information emerges. Yet current approaches fall short: neural retrievers lack reasoning capabilities, large language models (LLMs) provide semantic de...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "model",
        "RAG",
        "reasoning",
        "large language model",
        "LLM",
        "vision",
        "framework",
        "arxiv",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces",
      "url": "https://arxiv.org/abs/2511.07587",
      "description": "arXiv:2511.07587v1 Announce Type: new \nAbstract: Large Language Models (LLMs) face fundamental challenges in long-context reasoning: many documents exceed their finite context windows, while performance on texts that do fit degrades with sequence length, necessitating their augmentation with externa...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "context window",
        "model",
        "memory",
        "embedding",
        "RAG",
        "reasoning",
        "large language model",
        "LLM",
        "context",
        "framework",
        "arxiv",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "AI-Driven Contribution Evaluation and Conflict Resolution: A Framework & Design for Group Workload Investigation",
      "url": "https://arxiv.org/abs/2511.07667",
      "description": "arXiv:2511.07667v1 Announce Type: new \nAbstract: The equitable assessment of individual contribution in teams remains a persistent challenge, where conflict and disparity in workload can result in unfair performance evaluation, often requiring manual intervention - a costly and challenging process. ...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "analysis",
        "model",
        "large language model",
        "LLM",
        "context",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Making LLMs Reliable When It Matters Most: A Five-Layer Architecture for High-Stakes Decisions",
      "url": "https://arxiv.org/abs/2511.07669",
      "description": "arXiv:2511.07669v1 Announce Type: new \nAbstract: Current large language models (LLMs) excel in verifiable domains where outputs can be checked before action but prove less reliable for high-stakes strategic decisions with uncertain outcomes. This gap, driven by mutually reinforcing cognitive biases ...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompting",
        "model",
        "prompt",
        "large language model",
        "LLM",
        "context",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "AIA Forecaster: Technical Report",
      "url": "https://arxiv.org/abs/2511.07678",
      "description": "arXiv:2511.07678v1 Announce Type: new \nAbstract: This technical report describes the AIA Forecaster, a Large Language Model (LLM)-based system for judgmental forecasting using unstructured data. The AIA Forecaster approach combines three core elements: agentic search over high-quality news sources, ...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "research",
        "large language model",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents",
      "url": "https://arxiv.org/abs/2511.07685",
      "description": "arXiv:2511.07685v1 Announce Type: new \nAbstract: Deep Research (DR) is an emerging agent application that leverages large language models (LLMs) to address open-ended queries. It requires the integration of several capabilities, including multi-step reasoning, cross-document synthesis, and the gener...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "research",
        "prompt",
        "RAG",
        "reasoning",
        "large language model",
        "LLM",
        "release",
        "context",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "FAIRPLAI: A Human-in-the-Loop Approach to Fair and Private Machine Learning",
      "url": "https://arxiv.org/abs/2511.08702",
      "description": "arXiv:2511.08702v1 Announce Type: new \nAbstract: As machine learning systems move from theory to practice, they are increasingly tasked with decisions that affect healthcare access, financial opportunities, hiring, and public services. In these contexts, accuracy is only one piece of the puzzle - mo...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "embedding",
        "context",
        "framework",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Benevolent Dictators? On LLM Agent Behavior in Dictator Games",
      "url": "https://arxiv.org/abs/2511.08721",
      "description": "arXiv:2511.08721v1 Announce Type: new \nAbstract: In behavioral sciences, experiments such as the ultimatum game are conducted to assess preferences for fairness or self-interest of study participants. In the dictator game, a simplified version of the ultimatum game where only one of two players make...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "instruction",
        "model",
        "prompt",
        "reasoning",
        "large language model",
        "LLM",
        "study",
        "arxiv",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Macroscopic Emission Modeling of Urban Traffic Using Probe Vehicle Data: A Machine Learning Approach",
      "url": "https://arxiv.org/abs/2511.08722",
      "description": "arXiv:2511.08722v1 Announce Type: new \nAbstract: Urban congestions cause inefficient movement of vehicles and exacerbate greenhouse gas emissions and urban air pollution. Macroscopic emission fundamental diagram (eMFD)captures an orderly relationship among emission and aggregated traffic variables a...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "model",
        "RAG",
        "ICL",
        "framework",
        "study",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "context",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "audio",
        "reasoning",
        "framework",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "model",
        "API",
        "prompt",
        "LLM",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "context",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "knowledge base",
        "model",
        "vector",
        "RAG",
        "reasoning",
        "LLM",
        "framework",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "fine-tuning",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "RAG",
        "augmented",
        "product",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "prompt",
        "LLM",
        "platform",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "A Lightweight CNN-Attention-BiLSTM Architecture for Multi-Class Arrhythmia Classification on Standard and Wearable ECGs",
      "url": "https://arxiv.org/abs/2511.08650",
      "description": "arXiv:2511.08650v1 Announce Type: new \nAbstract: Early and accurate detection of cardiac arrhythmias is vital for timely diagnosis and intervention. We propose a lightweight deep learning model combining 1D Convolutional Neural Networks (CNN), attention mechanisms, and Bidirectional Long Short-Term ...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "model",
        "memory",
        "arxiv",
        "attention"
      ],
      "score": 0.8
    },
    {
      "title": "Accelerating Training Speed of Tiny Recursive Models via Curriculum Guided Adaptive Recursion",
      "url": "https://arxiv.org/abs/2511.08653",
      "description": "arXiv:2511.08653v1 Announce Type: new \nAbstract: Recursive reasoning models achieve remarkable performance on complex reasoning tasks through iterative refinement, enabling tiny networks to match large language models thousands of times their size. However, training remains computationally expensive...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "research",
        "reasoning",
        "large language model",
        "vision",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Gromov-Wasserstein Graph Coarsening",
      "url": "https://arxiv.org/abs/2511.08733",
      "description": "arXiv:2511.08733v1 Announce Type: new \nAbstract: We study the problem of graph coarsening within the Gromov-Wasserstein geometry. Specifically, we propose two algorithms that leverage a novel representation of the distortion induced by merging pairs of nodes. The first method, termed Greedy Pair Coa...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "arxiv",
        "study"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "context",
        "model",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Learning the Basis: A Kolmogorov-Arnold Network Approach Embedding Green's Function Priors",
      "url": "https://arxiv.org/abs/2511.08655",
      "description": "arXiv:2511.08655v1 Announce Type: new \nAbstract: The Method of Moments (MoM) is constrained by the usage of static, geometry-defined basis functions, such as the Rao-Wilton-Glisson (RWG) basis. This letter reframes electromagnetic modeling around a learnable basis representation rather than solving ...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "arxiv",
        "embedding"
      ],
      "score": 0.6
    },
    {
      "title": "TabPFN-2.5: Advancing the State of the Art in Tabular Foundation Models",
      "url": "https://arxiv.org/abs/2511.08667",
      "description": "arXiv:2511.08667v1 Announce Type: new \nAbstract: The first tabular foundation model, TabPFN, and its successor TabPFNv2 have impacted tabular AI substantially, with dozens of methods building on it and hundreds of applications across different use cases. This report introduces TabPFN-2.5, the next g...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "model",
        "release",
        "arxiv",
        "product"
      ],
      "score": 0.6
    },
    {
      "title": "PEGNet: A Physics-Embedded Graph Network for Long-Term Stable Multiphysics Simulation",
      "url": "https://arxiv.org/abs/2511.08697",
      "description": "arXiv:2511.08697v1 Announce Type: new \nAbstract: Accurate and efficient simulations of physical phenomena governed by partial differential equations (PDEs) are important for scientific and engineering progress. While traditional numerical solvers are powerful, they are often computationally expensiv...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "arxiv",
        "embedding"
      ],
      "score": 0.6
    },
    {
      "title": "Hey Pentti, We Did (More of) It!: A Vector-Symbolic Lisp With Residue Arithmetic",
      "url": "https://arxiv.org/abs/2511.08767",
      "description": "arXiv:2511.08767v1 Announce Type: new \nAbstract: Using Frequency-domain Holographic Reduced Representations (FHRRs), we extend a Vector-Symbolic Architecture (VSA) encoding of Lisp 1.5 with primitives for arithmetic operations using Residue Hyperdimensional Computing (RHC). Encoding a Turing-complet...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "vector"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Where did you get that? Towards Summarization Attribution for Analysts",
      "url": "https://arxiv.org/abs/2511.08589",
      "description": "arXiv:2511.08589v1 Announce Type: new \nAbstract: Analysts require attribution, as nothing can be reported without knowing the source of the information. In this paper, we will focus on automatic methods for attribution, linking each sentence in the summary to a portion of the source text, which may ...",
      "published_date": "2025-11-13T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "summarization",
        "paper",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}