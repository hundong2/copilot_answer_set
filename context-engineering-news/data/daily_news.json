{
  "generated_at": "2025-12-08T20:05:50.909470",
  "total_items": 44,
  "items": [
    {
      "title": "Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting",
      "url": "https://arxiv.org/abs/2512.05243",
      "description": "arXiv:2512.05243v1 Announce Type: new \nAbstract: Prompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabil...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "prompt",
        "LLM",
        "study",
        "model",
        "prompting",
        "tool",
        "paper",
        "prompt engineering",
        "RAG",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing Clinical Note Generation with ICD-10, Clinical Ontology Knowledge Graphs, and Chain-of-Thought Prompting Using GPT-4",
      "url": "https://arxiv.org/abs/2512.05256",
      "description": "arXiv:2512.05256v1 Announce Type: new \nAbstract: In the past decade a surge in the amount of electronic health record (EHR) data in the United States, attributed to a favorable policy environment created by the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and t...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "prompt",
        "LLM",
        "model",
        "CoT",
        "chain-of-thought",
        "prompting",
        "prompt engineering",
        "GPT",
        "ICL",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "To Think or Not to Think: The Hidden Cost of Meta-Training with Excessive CoT Examples",
      "url": "https://arxiv.org/abs/2512.05318",
      "description": "arXiv:2512.05318v1 Announce Type: new \nAbstract: Chain-of-thought (CoT) prompting combined with few-shot in-context learning (ICL) has unlocked significant reasoning capabilities in large language models (LLMs). However, ICL with CoT examples is ineffective on novel tasks when the pre-training knowl...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "vision",
        "arxiv",
        "transformer",
        "few-shot",
        "prompt",
        "LLM",
        "study",
        "CoT",
        "chain-of-thought",
        "framework",
        "prompting",
        "model",
        "reasoning",
        "in-context",
        "example",
        "ICL",
        "context",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Exposing Pink Slime Journalism: Linguistic Signatures and Robust Detection Against LLM-Generated Threats",
      "url": "https://arxiv.org/abs/2512.05331",
      "description": "arXiv:2512.05331v1 Announce Type: new \nAbstract: The local news landscape, a vital source of reliable information for 28 million Americans, faces a growing threat from Pink Slime Journalism, a low-quality, auto-generated articles that mimic legitimate local reporting. Detecting these deceptive artic...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "LLM",
        "model",
        "framework",
        "analysis",
        "vector",
        "ICL",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Transformer-Enabled Diachronic Analysis of Vedic Sanskrit: Neural Methods for Quantifying Types of Language Change",
      "url": "https://arxiv.org/abs/2512.05364",
      "description": "arXiv:2512.05364v1 Announce Type: new \nAbstract: This study demonstrates how hybrid neural-symbolic methods can yield significant new insights into the evolution of a morphologically rich, low-resource language. We challenge the naive assumption that linguistic change is simplification by quantitati...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "transformer",
        "study",
        "fine-tuning",
        "framework",
        "analysis",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "Learning from Self Critique and Refinement for Faithful LLM Summarization",
      "url": "https://arxiv.org/abs/2512.05387",
      "description": "arXiv:2512.05387v1 Announce Type: new \nAbstract: Large Language Models (LLMs) often suffer from hallucinations: output content that is not grounded in the input context, when performing long-form text generation tasks such as summarization. Prior works have shown that hallucinations can be reduced b...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "summarization",
        "arxiv",
        "LLM",
        "model",
        "framework",
        "context",
        "experiment",
        "RAG",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Documenting SME Processes with Conversational AI: From Tacit Knowledge to BPMN",
      "url": "https://arxiv.org/abs/2512.05122",
      "description": "arXiv:2512.05122v1 Announce Type: new \nAbstract: Small and medium-sized enterprises (SMEs) still depend heavily on tacit, experience-based know-how that rarely makes its way into formal documentation. This paper introduces a large-language-model (LLM)-driven conversational assistant that captures su...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "LLM",
        "model",
        "paper",
        "analysis",
        "API",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations",
      "url": "https://arxiv.org/abs/2512.05156",
      "description": "arXiv:2512.05156v1 Announce Type: new \nAbstract: Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two new unsupervised metrics for faithfulness evaluation using insights from information theory and thermodynamics. Our approach treats an LLM a...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "summarization",
        "arxiv",
        "prompt",
        "LLM",
        "model",
        "framework",
        "product",
        "context",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Bridging Traditional Machine Learning and Large Language Models: A Two-Part Course Design for Modern AI Education",
      "url": "https://arxiv.org/abs/2512.05167",
      "description": "arXiv:2512.05167v1 Announce Type: new \nAbstract: This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science that systematically bridges traditional machine learning techniques with modern Large Language Models (LLMs). We describe a course structured ...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "model",
        "paper",
        "API",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare",
      "url": "https://arxiv.org/abs/2512.05365",
      "description": "arXiv:2512.05365v1 Announce Type: new \nAbstract: Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: com...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "prompt",
        "LLM",
        "memory",
        "framework",
        "model",
        "paper",
        "reasoning",
        "RAG",
        "context",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications",
      "url": "https://arxiv.org/abs/2512.05371",
      "description": "arXiv:2512.05371v1 Announce Type: new \nAbstract: While Large Language Models (LLMs) demonstrate immense potential for automating integrated circuit (IC) development, their practical deployment is fundamentally limited by restricted context windows. Existing context-extension methods struggle to achi...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "retrieval",
        "LLM",
        "augmented",
        "context window",
        "framework",
        "model",
        "research",
        "reasoning",
        "context",
        "RAG",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "BEAVER: An Efficient Deterministic LLM Verifier",
      "url": "https://arxiv.org/abs/2512.05439",
      "description": "arXiv:2512.05439v1 Announce Type: new \nAbstract: As large language models (LLMs) transition from research prototypes to production systems, practitioners often need reliable methods to verify that model outputs satisfy required constraints. While sampling-based estimates provide an intuition of mode...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "model",
        "framework",
        "product",
        "research",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems",
      "url": "https://arxiv.org/abs/2512.05449",
      "description": "arXiv:2512.05449v1 Announce Type: new \nAbstract: Large language models display a peculiar form of inconsistency: they \"know\" the correct answer but fail to act on it. In human philosophy, this tension between global judgment and local impulse is called akrasia, or weakness of will. We propose akrasi...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "prompt",
        "model",
        "prompting",
        "alignment",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Advanced Unsupervised Learning: A Comprehensive Overview of Multi-View Clustering Techniques",
      "url": "https://arxiv.org/abs/2512.05169",
      "description": "arXiv:2512.05169v1 Announce Type: new \nAbstract: Machine learning techniques face numerous challenges to achieve optimal performance. These include computational constraints, the limitations of single-view learning algorithms and the complexity of processing large datasets from different domains, so...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "research",
        "analysis",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Rethinking Tokenization for Clinical Time Series: When Less is More",
      "url": "https://arxiv.org/abs/2512.05217",
      "description": "arXiv:2512.05217v1 Announce Type: new \nAbstract: Tokenization strategies shape how models process electronic health records, yet fair comparisons of their effectiveness remain limited. We present a systematic evaluation of tokenization approaches for clinical time series modeling using transformer-b...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "embedding",
        "arxiv",
        "transformer",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Variance Matters: Improving Domain Adaptation via Stratified Sampling",
      "url": "https://arxiv.org/abs/2512.05226",
      "description": "arXiv:2512.05226v1 Announce Type: new \nAbstract: Domain shift remains a key challenge in deploying machine learning models to the real world. Unsupervised domain adaptation (UDA) aims to address this by minimising domain discrepancy during training, but the discrepancy estimates suffer from high var...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "paper",
        "alignment",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "DMAGT: Unveiling miRNA-Drug Associations by Integrating SMILES and RNA Sequence Structures through Graph Transformer Models",
      "url": "https://arxiv.org/abs/2512.05287",
      "description": "arXiv:2512.05287v1 Announce Type: new \nAbstract: MiRNAs, due to their role in gene regulation, have paved a new pathway for pharmacology, focusing on drug development that targets miRNAs. However, traditional wet lab experiments are limited by efficiency and cost constraints, making it difficult to ...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "transformer",
        "model",
        "embedding",
        "experiment",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context",
        "prompt",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "audio",
        "CoT",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "LLM",
        "model",
        "tool",
        "API",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "context",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "LLM",
        "framework",
        "model",
        "reasoning",
        "vector",
        "RAG",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "product",
        "API",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "LLM",
        "framework",
        "vector",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale",
      "url": "https://arxiv.org/abs/2512.05179",
      "description": "arXiv:2512.05179v1 Announce Type: new \nAbstract: Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick's D...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "fine-tuning",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning",
      "url": "https://arxiv.org/abs/2512.05325",
      "description": "arXiv:2512.05325v1 Announce Type: new \nAbstract: Large reasoning models achieve strong performance on complex tasks by generating extended chains of thought, but they often \"overthink\": continuing to reason long after they have enough information to answer correctly. This wastes inference-time compu...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "zero-shot",
        "analysis",
        "reasoning",
        "vision"
      ],
      "score": 0.8
    },
    {
      "title": "Mitigating the Antigenic Data Bottleneck: Semi-supervised Learning with Protein Language Models for Influenza A Surveillance",
      "url": "https://arxiv.org/abs/2512.05222",
      "description": "arXiv:2512.05222v1 Announce Type: new \nAbstract: Influenza A viruses (IAVs) evolve antigenically at a pace that requires frequent vaccine updates, yet the haemagglutination inhibition (HI) assays used to quantify antigenicity are labor-intensive and unscalable. As a result, genomic data vastly outpa...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "model",
        "framework",
        "embedding",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "Edged Weisfeiler-Lehman Algorithm",
      "url": "https://arxiv.org/abs/2512.05238",
      "description": "arXiv:2512.05238v1 Announce Type: new \nAbstract: As a classical approach on graph learning, the propagation-aggregation methodology is widely exploited by many of Graph Neural Networks (GNNs), wherein the representation of a node is updated by aggregating representations from itself and neighbor nod...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "RAG",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "When unlearning is free: leveraging low influence points to reduce computational costs",
      "url": "https://arxiv.org/abs/2512.05254",
      "description": "arXiv:2512.05254v1 Announce Type: new \nAbstract: As concerns around data privacy in machine learning grow, the ability to unlearn, or remove, specific data points from trained models becomes increasingly important. While state of the art unlearning methods have emerged in response, they typically tr...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "framework",
        "analysis",
        "example",
        "vision",
        "RAG"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "tool",
        "context",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "AI & Human Co-Improvement for Safer Co-Superintelligence",
      "url": "https://arxiv.org/abs/2512.05356",
      "description": "arXiv:2512.05356v1 Announce Type: new \nAbstract: Self-improvement is a goal currently exciting the field of AI, but is fraught with danger, and may take time to fully achieve. We advocate that a more achievable and better goal for humanity is to maximize co-improvement: collaboration between human r...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "research"
      ],
      "score": 0.6
    },
    {
      "title": "MAR-FL: A Communication Efficient Peer-to-Peer Federated Learning System",
      "url": "https://arxiv.org/abs/2512.05234",
      "description": "arXiv:2512.05234v1 Announce Type: new \nAbstract: The convergence of next-generation wireless systems and distributed Machine Learning (ML) demands Federated Learning (FL) methods that remain efficient and robust with wireless connected peers and under network churn. Peer-to-peer (P2P) FL removes the...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "RAG"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "paper",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "Mitigating Self-Preference by Authorship Obfuscation",
      "url": "https://arxiv.org/abs/2512.05379",
      "description": "arXiv:2512.05379v1 Announce Type: new \nAbstract: Language models (LMs) judges are widely used to evaluate the quality of LM outputs. Despite many advantages, LM judges display concerning biases that can impair their integrity in evaluations. One such bias is self-preference: LM judges preferring the...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "On the Computability of Artificial General Intelligence",
      "url": "https://arxiv.org/abs/2512.05212",
      "description": "arXiv:2512.05212v1 Announce Type: new \nAbstract: In recent years we observed rapid and significant advancements in artificial intelligence (A.I.). So much so that many wonder how close humanity is to developing an A.I. model that can achieve human level of intelligence, also known as artificial gene...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "API",
        "arxiv",
        "study",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Resolving Zadehs Paradox Axiomatic Possibility Theory as a Foundation for Reliable Artificial Intelligence",
      "url": "https://arxiv.org/abs/2512.05257",
      "description": "arXiv:2512.05257v1 Announce Type: new \nAbstract: This work advances and substantiates the thesis that the resolution of this crisis lies in the domain of possibility theory, specifically in the axiomatic approach developed in Bychkovs article. Unlike numerous attempts to fix Dempster rule, this appr...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "arxiv",
        "analysis",
        "reasoning",
        "example",
        "ICL"
      ],
      "score": 0.4
    },
    {
      "title": "Coefficient of Variation Masking: A Volatility-Aware Strategy for EHR Foundation Models",
      "url": "https://arxiv.org/abs/2512.05216",
      "description": "arXiv:2512.05216v1 Announce Type: new \nAbstract: Masked autoencoders (MAEs) are increasingly applied to electronic health records (EHR) for learning general-purpose representations that support diverse clinical tasks. However, existing approaches typically rely on uniform random masking, implicitly ...",
      "published_date": "2025-12-08T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}