{
  "generated_at": "2026-02-12T20:11:55.856250",
  "total_items": 49,
  "items": [
    {
      "title": "Reviewing the Reviewer: Elevating Peer Review Quality through LLM-Guided Feedback",
      "url": "https://arxiv.org/abs/2602.10118",
      "description": "arXiv:2602.10118v1 Announce Type: new \nAbstract: Peer review is central to scientific quality, yet reliance on simple heuristics -- lazy thinking -- has lowered standards. Prior work treats lazy thinking detection as a single-label task, but review segments may exhibit multiple issues, including bro...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "experiment",
        "zero-shot",
        "release",
        "framework",
        "LLM",
        "template"
      ],
      "score": 1.0
    },
    {
      "title": "Latent Thoughts Tuning: Bridging Context and Reasoning with Fused Information in Latent Tokens",
      "url": "https://arxiv.org/abs/2602.10229",
      "description": "arXiv:2602.10229v1 Announce Type: new \nAbstract: While explicit Chain-of-Thought (CoT) equips Large Language Models (LLMs) with strong reasoning capabilities, it requires models to verbalize every intermediate step in text tokens, constraining the model thoughts to the discrete vocabulary space. Rec...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "model",
        "LLM",
        "experiment",
        "CoT",
        "context",
        "RAG",
        "framework",
        "reasoning",
        "chain-of-thought",
        "alignment",
        "large language model",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Learning to Evict from Key-Value Cache",
      "url": "https://arxiv.org/abs/2602.10238",
      "description": "arXiv:2602.10238v1 Announce Type: new \nAbstract: The growing size of Large Language Models (LLMs) makes efficient inference challenging, primarily due to the memory demands of the autoregressive Key-Value (KV) cache. Existing eviction or compression methods reduce cost but rely on heuristics, such a...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "arxiv",
        "model",
        "vector",
        "zero-shot",
        "compression",
        "memory",
        "context",
        "framework",
        "LLM",
        "attention",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "On Emergent Social World Models -- Evidence for Functional Integration of Theory of Mind and Pragmatic Reasoning in Language Models",
      "url": "https://arxiv.org/abs/2602.10298",
      "description": "arXiv:2602.10298v1 Announce Type: new \nAbstract: This paper investigates whether LMs recruit shared computational mechanisms for general Theory of Mind (ToM) and language-specific pragmatic reasoning in order to contribute to the general question of whether LMs may be said to have emergent \"social w...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "experiment",
        "paper",
        "RAG",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Are More Tokens Rational? Inference-Time Scaling in Language Models as Adaptive Resource Rationality",
      "url": "https://arxiv.org/abs/2602.10329",
      "description": "arXiv:2602.10329v1 Announce Type: new \nAbstract: Human reasoning is shaped by resource rationality -- optimizing performance under constraints. Recently, inference-time scaling has emerged as a powerful paradigm to improve the reasoning performance of Large Language Models by expanding test-time com...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "model",
        "reasoning",
        "instruction",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "The Subjectivity of Respect in Police Traffic Stops: Modeling Community Perspectives in Body-Worn Camera Footage",
      "url": "https://arxiv.org/abs/2602.10339",
      "description": "arXiv:2602.10339v1 Announce Type: new \nAbstract: Traffic stops are among the most frequent police-civilian interactions, and body-worn cameras (BWCs) provide a unique record of how these encounters unfold. Respect is a central dimension of these interactions, shaping public trust and perceived legit...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "study",
        "arxiv",
        "tool",
        "model",
        "framework",
        "RAG",
        "alignment",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "Geometry-Aware Decoding with Wasserstein-Regularized Truncation and Mass Penalties for Large Language Models",
      "url": "https://arxiv.org/abs/2602.10346",
      "description": "arXiv:2602.10346v1 Announce Type: new \nAbstract: Large language models (LLMs) must balance diversity and creativity against logical coherence in open-ended generation. Existing truncation-based samplers are effective but largely heuristic, relying mainly on probability mass and entropy while ignorin...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "LLM",
        "experiment",
        "instruction",
        "large language model",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "When Less Is More? Diagnosing ASR Predictions in Sardinian via Layer-Wise Decoding",
      "url": "https://arxiv.org/abs/2602.10350",
      "description": "arXiv:2602.10350v1 Announce Type: new \nAbstract: Recent studies have shown that intermediate layers in multilingual speech models often encode more phonetically accurate representations than the final output layer. In this work, we apply a layer-wise decoding strategy to a pretrained Wav2Vec2 model ...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "tool",
        "transformer",
        "model",
        "analysis",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Learning Self-Interpretation from Interpretability Artifacts: Training Lightweight Adapters on Vector-Label Pairs",
      "url": "https://arxiv.org/abs/2602.10352",
      "description": "arXiv:2602.10352v1 Announce Type: new \nAbstract: Self-interpretation methods prompt language models to describe their own internal states, but remain unreliable due to hyperparameter sensitivity. We show that training lightweight adapters on interpretability artifacts, while keeping the LM entirely ...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "prompt",
        "model",
        "vector",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "Physically Interpretable AlphaEarth Foundation Model Embeddings Enable LLM-Based Land Surface Intelligence",
      "url": "https://arxiv.org/abs/2602.10354",
      "description": "arXiv:2602.10354v1 Announce Type: new \nAbstract: Satellite foundation models produce dense embeddings whose physical interpretability remains poorly understood, limiting their integration into environmental decision systems. Using 12.1 million samples across the Continental United States (2017--2023...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "study",
        "arxiv",
        "model",
        "augmented",
        "vector",
        "analysis",
        "LLM",
        "attention",
        "retrieval",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Discovering Differences in Strategic Behavior Between Humans and LLMs",
      "url": "https://arxiv.org/abs/2602.10324",
      "description": "arXiv:2602.10324v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) are increasingly deployed in social and strategic scenarios, it becomes critical to understand where and why their behavior diverges from that of humans. While behavioral game theory (BGT) provides a framework for analy...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "tool",
        "model",
        "paper",
        "analysis",
        "framework",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation",
      "url": "https://arxiv.org/abs/2602.10367",
      "description": "arXiv:2602.10367v1 Announce Type: new \nAbstract: The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test s...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "model",
        "analysis",
        "context",
        "framework",
        "reasoning",
        "LLM",
        "alignment",
        "API",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Found-RL: foundation model-enhanced reinforcement learning for autonomous driving",
      "url": "https://arxiv.org/abs/2602.10458",
      "description": "arXiv:2602.10458v1 Announce Type: new \nAbstract: Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-La...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "ICL",
        "prompt",
        "model",
        "platform",
        "framework",
        "reasoning",
        "context",
        "alignment",
        "API",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "MERIT Feedback Elicits Better Bargaining in LLM Negotiators",
      "url": "https://arxiv.org/abs/2602.10467",
      "description": "arXiv:2602.10467v1 Announce Type: new \nAbstract: Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchm...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "prompt",
        "model",
        "framework",
        "LLM",
        "large language model",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Abstraction Generation for Generalized Planning with Pretrained Large Language Models",
      "url": "https://arxiv.org/abs/2602.10485",
      "description": "arXiv:2602.10485v1 Announce Type: new \nAbstract: Qualitative Numerical Planning (QNP) serves as an important abstraction model for generalized planning (GP), which aims to compute general plans that solve multiple instances at once. Recent works show that large language models (LLMs) can function as...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "prompt",
        "experiment",
        "model",
        "LLM",
        "large language model",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Flow of Spans: Generalizing Language Models to Dynamic Span-Vocabulary via GFlowNets",
      "url": "https://arxiv.org/abs/2602.10583",
      "description": "arXiv:2602.10583v1 Announce Type: new \nAbstract: Standard autoregressive language models generate text token-by-token from a fixed vocabulary, inducing a tree-structured state space when viewing token sampling as an action, which limits flexibility and expressiveness. Recent work introduces dynamic ...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "transformer",
        "experiment",
        "model",
        "framework",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "To Think or Not To Think, That is The Question for Large Reasoning Models in Theory of Mind Tasks",
      "url": "https://arxiv.org/abs/2602.10625",
      "description": "arXiv:2602.10625v1 Announce Type: new \nAbstract: Theory of Mind (ToM) assesses whether models can infer hidden mental states such as beliefs, desires, and intentions, which is essential for natural social interaction. Although recent progress in Large Reasoning Models (LRMs) has boosted step-by-step...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "model",
        "step-by-step",
        "analysis",
        "reasoning",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation",
      "url": "https://arxiv.org/abs/2602.10699",
      "description": "arXiv:2602.10699v1 Announce Type: new \nAbstract: Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-rewar...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "experiment",
        "fine-tuning",
        "compression",
        "framework",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Large Language Models Predict Functional Outcomes after Acute Ischemic Stroke",
      "url": "https://arxiv.org/abs/2602.10119",
      "description": "arXiv:2602.10119v1 Announce Type: new \nAbstract: Accurate prediction of functional outcomes after acute ischemic stroke can inform clinical decision-making and resource allocation. Prior work on modified Rankin Scale (mRS) prediction has relied primarily on structured variables (e.g., age, NIHSS) an...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "tool",
        "model",
        "LLM",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Versor: A Geometric Sequence Architecture",
      "url": "https://arxiv.org/abs/2602.10195",
      "description": "arXiv:2602.10195v1 Announce Type: new \nAbstract: A novel sequence architecture design is introduced, Versor, which uses Conformal Geometric Algebra (CGA) in place of the traditional fundamental non-linear operations to achieve structural generalization and significant performance improvements on a v...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "transformer",
        "model",
        "zero-shot",
        "multimodal",
        "reasoning",
        "attention",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Adaptive Optimization via Momentum on Variance-Normalized Gradients",
      "url": "https://arxiv.org/abs/2602.10204",
      "description": "arXiv:2602.10204v1 Announce Type: new \nAbstract: We introduce MVN-Grad (Momentum on Variance-Normalized Gradients), an Adam-style optimizer that improves stability and performance by combining two complementary ideas: variance-based normalization and momentum applied after normalization. MVN-Grad sc...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "model",
        "image",
        "GPT",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Neural Network Quantum Field Theory from Transformer Architectures",
      "url": "https://arxiv.org/abs/2602.10209",
      "description": "arXiv:2602.10209v1 Announce Type: new \nAbstract: We propose a neural-network construction of Euclidean scalar quantum field theories from transformer attention heads, defining $n$-point correlators by averaging over random network parameters in the NN-QFT framework. For a single attention head, shar...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "transformer",
        "framework",
        "RAG",
        "attention",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "How Much Reasoning Do Retrieval-Augmented Models Add beyond LLMs? A Benchmarking Framework for Multi-Hop Inference over Hybrid Knowledge",
      "url": "https://arxiv.org/abs/2602.10210",
      "description": "arXiv:2602.10210v1 Announce Type: new \nAbstract: Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up-to-date information and multi-hop reasoning. Augmenting LLMs with hybrid external knowledge, such as unstructured text and structured knowledge graphs...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "model",
        "augmented",
        "experiment",
        "large language model",
        "release",
        "RAG",
        "framework",
        "reasoning",
        "LLM",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Temper-Then-Tilt: Principled Unlearning for Generative Models through Tempering and Classifier Guidance",
      "url": "https://arxiv.org/abs/2602.10217",
      "description": "arXiv:2602.10217v1 Announce Type: new \nAbstract: We study machine unlearning in large generative models by framing the task as density ratio estimation to a target distribution rather than supervised fine-tuning. While classifier guidance is a standard approach for approximating this ratio and can s...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "model",
        "analysis",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "context window",
        "prompt engineering",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "CoT",
        "framework",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "prompt",
        "model",
        "context",
        "LLM",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "vector",
        "reasoning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "retrieval",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "vector",
        "RAG",
        "framework",
        "reasoning",
        "LLM",
        "knowledge base",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "retrieval",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "product",
        "RAG",
        "API",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "vector",
        "framework",
        "LLM",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "Rank-Accuracy Trade-off for LoRA: A Gradient-Flow Analysis",
      "url": "https://arxiv.org/abs/2602.10212",
      "description": "arXiv:2602.10212v1 Announce Type: new \nAbstract: Previous empirical studies have shown that LoRA achieves accuracy comparable to full-parameter methods on downstream fine-tuning tasks, even for rank-1 updates. By contrast, the theoretical underpinnings of the dependence of LoRA's accuracy on update ...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "arxiv",
        "analysis"
      ],
      "score": 0.8
    },
    {
      "title": "ELROND: Exploring and decomposing intrinsic capabilities of diffusion models",
      "url": "https://arxiv.org/abs/2602.10216",
      "description": "arXiv:2602.10216v1 Announce Type: new \nAbstract: A single text prompt passed to a diffusion model often yields a wide range of visual outputs determined solely by stochastic process, leaving users with no direct control over which specific semantic variations appear in the image. While existing unsu...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "prompt",
        "model",
        "image",
        "analysis",
        "framework",
        "embedding"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "tool",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Neuro-symbolic Action Masking for Deep Reinforcement Learning",
      "url": "https://arxiv.org/abs/2602.10598",
      "description": "arXiv:2602.10598v1 Announce Type: new \nAbstract: Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified ac...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "experiment",
        "paper",
        "framework",
        "reasoning"
      ],
      "score": 0.6
    },
    {
      "title": "OmniSapiens: A Foundation Model for Social Behavior Processing via Heterogeneity-Aware Relative Policy Optimization",
      "url": "https://arxiv.org/abs/2602.10635",
      "description": "arXiv:2602.10635v1 Announce Type: new \nAbstract: To develop socially intelligent AI, existing approaches typically model human behavioral dimensions (e.g., affective, cognitive, or social attributes) in isolation. Although useful, task-specific modeling often increases training costs and limits gene...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "model",
        "release",
        "reasoning",
        "API"
      ],
      "score": 0.6
    },
    {
      "title": "Towards Autonomous Mathematics Research",
      "url": "https://arxiv.org/abs/2602.10177",
      "description": "arXiv:2602.10177v1 Announce Type: new \nAbstract: Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad. The transition from competition-level problem-solving to professional research, however, requi...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "ICL",
        "tool",
        "model",
        "paper",
        "reasoning",
        "research"
      ],
      "score": 0.6
    },
    {
      "title": "Signature-Kernel Based Evaluation Metrics for Robust Probabilistic and Tail-Event Forecasting",
      "url": "https://arxiv.org/abs/2602.10182",
      "description": "arXiv:2602.10182v1 Announce Type: new \nAbstract: Probabilistic forecasting is increasingly critical across high-stakes domains, from finance and epidemiology to climate science. However, current evaluation frameworks lack a consensus metric and suffer from two critical flaws: they often assume indep...",
      "published_date": "2026-02-12T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "framework",
        "RAG"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "OpenEnv in Practice: Evaluating Tool-Using Agents in Real-World Environments",
      "url": "https://huggingface.co/blog/openenv-turing",
      "description": "...",
      "published_date": "2026-02-12T00:00:00",
      "source": "Hugging Face Blog",
      "category": "tools_frameworks",
      "keywords": [
        "tool"
      ],
      "score": 0.2
    }
  ]
}