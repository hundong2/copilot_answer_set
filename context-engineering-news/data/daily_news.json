{
  "generated_at": "2026-01-07T20:06:15.026221",
  "total_items": 46,
  "items": [
    {
      "title": "WearVox: An Egocentric Multichannel Voice Assistant Benchmark for Wearables",
      "url": "https://arxiv.org/abs/2601.02391",
      "description": "arXiv:2601.02391v1 Announce Type: new \nAbstract: Wearable devices such as AI glasses are transforming voice assistants into always-available, hands-free collaborators that integrate seamlessly with daily life, but they also introduce challenges like egocentric audio affected by motion and noise, rap...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "LLM",
        "arxiv",
        "context",
        "model",
        "study",
        "tool",
        "research",
        "large language model",
        "audio",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "PCEval: A Benchmark for Evaluating Physical Computing Capabilities of Large Language Models",
      "url": "https://arxiv.org/abs/2601.02404",
      "description": "arXiv:2601.02404v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, including software development, education, and technical assistance. Among these, software development is one of the key areas where LLMs are increasingly a...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "arxiv",
        "model",
        "tool",
        "large language model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "ModeX: Evaluator-Free Best-of-N Selection for Open-Ended Generation",
      "url": "https://arxiv.org/abs/2601.02535",
      "description": "arXiv:2601.02535v1 Announce Type: new \nAbstract: Selecting a single high-quality output from multiple stochastic generations remains a fundamental challenge for large language models (LLMs), particularly in open-ended tasks where no canonical answer exists. While Best-of-N and self-consistency metho...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "release",
        "reasoning",
        "LLM",
        "arxiv",
        "model",
        "large language model",
        "framework",
        "summarization"
      ],
      "score": 1.0
    },
    {
      "title": "LoRA-Drop: Temporal LoRA Decoding for Efficient LLM Inference",
      "url": "https://arxiv.org/abs/2601.02569",
      "description": "arXiv:2601.02569v1 Announce Type: new \nAbstract: Autoregressive large language models (LLMs) are bottlenecked by sequential decoding, where each new token typically requires executing all transformer layers. Existing dynamic-depth and layer-skipping methods reduce this cost, but often rely on auxili...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "LLM",
        "arxiv",
        "context",
        "model",
        "large language model",
        "framework",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "Fact-Checking with Large Language Models via Probabilistic Certainty and Consistency",
      "url": "https://arxiv.org/abs/2601.02574",
      "description": "arXiv:2601.02574v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly used in applications requiring factual accuracy, yet their outputs often contain hallucinated responses. While fact-checking can mitigate these errors, existing methods typically retrieve external evidence...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "retrieval",
        "reasoning",
        "LLM",
        "arxiv",
        "model",
        "experiment",
        "large language model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "DataParasite Enables Scalable and Repurposable Online Data Curation",
      "url": "https://arxiv.org/abs/2601.02578",
      "description": "arXiv:2601.02578v1 Announce Type: new \nAbstract: Many questions in computational social science rely on datasets assembled from heterogeneous online sources, a process that is often labor-intensive, costly, and difficult to reproduce. Recent advances in large language models enable agentic search an...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "instruction",
        "large language model",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Reconstructing Item Characteristic Curves using Fine-Tuned Large Language Models",
      "url": "https://arxiv.org/abs/2601.02580",
      "description": "arXiv:2601.02580v1 Announce Type: new \nAbstract: Traditional methods for determining assessment item parameters, such as difficulty and discrimination, rely heavily on expensive field testing to collect student performance data for Item Response Theory (IRT) calibration. This study introduces a nove...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "LLM",
        "arxiv",
        "model",
        "study",
        "RAG",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "FlowPlan-G2P: A Structured Generation Framework for Transforming Scientific Papers into Patent Descriptions",
      "url": "https://arxiv.org/abs/2601.02589",
      "description": "arXiv:2601.02589v1 Announce Type: new \nAbstract: Over 3.5 million patents are filed annually, with drafting patent descriptions requiring deep technical and legal expertise. Transforming scientific papers into patent descriptions is particularly challenging due to their differing rhetorical styles a...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "reasoning",
        "paper",
        "prompt",
        "LLM",
        "arxiv",
        "model",
        "experiment",
        "RAG",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Scalable Construction of a Lung Cancer Knowledge Base: Profiling Semantic Reasoning in LLMs",
      "url": "https://arxiv.org/abs/2601.02604",
      "description": "arXiv:2601.02604v1 Announce Type: new \nAbstract: The integration of Large Language Models (LLMs) into biomedical research offers new opportunities for domainspecific reasoning and knowledge representation. However, their performance depends heavily on the semantic quality of training data. In oncolo...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "reasoning",
        "fine-tuning",
        "LLM",
        "arxiv",
        "model",
        "study",
        "knowledge base",
        "research",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections",
      "url": "https://arxiv.org/abs/2601.00814",
      "description": "arXiv:2601.00814v1 Announce Type: new \nAbstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned trans...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "model",
        "vector",
        "context",
        "alignment",
        "embedding",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "CogCanvas: Verbatim-Grounded Artifact Extraction for Long LLM Conversations",
      "url": "https://arxiv.org/abs/2601.00821",
      "description": "arXiv:2601.00821v2 Announce Type: new \nAbstract: Conversation summarization loses nuanced details: when asked about coding preferences after 40 turns, summarization recalls \"use type hints\" but drops the critical constraint \"everywhere\" (19.0% exact match vs. 93.0% for our approach).\n  We present Co...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "release",
        "reasoning",
        "LLM",
        "arxiv",
        "memory",
        "RAG",
        "framework",
        "summarization"
      ],
      "score": 1.0
    },
    {
      "title": "Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis",
      "url": "https://arxiv.org/abs/2601.00828",
      "description": "arXiv:2601.00828v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "arxiv",
        "model",
        "experiment",
        "GPT",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning",
      "url": "https://arxiv.org/abs/2601.00830",
      "description": "arXiv:2601.00830v1 Announce Type: new \nAbstract: When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned the...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "arxiv",
        "model",
        "study",
        "step-by-step",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing Temporal Awareness in LLMs for Temporal Point Processes",
      "url": "https://arxiv.org/abs/2601.00845",
      "description": "arXiv:2601.00845v1 Announce Type: new \nAbstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounti...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "reasoning",
        "LLM",
        "arxiv",
        "context",
        "model",
        "experiment",
        "alignment",
        "large language model",
        "framework",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Physical Transformer",
      "url": "https://arxiv.org/abs/2601.02433",
      "description": "arXiv:2601.02433v1 Announce Type: new \nAbstract: Digital AI systems spanning large language models, vision models, and generative architectures that operate primarily in symbolic, linguistic, or pixel domains. They have achieved striking progress, but almost all of this progress lives in virtual spa...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "vision",
        "LLM",
        "arxiv",
        "model",
        "attention",
        "large language model",
        "framework",
        "embedding",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "WebGym: Scaling Training Environments for Visual Web Agents with Realistic Tasks",
      "url": "https://arxiv.org/abs/2601.02439",
      "description": "arXiv:2601.02439v1 Announce Type: new \nAbstract: We present WebGym, the largest-to-date open-source environment for training realistic visual web agents. Real websites are non-stationary and diverse, making artificial or small-scale task sets insufficient for robust policy learning. WebGym contains ...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "vision",
        "fine-tuning",
        "arxiv",
        "model",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "GEM-Style Constraints for PEFT with Dual Gradient Projection in LoRA",
      "url": "https://arxiv.org/abs/2601.02500",
      "description": "arXiv:2601.02500v1 Announce Type: new \nAbstract: Full fine-tuning of Large Language Models (LLMs) is computationally costly, motivating Continual Learning (CL) approaches that utilize parameter-efficient adapters. We revisit Gradient Episodic Memory (GEM) within the Low-Rank Adapter (LoRA) subspace ...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "LLM",
        "arxiv",
        "model",
        "memory",
        "GPT",
        "RAG",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection",
      "url": "https://arxiv.org/abs/2601.02511",
      "description": "arXiv:2601.02511v1 Announce Type: new \nAbstract: Detecting anomalies in time series data is crucial for finance, healthcare, sensor networks, and industrial monitoring applications. However, time series anomaly detection often suffers from sparse labels, complex temporal patterns, and costly expert ...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "arxiv",
        "model",
        "study",
        "RAG",
        "large language model",
        "framework",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "Multi-scale Graph Autoregressive Modeling: Molecular Property Prediction via Next Token Prediction",
      "url": "https://arxiv.org/abs/2601.02530",
      "description": "arXiv:2601.02530v1 Announce Type: new \nAbstract: We present Connection-Aware Motif Sequencing (CamS), a graph-to-sequence representation that enables decoder-only Transformers to learn molecular graphs via standard next-token prediction (NTP). For molecular property prediction, SMILES-based NTP scal...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "model",
        "attention",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "CutisAI: Deep Learning Framework for Automated Dermatology and Cancer Screening",
      "url": "https://arxiv.org/abs/2601.02562",
      "description": "arXiv:2601.02562v1 Announce Type: new \nAbstract: The rapid growth of dermatological imaging and mobile diagnostic tools calls for systems that not only demonstrate empirical performance but also provide strong theoretical guarantees. Deep learning models have shown high predictive accuracy; however,...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "model",
        "tool",
        "experiment",
        "RAG",
        "research",
        "framework",
        "API",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Small Yet Mighty: Improve Accuracy In Multimodal Search and Visual Document Retrieval with Llama Nemotron RAG Models",
      "url": "https://huggingface.co/blog/nvidia/llama-nemotron-vl-1b",
      "description": "...",
      "published_date": "2026-01-06T21:16:17",
      "source": "Hugging Face Blog",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "model",
        "RAG",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "context",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "CoT",
        "framework",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "LLM",
        "model",
        "context",
        "tool",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "framework",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "retrieval",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "reasoning",
        "LLM",
        "model",
        "vector",
        "knowledge base",
        "RAG",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "retrieval",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "product",
        "RAG",
        "augmented",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "prompt",
        "LLM",
        "vector",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Losses that Cook: Topological Optimal Transport for Structured Recipe Generation",
      "url": "https://arxiv.org/abs/2601.02531",
      "description": "arXiv:2601.02531v1 Announce Type: new \nAbstract: Cooking recipes are complex procedures that require not only a fluent and factual text, but also accurate timing, temperature, and procedural coherence, as well as the correct composition of ingredients. Standard training procedures are primarily base...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "model",
        "embedding"
      ],
      "score": 0.8
    },
    {
      "title": "Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models",
      "url": "https://arxiv.org/abs/2601.00848",
      "description": "arXiv:2601.00848v1 Announce Type: new \nAbstract: We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources ...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "release",
        "example",
        "fine-tuning",
        "analysis",
        "arxiv",
        "model",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "mHC-GNN: Manifold-Constrained Hyper-Connections for Graph Neural Networks",
      "url": "https://arxiv.org/abs/2601.02451",
      "description": "arXiv:2601.02451v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) suffer from over-smoothing in deep architectures and expressiveness bounded by the 1-Weisfeiler-Leman (1-WL) test. We adapt Manifold-Constrained Hyper-Connections (\\mhc)~\\citep{xie2025mhc}, recently proposed for Transforme...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "transformer"
      ],
      "score": 0.8
    },
    {
      "title": "hdlib 2.0: Extending Machine Learning Capabilities of Vector-Symbolic Architectures",
      "url": "https://arxiv.org/abs/2601.02509",
      "description": "arXiv:2601.02509v1 Announce Type: new \nAbstract: Following the initial publication of hdlib, a Python library for designing Vector-Symbolic Architectures (VSA), we introduce a major extension that significantly enhances its machine learning capabilities. VSA, also known as Hyperdimensional Computing...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "example",
        "arxiv",
        "library",
        "vector",
        "model",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "model",
        "context",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making",
      "url": "https://arxiv.org/abs/2601.00818",
      "description": "arXiv:2601.00818v1 Announce Type: new \nAbstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern ...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "reasoning",
        "paper",
        "arxiv",
        "model",
        "research",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "Polynomial Convergence of Riemannian Diffusion Models",
      "url": "https://arxiv.org/abs/2601.02499",
      "description": "arXiv:2601.02499v1 Announce Type: new \nAbstract: Diffusion models have demonstrated remarkable empirical success in the recent years and are considered one of the state-of-the-art generative models in modern AI. These models consist of a forward process, which gradually diffuses the data distributio...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback",
      "url": "https://arxiv.org/abs/2601.00816",
      "description": "arXiv:2601.00816v1 Announce Type: new \nAbstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal ver...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Normalized Conditional Mutual Information Surrogate Loss for Deep Neural Classifiers",
      "url": "https://arxiv.org/abs/2601.02543",
      "description": "arXiv:2601.02543v1 Announce Type: new \nAbstract: In this paper, we propose a novel information theoretic surrogate loss; normalized conditional mutual information (NCMI); as a drop in alternative to the de facto cross-entropy (CE) for training deep neural network (DNN) based classifiers. We first ob...",
      "published_date": "2026-01-07T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "image",
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}