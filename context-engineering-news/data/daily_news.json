{
  "generated_at": "2025-09-09T20:05:49.000827",
  "total_items": 45,
  "items": [
    {
      "title": "An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training",
      "url": "https://arxiv.org/abs/2509.05359",
      "description": "arXiv:2509.05359v1 Announce Type: new \nAbstract: This paper investigates discrete unit representations in Speech Language Models (SLMs), focusing on optimizing speech modeling during continual pre-training. In this paper, we systematically examine how model architecture, data representation, and tra...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "alignment",
        "experiment",
        "arxiv",
        "model",
        "analysis",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond ROUGE: N-Gram Subspace Features for LLM Hallucination Detection",
      "url": "https://arxiv.org/abs/2509.05360",
      "description": "arXiv:2509.05360v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated effectiveness across a wide variety of tasks involving natural language, however, a fundamental problem of hallucinations still plagues these models, limiting their trustworthiness in generating consisten...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "LLM",
        "RAG",
        "large language model",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "A Lightweight Framework for Trigger-Guided LoRA-Based Self-Adaptation in LLMs",
      "url": "https://arxiv.org/abs/2509.05385",
      "description": "arXiv:2509.05385v1 Announce Type: new \nAbstract: Large language models are unable to continuously adapt and learn from new data during reasoning at inference time. To address this limitation, we propose that complex reasoning tasks be decomposed into atomic subtasks and introduce SAGE, a trigger-gui...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "fine-tuning",
        "LLM",
        "reasoning",
        "large language model",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Direct-Scoring NLG Evaluators Can Use Pairwise Comparisons Too",
      "url": "https://arxiv.org/abs/2509.05440",
      "description": "arXiv:2509.05440v1 Announce Type: new \nAbstract: As large-language models have been increasingly used as automatic raters for evaluating free-form content, including document summarization, dialog, and story generation, work has been dedicated to evaluating such models by measuring their correlation...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "context",
        "in-context",
        "summarization",
        "RAG",
        "arxiv",
        "model",
        "release"
      ],
      "score": 1.0
    },
    {
      "title": "From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification Framework for Healthcare Analytics",
      "url": "https://arxiv.org/abs/2509.05484",
      "description": "arXiv:2509.05484v1 Announce Type: new \nAbstract: Hospital call centers serve as the primary contact point for patients within a hospital system. They also generate substantial volumes of staff messages as navigators process patient requests and communicate with the hospital offices following the est...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "GPT",
        "framework",
        "tool",
        "LLM",
        "reasoning",
        "large language model",
        "arxiv",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "The Token Tax: Systematic Bias in Multilingual Tokenization",
      "url": "https://arxiv.org/abs/2509.05486",
      "description": "arXiv:2509.05486v1 Announce Type: new \nAbstract: Tokenization inefficiency imposes structural disadvantages on morphologically complex, low-resource languages, inflating compute resources and depressing accuracy. We evaluate 10 large language models (LLMs) on AfriMMLU (9,000 MCQA items; 5 subjects; ...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "LLM",
        "reasoning",
        "large language model",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Biomedical Literature Q&A System Using Retrieval-Augmented Generation (RAG)",
      "url": "https://arxiv.org/abs/2509.05505",
      "description": "arXiv:2509.05505v1 Announce Type: new \nAbstract: This work presents a Biomedical Literature Question Answering (Q&amp;A) system based on a Retrieval-Augmented Generation (RAG) architecture, designed to improve access to accurate, evidence-based medical information. Addressing the shortcomings of con...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "research",
        "retrieval",
        "vector",
        "ICL",
        "augmented",
        "RAG",
        "arxiv",
        "embedding",
        "model",
        "vector search"
      ],
      "score": 1.0
    },
    {
      "title": "Using Contrastive Learning to Improve Two-Way Reasoning in Large Language Models: The Obfuscation Task as a Case Study",
      "url": "https://arxiv.org/abs/2509.05553",
      "description": "arXiv:2509.05553v1 Announce Type: new \nAbstract: This research addresses a fundamental question in AI: whether large language models truly understand concepts or simply recognize patterns. The authors propose bidirectional reasoning,the ability to apply transformations in both directions without bei...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "research",
        "fine-tuning",
        "example",
        "study",
        "reasoning",
        "experiment",
        "large language model",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Attention of a Kiss: Exploring Attention Maps in Video Diffusion for XAIxArts",
      "url": "https://arxiv.org/abs/2509.05323",
      "description": "arXiv:2509.05323v1 Announce Type: new \nAbstract: This paper presents an artistic and technical investigation into the attention mechanisms of video diffusion transformers. Inspired by early video artists who manipulated analog video signals to create new visual aesthetics, this study proposes a meth...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "transformer",
        "attention",
        "study",
        "tool",
        "arxiv",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Benchmarking Large Language Models for Personalized Guidance in AI-Enhanced Learning",
      "url": "https://arxiv.org/abs/2509.05346",
      "description": "arXiv:2509.05346v1 Announce Type: new \nAbstract: While Large Language Models (LLMs) are increasingly envisioned as intelligent assistants for personalized learning, systematic head-to-head evaluations within authentic learning scenarios remain limited. This study conducts an empirical comparison of ...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "research",
        "study",
        "LLM",
        "large language model",
        "arxiv",
        "model",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "SasAgent: Multi-Agent AI System for Small-Angle Scattering Data Analysis",
      "url": "https://arxiv.org/abs/2509.05363",
      "description": "arXiv:2509.05363v1 Announce Type: new \nAbstract: We introduce SasAgent, a multi-agent AI system powered by large language models (LLMs) that automates small-angle scattering (SAS) data analysis by leveraging tools from the SasView software and enables user interaction via text input. SasAgent featur...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "research",
        "retrieval",
        "example",
        "augmented",
        "tool",
        "LLM",
        "library",
        "experiment",
        "RAG",
        "large language model",
        "arxiv",
        "model",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Characterizing Fitness Landscape Structures in Prompt Engineering",
      "url": "https://arxiv.org/abs/2509.05375",
      "description": "arXiv:2509.05375v1 Announce Type: new \nAbstract: While prompt engineering has emerged as a crucial technique for optimizing large language model performance, the underlying optimization landscape remains poorly understood. Current approaches treat prompt optimization as a black-box problem, applying...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "prompt engineering",
        "experiment",
        "arxiv",
        "large language model",
        "embedding",
        "model",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Murphys Laws of AI Alignment: Why the Gap Always Wins",
      "url": "https://arxiv.org/abs/2509.05381",
      "description": "arXiv:2509.05381v1 Announce Type: new \nAbstract: Large language models are increasingly aligned to human preferences through reinforcement learning from human feedback (RLHF) and related methods such as Direct Preference Optimization (DPO), Constitutional AI, and RLAIF. While effective, these method...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "alignment",
        "RLHF",
        "large language model",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "From Image Generation to Infrastructure Design: a Multi-agent Pipeline for Street Design Generation",
      "url": "https://arxiv.org/abs/2509.05469",
      "description": "arXiv:2509.05469v1 Announce Type: new \nAbstract: Realistic visual renderings of street-design scenarios are essential for public engagement in active transportation planning. Traditional approaches are labor-intensive, hindering collective deliberation and collaborative decision-making. While AI-ass...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "framework",
        "prompt",
        "API",
        "experiment",
        "instruction",
        "arxiv",
        "image"
      ],
      "score": 1.0
    },
    {
      "title": "Standard vs. Modular Sampling: Best Practices for Reliable LLM Unlearning",
      "url": "https://arxiv.org/abs/2509.05316",
      "description": "arXiv:2509.05316v1 Announce Type: new \nAbstract: A conventional LLM Unlearning setting consists of two subsets -\"forget\" and \"retain\", with the objectives of removing the undesired knowledge from the forget set while preserving the remaining knowledge from the retain. In privacy-focused unlearning r...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "study",
        "augmented",
        "LLM",
        "arxiv",
        "model",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Neural Breadcrumbs: Membership Inference Attacks on LLMs Through Hidden State and Attention Pattern Analysis",
      "url": "https://arxiv.org/abs/2509.05449",
      "description": "arXiv:2509.05449v1 Announce Type: new \nAbstract: Membership inference attacks (MIAs) reveal whether specific data was used to train machine learning models, serving as important tools for privacy auditing and compliance assessment. Recent studies have reported that MIAs perform only marginally bette...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "research",
        "transformer",
        "attention",
        "tool",
        "LLM",
        "RAG",
        "large language model",
        "arxiv",
        "model",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Calibrated Recommendations with Contextual Bandits",
      "url": "https://arxiv.org/abs/2509.05460",
      "description": "arXiv:2509.05460v1 Announce Type: new \nAbstract: Spotify's Home page features a variety of content types, including music, podcasts, and audiobooks. However, historical data is heavily skewed toward music, making it challenging to deliver a balanced and personalized content mix. Moreover, users' pre...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "audio",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Self-Aligned Reward: Towards Effective and Efficient Reasoners",
      "url": "https://arxiv.org/abs/2509.05489",
      "description": "arXiv:2509.05489v1 Announce Type: new \nAbstract: Reinforcement learning with verifiable rewards has significantly advanced reasoning in large language models (LLMs), but such signals remain coarse, offering only binary correctness feedback. This limitation often results in inefficiencies, including ...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "reasoning",
        "RAG",
        "large language model",
        "arxiv",
        "model",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "context",
        "prompt",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "audio",
        "reasoning",
        "CoT",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "prompt",
        "API",
        "tool",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "context",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "retrieval",
        "knowledge base",
        "LLM",
        "reasoning",
        "RAG",
        "vector",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "LLM",
        "model",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "API",
        "augmented",
        "product",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "framework",
        "prompt",
        "LLM",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "framework",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "SynDelay: A Synthetic Dataset for Delivery Delay Prediction",
      "url": "https://arxiv.org/abs/2509.05325",
      "description": "arXiv:2509.05325v1 Announce Type: new \nAbstract: Artificial intelligence (AI) is transforming supply chain management, yet progress in predictive tasks -- such as delivery delay prediction -- remains constrained by the scarcity of high-quality, openly available datasets. Existing datasets are often ...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "ICL",
        "RAG",
        "arxiv",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Code Like Humans: A Multi-Agent Solution for Medical Coding",
      "url": "https://arxiv.org/abs/2509.05378",
      "description": "arXiv:2509.05378v1 Announce Type: new \nAbstract: In medical coding, experts map unstructured clinical notes to alphanumeric codes for diagnoses and procedures. We introduce Code Like Humans: a new agentic framework for medical coding with large language models. It implements official coding guidelin...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "large language model",
        "arxiv",
        "model",
        "analysis"
      ],
      "score": 0.8
    },
    {
      "title": "Feed Two Birds with One Scone: Exploiting Function-Space Regularization for Both OOD Robustness and ID Fine-Tuning Performance",
      "url": "https://arxiv.org/abs/2509.05328",
      "description": "arXiv:2509.05328v1 Announce Type: new \nAbstract: Robust fine-tuning aims to achieve competitive in-distribution (ID) performance while maintaining the out-of-distribution (OOD) robustness of a pre-trained model when transferring it to a downstream task. To remedy this, most robust fine-tuning method...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "model",
        "fine-tuning"
      ],
      "score": 0.8
    },
    {
      "title": "Safeguarding Graph Neural Networks against Topology Inference Attacks",
      "url": "https://arxiv.org/abs/2509.05429",
      "description": "arXiv:2509.05429v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) have emerged as powerful models for learning from graph-structured data. However, their widespread adoption has raised serious privacy concerns. While prior research has primarily focused on edge-level privacy, a critical ...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "research",
        "study",
        "experiment",
        "arxiv",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "STL-based Optimization of Biomolecular Neural Networks for Regression and Control",
      "url": "https://arxiv.org/abs/2509.05481",
      "description": "arXiv:2509.05481v1 Announce Type: new \nAbstract: Biomolecular Neural Networks (BNNs), artificial neural networks with biologically synthesizable architectures, achieve universal function approximation capabilities beyond simple biological circuits. However, training BNNs remains challenging due to t...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "experiment",
        "RAG"
      ],
      "score": 0.8
    },
    {
      "title": "Prior Distribution and Model Confidence",
      "url": "https://arxiv.org/abs/2509.05485",
      "description": "arXiv:2509.05485v1 Announce Type: new \nAbstract: This paper investigates the impact of training data distribution on the performance of image classification models. By analyzing the embeddings of the training set, we propose a framework to understand the confidence of model predictions on unseen dat...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "framework",
        "example",
        "model",
        "arxiv",
        "embedding",
        "image",
        "vision",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "MambaLite-Micro: Memory-Optimized Mamba Inference on MCUs",
      "url": "https://arxiv.org/abs/2509.05488",
      "description": "arXiv:2509.05488v1 Announce Type: new \nAbstract: Deploying Mamba models on microcontrollers (MCUs) remains challenging due to limited memory, the lack of native operator support, and the absence of embedded-friendly toolchains. We present, to our knowledge, the first deployment of a Mamba-based neur...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "memory",
        "tool",
        "RAG",
        "arxiv",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "context",
        "API",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent Debate",
      "url": "https://arxiv.org/abs/2509.05396",
      "description": "arXiv:2509.05396v1 Announce Type: new \nAbstract: While multi-agent debate has been proposed as a promising strategy for improving AI reasoning ability, we find that debate can sometimes be harmful rather than helpful. The prior work has exclusively focused on debates within homogeneous groups of age...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "reasoning",
        "experiment",
        "arxiv",
        "model",
        "analysis"
      ],
      "score": 0.6
    },
    {
      "title": "No Translation Needed: Forecasting Quality from Fertility and Metadata",
      "url": "https://arxiv.org/abs/2509.05425",
      "description": "arXiv:2509.05425v1 Announce Type: new \nAbstract: We show that translation quality can be predicted with surprising accuracy \\textit{without ever running the translation system itself}. Using only a handful of features, token fertility ratios, token counts, and basic linguistic metadata (language fam...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "GPT",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "PLanTS: Periodicity-aware Latent-state Representation Learning for Multivariate Time Series",
      "url": "https://arxiv.org/abs/2509.05478",
      "description": "arXiv:2509.05478v1 Announce Type: new \nAbstract: Multivariate time series (MTS) are ubiquitous in domains such as healthcare, climate science, and industrial monitoring, but their high dimensionality, limited labeled data, and non-stationary nature pose significant challenges for conventional machin...",
      "published_date": "2025-09-09T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "framework",
        "model",
        "RAG"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}