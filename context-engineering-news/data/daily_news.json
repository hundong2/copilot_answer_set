{
  "generated_at": "2026-02-03T20:12:23.912829",
  "total_items": 49,
  "items": [
    {
      "title": "PPoGA: Predictive Plan-on-Graph with Action for Knowledge Graph Question Answering",
      "url": "https://arxiv.org/abs/2602.00007",
      "description": "arXiv:2602.00007v1 Announce Type: new \nAbstract: Large Language Models (LLMs) augmented with Knowledge Graphs (KGs) have advanced complex question answering, yet they often remain susceptible to failure when their initial high-level reasoning plan is flawed. This limitation, analogous to cognitive f...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "experiment",
        "LLM",
        "model",
        "arxiv",
        "reasoning",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Unlocking Electronic Health Records: A Hybrid Graph RAG Approach to Safe Clinical AI for Patient QA",
      "url": "https://arxiv.org/abs/2602.00009",
      "description": "arXiv:2602.00009v1 Announce Type: new \nAbstract: Electronic health record (EHR) systems present clinicians with vast repositories of clinical information, creating a significant cognitive burden where critical details are easily overlooked. While Large Language Models (LLMs) offer transformative pot...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "embedding",
        "augmented",
        "RAG",
        "retrieval",
        "context",
        "LLM",
        "model",
        "arxiv",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "G-MemLLM: Gated Latent Memory Augmentation for Long-Context Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2602.00015",
      "description": "arXiv:2602.00015v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, yet they remain constrained by the finite capacity of their context windows and the inherent difficulty of maintaining long-term factual consiste...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "GPT",
        "augmented",
        "paper",
        "context",
        "compression",
        "LLM",
        "model",
        "context window",
        "arxiv",
        "reasoning",
        "memory",
        "zero-shot",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "PTCBENCH: Benchmarking Contextual Stability of Personality Traits in LLM Systems",
      "url": "https://arxiv.org/abs/2602.00016",
      "description": "arXiv:2602.00016v1 Announce Type: new \nAbstract: With the increasing deployment of large language models (LLMs) in affective agents and AI systems, maintaining a consistent and authentic LLM personality becomes critical for user trust and engagement. However, existing work overlooks a fundamental ps...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "LLM",
        "model",
        "arxiv",
        "reasoning",
        "study",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Construct, Align, and Reason: Large Ontology Models for Enterprise Knowledge Management",
      "url": "https://arxiv.org/abs/2602.00029",
      "description": "arXiv:2602.00029v1 Announce Type: new \nAbstract: Enterprise-scale knowledge management faces significant challenges in integrating multi-source heterogeneous data and enabling effective semantic reasoning. Traditional knowledge graphs often struggle with implicit relationship discovery and lack suff...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "fine-tuning",
        "model",
        "arxiv",
        "reasoning",
        "framework",
        "instruction"
      ],
      "score": 1.0
    },
    {
      "title": "DIVERGE: Diversity-Enhanced RAG for Open-Ended Information Seeking",
      "url": "https://arxiv.org/abs/2602.00238",
      "description": "arXiv:2602.00238v1 Announce Type: new \nAbstract: Existing retrieval-augmented generation (RAG) systems are primarily designed under the assumption that each query has a single correct answer. This overlooks common information-seeking scenarios with multiple plausible answers, where diversity is esse...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval",
        "context",
        "LLM",
        "analysis",
        "framework",
        "model",
        "arxiv",
        "memory"
      ],
      "score": 1.0
    },
    {
      "title": "Benchmarking Uncertainty Calibration in Large Language Model Long-Form Question Answering",
      "url": "https://arxiv.org/abs/2602.00279",
      "description": "arXiv:2602.00279v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are commonly used in Question Answering (QA) settings, increasingly in the natural sciences if not science at large. Reliable Uncertainty Quantification (UQ) is critical for the trustworthy uptake of generated answers. Exi...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompting",
        "retrieval",
        "LLM",
        "analysis",
        "model",
        "arxiv",
        "reasoning",
        "study",
        "framework",
        "instruction",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Faithful-Patchscopes: Understanding and Mitigating Model Bias in Hidden Representations Explanation of Large Language Models",
      "url": "https://arxiv.org/abs/2602.00300",
      "description": "arXiv:2602.00300v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated strong capabilities for hidden representation interpretation through Patchscopes, a framework that uses LLMs themselves to generate human-readable explanations by decoding from internal hidden representat...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "example",
        "RAG",
        "context",
        "experiment",
        "alignment",
        "LLM",
        "model",
        "arxiv",
        "study",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes",
      "url": "https://arxiv.org/abs/2602.00053",
      "description": "arXiv:2602.00053v1 Announce Type: new \nAbstract: Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing req...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "RAG",
        "experiment",
        "analysis",
        "product",
        "model",
        "study",
        "arxiv",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models",
      "url": "https://arxiv.org/abs/2602.00190",
      "description": "arXiv:2602.00190v1 Announce Type: new \nAbstract: Deep learning agents can achieve high performance in complex game domains without often understanding the underlying causal game mechanics. To address this, we investigate Causal Induction: the ability to infer governing laws from observational data, ...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "embedding",
        "prompting",
        "context",
        "LLM",
        "model",
        "arxiv",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Localizing and Correcting Errors for LLM-based Planners",
      "url": "https://arxiv.org/abs/2602.00276",
      "description": "arXiv:2602.00276v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated strong reasoning capabilities on math and coding, but frequently fail on symbolic classical planning tasks. Our studies, as well as prior work, show that LLM-generated plans routinely violate domain const...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "example",
        "context",
        "LLM",
        "ICL",
        "demonstration",
        "model",
        "reasoning",
        "arxiv",
        "instruction",
        "in-context",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
      "url": "https://arxiv.org/abs/2602.00298",
      "description": "arXiv:2602.00298v1 Announce Type: new \nAbstract: Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluatin...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "prompt",
        "fine-tuning",
        "paper",
        "RAG",
        "experiment",
        "alignment",
        "LLM",
        "ICL",
        "model",
        "arxiv",
        "research",
        "instruction",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Autonomous Data Processing using Meta-Agents",
      "url": "https://arxiv.org/abs/2602.00307",
      "description": "arXiv:2602.00307v1 Announce Type: new \nAbstract: Traditional data processing pipelines are typically static and handcrafted for specific tasks, limiting their adaptability to evolving requirements. While general-purpose agents and coding assistants can generate code for well-understood data pipeline...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "RAG",
        "context",
        "arxiv",
        "framework",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?",
      "url": "https://arxiv.org/abs/2602.00327",
      "description": "arXiv:2602.00327v1 Announce Type: new \nAbstract: We explore the use of large language models (LLMs) for next-utterance prediction in human dialogue. Despite recent advances in LLMs demonstrating their ability to engage in natural conversations with users, we show that even leading models surprisingl...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "experiment",
        "multimodal",
        "LLM",
        "model",
        "arxiv",
        "research",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants",
      "url": "https://arxiv.org/abs/2602.00353",
      "description": "arXiv:2602.00353v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly applied in mental health support systems, where reliable recognition of high-risk states such as suicidal ideation and self-harm is safety-critical. However, existing evaluations primarily rely on aggregat...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "platform",
        "LLM",
        "analysis",
        "model",
        "arxiv",
        "research",
        "API",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Position: Agentic Evolution is the Path to Evolving LLMs",
      "url": "https://arxiv.org/abs/2602.00359",
      "description": "arXiv:2602.00359v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) move from curated training sets into open-ended real-world environments, a fundamental limitation emerges: static training cannot keep pace with continual deployment environment change. Scaling training-time and inferen...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "fine-tuning",
        "LLM",
        "framework",
        "model",
        "arxiv",
        "memory",
        "vision",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "OGD4All: A Framework for Accessible Interaction with Geospatial Open Government Data Based on Large Language Models",
      "url": "https://arxiv.org/abs/2602.00012",
      "description": "arXiv:2602.00012v1 Announce Type: new \nAbstract: We present OGD4All, a transparent, auditable, and reproducible framework based on Large Language Models (LLMs) to enhance citizens' interaction with geospatial Open Government Data (OGD). The system combines semantic data retrieval, agentic reasoning ...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "retrieval",
        "multimodal",
        "LLM",
        "model",
        "arxiv",
        "reasoning",
        "framework",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Measurement for Opaque Systems: Multi-source Triangulation with Interpretable Machine Learning",
      "url": "https://arxiv.org/abs/2602.00022",
      "description": "arXiv:2602.00022v1 Announce Type: new \nAbstract: We propose a measurement framework for difficult-to-access contexts that uses indirect data traces, interpretable machine-learning models, and theory-guided triangulation to fill inaccessible measurement spaces. Many high-stakes systems of scientific ...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "context",
        "analysis",
        "model",
        "arxiv",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Representation Learning Enhanced Deep Reinforcement Learning for Optimal Operation of Hydrogen-based Multi-Energy Systems",
      "url": "https://arxiv.org/abs/2602.00027",
      "description": "arXiv:2602.00027v1 Announce Type: new \nAbstract: Hydrogen-based multi-energy systems (HMES) have emerged as a promising low-carbon and energy-efficient solution, as it can enable the coordinated operation of electricity, heating and cooling supply and demand to enhance operational flexibility, impro...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "RAG",
        "experiment",
        "model",
        "arxiv",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "ELLMPEG: An Edge-based Agentic LLM Video Processing Tool",
      "url": "https://arxiv.org/abs/2602.00028",
      "description": "arXiv:2602.00028v1 Announce Type: new \nAbstract: Large language models (LLMs), the foundation of generative AI systems like ChatGPT, are transforming many fields and applications, including multimedia, enabling more advanced content generation, analysis, and interaction. However, cloud-based LLM dep...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "prompt",
        "augmented",
        "paper",
        "RAG",
        "retrieval",
        "experiment",
        "LLM",
        "analysis",
        "model",
        "arxiv",
        "reasoning",
        "framework",
        "API",
        "large language model",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "RAPTOR-AI for Disaster OODA Loop: Hierarchical Multimodal RAG with Experience-Driven Agentic Decision-Making",
      "url": "https://arxiv.org/abs/2602.00030",
      "description": "arXiv:2602.00030v1 Announce Type: new \nAbstract: Effective humanitarian assistance and disaster relief (HADR) requires rapid situational understanding, reliable decision support, and the ability to generalize across diverse and previously unseen disaster contexts. This work introduces an agentic Ret...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "embedding",
        "knowledge base",
        "RAG",
        "retrieval",
        "context",
        "experiment",
        "summarization",
        "multimodal",
        "image",
        "model",
        "arxiv",
        "reasoning",
        "chain-of-thought",
        "framework",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing few-shot time series forecasting with LLM-guided diffusion",
      "url": "https://arxiv.org/abs/2602.00040",
      "description": "arXiv:2602.00040v1 Announce Type: new \nAbstract: Time series forecasting in specialized domains is often constrained by limited data availability, where conventional models typically require large-scale datasets to effectively capture underlying temporal dynamics. To tackle this few-shot challenge, ...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "LLM",
        "few-shot",
        "analysis",
        "framework",
        "model",
        "arxiv",
        "memory",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Extending Beacon to Hindi: Cultural Adaptation Drives Cross-Lingual Sycophancy",
      "url": "https://arxiv.org/abs/2602.00046",
      "description": "arXiv:2602.00046v1 Announce Type: new \nAbstract: Sycophancy, the tendency of language models to prioritize agreement with user preferences over principled reasoning, has been identified as a persistent alignment failure in English-language evaluations. However, it remains unclear whether such diagno...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "context",
        "alignment",
        "analysis",
        "model",
        "reasoning",
        "release",
        "arxiv",
        "instruction"
      ],
      "score": 1.0
    },
    {
      "title": "Lightweight Edge Learning via Dataset Pruning",
      "url": "https://arxiv.org/abs/2602.00047",
      "description": "arXiv:2602.00047v1 Announce Type: new \nAbstract: Edge learning facilitates ubiquitous intelligence by enabling model training and adaptation directly on data-generating devices, thereby mitigating privacy risks and communication latency. However, the high computational and energy overhead of on-devi...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "RAG",
        "experiment",
        "image",
        "framework",
        "model",
        "arxiv",
        "memory"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt engineering",
        "prompt",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "CoT",
        "reasoning",
        "framework",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "context",
        "LLM",
        "model",
        "API",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "vector",
        "RAG",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "knowledge base",
        "RAG",
        "retrieval",
        "LLM",
        "model",
        "reasoning",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval",
        "product",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "prompt",
        "vector",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "SafeTalkCoach: Diversity-Driven Multi-Agent Simulation for Parent-Teen Health Conversations",
      "url": "https://arxiv.org/abs/2602.00017",
      "description": "arXiv:2602.00017v1 Announce Type: new \nAbstract: The importance of effective parent-child communication about sexual health is widely acknowledged, but real-world data on these conversations is scarce and challenging to collect, due to their private and sensitive nature. Although LLMs have been wide...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "LLM",
        "company",
        "arxiv",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "Reversible Diffusion Decoding for Diffusion Language Models",
      "url": "https://arxiv.org/abs/2602.00150",
      "description": "arXiv:2602.00150v1 Announce Type: new \nAbstract: Diffusion language models enable parallel token generation through block-wise decoding, but their irreversible commitments can lead to stagnation, where the reverse diffusion process fails to make further progress under a suboptimal context.We propose...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "experiment",
        "model",
        "arxiv",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "Distributional Reinforcement Learning for Condition-Based Maintenance of Multi-Pump Equipment",
      "url": "https://arxiv.org/abs/2602.00051",
      "description": "arXiv:2602.00051v1 Announce Type: new \nAbstract: Condition-Based Maintenance (CBM) signifies a paradigm shift from reactive to proactive equipment management strategies in modern industrial systems. Conventional time-based maintenance schedules frequently engender superfluous expenditures and unanti...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "paper",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "TextBFGS: Quasi-Newton Optimization for Discrete Executable Text via Gradient-Operator Retrieval",
      "url": "https://arxiv.org/abs/2602.00059",
      "description": "arXiv:2602.00059v1 Announce Type: new \nAbstract: Optimizing discrete executable text such as prompts and code has recently been framed as a gradient-based process, effectively translating backpropagation concepts to the semantic space. However, existing methods predominantly operate as first-order o...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "prompt",
        "knowledge base",
        "retrieval",
        "model",
        "arxiv",
        "framework",
        "memory"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "model",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Learning to Price: Interpretable Attribute-Level Models for Dynamic Markets",
      "url": "https://arxiv.org/abs/2602.00188",
      "description": "arXiv:2602.00188v1 Announce Type: new \nAbstract: Dynamic pricing in high-dimensional markets poses fundamental challenges of scalability, uncertainty, and interpretability. Existing low-rank bandit formulations learn efficiently but rely on latent features that obscure how individual product attribu...",
      "published_date": "2026-02-03T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "API",
        "model",
        "product"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "H Company's new Holo2 model takes the lead in UI Localization",
      "url": "https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b",
      "description": "...",
      "published_date": "2026-02-03T17:40:14",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model",
        "company"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Training Design for Text-to-Image Models: Lessons from Ablations",
      "url": "https://huggingface.co/blog/Photoroom/prx-part2",
      "description": "...",
      "published_date": "2026-02-03T11:25:53",
      "source": "Hugging Face Blog",
      "category": "multimodal_context",
      "keywords": [
        "model",
        "image"
      ],
      "score": 0.2
    }
  ]
}