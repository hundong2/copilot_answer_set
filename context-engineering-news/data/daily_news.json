{
  "generated_at": "2026-01-09T20:06:25.192469",
  "total_items": 44,
  "items": [
    {
      "title": "MedPI: Evaluating AI Systems in Medical Patient-facing Interactions",
      "url": "https://arxiv.org/abs/2601.04195",
      "description": "arXiv:2601.04195v1 Announce Type: new \nAbstract: We present MedPI, a high-dimensional benchmark for evaluating large language models (LLMs) in patient-clinician conversations. Unlike single-turn question-answer (QA) benchmarks, MedPI evaluates the medical dialogue across 105 dimensions comprising th...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "prompt",
        "framework",
        "LLM",
        "GPT",
        "model",
        "arxiv",
        "memory"
      ],
      "score": 1.0
    },
    {
      "title": "RAGVUE: A Diagnostic View for Explainable and Automated Evaluation of Retrieval-Augmented Generation",
      "url": "https://arxiv.org/abs/2601.04196",
      "description": "arXiv:2601.04196v1 Announce Type: new \nAbstract: Evaluating Retrieval-Augmented Generation (RAG) systems remains a challenging task: existing metrics often collapse heterogeneous behaviors into single scores and provide little insight into whether errors arise from retrieval,reasoning, or grounding....",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "reasoning",
        "paper",
        "augmented",
        "API",
        "framework",
        "experiment",
        "research",
        "retrieval",
        "RAG",
        "arxiv",
        "tool",
        "instruction",
        "ICL"
      ],
      "score": 1.0
    },
    {
      "title": "Automatic Construction of Chinese Verb Collostruction Database",
      "url": "https://arxiv.org/abs/2601.04197",
      "description": "arXiv:2601.04197v1 Announce Type: new \nAbstract: This paper proposes a fully unsupervised approach to the construction of verb collostruction database for Chinese language, aimed at complementing LLMs by providing explicit and interpretable rules for application scenarios where explanation and inter...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "analysis",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Attribute-Aware Controlled Product Generation with LLMs for E-commerce",
      "url": "https://arxiv.org/abs/2601.04200",
      "description": "arXiv:2601.04200v1 Announce Type: new \nAbstract: Product information extraction is crucial for e-commerce services, but obtaining high-quality labeled datasets remains challenging. We present a systematic approach for generating synthetic e-commerce product data using Large Language Models (LLMs), i...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "prompt",
        "zero-shot",
        "framework",
        "LLM",
        "model",
        "arxiv",
        "product",
        "example"
      ],
      "score": 1.0
    },
    {
      "title": "Collective Narrative Grounding: Community-Coordinated Data Contributions to Improve Local AI Systems",
      "url": "https://arxiv.org/abs/2601.04201",
      "description": "arXiv:2601.04201v1 Announce Type: new \nAbstract: Large language model (LLM) question-answering systems often fail on community-specific queries, creating \"knowledge blind spots\" that marginalize local voices and reinforce epistemic injustice. We present Collective Narrative Grounding, a participator...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "LLM",
        "model",
        "context",
        "retrieval",
        "arxiv",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "TeleTables: A Benchmark for Large Language Models in Telecom Table Interpretation",
      "url": "https://arxiv.org/abs/2601.04202",
      "description": "arXiv:2601.04202v1 Announce Type: new \nAbstract: Language Models (LLMs) are increasingly explored in the telecom industry to support engineering tasks, accelerate troubleshooting, and assist in interpreting complex technical documents. However, recent studies show that LLMs perform poorly on telecom...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "large language model",
        "reasoning",
        "multimodal",
        "LLM",
        "model",
        "arxiv",
        "fine-tuning",
        "ICL"
      ],
      "score": 1.0
    },
    {
      "title": "FronTalk: Benchmarking Front-End Development as Conversational Code Generation with Multi-Modal Feedback",
      "url": "https://arxiv.org/abs/2601.04203",
      "description": "arXiv:2601.04203v1 Announce Type: new \nAbstract: We present FronTalk, a benchmark for front-end code generation that pioneers the study of a unique interaction dynamic: conversational code generation with multi-modal feedback. In front-end development, visual artifacts such as sketches, mockups and ...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "study",
        "vision",
        "research",
        "model",
        "RAG",
        "arxiv",
        "release",
        "instruction"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing Admission Inquiry Responses with Fine-Tuned Models and Retrieval-Augmented Generation",
      "url": "https://arxiv.org/abs/2601.04206",
      "description": "arXiv:2601.04206v1 Announce Type: new \nAbstract: University admissions offices face the significant challenge of managing high volumes of inquiries efficiently while maintaining response quality, which critically impacts prospective students' perceptions. This paper addresses the issues of response ...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "paper",
        "augmented",
        "experiment",
        "model",
        "context",
        "RAG",
        "retrieval",
        "arxiv",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "Ideology as a Problem: Lightweight Logit Steering for Annotator-Specific Alignment in Social Media Analysis",
      "url": "https://arxiv.org/abs/2601.04207",
      "description": "arXiv:2601.04207v1 Announce Type: new \nAbstract: LLMs internally organize political ideology along low-dimensional structures that are partially, but not fully aligned with human ideological space. This misalignment is systematic, model specific, and measurable. We introduce a lightweight linear pro...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "reasoning",
        "paper",
        "analysis",
        "LLM",
        "model",
        "arxiv",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Digital Red Queen: Adversarial Program Evolution in Core War with LLMs",
      "url": "https://arxiv.org/abs/2601.03335",
      "description": "arXiv:2601.03335v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optim...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "framework",
        "study",
        "LLM",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization",
      "url": "https://arxiv.org/abs/2601.03359",
      "description": "arXiv:2601.03359v1 Announce Type: new \nAbstract: Large Language Models (LLMs) often generate substantively relevant content but fail to adhere to formal constraints, leading to outputs that are conceptually correct but procedurally flawed. Traditional prompt refinement approaches focus on rephrasing...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "prompt",
        "LLM",
        "model",
        "arxiv",
        "instruction"
      ],
      "score": 1.0
    },
    {
      "title": "CPGPrompt: Translating Clinical Guidelines into LLM-Executable Decision Support",
      "url": "https://arxiv.org/abs/2601.03475",
      "description": "arXiv:2601.03475v1 Announce Type: new \nAbstract: Clinical practice guidelines (CPGs) provide evidence-based recommendations for patient care; however, integrating them into Artificial Intelligence (AI) remains challenging. Previous approaches, such as rule-based systems, face significant limitations...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "reasoning",
        "prompt",
        "framework",
        "LLM",
        "prompting",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Personalization of Large Foundation Models for Health Interventions",
      "url": "https://arxiv.org/abs/2601.03482",
      "description": "arXiv:2601.03482v1 Announce Type: new \nAbstract: Large foundation models (LFMs) transform healthcare AI in prevention, diagnostics, and treatment. However, whether LFMs can provide truly personalized treatment recommendations remains an open question. Recent research has revealed multiple challenges...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "multimodal",
        "paper",
        "API",
        "framework",
        "experiment",
        "study",
        "research",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Evolving Programmatic Skill Networks",
      "url": "https://arxiv.org/abs/2601.03509",
      "description": "arXiv:2601.03509v1 Announce Type: new \nAbstract: We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are exe...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "large language model",
        "API",
        "framework",
        "experiment",
        "study",
        "model",
        "arxiv",
        "library"
      ],
      "score": 1.0
    },
    {
      "title": "STAR-S: Improving Safety Alignment through Self-Taught Reasoning on Safety Rules",
      "url": "https://arxiv.org/abs/2601.03537",
      "description": "arXiv:2601.03537v1 Announce Type: new \nAbstract: Defending against jailbreak attacks is crucial for the safe deployment of Large Language Models (LLMs). Recent research has attempted to improve safety by training models to reason over safety rules before responding. However, a key issue lies in dete...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "reasoning",
        "prompt",
        "framework",
        "experiment",
        "LLM",
        "research",
        "model",
        "RAG",
        "arxiv",
        "alignment",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "The Forgotten Shield: Safety Grafting in Parameter-Space for Medical MLLMs",
      "url": "https://arxiv.org/abs/2601.04199",
      "description": "arXiv:2601.04199v1 Announce Type: new \nAbstract: Medical Multimodal Large Language Models (Medical MLLMs) have achieved remarkable progress in specialized medical tasks; however, research into their safety has lagged, posing potential risks for real-world deployment. In this paper, we first establis...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "multimodal",
        "cross-modal",
        "paper",
        "framework",
        "experiment",
        "analysis",
        "LLM",
        "research",
        "model",
        "RAG",
        "arxiv",
        "alignment",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis",
      "url": "https://arxiv.org/abs/2601.04262",
      "description": "arXiv:2601.04262v1 Announce Type: new \nAbstract: Safety alignment in Large Language Models (LLMs) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geom...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "attention",
        "transformer",
        "framework",
        "experiment",
        "LLM",
        "model",
        "arxiv",
        "alignment",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "MemKD: Memory-Discrepancy Knowledge Distillation for Efficient Time Series Classification",
      "url": "https://arxiv.org/abs/2601.04264",
      "description": "arXiv:2601.04264v1 Announce Type: new \nAbstract: Deep learning models, particularly recurrent neural networks and their variants, such as long short-term memory, have significantly advanced time series data analysis. These models capture complex, sequential patterns in time series, enabling real-tim...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "platform",
        "framework",
        "experiment",
        "analysis",
        "vision",
        "model",
        "RAG",
        "arxiv",
        "memory"
      ],
      "score": 1.0
    },
    {
      "title": "Unlocking the Pre-Trained Model as a Dual-Alignment Calibrator for Post-Trained LLMs",
      "url": "https://arxiv.org/abs/2601.04277",
      "description": "arXiv:2601.04277v1 Announce Type: new \nAbstract: Post-training improves large language models (LLMs) but often worsens confidence calibration, leading to systematic overconfidence. Recent unsupervised post-hoc methods for post-trained LMs (PoLMs) mitigate this by aligning PoLM confidence to that of ...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "framework",
        "experiment",
        "LLM",
        "model",
        "arxiv",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt engineering",
        "context",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "reasoning",
        "chain-of-thought",
        "framework",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "API",
        "LLM",
        "model",
        "context",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "context",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "reasoning",
        "framework",
        "vector",
        "LLM",
        "knowledge base",
        "model",
        "retrieval",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "API",
        "retrieval",
        "RAG",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "prompt",
        "framework",
        "vector",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Learning to Reason: Temporal Saliency Distillation for Interpretable Knowledge Transfer",
      "url": "https://arxiv.org/abs/2601.04263",
      "description": "arXiv:2601.04263v1 Announce Type: new \nAbstract: Knowledge distillation has proven effective for model compression by transferring knowledge from a larger network called the teacher to a smaller network called the student. Current knowledge distillation in time series is predominantly based on logit...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "reasoning",
        "compression",
        "vision",
        "analysis",
        "model",
        "RAG",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "LEGATO: Good Identity Unlearning Is Continuous",
      "url": "https://arxiv.org/abs/2601.04282",
      "description": "arXiv:2601.04282v1 Announce Type: new \nAbstract: Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget id...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "experiment",
        "fine-tuning",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "context",
        "tool",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Green MLOps: Closed-Loop, Energy-Aware Inference with NVIDIA Triton, FastAPI, and Bio-Inspired Thresholding",
      "url": "https://arxiv.org/abs/2601.04250",
      "description": "arXiv:2601.04250v1 Announce Type: new \nAbstract: Energy efficiency is a first-order concern in AI deployment, as long-running inference can exceed training in cumulative carbon impact. We propose a bio-inspired framework that maps protein-folding energy basins to inference cost landscapes and contro...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "API",
        "framework",
        "study",
        "model",
        "arxiv",
        "product"
      ],
      "score": 0.6
    },
    {
      "title": "Predictable Gradient Manifolds in Deep Learning: Temporal Path-Length and Intrinsic Rank as a Complexity Regime",
      "url": "https://arxiv.org/abs/2601.04270",
      "description": "arXiv:2601.04270v1 Announce Type: new \nAbstract: Deep learning optimization exhibits structure that is not captured by worst-case gradient bounds. Empirically, gradients along training trajectories are often temporally predictable and evolve within a low-dimensional subspace. In this work we formali...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "framework",
        "transformer",
        "vision",
        "model",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Generation of synthetic delay time series for air transport applications",
      "url": "https://arxiv.org/abs/2601.04279",
      "description": "arXiv:2601.04279v1 Announce Type: new \nAbstract: The generation of synthetic data is receiving increasing attention from the scientific community, thanks to its ability to solve problems like data scarcity and privacy, and is starting to find applications in air transport. We here tackle the problem...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "model",
        "attention",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Exploration Through Introspection: A Self-Aware Reward Model",
      "url": "https://arxiv.org/abs/2601.03389",
      "description": "arXiv:2601.03389v1 Announce Type: new \nAbstract: Understanding how artificial agents model internal mental states is central to advancing Theory of Mind in AI. Evidence points to a unified system for self- and other-awareness. We explore this self-awareness by having reinforcement learning agents in...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "framework",
        "study",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Toward Maturity-Based Certification of Embodied AI: Quantifying Trustworthiness Through Measurement Mechanisms",
      "url": "https://arxiv.org/abs/2601.03470",
      "description": "arXiv:2601.03470v2 Announce Type: new \nAbstract: We propose a maturity-based framework for certifying embodied AI systems through explicit measurement mechanisms. We argue that certifiable embodied AI requires structured assessment frameworks, quantitative scoring mechanisms, and methods for navigat...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "study",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Making Tunable Parameters State-Dependent in Weather and Climate Models with Reinforcement Learning",
      "url": "https://arxiv.org/abs/2601.04268",
      "description": "arXiv:2601.04268v1 Announce Type: new \nAbstract: Weather and climate models rely on parametrisations to represent unresolved sub-grid processes. Traditional schemes rely on fixed coefficients that are weakly constrained and tuned offline, contributing to persistent biases that limit their ability to...",
      "published_date": "2026-01-09T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "framework",
        "study",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}