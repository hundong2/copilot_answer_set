{
  "generated_at": "2026-02-05T20:10:18.325317",
  "total_items": 50,
  "items": [
    {
      "title": "Automatic Classification of Pedagogical Materials against CS Curriculum Guidelines",
      "url": "https://arxiv.org/abs/2602.03962",
      "description": "arXiv:2602.03962v1 Announce Type: new \nAbstract: Professional societies often publish curriculum guidelines to help programs align their content to international standards. In Computer Science, the primary standard is published by ACM and IEEE and provide detailed guidelines for what should be and c...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "embedding",
        "arxiv",
        "RAG",
        "model",
        "large language model",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Likelihood-Based Reward Designs for General LLM Reasoning",
      "url": "https://arxiv.org/abs/2602.03979",
      "description": "arXiv:2602.03979v1 Announce Type: new \nAbstract: Fine-tuning large language models (LLMs) on reasoning benchmarks via reinforcement learning requires a specific reward function, often binary, for each benchmark. This comes with two potential limitations: the need to design the reward, and the potent...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "fine-tuning",
        "arxiv",
        "reasoning",
        "LLM",
        "CoT",
        "prompt",
        "model",
        "large language model",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "Transformers perform adaptive partial pooling",
      "url": "https://arxiv.org/abs/2602.03980",
      "description": "arXiv:2602.03980v1 Announce Type: new \nAbstract: Because language is creative, any reasonable language model must generalize, deciding what to say in novel contexts by using information from similar contexts. But what about contexts that are not novel but merely infrequent? In hierarchical regressio...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "arxiv",
        "transformer",
        "context",
        "paper",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "On the Credibility of Evaluating LLMs using Survey Questions",
      "url": "https://arxiv.org/abs/2602.04033",
      "description": "arXiv:2602.04033v1 Announce Type: new \nAbstract: Recent studies evaluate the value orientation of large language models (LLMs) using adapted social surveys, typically by prompting models with survey questions and comparing their responses to average human responses. This paper identifies limitations...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "alignment",
        "LLM",
        "analysis",
        "RAG",
        "paper",
        "research",
        "CoT",
        "prompt",
        "model",
        "large language model",
        "chain-of-thought",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Abstraction Induces the Brain Alignment of Language and Speech Models",
      "url": "https://arxiv.org/abs/2602.04081",
      "description": "arXiv:2602.04081v1 Announce Type: new \nAbstract: Research has repeatedly demonstrated that intermediate hidden states extracted from large language models and speech audio models predict measured brain response to natural language stimuli. Yet, very little is known about the representation propertie...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "audio",
        "arxiv",
        "alignment",
        "research",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Expert Selections In MoE Models Reveal (Almost) As Much As Text",
      "url": "https://arxiv.org/abs/2602.04105",
      "description": "arXiv:2602.04105v1 Announce Type: new \nAbstract: We present a text-reconstruction attack on mixture-of-experts (MoE) language models that recovers tokens from expert selections alone. In MoE models, each token is routed to a subset of expert subnetworks; we show these routing decisions leak substant...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "transformer",
        "embedding",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "The Missing Half: Unveiling Training-time Implicit Safety Risks Beyond Deployment",
      "url": "https://arxiv.org/abs/2602.04196",
      "description": "arXiv:2602.04196v1 Announce Type: new \nAbstract: Safety risks of AI models have been widely studied at deployment time, such as jailbreak attacks that elicit harmful outputs. In contrast, safety risks emerging during training remain largely unexplored. Beyond explicit reward hacking that directly ma...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "context",
        "experiment",
        "model",
        "example"
      ],
      "score": 1.0
    },
    {
      "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks",
      "url": "https://arxiv.org/abs/2602.03900",
      "description": "arXiv:2602.03900v1 Announce Type: new \nAbstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "reasoning",
        "study",
        "LLM",
        "context",
        "paper",
        "experiment",
        "CoT",
        "prompt",
        "model",
        "large language model",
        "framework",
        "chain-of-thought",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation",
      "url": "https://arxiv.org/abs/2602.03950",
      "description": "arXiv:2602.03950v1 Announce Type: new \nAbstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although r...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "reasoning",
        "LLM",
        "context",
        "model",
        "release",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent",
      "url": "https://arxiv.org/abs/2602.03955",
      "description": "arXiv:2602.03955v1 Announce Type: new \nAbstract: While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framewo...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "arxiv",
        "reasoning",
        "LLM",
        "paper",
        "research",
        "model",
        "large language model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Active Epistemic Control for Query-Efficient Verified Planning",
      "url": "https://arxiv.org/abs/2602.03974",
      "description": "arXiv:2602.03974v1 Announce Type: new \nAbstract: Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world ...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "LLM",
        "RAG",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure",
      "url": "https://arxiv.org/abs/2602.03975",
      "description": "arXiv:2602.03975v1 Announce Type: new \nAbstract: Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant ...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "reasoning",
        "study",
        "LLM",
        "model",
        "large language model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning",
      "url": "https://arxiv.org/abs/2602.03978",
      "description": "arXiv:2602.03978v1 Announce Type: new \nAbstract: As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal ...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "attention",
        "arxiv",
        "reasoning",
        "analysis",
        "CoT",
        "prompt",
        "model",
        "instruction",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making",
      "url": "https://arxiv.org/abs/2602.04003",
      "description": "arXiv:2602.04003v1 Announce Type: new \nAbstract: Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model rec...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "reasoning",
        "study",
        "LLM",
        "experiment",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL",
      "url": "https://arxiv.org/abs/2602.04089",
      "description": "arXiv:2602.04089v1 Announce Type: new \nAbstract: Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial ...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "in-context",
        "GPT",
        "fine-tuning",
        "arxiv",
        "LLM",
        "context",
        "RAG",
        "paper",
        "experiment",
        "model",
        "instruction",
        "large language model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Interfaze: The Future of AI is built on Task-Specific Small Models",
      "url": "https://arxiv.org/abs/2602.04101",
      "description": "arXiv:2602.04101v1 Announce Type: new \nAbstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "multimodal",
        "arxiv",
        "transformer",
        "LLM",
        "context",
        "model",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "GOPO: Policy Optimization using Ranked Rewards",
      "url": "https://arxiv.org/abs/2602.03876",
      "description": "arXiv:2602.03876v1 Announce Type: new \nAbstract: Standard reinforcement learning from human feedback (RLHF) trains a reward model on pairwise preference data and then uses it for policy optimization. However, while reward models are optimized to capture relative preferences, existing policy optimiza...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "RLHF",
        "alignment",
        "LLM",
        "model",
        "instruction",
        "summarization"
      ],
      "score": 1.0
    },
    {
      "title": "Causal Discovery for Cross-Sectional Data Based on Super-Structure and Divide-and-Conquer",
      "url": "https://arxiv.org/abs/2602.03914",
      "description": "arXiv:2602.03914v1 Announce Type: new \nAbstract: This paper tackles a critical bottleneck in Super-Structure-based divide-and-conquer causal discovery: the high computational cost of constructing accurate Super-Structures--particularly when conditional independence (CI) tests are expensive and domai...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "research",
        "paper",
        "experiment",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Online Vector Quantized Attention",
      "url": "https://arxiv.org/abs/2602.03922",
      "description": "arXiv:2602.03922v1 Announce Type: new \nAbstract: Standard sequence mixing layers used in language models struggle to balance efficiency and performance. Self-attention performs well on long context tasks but has expensive quadratic compute and linear memory costs, while linear attention and SSMs use...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "attention",
        "arxiv",
        "context",
        "memory",
        "paper",
        "model",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "context",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "reasoning",
        "CoT",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "LLM",
        "context",
        "model",
        "prompt",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "vector",
        "reasoning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "reasoning",
        "knowledge base",
        "LLM",
        "RAG",
        "retrieval",
        "model",
        "framework",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "product",
        "API",
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "prompt",
        "framework",
        "vector",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "Linguistic Blind Spots in Clinical Decision Extraction",
      "url": "https://arxiv.org/abs/2602.03942",
      "description": "arXiv:2602.03942v1 Announce Type: new \nAbstract: Extracting medical decisions from clinical notes is a key step for clinical decision support and patient-facing care summaries. We study how the linguistic characteristics of clinical decisions vary across decision categories and whether these differe...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "transformer",
        "model",
        "study",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "DELTA: Deliberative Multi-Agent Reasoning with Reinforcement Learning for Multimodal Psychological Counseling",
      "url": "https://arxiv.org/abs/2602.04112",
      "description": "arXiv:2602.04112v1 Announce Type: new \nAbstract: Psychological counseling is a fundamentally multimodal cognitive process in which clinicians integrate verbal content with visual and vocal cues to infer clients' mental states and respond empathically. However, most existing language-model-based coun...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "multimodal",
        "arxiv",
        "reasoning",
        "RAG",
        "experiment",
        "model",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "Understanding the Impact of Differentially Private Training on Memorization of Long-Tailed Data",
      "url": "https://arxiv.org/abs/2602.03872",
      "description": "arXiv:2602.03872v1 Announce Type: new \nAbstract: Recent research shows that modern deep learning models achieve high predictive accuracy partly by memorizing individual training samples. Such memorization raises serious privacy concerns, motivating the widespread adoption of differentially private t...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "experiment",
        "research",
        "model",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "GeoIB: Geometry-Aware Information Bottleneck via Statistical-Manifold Compression",
      "url": "https://arxiv.org/abs/2602.03906",
      "description": "arXiv:2602.03906v1 Announce Type: new \nAbstract: Information Bottleneck (IB) is widely used, but in deep learning, it is usually implemented through tractable surrogates, such as variational bounds or neural mutual information (MI) estimators, rather than directly controlling the MI I(X;Z) itself. T...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "compression",
        "arxiv",
        "RAG",
        "experiment",
        "release"
      ],
      "score": 0.8
    },
    {
      "title": "The Role of Target Update Frequencies in Q-Learning",
      "url": "https://arxiv.org/abs/2602.03911",
      "description": "arXiv:2602.03911v1 Announce Type: new \nAbstract: The target network update frequency (TUF) is a central stabilization mechanism in (deep) Q-learning. However, their selection remains poorly understood and is often treated merely as another tunable hyperparameter rather than as a principled design de...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "analysis",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Echo State Networks for Time Series Forecasting: Hyperparameter Sweep and Benchmarking",
      "url": "https://arxiv.org/abs/2602.03912",
      "description": "arXiv:2602.03912v1 Announce Type: new \nAbstract: This paper investigates the forecasting performance of Echo State Networks (ESNs) for univariate time series forecasting using a subset of the M4 Forecasting Competition dataset. Focusing on monthly and quarterly time series with at most 20 years of h...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "analysis",
        "paper",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "model",
        "tool",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Axiomatic Foundations of Counterfactual Explanations",
      "url": "https://arxiv.org/abs/2602.04028",
      "description": "arXiv:2602.04028v1 Announce Type: new \nAbstract: Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions coul...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "reasoning",
        "study",
        "paper",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "SpecMD: A Comprehensive Study On Speculative Expert Prefetching",
      "url": "https://arxiv.org/abs/2602.03921",
      "description": "arXiv:2602.03921v1 Announce Type: new \nAbstract: Mixture-of-Experts (MoE) models enable sparse expert activation, meaning that only a subset of the model's parameters is used during each inference. However, to translate this sparsity into practical performance, an expert caching mechanism is require...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "experiment",
        "model",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3â€™s Top Model",
      "url": "https://huggingface.co/blog/nvidia/nemotron-colembed-v2",
      "description": "...",
      "published_date": "2026-02-04T15:00:40",
      "source": "Hugging Face Blog",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "multimodal",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "From Lemmas to Dependencies: What Signals Drive Light Verbs Classification?",
      "url": "https://arxiv.org/abs/2602.04127",
      "description": "arXiv:2602.04127v1 Announce Type: new \nAbstract: Light verb constructions (LVCs) are a challenging class of verbal multiword expressions, especially in Turkish, where rich morphology and productive complex predicates create minimal contrasts between idiomatic predicate meanings and literal verb--arg...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "product",
        "arxiv",
        "paper",
        "vision",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "NeuroPareto: Calibrated Acquisition for Costly Many-Goal Search in Vast Parameter Spaces",
      "url": "https://arxiv.org/abs/2602.03901",
      "description": "arXiv:2602.03901v1 Announce Type: new \nAbstract: The pursuit of optimal trade-offs in high-dimensional search spaces under stringent computational constraints poses a fundamental challenge for contemporary multi-objective optimization. We develop NeuroPareto, a cohesive architecture that integrates ...",
      "published_date": "2026-02-05T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "API",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "H Company's new Holo2 model takes the lead in UI Localization",
      "url": "https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b",
      "description": "...",
      "published_date": "2026-02-03T17:40:14",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model",
        "company"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Training Design for Text-to-Image Models: Lessons from Ablations",
      "url": "https://huggingface.co/blog/Photoroom/prx-part2",
      "description": "...",
      "published_date": "2026-02-03T11:25:53",
      "source": "Hugging Face Blog",
      "category": "multimodal_context",
      "keywords": [
        "model",
        "image"
      ],
      "score": 0.2
    }
  ]
}