{
  "generated_at": "2026-02-11T20:12:45.612351",
  "total_items": 49,
  "items": [
    {
      "title": "Overview of PAN 2026: Voight-Kampff Generative AI Detection, Text Watermarking, Multi-Author Writing Style Analysis, Generative Plagiarism Detection, and Reasoning Trajectory Detection",
      "url": "https://arxiv.org/abs/2602.09147",
      "description": "arXiv:2602.09147v1 Announce Type: new \nAbstract: The goal of the PAN workshop is to advance computational stylometry and text forensics via objective and reproducible evaluation. In 2026, we run the following five tasks: (1) Voight-Kampff Generative AI Detection, particularly in mixed and obfuscated...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "retrieval",
        "platform",
        "analysis",
        "experiment",
        "LLM",
        "arxiv",
        "alignment",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Effective Reasoning Chains Reduce Intrinsic Dimensionality",
      "url": "https://arxiv.org/abs/2602.09276",
      "description": "arXiv:2602.09276v1 Announce Type: new \nAbstract: Chain-of-thought (CoT) reasoning and its variants have substantially improved the performance of language models on complex reasoning tasks, yet the precise mechanisms by which different strategies facilitate generalization remain poorly understood. W...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "chain-of-thought",
        "model",
        "arxiv",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Don't Shoot The Breeze: Topic Continuity Model Using Nonlinear Naive Bayes With Attention",
      "url": "https://arxiv.org/abs/2602.09312",
      "description": "arXiv:2602.09312v1 Announce Type: new \nAbstract: Utilizing Large Language Models (LLM) as chatbots in diverse business scenarios often presents the challenge of maintaining topic continuity. Abrupt shifts in topics can lead to poor user experiences and inefficient utilization of computational resour...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "attention",
        "experiment",
        "model",
        "LLM",
        "paper",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Understanding Risk and Dependency in AI Chatbot Use from User Discourse",
      "url": "https://arxiv.org/abs/2602.09339",
      "description": "arXiv:2602.09339v1 Announce Type: new \nAbstract: Generative AI systems are increasingly embedded in everyday life, yet empirical understanding of how psychological risk associated with AI use emerges, is experienced, and is regulated by users remains limited. We present a large-scale computational t...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "analysis",
        "framework",
        "context",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Digital Linguistic Bias in Spanish: Evidence from Lexical Variation in LLMs",
      "url": "https://arxiv.org/abs/2602.09346",
      "description": "arXiv:2602.09346v1 Announce Type: new \nAbstract: This study examines the extent to which Large Language Models (LLMs) capture geographic lexical variation in Spanish, a language that exhibits substantial regional variation. Treating LLMs as virtual informants, we probe their dialectal knowledge usin...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "study",
        "LLM",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Unsupervised Cross-Lingual Part-of-Speech Tagging with Monolingual Corpora Only",
      "url": "https://arxiv.org/abs/2602.09366",
      "description": "arXiv:2602.09366v1 Announce Type: new \nAbstract: Due to the scarcity of part-of-speech annotated data, existing studies on low-resource languages typically adopt unsupervised approaches for POS tagging. Among these, POS tag projection with word alignment method transfers POS tags from a high-resourc...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "experiment",
        "framework",
        "arxiv",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "AgentSkiller: Scaling Generalist Agent Intelligence through Semantically Integrated Cross-Domain Data Synthesis",
      "url": "https://arxiv.org/abs/2602.09372",
      "description": "arXiv:2602.09372v1 Announce Type: new \nAbstract: Large Language Model agents demonstrate potential in solving real-world problems via tools, yet generalist intelligence is bottlenecked by scarce high-quality, long-horizon data. Existing methods collect privacy-constrained API logs or generate script...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "large language model",
        "API",
        "framework",
        "experiment",
        "context",
        "tool",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation",
      "url": "https://arxiv.org/abs/2602.07032",
      "description": "arXiv:2602.07032v1 Announce Type: new \nAbstract: Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machi...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "prompt",
        "example",
        "experiment",
        "fine-tuning",
        "model",
        "context",
        "LLM",
        "paper",
        "arxiv",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "ST-Raptor: An Agentic System for Semi-Structured Table QA",
      "url": "https://arxiv.org/abs/2602.07034",
      "description": "arXiv:2602.07034v1 Announce Type: new \nAbstract: Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "demonstration",
        "multimodal",
        "analysis",
        "experiment",
        "LLM",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
      "url": "https://arxiv.org/abs/2602.07035",
      "description": "arXiv:2602.07035v1 Announce Type: new \nAbstract: Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, thei...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "large language model",
        "API",
        "RAG",
        "tool",
        "fine-tuning",
        "instruction",
        "framework",
        "experiment",
        "model",
        "LLM",
        "paper",
        "arxiv",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
      "url": "https://arxiv.org/abs/2602.07153",
      "description": "arXiv:2602.07153v1 Announce Type: new \nAbstract: End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drift...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "demonstration",
        "zero-shot",
        "framework",
        "experiment",
        "instruction",
        "context",
        "vision",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Is there \"Secret Sauce'' in Large Language Model Development?",
      "url": "https://arxiv.org/abs/2602.07238",
      "description": "arXiv:2602.07238v1 Announce Type: new \nAbstract: Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-dat...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "large language model",
        "LLM",
        "model",
        "arxiv",
        "release"
      ],
      "score": 1.0
    },
    {
      "title": "Enhanced Graph Transformer with Serialized Graph Tokens",
      "url": "https://arxiv.org/abs/2602.09065",
      "description": "arXiv:2602.09065v1 Announce Type: new \nAbstract: Transformers have demonstrated success in graph learning, particularly for node-level tasks. However, existing methods encounter an information bottleneck when generating graph-level representations. The prevalent single token paradigm fails to fully ...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "transformer",
        "attention",
        "RAG",
        "experiment",
        "model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Spectral Disentanglement and Enhancement: A Dual-domain Contrastive Framework for Representation Learning",
      "url": "https://arxiv.org/abs/2602.09066",
      "description": "arXiv:2602.09066v1 Announce Type: new \nAbstract: Large-scale multimodal contrastive learning has recently achieved impressive success in learning rich and transferable representations, yet it remains fundamentally limited by the uniform treatment of feature dimensions and the neglect of the intrinsi...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "multimodal",
        "RAG",
        "framework",
        "experiment",
        "model",
        "arxiv",
        "alignment",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Learning to Remember, Learn, and Forget in Attention-Based Models",
      "url": "https://arxiv.org/abs/2602.09075",
      "description": "arXiv:2602.09075v1 Announce Type: new \nAbstract: In-Context Learning (ICL) in transformers acts as an online associative memory and is believed to underpin their high performance on complex sequence processing tasks. However, in gated linear attention models, this memory has a fixed capacity and is ...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "in-context",
        "ICL",
        "transformer",
        "attention",
        "experiment",
        "arxiv",
        "context",
        "model",
        "memory",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Distributed Hybrid Parallelism for Large Language Models: Comparative Study and System Design Guide",
      "url": "https://arxiv.org/abs/2602.09109",
      "description": "arXiv:2602.09109v1 Announce Type: new \nAbstract: With the rapid growth of large language models (LLMs), a wide range of methods have been developed to distribute computation and memory across hardware devices for efficient training and inference. While existing surveys provide descriptive overviews ...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "large language model",
        "API",
        "study",
        "analysis",
        "model",
        "arxiv",
        "LLM",
        "paper",
        "memory"
      ],
      "score": 1.0
    },
    {
      "title": "Benchmarking the Energy Savings with Speculative Decoding Strategies",
      "url": "https://arxiv.org/abs/2602.09113",
      "description": "arXiv:2602.09113v1 Announce Type: new \nAbstract: Speculative decoding has emerged as an effective method to reduce latency and inference cost of LLM inferences. However, there has been inadequate attention towards the energy requirements of these models. To address this gap, this paper presents a co...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "analysis",
        "model",
        "LLM",
        "paper",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt engineering",
        "prompt",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "framework",
        "chain-of-thought",
        "audio",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "prompt",
        "tool",
        "context",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "vector",
        "reasoning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "vector",
        "RAG",
        "knowledge base",
        "framework",
        "LLM",
        "model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "API",
        "augmented",
        "RAG",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "prompt",
        "platform",
        "framework",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond Uniform Credit: Causal Credit Assignment for Policy Optimization",
      "url": "https://arxiv.org/abs/2602.09331",
      "description": "arXiv:2602.09331v1 Announce Type: new \nAbstract: Policy gradient methods for language model reasoning, such as GRPO and DAPO, assign uniform credit to all generated tokens - the filler phrase \"Let me think\" receives the same gradient update as the critical calculation \"23 + 45 = 68.\" We propose coun...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "analysis",
        "experiment",
        "model",
        "arxiv",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
      "url": "https://arxiv.org/abs/2602.07040",
      "description": "arXiv:2602.07040v1 Announce Type: new \nAbstract: We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improv...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "analysis",
        "framework",
        "GPT",
        "model",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Looping Back to Move Forward: Recursive Transformers for Efficient and Flexible Large Multimodal Models",
      "url": "https://arxiv.org/abs/2602.09080",
      "description": "arXiv:2602.09080v1 Announce Type: new \nAbstract: Large Multimodal Models (LMMs) have achieved remarkable success in vision-language tasks, yet their vast parameter counts are often underutilized during both training and inference. In this work, we embrace the idea of looping back to move forward: re...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "multimodal",
        "transformer",
        "experiment",
        "vision",
        "model",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "context",
        "tool",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Measuring Inclusion in Interaction: Inclusion Analytics for Human-AI Collaborative Learning",
      "url": "https://arxiv.org/abs/2602.09269",
      "description": "arXiv:2602.09269v1 Announce Type: new \nAbstract: Inclusion, equity, and access are widely valued in AI and education, yet are often assessed through coarse sample descriptors or post-hoc self-reports that miss how inclusion is shaped moment by moment in collaborative problem solving (CPS). In this p...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "framework",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents",
      "url": "https://arxiv.org/abs/2602.07187",
      "description": "arXiv:2602.07187v1 Announce Type: new \nAbstract: Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe ...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "model",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View",
      "url": "https://arxiv.org/abs/2602.07253",
      "description": "arXiv:2602.07253v1 Announce Type: new \nAbstract: Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain l...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "large language model",
        "vision",
        "model",
        "arxiv",
        "reasoning"
      ],
      "score": 0.6
    },
    {
      "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective",
      "url": "https://arxiv.org/abs/2602.07259",
      "description": "arXiv:2602.07259v1 Announce Type: new \nAbstract: As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety fra...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "model",
        "arxiv",
        "alignment",
        "reasoning"
      ],
      "score": 0.6
    },
    {
      "title": "DMamba: Decomposition-enhanced Mamba for Time Series Forecasting",
      "url": "https://arxiv.org/abs/2602.09081",
      "description": "arXiv:2602.09081v1 Announce Type: new \nAbstract: State Space Models (SSMs), particularly Mamba, have shown potential in long-term time series forecasting. However, existing Mamba-based architectures often struggle with datasets characterized by non-stationary patterns. A key observation from time se...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "experiment",
        "paper",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "FM SO.P: A Progressive Task Mixture Framework with Automatic Evaluation for Cross-Domain SOP Understanding",
      "url": "https://arxiv.org/abs/2602.09336",
      "description": "arXiv:2602.09336v1 Announce Type: new \nAbstract: Standard Operating Procedures (SOPs) are critical for enterprise operations, yet existing language models struggle with SOP understanding and cross-domain generalization. Current methods fail because joint training cannot differentiate between reasoni...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "library",
        "framework",
        "model",
        "arxiv",
        "reasoning"
      ],
      "score": 0.4
    },
    {
      "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
      "url": "https://arxiv.org/abs/2602.07055",
      "description": "arXiv:2602.07055v1 Announce Type: new \nAbstract: Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We prop...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "multimodal",
        "prompt",
        "vision",
        "model",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Patient foundation model for risk stratification in low-risk overweight patients",
      "url": "https://arxiv.org/abs/2602.09079",
      "description": "arXiv:2602.09079v1 Announce Type: new \nAbstract: Accurate risk stratification in patients with overweight or obesity is critical for guiding preventive care and allocating high-cost therapies such as GLP-1 receptor agonists. We present PatientTPP, a neural temporal point process (TPP) model trained ...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "API",
        "model",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "From Adam to Adam-Like Lagrangians: Second-Order Nonlocal Dynamics",
      "url": "https://arxiv.org/abs/2602.09101",
      "description": "arXiv:2602.09101v1 Announce Type: new \nAbstract: In this paper, we derive an accelerated continuous-time formulation of Adam by modeling it as a second-order integro-differential dynamical system. We relate this inertial nonlocal model to an existing first-order nonlocal Adam flow through an $\\alpha...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "paper",
        "arxiv",
        "example"
      ],
      "score": 0.4
    },
    {
      "title": "Importance inversion transfer identifies shared principles for cross-domain learning",
      "url": "https://arxiv.org/abs/2602.09116",
      "description": "arXiv:2602.09116v1 Announce Type: new \nAbstract: The capacity to transfer knowledge across scientific domains relies on shared organizational principles. However, existing transfer-learning methodologies often fail to bridge radically heterogeneous systems, particularly under severe data scarcity or...",
      "published_date": "2026-02-11T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "study",
        "framework",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Transformers.js v4 Preview: Now Available on NPM!",
      "url": "https://huggingface.co/blog/transformersjs-v4",
      "description": "...",
      "published_date": "2026-02-09T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "transformer"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}