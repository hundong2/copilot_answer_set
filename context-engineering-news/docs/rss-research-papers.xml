<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2507.17842</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17842</guid>
      <description>arXiv:2507.17842v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have recently demonstrated strong potential in generating &amp;#x27;believable human-like&amp;#x27; behavior in web environments. Prior work has explored augmenting training data with LLM-synthesized rationales and applying supervised fine-...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, experiment, large language model, framework, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>fine-tuning</category>
      <category>experiment</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Dynamic and Generalizable Process Reward Modeling</title>
      <link>https://arxiv.org/abs/2507.17849</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17849</guid>
      <description>arXiv:2507.17849v1 Announce Type: new 
Abstract: Process Reward Models (PRMs) are crucial for guiding Large Language Models (LLMs) in complex scenarios by providing dense reward signals. However, existing PRMs primarily rely on heuristic approaches, which struggle with cross-domain generalization. W...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, vision, research, analysis, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>vision</category>
      <category>research</category>
    </item>
    <item>
      <title>VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL</title>
      <link>https://arxiv.org/abs/2507.17896</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17896</guid>
      <description>arXiv:2507.17896v1 Announce Type: new 
Abstract: Application systems using natural language interfaces to databases (NLIDBs) have democratized data analysis. This positive development has also brought forth an urgent challenge to help users who might use these systems without a background in statist...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, analysis, prompt, framework, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>analysis</category>
      <category>prompt</category>
    </item>
    <item>
      <title>NeuralDB: Scaling Knowledge Editing in LLMs to 100,000 Facts with Neural KV Database</title>
      <link>https://arxiv.org/abs/2507.18028</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.18028</guid>
      <description>arXiv:2507.18028v1 Announce Type: new 
Abstract: Efficiently editing knowledge stored in large language models (LLMs) enables model updates without large-scale training. One possible solution is Locate-and-Edit (L\&amp;amp;amp;E), allowing simultaneous modifications of a massive number of facts. However, su...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, arxiv, large language model, GPT, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>arxiv</category>
      <category>large language model</category>
    </item>
    <item>
      <title>I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis</title>
      <link>https://arxiv.org/abs/2507.17874</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17874</guid>
      <description>arXiv:2507.17874v1 Announce Type: new 
Abstract: Recent advances in agentic systems for data analysis have emphasized automation of insight generation through multi-agent frameworks, and orchestration layers. While these systems effectively manage tasks like query translation, data transformation, a...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; alignment, analysis, large language model, framework, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>alignment</category>
      <category>analysis</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Does visualization help AI understand data?</title>
      <link>https://arxiv.org/abs/2507.18022</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.18022</guid>
      <description>arXiv:2507.18022v1 Announce Type: new 
Abstract: Charts and graphs help people analyze data, but can they also be useful to AI systems? To investigate this question, we perform a series of experiments with two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three representative ana...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, vision, analysis, GPT, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>vision</category>
      <category>analysis</category>
    </item>
    <item>
      <title>AlphaGo Moment for Model Architecture Discovery</title>
      <link>https://arxiv.org/abs/2507.18074</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.18074</guid>
      <description>arXiv:2507.18074v1 Announce Type: new 
Abstract: While AI systems demonstrate exponentially improving capabilities, the pace of AI research itself remains linearly bounded by human cognitive capacity, creating an increasingly severe development bottleneck. We present ASI-Arch, the first demonstratio...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, analysis, research, attention, demonstration | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>analysis</category>
      <category>research</category>
    </item>
    <item>
      <title>Self-similarity Analysis in Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2507.17785</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17785</guid>
      <description>arXiv:2507.17785v1 Announce Type: new 
Abstract: Current research has found that some deep neural networks exhibit strong hierarchical self-similarity in feature representation or parameter distribution. However, aside from preliminary studies on how the power-law distribution of weights across diff...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, study, research, analysis, attention | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>study</category>
      <category>research</category>
    </item>
    <item>
      <title>Adaptive Repetition for Mitigating Position Bias in LLM-Based Ranking</title>
      <link>https://arxiv.org/abs/2507.17788</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17788</guid>
      <description>arXiv:2507.17788v1 Announce Type: new 
Abstract: When using LLMs to rank items based on given criteria, or evaluate answers, the order of candidate items can influence the model&amp;#x27;s final decision. This sensitivity to item positioning in a LLM&amp;#x27;s prompt is known as position bias. Prior research shows t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; alignment, research, prompt, LLM, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>alignment</category>
      <category>research</category>
      <category>prompt</category>
    </item>
    <item>
      <title>Synthesis of timeline-based planning strategies avoiding determinization</title>
      <link>https://arxiv.org/abs/2507.17988</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17988</guid>
      <description>arXiv:2507.17988v1 Announce Type: new 
Abstract: Qualitative timeline-based planning models domains as sets of independent, but
  interacting, components whose behaviors over time, the timelines, are governed
  by sets of qualitative temporal constraints (ordering relations), called
  synchronizatio...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, paper, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>paper</category>
      <category>model</category>
    </item>
    <item>
      <title>Multi-Agent Guided Policy Optimization</title>
      <link>https://arxiv.org/abs/2507.18059</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.18059</guid>
      <description>arXiv:2507.18059v1 Announce Type: new 
Abstract: Due to practical constraints such as partial observability and limited communication, Centralized Training with Decentralized Execution (CTDE) has become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning (MARL). However, existing...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, RAG, framework, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>RAG</category>
      <category>framework</category>
    </item>
    <item>
      <title>Knowledge Abstraction for Knowledge-based Semantic Communication: A Generative Causality Invariant Approach</title>
      <link>https://arxiv.org/abs/2507.17784</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17784</guid>
      <description>arXiv:2507.17784v1 Announce Type: new 
Abstract: In this study, we design a low-complexity and generalized AI model that can capture common knowledge to improve data reconstruction of the channel decoder for semantic communication. Specifically, we propose a generative adversarial network that lever...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; compression, study, RAG, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>compression</category>
      <category>study</category>
      <category>RAG</category>
    </item>
    <item>
      <title>CoCAI: Copula-based Conformal Anomaly Identification for Multivariate Time-Series</title>
      <link>https://arxiv.org/abs/2507.17796</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17796</guid>
      <description>arXiv:2507.17796v1 Announce Type: new 
Abstract: We propose a novel framework that harnesses the power of generative artificial intelligence and copula-based modeling to address two critical challenges in multivariate time-series analysis: delivering accurate predictions and enabling robust anomaly ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, framework, RAG, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>framework</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Natural Language Processing for Tigrinya: Current State and Future Directions</title>
      <link>https://arxiv.org/abs/2507.17974</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17974</guid>
      <description>arXiv:2507.17974v1 Announce Type: new 
Abstract: Despite being spoken by millions of people, Tigrinya remains severely underrepresented in Natural Language Processing (NLP) research. This work presents a comprehensive survey of NLP research for Tigrinya, analyzing over 40 studies spanning more than ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; ICL, research, analysis, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>ICL</category>
      <category>research</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Helix 1.0: An Open-Source Framework for Reproducible and Interpretable Machine Learning on Tabular Scientific Data</title>
      <link>https://arxiv.org/abs/2507.17791</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17791</guid>
      <description>arXiv:2507.17791v1 Announce Type: new 
Abstract: Helix is an open-source, extensible, Python-based software framework to facilitate reproducible and interpretable machine learning workflows for tabular data. It addresses the growing need for transparent experimental data analytics provenance, ensuri...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, research, release, framework, platform | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>research</category>
      <category>release</category>
    </item>
    <item>
      <title>Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes</title>
      <link>https://arxiv.org/abs/2507.18123</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.18123</guid>
      <description>arXiv:2507.18123v1 Announce Type: new 
Abstract: The rapid development of COVID-19 vaccines has showcased the global communitys ability to combat infectious diseases. However, the need for post-licensure surveillance systems has grown due to the limited window for safety data collection in clinical ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; API, model, study, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>API</category>
      <category>model</category>
      <category>study</category>
    </item>
    <item>
      <title>Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction</title>
      <link>https://arxiv.org/abs/2507.17768</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2507.17768</guid>
      <description>arXiv:2507.17768v1 Announce Type: new 
Abstract: With the development of mobile and edge computing, the demand for low-bit quantized models on edge devices is increasing to achieve efficient deployment. To enhance the performance, it is often necessary to retrain the quantized models using edge data...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, image, framework, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 25 Jul 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>image</category>
      <category>framework</category>
    </item>
  </channel>
</rss>