<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Mapping Toxic Comments Across Demographics: A Dataset from German Public Broadcasting</title>
      <link>https://arxiv.org/abs/2508.21084</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21084</guid>
      <description>arXiv:2508.21084v1 Announce Type: new 
Abstract: A lack of demographic context in existing toxic speech datasets limits our understanding of how different age groups communicate online. In collaboration with funk, a German public service content network, this research introduces the first large-scal...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; platform, LLM, research, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>platform</category>
      <category>LLM</category>
      <category>research</category>
    </item>
    <item>
      <title>TrInk: Ink Generation with Transformer Network</title>
      <link>https://arxiv.org/abs/2508.21098</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21098</guid>
      <description>arXiv:2508.21098v1 Announce Type: new 
Abstract: In this paper, we propose TrInk, a Transformer-based model for ink generation, which effectively captures global dependencies. To better facilitate the alignment between the input text and generated stroke points, we introduce scaled positional embedd...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; attention, embedding, experiment, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>attention</category>
      <category>embedding</category>
      <category>experiment</category>
    </item>
    <item>
      <title>How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations</title>
      <link>https://arxiv.org/abs/2508.21137</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21137</guid>
      <description>arXiv:2508.21137v1 Announce Type: new 
Abstract: Cognitive biases, well-studied in humans, can also be observed in LLMs, affecting their reliability in real-world applications. This paper investigates the anchoring effect in LLM-driven price negotiations. To this end, we instructed seller LLM agents...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, experiment, LLM, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>experiment</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?</title>
      <link>https://arxiv.org/abs/2508.21143</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21143</guid>
      <description>arXiv:2508.21143v1 Announce Type: new 
Abstract: The reasoning abilities of Multimodal Large Language Models (MLLMs) have garnered a lot of attention in recent times, with advances made in frontiers like coding, mathematics, and science. However, very limited experiments have been done to assess the...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, attention, LLM, experiment, multimodal | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>attention</category>
      <category>LLM</category>
    </item>
    <item>
      <title>A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers</title>
      <link>https://arxiv.org/abs/2508.21148</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21148</guid>
      <description>arXiv:2508.21148v1 Announce Type: new 
Abstract: Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is represented, integrated, and applied in scientific research, yet their progress is shaped by the complex nature of scientific data. This survey presents a comprehensive, dat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, experiment, LLM, multimodal, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>experiment</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations</title>
      <link>https://arxiv.org/abs/2508.21164</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21164</guid>
      <description>arXiv:2508.21164v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used to evaluate outputs, yet their judgments may be influenced. This study examines bias in self- and cross-model evaluations by ChatGPT, Gemini, and Claude under four conditions: no labels, true labels, ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, arxiv, model, GPT, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization</title>
      <link>https://arxiv.org/abs/2508.21201</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21201</guid>
      <description>arXiv:2508.21201v1 Announce Type: new 
Abstract: Analyzing the human factors behind aviation accidents is crucial for preventing future incidents, yet traditional methods using the Human Factors Analysis and Classification System (HFACS) are limited by scalability and consistency. To address this, w...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, LLM, research, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>LLM</category>
      <category>research</category>
    </item>
    <item>
      <title>Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding</title>
      <link>https://arxiv.org/abs/2508.21204</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21204</guid>
      <description>arXiv:2508.21204v1 Announce Type: new 
Abstract: We study how architectural inductive biases influence the cognitive behavior of large language models (LLMs) in instructional dialogue. We introduce a symbolic scaffolding mechanism paired with a short-term memory schema designed to promote adaptive, ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, experiment, LLM, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>experiment</category>
      <category>LLM</category>
    </item>
    <item>
      <title>AI Compute Architecture and Evolution Trends</title>
      <link>https://arxiv.org/abs/2508.21394</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21394</guid>
      <description>arXiv:2508.21394v1 Announce Type: new 
Abstract: The focus of AI development has shifted from academic research to practical applications. However, AI development faces numerous challenges at various levels. This article will attempt to analyze the opportunities and challenges of AI from several dif...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; ICL, LLM, research, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>ICL</category>
      <category>LLM</category>
      <category>research</category>
    </item>
    <item>
      <title>Spatiotemporal EEG-Based Emotion Recognition Using SAM Ratings from Serious Games with Hybrid Deep Learning</title>
      <link>https://arxiv.org/abs/2508.21103</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21103</guid>
      <description>arXiv:2508.21103v1 Announce Type: new 
Abstract: Recent advancements in EEG-based emotion recognition have shown promising outcomes using both deep learning and classical machine learning approaches; however, most existing studies focus narrowly on binary valence prediction or subject-specific class...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, arxiv, model, framework, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>vector</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI</title>
      <link>https://arxiv.org/abs/2508.21111</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21111</guid>
      <description>arXiv:2508.21111v1 Announce Type: new 
Abstract: The Deep Space Network (DSN) is NASA&amp;#x27;s largest network of antenna facilities that generate a large volume of multivariate time-series data. These facilities contain DSN antennas and transmitters that undergo degradation over long periods of time, whic...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, experiment, research, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>experiment</category>
      <category>research</category>
    </item>
    <item>
      <title>Adaptive LLM Routing under Budget Constraints</title>
      <link>https://arxiv.org/abs/2508.21141</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21141</guid>
      <description>arXiv:2508.21141v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have revolutionized natural language processing, but their varying capabilities and costs pose challenges in practical applications. LLM routing addresses this by dynamically selecting the most suitable LLM for each query/...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; embedding, LLM, arxiv, model, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>embedding</category>
      <category>LLM</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Deep Residual Echo State Networks: exploring residual orthogonal connections in untrained Recurrent Neural Networks</title>
      <link>https://arxiv.org/abs/2508.21172</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21172</guid>
      <description>arXiv:2508.21172v1 Announce Type: new 
Abstract: Echo State Networks (ESNs) are a particular type of untrained Recurrent Neural Networks (RNNs) within the Reservoir Computing (RC) framework, popular for their fast and efficient learning. However, traditional ESNs often struggle with long-term inform...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, arxiv, model, framework, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning</title>
      <link>https://arxiv.org/abs/2508.21104</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21104</guid>
      <description>arXiv:2508.21104v1 Announce Type: new 
Abstract: Critic-free reinforcement learning methods, particularly group policies, have attracted considerable attention for their efficiency in complex tasks. However, these methods rely heavily on multiple sampling and comparisons within the policy to estimat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, attention, experiment, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>reasoning</category>
      <category>attention</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Privacy Auditing Synthetic Data Release through Local Likelihood Attacks</title>
      <link>https://arxiv.org/abs/2508.21146</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21146</guid>
      <description>arXiv:2508.21146v1 Announce Type: new 
Abstract: Auditing the privacy leakage of synthetic data is an important but unresolved problem. Most existing privacy auditing frameworks for synthetic data rely on heuristics and unreasonable assumptions to attack the failure modes of generative models, exhib...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, model, framework, paper, tool | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>model</category>
      <category>framework</category>
    </item>
    <item>
      <title>CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples</title>
      <link>https://arxiv.org/abs/2508.21083</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21083</guid>
      <description>arXiv:2508.21083v1 Announce Type: new 
Abstract: Deep learning models often learn and exploit spurious correlations in training data, using these non-target features to inform their predictions. Such reliance leads to performance degradation and poor generalization on unseen data. To address these l...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, framework, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>framework</category>
    </item>
    <item>
      <title>A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions</title>
      <link>https://arxiv.org/abs/2508.21441</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21441</guid>
      <description>arXiv:2508.21441v1 Announce Type: new 
Abstract: Forgetting as a knowledge management operation deliberately ignores parts of the knowledge and beliefs of an agent, for various reasons. Forgetting has many facets, one may want to forget parts of the syntax, a proposition, or a conditional. In the li...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; ICL, arxiv, framework, vision, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>ICL</category>
      <category>arxiv</category>
      <category>framework</category>
    </item>
    <item>
      <title>Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI</title>
      <link>https://arxiv.org/abs/2508.21101</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21101</guid>
      <description>arXiv:2508.21101v1 Announce Type: new 
Abstract: Reinforcement learning (RL) marks a fundamental shift in how artificial intelligence is applied in healthcare. Instead of merely predicting outcomes, RL actively decides interventions with long term goals. Unlike traditional models that operate on fix...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; tool, arxiv, model, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>tool</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Dynamic Low-rank Approximation of Full-Matrix Preconditioner for Training Generalized Linear Models</title>
      <link>https://arxiv.org/abs/2508.21106</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21106</guid>
      <description>arXiv:2508.21106v1 Announce Type: new 
Abstract: Adaptive gradient methods like Adagrad and its variants are widespread in large-scale optimization. However, their use of diagonal preconditioning matrices limits the ability to capture parameter correlations. Full-matrix adaptive methods, approximati...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, memory, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 01 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>memory</category>
    </item>
  </channel>
</rss>