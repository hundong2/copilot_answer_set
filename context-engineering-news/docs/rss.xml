<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Context Engineering Daily</title>
    <link>https://your-username.github.io/context-engineering-news</link>
    <description>Daily news and research updates in AI Context Engineering, Prompt Engineering, RAG, and LLM development</description>
    <language>en-us</language>
    <copyright>Copyright 2026 Context Engineering Daily</copyright>
    <generator>Context Engineering News Generator</generator>
    <lastBuildDate>Fri, 06 Feb 2026 20:09:29 +0000</lastBuildDate>
    <atom:link href="https://your-username.github.io/context-engineering-news/rss.xml" rel="self" type="application/rss+xml"/>
    <category>Technology</category>
    <category>Artificial Intelligence</category>
    <category>Machine Learning</category>
    <item>
      <title>BioACE: An Automated Framework for Biomedical Answer and Citation Evaluations</title>
      <link>https://arxiv.org/abs/2602.04982</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04982</guid>
      <description>arXiv:2602.04982v1 Announce Type: new 
Abstract: With the increasing use of large language models (LLMs) for generating answers to biomedical questions, it is crucial to evaluate the quality of the generated answers and the references provided to support the facts in the generated answers. Evaluatio...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, framework, summarization, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>RAG</category>
      <category>framework</category>
      <category>summarization</category>
    </item>
    <item>
      <title>CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System</title>
      <link>https://arxiv.org/abs/2602.05004</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.05004</guid>
      <description>arXiv:2602.05004v1 Announce Type: new 
Abstract: Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, memory, library, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>framework</category>
      <category>memory</category>
      <category>library</category>
    </item>
    <item>
      <title>Capacity Constraints and the Multilingual Penalty for Lexical Disambiguation</title>
      <link>https://arxiv.org/abs/2602.05035</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.05035</guid>
      <description>arXiv:2602.05035v1 Announce Type: new 
Abstract: Multilingual language models (LMs) sometimes under-perform their monolingual counterparts, possibly due to capacity limitations. We quantify this ``multilingual penalty&amp;#x27;&amp;#x27; for lexical disambiguation--a task requiring precise semantic representations an...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, attention, model, arxiv, embedding | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>context</category>
      <category>attention</category>
      <category>model</category>
    </item>
    <item>
      <title>Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories</title>
      <link>https://arxiv.org/abs/2602.05085</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.05085</guid>
      <description>arXiv:2602.05085v1 Announce Type: new 
Abstract: In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks i...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, context, memory, context window, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Context Management</category>
      <category>paper</category>
      <category>context</category>
      <category>memory</category>
    </item>
    <item>
      <title>Data Kernel Perspective Space Performance Guarantees for Synthetic Data from Transformer Models</title>
      <link>https://arxiv.org/abs/2602.05106</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.05106</guid>
      <description>arXiv:2602.05106v1 Announce Type: new 
Abstract: Scarcity of labeled training data remains the long pole in the tent for building performant language technology and generative AI models. Transformer models -- particularly LLMs -- are increasingly being used to mitigate the data scarcity problem via ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, model, analysis, arxiv, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>LLM</category>
      <category>model</category>
      <category>analysis</category>
    </item>
    <item>
      <title>GreekMMLU: A Native-Sourced Multitask Benchmark for Evaluating Language Models in Greek</title>
      <link>https://arxiv.org/abs/2602.05150</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.05150</guid>
      <description>arXiv:2602.05150v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are commonly trained on multilingual corpora that include Greek, yet reliable evaluation benchmarks for Greek-particularly those based on authentic, native-sourced content-remain limited. Existing datasets are often machin...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; release, prompting, prompt, LLM, ICL | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Prompt Engineering</category>
      <category>release</category>
      <category>prompting</category>
      <category>prompt</category>
    </item>
    <item>
      <title>Among Us: Measuring and Mitigating Malicious Contributions in Model Collaboration Systems</title>
      <link>https://arxiv.org/abs/2602.05176</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.05176</guid>
      <description>arXiv:2602.05176v1 Announce Type: new 
Abstract: Language models (LMs) are increasingly used in collaboration: multiple LMs trained by different parties collaborate through routing systems, multi-agent debate, model merging, and more. Critical safety risks remain in this decentralized paradigm: what...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, LLM, model, arxiv, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>The Single-Multi Evolution Loop for Self-Improving Model Collaboration Systems</title>
      <link>https://arxiv.org/abs/2602.05182</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.05182</guid>
      <description>arXiv:2602.05182v1 Announce Type: new 
Abstract: Model collaboration -- systems where multiple language models (LMs) collaborate -- combines the strengths of diverse models with cost in loading multiple LMs. We improve efficiency while preserving the strengths of collaboration by distilling collabor...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, model, analysis, arxiv, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>model</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Are Open-Weight LLMs Ready for Social Media Moderation? A Comparative Study on Bluesky</title>
      <link>https://arxiv.org/abs/2602.05189</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.05189</guid>
      <description>arXiv:2602.05189v1 Announce Type: new 
Abstract: As internet access expands, so does exposure to harmful content, increasing the need for effective moderation. Research has demonstrated that large language models (LLMs) can be effectively utilized for social media moderation tasks, including harmful...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; platform, context, LLM, model, zero-shot | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>platform</category>
      <category>context</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Knowledge Model Prompting Increases LLM Performance on Planning Tasks</title>
      <link>https://arxiv.org/abs/2602.03900</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.03900</guid>
      <description>arXiv:2602.03900v1 Announce Type: new 
Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, chain-of-thought, framework, paper, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>chain-of-thought</category>
      <category>framework</category>
    </item>
    <item>
      <title>Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation</title>
      <link>https://arxiv.org/abs/2602.03950</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.03950</guid>
      <description>arXiv:2602.03950v1 Announce Type: new 
Abstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although r...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; release, chain-of-thought, context, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Chain Of Thought</category>
      <category>release</category>
      <category>chain-of-thought</category>
      <category>context</category>
    </item>
    <item>
      <title>AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent</title>
      <link>https://arxiv.org/abs/2602.03955</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.03955</guid>
      <description>arXiv:2602.03955v1 Announce Type: new 
Abstract: While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framewo...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, framework, paper, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>fine-tuning</category>
      <category>framework</category>
      <category>paper</category>
    </item>
    <item>
      <title>Active Epistemic Control for Query-Efficient Verified Planning</title>
      <link>https://arxiv.org/abs/2602.03974</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.03974</guid>
      <description>arXiv:2602.03974v1 Announce Type: new 
Abstract: Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, LLM, model, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure</title>
      <link>https://arxiv.org/abs/2602.03975</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.03975</guid>
      <description>arXiv:2602.03975v1 Announce Type: new 
Abstract: Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, LLM, model, arxiv, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning</title>
      <link>https://arxiv.org/abs/2602.03978</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.03978</guid>
      <description>arXiv:2602.03978v1 Announce Type: new 
Abstract: As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; chain-of-thought, attention, prompt, model, instruction | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Chain Of Thought</category>
      <category>chain-of-thought</category>
      <category>attention</category>
      <category>prompt</category>
    </item>
    <item>
      <title>When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making</title>
      <link>https://arxiv.org/abs/2602.04003</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04003</guid>
      <description>arXiv:2602.04003v1 Announce Type: new 
Abstract: Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model rec...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, LLM, model, arxiv, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL</title>
      <link>https://arxiv.org/abs/2602.04089</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04089</guid>
      <description>arXiv:2602.04089v1 Announce Type: new 
Abstract: Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, RAG, framework, paper, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>fine-tuning</category>
      <category>RAG</category>
      <category>framework</category>
    </item>
    <item>
      <title>Interfaze: The Future of AI is built on Task-Specific Small Models</title>
      <link>https://arxiv.org/abs/2602.04101</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04101</guid>
      <description>arXiv:2602.04101v1 Announce Type: new 
Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; tool, context, multimodal, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Multimodal Context</category>
      <category>tool</category>
      <category>context</category>
      <category>multimodal</category>
    </item>
    <item>
      <title>Denoising diffusion networks for normative modeling in neuroimaging</title>
      <link>https://arxiv.org/abs/2602.04886</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04886</guid>
      <description>arXiv:2602.04886v1 Announce Type: new 
Abstract: Normative modeling estimates reference distributions of biological measures conditional on covariates, enabling centiles and clinically interpretable deviation scores to be derived. Most neuroimaging pipelines fit one model per imaging-derived phenoty...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, attention, multimodal, model, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>RAG</category>
      <category>attention</category>
      <category>multimodal</category>
    </item>
    <item>
      <title>A Causal Perspective for Enhancing Jailbreak Attack and Defense</title>
      <link>https://arxiv.org/abs/2602.04893</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04893</guid>
      <description>arXiv:2602.04893v1 Announce Type: new 
Abstract: Uncovering the mechanisms behind &amp;quot;jailbreaks&amp;quot; in large language models (LLMs) is crucial for enhancing their safety and reliability, yet these mechanisms remain poorly understood. Existing studies predominantly analyze jailbreak prompts by probing lat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; template, RAG, framework, prompt, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>template</category>
      <category>RAG</category>
      <category>framework</category>
    </item>
    <item>
      <title>Momentum Attention: The Physics of In-Context Learning and Spectral Forensics for Mechanistic Interpretability</title>
      <link>https://arxiv.org/abs/2602.04902</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04902</guid>
      <description>arXiv:2602.04902v1 Announce Type: new 
Abstract: The Mechanistic Interpretability (MI) program has mapped the Transformer as a precise computational graph. We extend this graph with a conservation law and time-varying AC dynamics, viewing it as a physical circuit. We introduce Momentum Attention, a ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, framework, tool, context, attention | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>experiment</category>
      <category>framework</category>
      <category>tool</category>
    </item>
    <item>
      <title>Mind the Performance Gap: Capability-Behavior Trade-offs in Feature Steering</title>
      <link>https://arxiv.org/abs/2602.04903</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04903</guid>
      <description>arXiv:2602.04903v1 Announce Type: new 
Abstract: Feature steering has emerged as a promising approach for controlling LLM behavior through direct manipulation of internal representations, offering advantages over prompt engineering. However, its practical effectiveness in real-world applications rem...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt engineering, prompting, prompt, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Prompt Engineering</category>
      <category>prompt engineering</category>
      <category>prompting</category>
      <category>prompt</category>
    </item>
    <item>
      <title>LISA: Laplacian In-context Spectral Analysis</title>
      <link>https://arxiv.org/abs/2602.04906</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04906</guid>
      <description>arXiv:2602.04906v1 Announce Type: new 
Abstract: We propose Laplacian In-context Spectral Analysis (LISA), a method for inference-time adaptation of Laplacian-based time-series models using only an observed prefix. LISA combines delay-coordinate embeddings and Laplacian spectral learning to produce ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, attention, context window, in-context, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>attention</category>
      <category>context window</category>
    </item>
    <item>
      <title>Learning Where It Matters: Geometric Anchoring for Robust Preference Alignment</title>
      <link>https://arxiv.org/abs/2602.04909</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04909</guid>
      <description>arXiv:2602.04909v1 Announce Type: new 
Abstract: Direct Preference Optimization (DPO) and related methods align large language models from pairwise preferences by regularizing updates against a fixed reference policy. As the policy drifts, a static reference, however, can become increasingly miscali...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; alignment, LLM, model, arxiv, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Chain Of Thought</category>
      <category>alignment</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>Context-Engineering - &amp;quot;Context engineering is the delicate art and science of filling the context window with just the right information for the next step.&amp;quot; â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.</title>
      <link>https://github.com/davidkimai/Context-Engineering</link>
      <guid isPermaLink="false">https://github.com/davidkimai/Context-Engineering</guid>
      <description>&amp;quot;Context engineering is the delicate art and science of filling the context window with just the right information for the next step.&amp;quot; â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt engineering, context, context window, prompt | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 29 Jun 2025 00:16:36 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>prompt engineering</category>
      <category>context</category>
      <category>context window</category>
    </item>
    <item>
      <title>ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.</title>
      <link>https://github.com/FunAudioLLM/ThinkSound</link>
      <guid isPermaLink="false">https://github.com/FunAudioLLM/ThinkSound</guid>
      <description>[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; chain-of-thought, framework, audio, CoT, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 27 Jun 2025 02:27:00 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>chain-of-thought</category>
      <category>framework</category>
      <category>audio</category>
    </item>
    <item>
      <title>mcp-context-forge - A Model Context Protocol (MCP) Gateway &amp;amp; Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).</title>
      <link>https://github.com/IBM/mcp-context-forge</link>
      <guid isPermaLink="false">https://github.com/IBM/mcp-context-forge</guid>
      <description>A Model Context Protocol (MCP) Gateway &amp;amp; Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; tool, context, API, prompt, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 08 May 2025 08:16:59 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>tool</category>
      <category>context</category>
      <category>API</category>
    </item>
    <item>
      <title>PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG</title>
      <link>https://github.com/VectifyAI/PageIndex</link>
      <guid isPermaLink="false">https://github.com/VectifyAI/PageIndex</guid>
      <description>ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, RAG, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 01 Apr 2025 10:53:54 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>vector</category>
      <category>RAG</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code</title>
      <link>https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-</link>
      <guid isPermaLink="false">https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-</guid>
      <description>A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, chain-of-thought, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 18 Feb 2025 15:45:30 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>context</category>
      <category>chain-of-thought</category>
      <category>framework</category>
    </item>
    <item>
      <title>airweave - Open-source context retrieval layer for AI agents</title>
      <link>https://github.com/airweave-ai/airweave</link>
      <guid isPermaLink="false">https://github.com/airweave-ai/airweave</guid>
      <description>Open-source context retrieval layer for AI agents&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 24 Dec 2024 10:00:06 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>context</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>LightRAG - [EMNLP2025] &amp;quot;LightRAG: Simple and Fast Retrieval-Augmented Generation&amp;quot;</title>
      <link>https://github.com/HKUDS/LightRAG</link>
      <guid isPermaLink="false">https://github.com/HKUDS/LightRAG</guid>
      <description>[EMNLP2025] &amp;quot;LightRAG: Simple and Fast Retrieval-Augmented Generation&amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, RAG, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 02 Oct 2024 11:57:54 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>RAG</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&amp;amp;A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.</title>
      <link>https://github.com/OpenSPG/KAG</link>
      <guid isPermaLink="false">https://github.com/OpenSPG/KAG</guid>
      <description>KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&amp;amp;A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, RAG, framework, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sat, 21 Sep 2024 13:56:44 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>vector</category>
      <category>RAG</category>
      <category>framework</category>
    </item>
    <item>
      <title>Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.</title>
      <link>https://github.com/Kiln-AI/Kiln</link>
      <guid isPermaLink="false">https://github.com/Kiln-AI/Kiln</guid>
      <description>Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 23 Jul 2024 23:10:13 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>fine-tuning</category>
      <category>RAG</category>
    </item>
    <item>
      <title>graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system</title>
      <link>https://github.com/microsoft/graphrag</link>
      <guid isPermaLink="false">https://github.com/microsoft/graphrag</guid>
      <description>A modular graph-based Retrieval-Augmented Generation (RAG) system&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, RAG, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 27 Mar 2024 17:57:52 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>augmented</category>
      <category>RAG</category>
      <category>retrieval</category>
    </item>
    <item>
      <title>R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.</title>
      <link>https://github.com/SciPhi-AI/R2R</link>
      <guid isPermaLink="false">https://github.com/SciPhi-AI/R2R</guid>
      <description>SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, API, product, augmented, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 12 Feb 2024 03:24:27 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>RAG</category>
      <category>API</category>
      <category>product</category>
    </item>
    <item>
      <title>openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.</title>
      <link>https://github.com/openlit/openlit</link>
      <guid isPermaLink="false">https://github.com/openlit/openlit</guid>
      <description>Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, framework, platform, prompt, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 23 Jan 2024 17:40:59 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>vector</category>
      <category>framework</category>
      <category>platform</category>
    </item>
    <item>
      <title>Multilingual Extraction and Recognition of Implicit Discourse Relations in Speech and Text</title>
      <link>https://arxiv.org/abs/2602.05107</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.05107</guid>
      <description>arXiv:2602.05107v1 Announce Type: new 
Abstract: Implicit discourse relation classification is a challenging task, as it requires inferring meaning from context. While contextual cues can be distributed across modalities and vary across languages, they are not always captured by text alone. To addre...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, audio, multimodal, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Multimodal Context</category>
      <category>context</category>
      <category>audio</category>
      <category>multimodal</category>
    </item>
    <item>
      <title>Physics as the Inductive Bias for Causal Discovery</title>
      <link>https://arxiv.org/abs/2602.04907</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04907</guid>
      <description>arXiv:2602.04907v1 Announce Type: new 
Abstract: Causal discovery is often a data-driven paradigm to analyze complex real-world systems. In parallel, physics-based models such as ordinary differential equations (ODEs) provide mechanistic structure for many dynamical processes. Integrating these para...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, framework, model, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>framework</category>
      <category>model</category>
    </item>
    <item>
      <title>Temporal Pair Consistency for Variance-Reduced Flow Matching</title>
      <link>https://arxiv.org/abs/2602.04908</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04908</guid>
      <description>arXiv:2602.04908v1 Announce Type: new 
Abstract: Continuous-time generative models, such as diffusion models, flow matching, and rectified flow, learn time-dependent vector fields but are typically trained with objectives that treat timesteps independently, leading to high estimator variance and ine...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, image, model, augmented, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>vector</category>
      <category>image</category>
      <category>model</category>
    </item>
    <item>
      <title>fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!</title>
      <link>https://github.com/tadata-org/fastapi_mcp</link>
      <guid isPermaLink="false">https://github.com/tadata-org/fastapi_mcp</guid>
      <description>Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, context, API, tool | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sat, 08 Mar 2025 11:15:43 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>model</category>
      <category>context</category>
      <category>API</category>
    </item>
    <item>
      <title>cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.</title>
      <link>https://github.com/nvidia-cosmos/cosmos-reason1</link>
      <guid isPermaLink="false">https://github.com/nvidia-cosmos/cosmos-reason1</guid>
      <description>Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, chain-of-thought, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 02 Mar 2025 15:23:55 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>model</category>
      <category>chain-of-thought</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>Axiomatic Foundations of Counterfactual Explanations</title>
      <link>https://arxiv.org/abs/2602.04028</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04028</guid>
      <description>arXiv:2602.04028v1 Announce Type: new 
Abstract: Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not&amp;#x27;&amp;#x27; questions by revealing how decisions coul...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, paper, arxiv, reasoning, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>paper</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>DCER: Dual-Stage Compression and Energy-Based Reconstruction</title>
      <link>https://arxiv.org/abs/2602.04904</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04904</guid>
      <description>arXiv:2602.04904v1 Announce Type: new 
Abstract: Multimodal fusion faces two robustness challenges: noisy inputs degrade representation quality, and missing modalities cause prediction failures. We propose DCER, a
  unified framework addressing both challenges through dual-stage compression and ener...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, compression, framework, audio, multimodal | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Multimodal Context</category>
      <category>experiment</category>
      <category>compression</category>
      <category>framework</category>
    </item>
    <item>
      <title>A logical re-conception of neural networks: Hamiltonian bitwise part-whole architecture</title>
      <link>https://arxiv.org/abs/2602.04911</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.04911</guid>
      <description>arXiv:2602.04911v1 Announce Type: new 
Abstract: We introduce a simple initial working system in which relations (such as part-whole) are directly represented via an architecture with operating and learning rules fundamentally distinct from standard artificial neural network methods. Arbitrary data ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, arxiv, example, tool | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 06 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>In Context Learning</category>
      <category>vector</category>
      <category>arxiv</category>
      <category>example</category>
    </item>
    <item>
      <title>Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3â€™s Top Model</title>
      <link>https://huggingface.co/blog/nvidia/nemotron-colembed-v2</link>
      <guid isPermaLink="false">https://huggingface.co/blog/nvidia/nemotron-colembed-v2</guid>
      <description>...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; Hugging Face Blog | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, retrieval, multimodal | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 04 Feb 2026 15:00:40 </pubDate>
      <author>noreply@contextengineering.news (Hugging Face Blog)</author>
      <category>Rag Retrieval</category>
      <category>model</category>
      <category>retrieval</category>
      <category>multimodal</category>
    </item>
    <item>
      <title>excel-mcp-server - A Model Context Protocol server for Excel file manipulation</title>
      <link>https://github.com/haris-musa/excel-mcp-server</link>
      <guid isPermaLink="false">https://github.com/haris-musa/excel-mcp-server</guid>
      <description>A Model Context Protocol server for Excel file manipulation&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Feb 2025 06:39:48 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Industry News</category>
      <category>model</category>
      <category>context</category>
    </item>
    <item>
      <title>mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns</title>
      <link>https://github.com/lastmile-ai/mcp-agent</link>
      <guid isPermaLink="false">https://github.com/lastmile-ai/mcp-agent</guid>
      <description>Build effective agents using Model Context Protocol and simple workflow patterns&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 18 Dec 2024 01:55:10 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Industry News</category>
      <category>model</category>
      <category>context</category>
    </item>
    <item>
      <title>AlphaCodium - Official implementation for the paper: &amp;quot;Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering&amp;quot;&amp;quot;</title>
      <link>https://github.com/Codium-ai/AlphaCodium</link>
      <guid isPermaLink="false">https://github.com/Codium-ai/AlphaCodium</guid>
      <description>Official implementation for the paper: &amp;quot;Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering&amp;quot;&amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt engineering, prompt, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 14 Jan 2024 15:17:18 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>prompt engineering</category>
      <category>prompt</category>
      <category>paper</category>
    </item>
    <item>
      <title>optillm - Optimizing inference proxy for LLMs</title>
      <link>https://github.com/algorithmicsuperintelligence/optillm</link>
      <guid isPermaLink="false">https://github.com/algorithmicsuperintelligence/optillm</guid>
      <description>Optimizing inference proxy for LLMs&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 22 Aug 2024 19:46:07 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>LLM</category>
    </item>
  </channel>
</rss>