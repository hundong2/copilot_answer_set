<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data</title>
      <link>https://arxiv.org/abs/2512.19864</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.19864</guid>
      <description>arXiv:2512.19864v1 Announce Type: new 
Abstract: Unstructured notes within the electronic health record (EHR) contain rich clinical information vital for cancer treatment decision making and research, yet reliably extracting structured oncology data remains challenging due to extensive variability, ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, retrieval, study, model, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>retrieval</category>
      <category>study</category>
    </item>
    <item>
      <title>Counterfactual LLM-based Framework for Measuring Rhetorical Style</title>
      <link>https://arxiv.org/abs/2512.19908</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.19908</guid>
      <description>arXiv:2512.19908v1 Announce Type: new 
Abstract: The rise of AI has fueled growing concerns about ``hype&amp;#x27;&amp;#x27; in machine learning papers, yet a reliable way to quantify rhetorical style independently of substantive content has remained elusive. Because bold language can stem from either strong empirica...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, LLM, arxiv, paper, ICL | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>LLM</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems</title>
      <link>https://arxiv.org/abs/2512.19950</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.19950</guid>
      <description>arXiv:2512.19950v1 Announce Type: new 
Abstract: Large Language Models are increasingly used in conversational systems such as digital personal assistants, shaping how people interact with technology through language. While their responses often sound fluent and natural, they can also carry subtle t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, model, LLM, arxiv, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>model</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents</title>
      <link>https://arxiv.org/abs/2512.20092</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.20092</guid>
      <description>arXiv:2512.20092v1 Announce Type: new 
Abstract: Temporal reasoning over long, multi-session dialogues is a critical capability for conversational agents. However, existing works and our pilot study have shown that as dialogue histories grow in length and accumulate noise, current long-context model...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, alignment, study, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>alignment</category>
      <category>study</category>
    </item>
    <item>
      <title>A Novel Graph-Sequence Learning Model for Inductive Text Classification</title>
      <link>https://arxiv.org/abs/2512.20097</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.20097</guid>
      <description>arXiv:2512.20097v1 Announce Type: new 
Abstract: Text classification plays an important role in various downstream text-related tasks, such as sentiment analysis, fake news detection, and public opinion analysis. Recently, text classification based on Graph Neural Networks (GNNs) has made significan...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, model, transformer, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>model</category>
      <category>transformer</category>
    </item>
    <item>
      <title>ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language</title>
      <link>https://arxiv.org/abs/2512.20111</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.20111</guid>
      <description>arXiv:2512.20111v1 Announce Type: new 
Abstract: As the length of sequential decision-making tasks increases, it becomes computationally impractical to keep full interaction histories in context. We introduce a general framework for LLM agents to maintain concise contexts through multi-step interact...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, model, LLM, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>model</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs</title>
      <link>https://arxiv.org/abs/2512.19937</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.19937</guid>
      <description>arXiv:2512.19937v1 Announce Type: new 
Abstract: Recent research has explored using very large language models (LLMs) as proxies for humans in tasks such as simulation, surveys, and studies. While LLMs do not possess a human psychology, they often can emulate human behaviors with sufficiently high f...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, LLM, RAG, large language model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>LLM</category>
      <category>RAG</category>
    </item>
    <item>
      <title>FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification</title>
      <link>https://arxiv.org/abs/2512.19960</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.19960</guid>
      <description>arXiv:2512.19960v1 Announce Type: new 
Abstract: Intra-class variability is given according to the significance in the degree of dissimilarity between images within a class. In that sense, depending on its intensity, intra-class variability can hinder the learning process for DL models, specially wh...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, RAG, arxiv, experiment, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>RAG</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach</title>
      <link>https://arxiv.org/abs/2512.20056</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.20056</guid>
      <description>arXiv:2512.20056v1 Announce Type: new 
Abstract: As Earth&amp;#x27;s climate changes, it is impacting disasters and extreme weather events across the planet. Record-breaking heat waves, drenching rainfalls, extreme wildfires, and widespread flooding during hurricanes are all becoming more frequent and more i...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, RAG, API, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>RAG</category>
      <category>API</category>
    </item>
    <item>
      <title>Reducing Label Dependency in Human Activity Recognition with Wearables: From Supervised Learning to Novel Weakly Self-Supervised Approaches</title>
      <link>https://arxiv.org/abs/2512.19713</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.19713</guid>
      <description>arXiv:2512.19713v1 Announce Type: new 
Abstract: Human activity recognition (HAR) using wearable sensors has advanced through various machine learning paradigms, each with inherent trade-offs between performance and labeling requirements. While fully supervised techniques achieve high accuracy, they...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, arxiv, experiment, framework, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Per-Axis Weight Deltas for Frequent Model Updates</title>
      <link>https://arxiv.org/abs/2512.19720</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.19720</guid>
      <description>arXiv:2512.19720v1 Announce Type: new 
Abstract: Serving many task-specialized LLM variants is often limited by the large size of fine-tuned checkpoints and the resulting cold-start latency. Since fine-tuned weights differ from their base model by relatively small structured residuals, a natural app...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, LLM, RAG, experiment, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>LLM</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Schoenfeld&amp;#x27;s Anatomy of Mathematical Reasoning by Language Models</title>
      <link>https://arxiv.org/abs/2512.19995</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.19995</guid>
      <description>arXiv:2512.19995v1 Announce Type: new 
Abstract: Large language models increasingly expose reasoning traces, yet their underlying cognitive structure and steps remain difficult to identify and analyze beyond surface-level statistics. We adopt Schoenfeld&amp;#x27;s Episode Theory as an inductive, intermediate...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, model, arxiv, large language model, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>model</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Discovering Lie Groups with Flow Matching</title>
      <link>https://arxiv.org/abs/2512.20043</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.20043</guid>
      <description>arXiv:2512.20043v1 Announce Type: new 
Abstract: Symmetry is fundamental to understanding physical systems, and at the same time, can improve performance and sample efficiency in machine learning. Both pursuits require knowledge of the underlying symmetries in data. To address this, we propose learn...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Learning Skills from Action-Free Videos</title>
      <link>https://arxiv.org/abs/2512.20052</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.20052</guid>
      <description>arXiv:2512.20052v1 Announce Type: new 
Abstract: Learning from videos offers a promising path toward generalist robots by providing rich visual and temporal priors beyond what real robot datasets contain. While existing video generative models produce impressive visual predictions, they are difficul...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, arxiv, experiment, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference</title>
      <link>https://arxiv.org/abs/2512.19717</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.19717</guid>
      <description>arXiv:2512.19717v1 Announce Type: new 
Abstract: Finding rare but useful solutions in very large candidate spaces is a recurring practical challenge across language generation, planning, and reinforcement learning. We present a practical framework, \emph{Inverted Causality Focusing Algorithm} (ICFA)...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, framework, prompt | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 24 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>framework</category>
    </item>
  </channel>
</rss>