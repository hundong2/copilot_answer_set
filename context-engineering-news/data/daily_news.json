{
  "generated_at": "2025-08-14T20:06:12.898072",
  "total_items": 49,
  "items": [
    {
      "title": "ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning",
      "url": "https://arxiv.org/abs/2508.09303",
      "description": "arXiv:2508.09303v1 Announce Type: new \nAbstract: Reasoning-augmented search agents such as Search-R1, trained via reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable capabilities in multi-step information retrieval from external knowledge sources. These agents address the l...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "memory",
        "experiment",
        "arxiv",
        "reasoning",
        "augmented",
        "framework",
        "large language model",
        "retrieval",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Leveraging Large Language Models for Rare Disease Named Entity Recognition",
      "url": "https://arxiv.org/abs/2508.09323",
      "description": "arXiv:2508.09323v1 Announce Type: new \nAbstract: Named Entity Recognition (NER) in the rare disease domain poses unique challenges due to limited labeled data, semantic ambiguity between entity types, and long-tail distributions. In this study, we evaluate the capabilities of GPT-4o for rare disease...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "zero-shot",
        "large language model",
        "LLM",
        "context",
        "prompting",
        "framework",
        "retrieval",
        "example",
        "prompt",
        "GPT",
        "in-context",
        "analysis",
        "RAG",
        "experiment",
        "augmented",
        "fine-tuning",
        "few-shot",
        "model",
        "study",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "TEN: Table Explicitization, Neurosymbolically",
      "url": "https://arxiv.org/abs/2508.09324",
      "description": "arXiv:2508.09324v1 Announce Type: new \nAbstract: We present a neurosymbolic approach, TEN, for extracting tabular data from semistructured input text. This task is particularly challenging for text input that does not use special delimiters consistently to separate columns and rows. Purely neural ap...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "prompting",
        "experiment",
        "chain-of-thought",
        "arxiv",
        "large language model",
        "LLM",
        "prompt",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Decoding Neural Emotion Patterns through Natural Language Processing Embeddings",
      "url": "https://arxiv.org/abs/2508.09337",
      "description": "arXiv:2508.09337v1 Announce Type: new \nAbstract: Understanding how emotional expression in language relates to brain function is a challenge in computational neuroscience and affective computing. Traditional neuroimaging is costly and lab-bound, but abundant digital text offers new avenues for emoti...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "experiment",
        "arxiv",
        "framework",
        "large language model",
        "LLM",
        "embedding",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains",
      "url": "https://arxiv.org/abs/2508.09349",
      "description": "arXiv:2508.09349v1 Announce Type: new \nAbstract: Expert consensus plays a critical role in domains where evidence is complex, conflicting, or insufficient for direct prescription. Traditional methods, such as Delphi studies, consensus conferences, and systematic guideline synthesis, offer structure ...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "study",
        "RAG",
        "arxiv",
        "framework",
        "ICL",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Flow-SLM: Joint Learning of Linguistic and Acoustic Information for Spoken Language Modeling",
      "url": "https://arxiv.org/abs/2508.09350",
      "description": "arXiv:2508.09350v1 Announce Type: new \nAbstract: Textless spoken language models (SLMs) are generative models of speech that do not rely on text supervision. Most textless SLMs learn to predict the next semantic token, a discrete representation of linguistic content, and rely on a separate vocoder t...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "study",
        "vector",
        "arxiv",
        "prompt",
        "vision",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification",
      "url": "https://arxiv.org/abs/2508.09378",
      "description": "arXiv:2508.09378v1 Announce Type: new \nAbstract: Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, several approaches have been proposed to engineer prompts ...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompting",
        "chain-of-thought",
        "arxiv",
        "research",
        "API",
        "large language model",
        "ICL",
        "LLM",
        "prompt",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models",
      "url": "https://arxiv.org/abs/2508.09403",
      "description": "arXiv:2508.09403v1 Announce Type: new \nAbstract: Expanding the abbreviated column names of tables, such as ``esal'' to ``employee salary'', is critical for numerous downstream data tasks. This problem arises in enterprises, domain sciences, government agencies, and more. In this paper we make three ...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "product",
        "analysis",
        "experiment",
        "chain-of-thought",
        "arxiv",
        "reasoning",
        "paper",
        "large language model",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Leveraging Zipformer Model for Effective Language Identification in Code-Switched Child-Directed Speech",
      "url": "https://arxiv.org/abs/2508.09430",
      "description": "arXiv:2508.09430v1 Announce Type: new \nAbstract: Code-switching and language identification in child-directed scenarios present significant challenges, particularly in bilingual environments. This paper addresses this challenge by using Zipformer to handle the nuances of speech, which contains two i...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "RAG",
        "arxiv",
        "paper",
        "transformer",
        "embedding",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "From Charts to Fair Narratives: Uncovering and Mitigating Geo-Economic Biases in Chart-to-Text",
      "url": "https://arxiv.org/abs/2508.09450",
      "description": "arXiv:2508.09450v1 Announce Type: new \nAbstract: Charts are very common for exploring data and communicating insights, but extracting key takeaways from charts and articulating them in natural language can be challenging. The chart-to-text task aims to automate this process by generating textual sum...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "analysis",
        "arxiv",
        "attention",
        "paper",
        "API",
        "ICL",
        "prompt",
        "vision",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants",
      "url": "https://arxiv.org/abs/2508.09507",
      "description": "arXiv:2508.09507v1 Announce Type: new \nAbstract: With the rapid development of mobile intelligent assistant technologies, multi-modal AI assistants have become essential interfaces for daily user interactions. However, current evaluation methods face challenges including high manual costs, inconsist...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "paper",
        "API",
        "fine-tuning",
        "framework",
        "large language model",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making",
      "url": "https://arxiv.org/abs/2508.09586",
      "description": "arXiv:2508.09586v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, including programming, planning, and decision-making. However, their performance often degrades when faced with highly complex problem instances that requir...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "reasoning",
        "framework",
        "large language model",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement",
      "url": "https://arxiv.org/abs/2508.09670",
      "description": "arXiv:2508.09670v1 Announce Type: new \nAbstract: Recent advances demonstrate that reinforcement learning with verifiable rewards (RLVR) significantly enhances the reasoning capabilities of large language models (LLMs). However, standard RLVR faces challenges with reward sparsity, where zero rewards ...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "experiment",
        "arxiv",
        "reasoning",
        "framework",
        "large language model",
        "LLM",
        "prompt",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge",
      "url": "https://arxiv.org/abs/2508.09724",
      "description": "arXiv:2508.09724v1 Announce Type: new \nAbstract: Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but it is prone to preference bias, where judges systematically favor certain outputs, such as their own. This bias leads to inconsistent and skewed rankings across different ju...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "experiment",
        "arxiv",
        "alignment",
        "framework",
        "large language model",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?",
      "url": "https://arxiv.org/abs/2508.09762",
      "description": "arXiv:2508.09762v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) become increasingly autonomous and integrated into critical societal functions, the focus of AI safety must evolve from mitigating harmful content to evaluating underlying behavioral alignment. Current safety benchmarks...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "GPT",
        "arxiv",
        "alignment",
        "tool",
        "large language model",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation",
      "url": "https://arxiv.org/abs/2508.09860",
      "description": "arXiv:2508.09860v1 Announce Type: new \nAbstract: Human-aligned AI is a critical component of co-creativity, as it enables models to accurately interpret human intent and generate controllable outputs that align with design goals in collaborative content creation. This direction is especially relevan...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vision",
        "experiment",
        "arxiv",
        "paper",
        "tool",
        "framework",
        "instruction",
        "embedding",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Efficient Real-Time Aircraft ETA Prediction via Feature Tokenization Transformer",
      "url": "https://arxiv.org/abs/2508.09144",
      "description": "arXiv:2508.09144v1 Announce Type: new \nAbstract: Estimated time of arrival (ETA) for airborne aircraft in real-time is crucial for arrival management in aviation, particularly for runway sequencing. Given the rapidly changing airspace context, the ETA prediction efficiency is as important as its acc...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "study",
        "experiment",
        "arxiv",
        "attention",
        "transformer",
        "API",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "MoLAN: A Unified Modality-Aware Noise Dynamic Editing Framework for Multimodal Sentiment Analysis",
      "url": "https://arxiv.org/abs/2508.09145",
      "description": "arXiv:2508.09145v1 Announce Type: new \nAbstract: Multimodal Sentiment Analysis aims to integrate information from various modalities, such as audio, visual, and text, to make complementary predictions. However, it often struggles with irrelevant or misleading visual and auditory information. Most ex...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "analysis",
        "RAG",
        "experiment",
        "audio",
        "arxiv",
        "multimodal",
        "image",
        "framework",
        "ICL",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA",
      "url": "https://arxiv.org/abs/2508.09146",
      "description": "arXiv:2508.09146v1 Announce Type: new \nAbstract: The binary exponential backoff scheme is widely used in WiFi 7 and still incurs poor throughput performance under dynamic channel environments. Recent model-based approaches (e.g., non-persistent and $p$-persistent CSMA) simply optimize backoff strate...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "context",
        "in-context",
        "experiment",
        "arxiv",
        "transformer",
        "paper",
        "ICL",
        "LLM",
        "example",
        "prompt",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Motif 2.6B Technical Report",
      "url": "https://arxiv.org/abs/2508.09148",
      "description": "arXiv:2508.09148v1 Announce Type: new \nAbstract: Recent advancements in Large Language Models (LLMs) have revolutionized artificial intelligence, yet developing an effective foundational LLM that balances high performance with computational efficiency remains challenging, especially for emerging res...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "in-context",
        "experiment",
        "arxiv",
        "research",
        "attention",
        "large language model",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "JustDense: Just using Dense instead of Sequence Mixer for Time Series analysis",
      "url": "https://arxiv.org/abs/2508.09153",
      "description": "arXiv:2508.09153v1 Announce Type: new \nAbstract: Sequence and channel mixers, the core mechanism in sequence models, have become the de facto standard in time series analysis (TSA). However, recent studies have questioned the necessity of complex sequence mixers, such as attention mechanisms, demons...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "analysis",
        "experiment",
        "arxiv",
        "research",
        "attention",
        "framework",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt",
        "context window",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "chain-of-thought",
        "reasoning",
        "framework",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "context",
        "attention",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "vector",
        "reasoning",
        "knowledge base",
        "framework",
        "retrieval",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "fine-tuning",
        "tool",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "product",
        "RAG",
        "API",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "framework",
        "LLM",
        "platform",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning",
      "url": "https://arxiv.org/abs/2508.09277",
      "description": "arXiv:2508.09277v1 Announce Type: new \nAbstract: Value function initialization (VFI) is an effective way to achieve a jumpstart in reinforcement learning (RL) by leveraging value estimates from prior tasks. While this approach is well established in tabular settings, extending it to deep reinforceme...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "experiment",
        "RAG",
        "arxiv",
        "knowledge base",
        "demonstration",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards",
      "url": "https://arxiv.org/abs/2508.09292",
      "description": "arXiv:2508.09292v1 Announce Type: new \nAbstract: The ability to rapidly adapt to novel and unforeseen environmental changes is a cornerstone of artificial general intelligence (AGI), yet it remains a critical blind spot in most existing AI benchmarks. Traditional evaluation largely focuses on optimi...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "analysis",
        "arxiv",
        "research",
        "API",
        "tool",
        "framework",
        "platform",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Peer Effect Estimation in the Presence of Simultaneous Feedback and Unobserved Confounders",
      "url": "https://arxiv.org/abs/2508.09154",
      "description": "arXiv:2508.09154v1 Announce Type: new \nAbstract: Estimating peer causal effects within complex real-world networks such as social networks is challenging, primarily due to simultaneous feedback between peers and unobserved confounders. Existing methods either address unobserved confounders while ign...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "arxiv",
        "paper",
        "augmented",
        "framework",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Presenting DiaData for Research on Type 1 Diabetes",
      "url": "https://arxiv.org/abs/2508.09160",
      "description": "arXiv:2508.09160v1 Announce Type: new \nAbstract: Type 1 diabetes (T1D) is an autoimmune disorder that leads to the destruction of insulin-producing cells, resulting in insulin deficiency, as to why the affected individuals depend on external insulin injections. However, insulin can decrease blood gl...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "analysis",
        "arxiv",
        "research",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "tool",
        "API",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "model",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "A Rolling Stone Gathers No Moss: Adaptive Policy Optimization for Stable Self-Evaluation in Large Multimodal Models",
      "url": "https://arxiv.org/abs/2508.09155",
      "description": "arXiv:2508.09155v1 Announce Type: new \nAbstract: Self-evaluation, a model's ability to assess the correctness of its own output, is crucial for Large Multimodal Models (LMMs) to achieve self-improvement in multi-turn conversations, yet largely absent in foundation models. Recent work has employed re...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "reasoning",
        "multimodal",
        "paper",
        "release",
        "framework",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Physics-Constrained Fine-Tuning of Flow-Matching Models for Generation and Inverse Problems",
      "url": "https://arxiv.org/abs/2508.09156",
      "description": "arXiv:2508.09156v1 Announce Type: new \nAbstract: We present a framework for fine-tuning flow-matching generative models to enforce physical constraints and solve inverse problems in scientific systems. Starting from a model trained on low-fidelity or observational data, we apply a differentiable pos...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "augmented",
        "fine-tuning",
        "framework",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "paper",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles",
      "url": "https://arxiv.org/abs/2508.09639",
      "description": "arXiv:2508.09639v1 Announce Type: new \nAbstract: Explainable Artificial Intelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP), have become essential tools for interpreting complex ensemble tree-based models, especially in high-stakes domains such as healthcare analytics. Howeve...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "tool",
        "experiment",
        "arxiv",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete",
      "url": "https://arxiv.org/abs/2508.09784",
      "description": "arXiv:2508.09784v1 Announce Type: new \nAbstract: Logics for reasoning about knowledge and actions have seen many applications in various domains of multi-agent systems, including epistemic planning. Change of knowledge based on observations about the surroundings forms a key aspect in such planning ...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "announcement",
        "arxiv",
        "reasoning",
        "knowledge base",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving",
      "url": "https://arxiv.org/abs/2508.09158",
      "description": "arXiv:2508.09158v1 Announce Type: new \nAbstract: Autonomous driving faces significant challenges in achieving human-like iterative decision-making, which continuously generates, evaluates, and refines trajectory proposals. Current generation-evaluation frameworks isolate trajectory generation from q...",
      "published_date": "2025-08-14T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "experiment",
        "arxiv",
        "API",
        "framework",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "TextQuests: How Good are LLMs at Text-Based Video Games?",
      "url": "https://huggingface.co/blog/textquests",
      "description": "...",
      "published_date": "2025-08-12T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "🇵🇭 FilBench - Can LLMs Understand and Generate Filipino?",
      "url": "https://huggingface.co/blog/filbench",
      "description": "...",
      "published_date": "2025-08-12T00:00:00",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}