{
  "generated_at": "2025-10-30T20:05:42.626190",
  "total_items": 45,
  "items": [
    {
      "title": "Iti-Validator: A Guardrail Framework for Validating and Correcting LLM-Generated Itineraries",
      "url": "https://arxiv.org/abs/2510.24719",
      "description": "arXiv:2510.24719v1 Announce Type: new \nAbstract: The rapid advancement of Large Language Models (LLMs) has enabled them to generate complex, multi-step plans and itineraries. However, these generated plans often lack temporal and spatial consistency, particularly in scenarios involving physical trav...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "API",
        "framework",
        "experiment",
        "model",
        "arxiv",
        "reasoning",
        "study",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Confidence is Not Competence",
      "url": "https://arxiv.org/abs/2510.24772",
      "description": "arXiv:2510.24772v1 Announce Type: new \nAbstract: Large language models (LLMs) often exhibit a puzzling disconnect between their asserted confidence and actual problem-solving competence. We offer a mechanistic account of this decoupling by analyzing the geometry of internal states across two phases ...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "arxiv",
        "reasoning",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "SwiftEmbed: Ultra-Fast Text Embeddings via Static Token Lookup for Real-Time Applications",
      "url": "https://arxiv.org/abs/2510.24793",
      "description": "arXiv:2510.24793v1 Announce Type: new \nAbstract: We present a static token lookup methodology for text embedding generation that achieves 1.12 ms p50 latency for single text embeddings while maintaining 60.6 MTEB average score across 8 representative tasks, corresponding to 89% of contextual model q...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "RAG",
        "model",
        "arxiv",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "MR-Align: Meta-Reasoning Informed Factuality Alignment for Large Reasoning Models",
      "url": "https://arxiv.org/abs/2510.24794",
      "description": "arXiv:2510.24794v1 Announce Type: new \nAbstract: Large reasoning models (LRMs) show strong capabilities in complex reasoning, yet their marginal gains on evidence-dependent factual questions are limited. We find this limitation is partially attributable to a reasoning-answer hit gap, where the model...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "RAG",
        "model",
        "arxiv",
        "alignment",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Large Language Models Report Subjective Experience Under Self-Referential Processing",
      "url": "https://arxiv.org/abs/2510.24797",
      "description": "arXiv:2510.24797v1 Announce Type: new \nAbstract: Large language models sometimes produce structured, first-person descriptions that explicitly reference awareness or subjective experience. To better understand this behavior, we investigate one theoretically motivated condition under which such repor...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "GPT",
        "prompt",
        "experiment",
        "model",
        "arxiv",
        "reasoning",
        "prompting",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "ProofSketch: Efficient Verified Reasoning for Large Language Models",
      "url": "https://arxiv.org/abs/2510.24811",
      "description": "arXiv:2510.24811v1 Announce Type: new \nAbstract: Reasoning methods such as chain-of-thought prompting and self-consistency have shown immense potential to improve the accuracy of large language models across various reasoning tasks. However such methods involve generation of lengthy reasoning chains...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "framework",
        "prompt",
        "experiment",
        "model",
        "arxiv",
        "reasoning",
        "chain-of-thought",
        "prompting",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Scheduling Your LLM Reinforcement Learning with Reasoning Trees",
      "url": "https://arxiv.org/abs/2510.24832",
      "description": "arXiv:2510.24832v1 Announce Type: new \nAbstract: Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large Language Models (LLMs) can be conceptualized as progressively editing a query's `Reasoning Tree'. This process involves exploring nodes (tokens) and dynamically modifying th...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "RAG",
        "experiment",
        "model",
        "arxiv",
        "reasoning",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Taming the Real-world Complexities in CPT E/M Coding with Large Language Models",
      "url": "https://arxiv.org/abs/2510.25007",
      "description": "arXiv:2510.25007v1 Announce Type: new \nAbstract: Evaluation and Management (E/M) coding, under the Current Procedural Terminology (CPT) taxonomy, documents medical services provided to patients by physicians. Used primarily for billing purposes, it is in physicians' best interest to provide accurate...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "framework",
        "prompt",
        "model",
        "arxiv",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading",
      "url": "https://arxiv.org/abs/2510.25014",
      "description": "arXiv:2510.25014v1 Announce Type: new \nAbstract: Large Language Models (LLMs) enable dynamic game interactions but fail to follow essential procedural flows in rule-governed trading systems, eroding player trust. This work resolves the core tension between the creative flexibility of LLMs and the pr...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt",
        "model",
        "arxiv",
        "prompting",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and Style-Structured Mixture of Experts",
      "url": "https://arxiv.org/abs/2510.25091",
      "description": "arXiv:2510.25091v1 Announce Type: new \nAbstract: Stock movement prediction remains fundamentally challenging due to complex temporal dependencies, heterogeneous modalities, and dynamically evolving inter-stock relationships. Existing approaches often fail to unify structural, semantic, and regime-ad...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "context",
        "cross-modal",
        "vector",
        "framework",
        "RAG",
        "experiment",
        "model",
        "arxiv",
        "alignment",
        "reasoning",
        "multimodal",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA",
      "url": "https://arxiv.org/abs/2510.25101",
      "description": "arXiv:2510.25101v1 Announce Type: new \nAbstract: Knowledge Base Question Answering (KBQA) aims to answer natural-language questions over a structured Knowledge Base (KB). Recent work improves KBQA by adopting an agentic reasoning paradigm, in which Large Language Models (LLMs) iteratively decompose ...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vision",
        "paper",
        "model",
        "arxiv",
        "knowledge base",
        "zero-shot",
        "reasoning",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models",
      "url": "https://arxiv.org/abs/2510.25179",
      "description": "arXiv:2510.25179v1 Announce Type: new \nAbstract: Agentic methods have emerged as a powerful and autonomous paradigm that enhances reasoning, collaboration, and adaptive control, enabling systems to coordinate and independently solve complex tasks. We extend this paradigm to safety alignment by intro...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "context",
        "vision",
        "framework",
        "RAG",
        "experiment",
        "model",
        "arxiv",
        "alignment",
        "reasoning",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models",
      "url": "https://arxiv.org/abs/2510.25206",
      "description": "arXiv:2510.25206v1 Announce Type: new \nAbstract: Reinforcement learning (RL) can refine the reasoning abilities of large language models (LLMs), but critically depends on a key prerequisite: the LLM can already generate high-utility reasoning paths with non-negligible probability. For tasks beyond t...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "RAG",
        "experiment",
        "model",
        "arxiv",
        "reasoning",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Can Aha Moments Be Fake? Identifying True and Decorative Thinking Steps in Chain-of-Thought",
      "url": "https://arxiv.org/abs/2510.24941",
      "description": "arXiv:2510.24941v1 Announce Type: new \nAbstract: Recent large language models (LLMs) can generate long Chain-of-Thought (CoT) at test time, enabling them to solve complex tasks. These reasoning steps in CoT are often assumed as a faithful reflection of the model's internal thinking process, and used...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "RAG",
        "large language model",
        "model",
        "arxiv",
        "reasoning",
        "chain-of-thought",
        "CoT",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt engineering",
        "context window",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "audio",
        "reasoning",
        "chain-of-thought",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "tool",
        "prompt",
        "model",
        "API",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "framework",
        "retrieval",
        "RAG",
        "model",
        "knowledge base",
        "reasoning",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "fine-tuning",
        "tool",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "product",
        "retrieval",
        "RAG",
        "augmented",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "vector",
        "prompt",
        "platform",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Cross-Lingual Summarization as a Black-Box Watermark Removal Attack",
      "url": "https://arxiv.org/abs/2510.24789",
      "description": "arXiv:2510.24789v1 Announce Type: new \nAbstract: Watermarking has been proposed as a lightweight mechanism to identify AI-generated text, with schemes typically relying on perturbations to token distributions. While prior work shows that paraphrasing can weaken such signals, these attacks remain par...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vector",
        "experiment",
        "summarization",
        "model",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Fortytwo: Swarm Inference with Peer-Ranked Consensus",
      "url": "https://arxiv.org/abs/2510.24801",
      "description": "arXiv:2510.24801v1 Announce Type: new \nAbstract: As centralized AI hits compute ceilings and diminishing returns from ever-larger training runs, meeting demand requires an inference layer that scales horizontally in both capacity and capability. We present Fortytwo, a novel protocol that leverages s...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "RAG",
        "model",
        "arxiv",
        "prompting"
      ],
      "score": 0.8
    },
    {
      "title": "Augmenting Biological Fitness Prediction Benchmarks with Landscapes Features from GraphFLA",
      "url": "https://arxiv.org/abs/2510.24826",
      "description": "arXiv:2510.24826v1 Announce Type: new \nAbstract: Machine learning models increasingly map biological sequence-fitness landscapes to predict mutational effects. Effective evaluation of these models requires benchmarks curated from empirical data. Despite their impressive scales, existing benchmarks l...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "framework",
        "RAG",
        "model",
        "arxiv",
        "release"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "context",
        "model",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Falcon: A Comprehensive Chinese Text-to-SQL Benchmark for Enterprise-Grade Evaluation",
      "url": "https://arxiv.org/abs/2510.24762",
      "description": "arXiv:2510.24762v1 Announce Type: new \nAbstract: We introduce Falcon, a cross-domain Chinese text-to-SQL benchmark grounded in an enterprise-compatible dialect (MaxCompute/Hive). It contains 600 Chinese questions over 28 databases; 77% require multi-table reasoning and over half touch more than four...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "product",
        "example",
        "model",
        "arxiv",
        "release",
        "reasoning",
        "template"
      ],
      "score": 0.6
    },
    {
      "title": "COMMUNITYNOTES: A Dataset for Exploring the Helpfulness of Fact-Checking Explanations",
      "url": "https://arxiv.org/abs/2510.24810",
      "description": "arXiv:2510.24810v1 Announce Type: new \nAbstract: Fact-checking on major platforms, such as X, Meta, and TikTok, is shifting from expert-driven verification to a community-based setup, where users contribute explanatory notes to clarify why a post might be misleading. An important challenge here is d...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "framework",
        "prompt",
        "experiment",
        "arxiv",
        "platform"
      ],
      "score": 0.6
    },
    {
      "title": "Reasoning-Aware GRPO using Process Mining",
      "url": "https://arxiv.org/abs/2510.25065",
      "description": "arXiv:2510.25065v1 Announce Type: new \nAbstract: Reinforcement learning (RL)-based post-training has been crucial for enabling multi-step reasoning in large reasoning models (LRMs), yet current reward schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware Group Relative Policy ...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "arxiv",
        "RAG",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "From Linear to Nonlinear: Provable Weak-to-Strong Generalization through Feature Learning",
      "url": "https://arxiv.org/abs/2510.24812",
      "description": "arXiv:2510.24812v1 Announce Type: new \nAbstract: Weak-to-strong generalization refers to the phenomenon where a stronger model trained under supervision from a weaker one can outperform its teacher. While prior studies aim to explain this effect, most theoretical insights are limited to abstract fra...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "vision",
        "paper",
        "framework",
        "model",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "paper",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "Dingtalk DeepResearch: A Unified Multi Agent Framework for Adaptive Intelligence in Enterprise Environments",
      "url": "https://arxiv.org/abs/2510.24760",
      "description": "arXiv:2510.24760v1 Announce Type: new \nAbstract: We present Dingtalk DeepResearch, a unified multi agent intelligence framework for real world enterprise environments, delivering deep research, heterogeneous table reasoning, and multimodal report generation....",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "framework",
        "arxiv",
        "reasoning",
        "multimodal"
      ],
      "score": 0.4
    },
    {
      "title": "Cyclic Counterfactuals under Shift-Scale Interventions",
      "url": "https://arxiv.org/abs/2510.25005",
      "description": "arXiv:2510.25005v1 Announce Type: new \nAbstract: Most counterfactual inference frameworks traditionally assume acyclic structural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However, many real-world systems (e.g. biological systems) contain feedback loops or cyclic dependencies that v...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "model",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision",
      "url": "https://arxiv.org/abs/2510.25205",
      "description": "arXiv:2510.25205v1 Announce Type: new \nAbstract: Autonomous driving is an emerging technology that is expected to bring significant social, economic, and environmental benefits. However, these benefits come with rising energy consumption by computation engines, limiting the driving range of vehicles...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "experiment",
        "ICL",
        "model",
        "compression",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Send Less, Save More: Energy-Efficiency Benchmark of Embedded CNN Inference vs. Data Transmission in IoT",
      "url": "https://arxiv.org/abs/2510.24829",
      "description": "arXiv:2510.24829v1 Announce Type: new \nAbstract: The integration of the Internet of Things (IoT) and Artificial Intelligence offers significant opportunities to enhance our ability to monitor and address ecological changes. As environmental challenges become increasingly pressing, the need for effec...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "model",
        "compression",
        "arxiv",
        "image"
      ],
      "score": 0.4
    },
    {
      "title": "Aggregation Hides Out-of-Distribution Generalization Failures from Spurious Correlations",
      "url": "https://arxiv.org/abs/2510.24884",
      "description": "arXiv:2510.24884v1 Announce Type: new \nAbstract: Benchmarks for out-of-distribution (OOD) generalization frequently show a strong positive correlation between in-distribution (ID) and OOD accuracy across models, termed \"accuracy-on-the-line.\" This pattern is often taken to imply that spurious correl...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "example",
        "model",
        "arxiv",
        "release"
      ],
      "score": 0.4
    },
    {
      "title": "Adaptive EEG-based stroke diagnosis with a GRU-TCN classifier and deep Q-learning thresholding",
      "url": "https://arxiv.org/abs/2510.24889",
      "description": "arXiv:2510.24889v1 Announce Type: new \nAbstract: Rapid triage of suspected stroke needs accurate, bedside-deployable tools; EEG is promising but underused at first contact. We present an adaptive multitask EEG classifier that converts 32-channel signals to power spectral density features (Welch), us...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "arxiv",
        "tool"
      ],
      "score": 0.4
    },
    {
      "title": "Topic Analysis with Side Information: A Neural-Augmented LDA Approach",
      "url": "https://arxiv.org/abs/2510.24918",
      "description": "arXiv:2510.24918v1 Announce Type: new \nAbstract: Traditional topic models such as Latent Dirichlet Allocation (LDA) have been widely used to uncover latent structures in text corpora, but they often struggle to integrate auxiliary information such as metadata, user attributes, or document labels. Th...",
      "published_date": "2025-10-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "augmented",
        "model",
        "analysis"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}