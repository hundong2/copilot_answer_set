{
  "generated_at": "2026-01-22T20:06:35.212437",
  "total_items": 47,
  "items": [
    {
      "title": "From Chaos to Clarity: Schema-Constrained AI for Auditable Biomedical Evidence Extraction from Full-Text PDFs",
      "url": "https://arxiv.org/abs/2601.14267",
      "description": "arXiv:2601.14267v1 Announce Type: new \nAbstract: Biomedical evidence synthesis relies on accurate extraction of methodological, laboratory, and outcome variables from full-text research articles, yet these variables are embedded in complex scientific PDFs that make manual abstraction time-consuming ...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "ICL",
        "arxiv",
        "RAG",
        "analysis",
        "model",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "The Slow Drift of Support: Boundary Failures in Multi-Turn Mental Health LLM Dialogues",
      "url": "https://arxiv.org/abs/2601.14269",
      "description": "arXiv:2601.14269v1 Announce Type: new \nAbstract: Large language models (LLMs) have been widely used for mental health support. However, current safety evaluations in this field are mostly limited to detecting whether LLMs output prohibited words in single-turn conversations, neglecting the gradual e...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "experiment",
        "arxiv",
        "example",
        "large language model",
        "RAG",
        "model",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Opening the Black Box: A Survey on the Mechanisms of Multi-Step Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2601.14270",
      "description": "arXiv:2601.14270v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable abilities to solve problems requiring multiple reasoning steps, yet the internal mechanisms enabling such capabilities remain elusive. Unlike existing surveys that primarily focus on engineerin...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "large language model",
        "reasoning",
        "model",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Hallucination-Free Automatic Question & Answer Generation for Intuitive Learning",
      "url": "https://arxiv.org/abs/2601.14280",
      "description": "arXiv:2601.14280v1 Announce Type: new \nAbstract: Hallucinations in large language models (LLMs), defined as fluent yet incorrect or incoherent outputs, pose a significant challenge to the automatic generation of educational multiple-choice questions (MCQs). We identified four key hallucination types...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "tool",
        "arxiv",
        "CoT",
        "large language model",
        "reasoning",
        "model",
        "LLM",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "RPC-Bench: A Fine-grained Benchmark for Research Paper Comprehension",
      "url": "https://arxiv.org/abs/2601.14289",
      "description": "arXiv:2601.14289v1 Announce Type: new \nAbstract: Understanding research papers remains challenging for foundation models due to specialized scientific discourse and complex figures and tables, yet existing benchmarks offer limited fine-grained evaluation at scale. To address this gap, we introduce R...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "research",
        "experiment",
        "arxiv",
        "context",
        "model",
        "LLM",
        "framework",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Guided by the Plan: Enhancing Faithful Autoregressive Text-to-Audio Generation with Guided Decoding",
      "url": "https://arxiv.org/abs/2601.14304",
      "description": "arXiv:2601.14304v1 Announce Type: new \nAbstract: Autoregressive (AR) models excel at generating temporally coherent audio by producing tokens sequentially, yet they often falter in faithfully following complex textual prompts, especially those describing complex sound events. We uncover a surprising...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "alignment",
        "arxiv",
        "audio",
        "model",
        "instruction"
      ],
      "score": 1.0
    },
    {
      "title": "Quantifying Speaker Embedding Phonological Rule Interactions in Accented Speech Synthesis",
      "url": "https://arxiv.org/abs/2601.14417",
      "description": "arXiv:2601.14417v1 Announce Type: new \nAbstract: Many spoken languages, including English, exhibit wide variation in dialects and accents, making accent control an important capability for flexible text-to-speech (TTS) models. Current TTS systems typically generate accented speech by conditioning on...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "model",
        "embedding",
        "framework",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Large Language Models for Large-Scale, Rigorous Qualitative Analysis in Applied Health Services Research",
      "url": "https://arxiv.org/abs/2601.14478",
      "description": "arXiv:2601.14478v1 Announce Type: new \nAbstract: Large language models (LLMs) show promise for improving the efficiency of qualitative analysis in large, multi-site health-services research. Yet methodological guidance for LLM integration into qualitative analysis and evidence of their impact on rea...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "large language model",
        "RAG",
        "analysis",
        "model",
        "LLM",
        "framework",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Can LLM Reasoning Be Trusted? A Comparative Study: Using Human Benchmarking on Statistical Tasks",
      "url": "https://arxiv.org/abs/2601.14479",
      "description": "arXiv:2601.14479v1 Announce Type: new \nAbstract: This paper investigates the ability of large language models (LLMs) to solve statistical tasks, as well as their capacity to assess the quality of reasoning. While state-of-the-art LLMs have demonstrated remarkable performance in a range of NLP tasks,...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "research",
        "tool",
        "arxiv",
        "large language model",
        "reasoning",
        "analysis",
        "platform",
        "model",
        "fine-tuning",
        "LLM",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "VisTIRA: Closing the Image-Text Modality Gap in Visual Math Reasoning via Structured Tool Integration",
      "url": "https://arxiv.org/abs/2601.14440",
      "description": "arXiv:2601.14440v1 Announce Type: new \nAbstract: Vision-language models (VLMs) lag behind text-only language models on mathematical reasoning when the same problems are presented as images rather than text. We empirically characterize this as a modality gap: the same question in text form yields mar...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "image",
        "experiment",
        "tool",
        "arxiv",
        "vision",
        "context",
        "reasoning",
        "model",
        "fine-tuning",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "On the Generalization Gap in LLM Planning: Tests and Verifier-Reward RL",
      "url": "https://arxiv.org/abs/2601.14456",
      "description": "arXiv:2601.14456v1 Announce Type: new \nAbstract: Recent work shows that fine-tuned Large Language Models (LLMs) can achieve high valid plan rates on PDDL planning tasks. However, it remains unclear whether this reflects transferable planning competence or domain-specific memorization. In this work, ...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "tool",
        "arxiv",
        "large language model",
        "model",
        "fine-tuning",
        "LLM",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Large Language Model-Powered Evolutionary Code Optimization on a Phylogenetic Tree",
      "url": "https://arxiv.org/abs/2601.14523",
      "description": "arXiv:2601.14523v1 Announce Type: new \nAbstract: Optimizing scientific computing algorithms for modern GPUs is a labor-intensive and iterative process involving repeated code modification, benchmarking, and tuning across complex hardware and software stacks. Recent work has explored large language m...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "transformer",
        "in-context",
        "arxiv",
        "large language model",
        "context",
        "memory",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Query-Efficient Agentic Graph Extraction Attacks on GraphRAG Systems",
      "url": "https://arxiv.org/abs/2601.14662",
      "description": "arXiv:2601.14662v1 Announce Type: new \nAbstract: Graph-based retrieval-augmented generation (GraphRAG) systems construct knowledge graphs over document collections to support multi-hop reasoning. While prior work shows that GraphRAG responses may leak retrieved subgraphs, the feasibility of query-ef...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "arxiv",
        "RAG",
        "reasoning",
        "memory",
        "LLM",
        "framework",
        "augmented",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Local Language Models for Context-Aware Adaptive Anonymization of Sensitive Text",
      "url": "https://arxiv.org/abs/2601.14683",
      "description": "arXiv:2601.14683v1 Announce Type: new \nAbstract: Qualitative research often contains personal, contextual, and organizational details that pose privacy risks if not handled appropriately. Manual anonymization is time-consuming, inconsistent, and frequently omits critical identifiers. Existing automa...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "tool",
        "arxiv",
        "context",
        "analysis",
        "model",
        "LLM",
        "framework",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Call2Instruct: Automated Pipeline for Generating Q&A Datasets from Call Center Recordings for LLM Fine-Tuning",
      "url": "https://arxiv.org/abs/2601.14263",
      "description": "arXiv:2601.14263v1 Announce Type: new \nAbstract: The adaptation of Large-Scale Language Models (LLMs) to specific domains depends on high-quality fine-tuning datasets, particularly in instructional format (e.g., Question-Answer - Q&amp;A). However, generating these datasets, particularly from unstru...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vector",
        "paper",
        "research",
        "ICL",
        "arxiv",
        "audio",
        "model",
        "fine-tuning",
        "instruction",
        "LLM",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "GCG Attack On A Diffusion LLM",
      "url": "https://arxiv.org/abs/2601.14266",
      "description": "arXiv:2601.14266v1 Announce Type: new \nAbstract: While most LLMs are autoregressive, diffusion-based LLMs have recently emerged as an alternative method for generation. Greedy Coordinate Gradient (GCG) attacks have proven effective against autoregressive models, but their applicability to diffusion ...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "arxiv",
        "analysis",
        "model",
        "LLM",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Divide and Refine: Enhancing Multimodal Representation and Explainability for Emotion Recognition in Conversation",
      "url": "https://arxiv.org/abs/2601.14274",
      "description": "arXiv:2601.14274v1 Announce Type: new \nAbstract: Multimodal emotion recognition in conversation (MERC) requires representations that effectively integrate signals from multiple modalities. These signals include modality-specific cues, information shared across modalities, and interactions that emerg...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "multimodal",
        "experiment",
        "arxiv",
        "cross-modal",
        "RAG",
        "embedding",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Which Quantization Should I Use? A Unified Evaluation of llama.cpp Quantization on Llama-3.1-8B-Instruct",
      "url": "https://arxiv.org/abs/2601.14277",
      "description": "arXiv:2601.14277v1 Announce Type: new \nAbstract: Quantization is a practical technique for making large language models easier to deploy by reducing the precision used to store and operate on model weights. This can lower memory use and improve runtime feasibility on constrained hardware, which is e...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "arxiv",
        "large language model",
        "context",
        "reasoning",
        "memory",
        "model",
        "instruction",
        "compression",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Chain-of-Memory: Lightweight Memory Construction with Dynamic Evolution for LLM Agents",
      "url": "https://arxiv.org/abs/2601.14287",
      "description": "arXiv:2601.14287v1 Announce Type: new \nAbstract: External memory systems are pivotal for enabling Large Language Model (LLM) agents to maintain persistent knowledge and perform long-horizon decision-making. Existing paradigms typically follow a two-stage process: computationally expensive memory con...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "experiment",
        "retrieval",
        "arxiv",
        "large language model",
        "context",
        "RAG",
        "reasoning",
        "memory",
        "analysis",
        "LLM",
        "model",
        "framework",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt",
        "context window",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "audio",
        "reasoning",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "tool",
        "context",
        "API",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "PageIndex - ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "url": "https://github.com/VectifyAI/PageIndex",
      "description": "ðŸ“‘ PageIndex: Document Index for Vectorless, Reasoning-based RAG",
      "published_date": "2025-04-01T10:53:54+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "vector",
        "RAG",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Open-source context retrieval layer for AI agents",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Open-source context retrieval layer for AI agents",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "context",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "retrieval",
        "RAG",
        "reasoning",
        "model",
        "LLM",
        "framework",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Build, Evaluate, and Optimize AI Systems. Includes evals, RAG, agents, fine-tuning, synthetic data generation, dataset management, MCP, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "product",
        "RAG",
        "API",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "prompt",
        "platform",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Epistemic Constitutionalism Or: how to avoid coherence bias",
      "url": "https://arxiv.org/abs/2601.14295",
      "description": "arXiv:2601.14295v1 Announce Type: new \nAbstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for ...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "paper",
        "large language model"
      ],
      "score": 0.8
    },
    {
      "title": "On the Limits of Learned Importance Scoring for KV Cache Compression",
      "url": "https://arxiv.org/abs/2601.14279",
      "description": "arXiv:2601.14279v1 Announce Type: new \nAbstract: We investigate learned KV cache compression through Speculative Importance Prediction (SIP), a 1.7M parameter non-query-aware scorer that predicts token importance from KV representations alone. Despite architectural sophistication (multi-horizon look...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "arxiv",
        "compression",
        "attention"
      ],
      "score": 0.8
    },
    {
      "title": "Beyond Affinity: A Benchmark of 1D, 2D, and 3D Methods Reveals Critical Trade-offs in Structure-Based Drug Design",
      "url": "https://arxiv.org/abs/2601.14283",
      "description": "arXiv:2601.14283v1 Announce Type: new \nAbstract: Currently, the field of structure-based drug design is dominated by three main types of algorithms: search-based algorithms, deep generative models, and reinforcement learning. While existing works have typically focused on comparing models within a s...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "paper",
        "arxiv",
        "analysis",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "model",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks",
      "url": "https://arxiv.org/abs/2601.14652",
      "description": "arXiv:2601.14652v1 Announce Type: new \nAbstract: While multi-agent systems (MAS) promise elevated intelligence through coordination of agents, current approaches to automatic MAS design under-deliver. Such shortcomings stem from two key factors: (1) methodological complexity - agent orchestration is...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "reasoning",
        "analysis",
        "framework",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "Gradient Structure Estimation under Label-Only Oracles via Spectral Sensitivity",
      "url": "https://arxiv.org/abs/2601.14300",
      "description": "arXiv:2601.14300v1 Announce Type: new \nAbstract: Hard-label black-box settings, where only top-1 predicted labels are observable, pose a fundamentally constrained yet practically important feedback model for understanding model behavior. A central challenge in this regime is whether meaningful gradi...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "experiment",
        "ICL",
        "arxiv",
        "API",
        "model",
        "framework",
        "image",
        "release"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "paper",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "The Ontological Neutrality Theorem: Why Neutral Ontological Substrates Must Be Pre-Causal and Pre-Normative",
      "url": "https://arxiv.org/abs/2601.14271",
      "description": "arXiv:2601.14271v1 Announce Type: new \nAbstract: Modern data systems must support accountability across persistent legal, political, and analytic disagreement. This requirement imposes strict constraints on the design of any ontology intended to function as a shared substrate. We establish an imposs...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "vision",
        "paper",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Scalable Knee-Point Guided Activity Group Selection in Multi-Tree Genetic Programming for Dynamic Multi-Mode Project Scheduling",
      "url": "https://arxiv.org/abs/2601.14485",
      "description": "arXiv:2601.14485v1 Announce Type: new \nAbstract: The dynamic multi-mode resource-constrained project scheduling problem is a challenging scheduling problem that requires making decisions on both the execution order of activities and their corresponding execution modes. Genetic programming has been w...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "experiment",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Quality or Quantity? Error-Informed Selective Online Learning with Gaussian Processes in Multi-Agent Systems: Extended Version",
      "url": "https://arxiv.org/abs/2601.14275",
      "description": "arXiv:2601.14275v1 Announce Type: new \nAbstract: Effective cooperation is pivotal in distributed learning for multi-agent systems, where the interplay between the quantity and quality of the machine learning models is crucial. This paper reveals the irrationality of indiscriminate inclusion of all m...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "model",
        "paper",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "A Comparison of Polynomial-Based Tree Clustering Methods",
      "url": "https://arxiv.org/abs/2601.14285",
      "description": "arXiv:2601.14285v1 Announce Type: new \nAbstract: Tree structures appear in many fields of the life sciences, including phylogenetics, developmental biology and nucleic acid structures. Trees can be used to represent RNA secondary structures, which directly relate to the function of non-coding RNAs. ...",
      "published_date": "2026-01-22T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "tool",
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "Differential Transformer V2",
      "url": "https://huggingface.co/blog/microsoft/diff-attn-v2",
      "description": "...",
      "published_date": "2026-01-20T03:20:57",
      "source": "Hugging Face Blog",
      "category": "prompt_engineering",
      "keywords": [
        "transformer"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}