<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Teaching People LLM&amp;#x27;s Errors and Getting it Right</title>
      <link>https://arxiv.org/abs/2512.21422</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21422</guid>
      <description>arXiv:2512.21422v1 Announce Type: new 
Abstract: People use large language models (LLMs) when they should not. This is partly because they see LLMs compose poems and answer intricate questions, so they understandably, but incorrectly, assume LLMs won&amp;#x27;t stumble on basic tasks like simple arithmetic. ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, paper, study, analysis, prompting | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>paper</category>
      <category>study</category>
    </item>
    <item>
      <title>Oogiri-Master: Benchmarking Humor Understanding via Oogiri</title>
      <link>https://arxiv.org/abs/2512.21494</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21494</guid>
      <description>arXiv:2512.21494v1 Announce Type: new 
Abstract: Humor is a salient testbed for human-like creative thinking in large language models (LLMs). We study humor using the Japanese creative response game Oogiri, in which participants produce witty responses to a given prompt, and ask the following resear...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, arxiv, augmented, study, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>arxiv</category>
      <category>augmented</category>
    </item>
    <item>
      <title>Gamayun&amp;#x27;s Path to Multilingual Mastery: Cost-Efficient Training of a 1.5B-Parameter LLM</title>
      <link>https://arxiv.org/abs/2512.21580</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21580</guid>
      <description>arXiv:2512.21580v1 Announce Type: new 
Abstract: We present Gamayun, a 1.5B-parameter multilingual language model trained entirely from scratch on 2.5T tokens. Designed for efficiency and deployment in resource-constrained environments, Gamayun addresses the lack of research on small non-English-cen...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, arxiv, LLM, model, alignment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>arxiv</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards</title>
      <link>https://arxiv.org/abs/2512.21625</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21625</guid>
      <description>arXiv:2512.21625v1 Announce Type: new 
Abstract: Large reasoning models (LRMs) are typically trained using reinforcement learning with verifiable reward (RLVR) to enhance their reasoning abilities. In this paradigm, policies are updated using both positive and negative self-generated rollouts, which...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, RAG, paper, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations</title>
      <link>https://arxiv.org/abs/2512.21635</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21635</guid>
      <description>arXiv:2512.21635v1 Announce Type: new 
Abstract: Hallucinations in large language models (LLMs) are commonly regarded as errors to be minimized. However, recent perspectives suggest that some hallucinations may encode creative or epistemically valuable content, a dimension that remains underquantifi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, arxiv, experiment, RAG, prompt | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles</title>
      <link>https://arxiv.org/abs/2512.21708</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21708</guid>
      <description>arXiv:2512.21708v1 Announce Type: new 
Abstract: Despite recent advancements of fine-tuning large language models (LLMs) to facilitate agent tasks, parameter-efficient fine-tuning (PEFT) methodologies for agent remain largely unexplored. In this paper, we introduce three key strategies for PEFT in a...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, RAG, paper, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Three-way conflict analysis based on alliance and conflict functions</title>
      <link>https://arxiv.org/abs/2512.21419</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21419</guid>
      <description>arXiv:2512.21419v1 Announce Type: new 
Abstract: Trisecting agents, issues, and agent pairs are essential topics of three-way conflict analysis. They have been commonly studied based on either a rating or an auxiliary function. A rating function defines the positive, negative, or neutral ratings of ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, example, RAG, study, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>example</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Feasible strategies in three-way conflict analysis with three-valued ratings</title>
      <link>https://arxiv.org/abs/2512.21420</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21420</guid>
      <description>arXiv:2512.21420v1 Announce Type: new 
Abstract: Most existing work on three-way conflict analysis has focused on trisecting agent pairs, agents, or issues, which contributes to understanding the nature of conflicts but falls short in addressing their resolution. Specifically, the formulation of fea...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; attention, arxiv, paper, analysis, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>attention</category>
      <category>arxiv</category>
      <category>paper</category>
    </item>
    <item>
      <title>LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis</title>
      <link>https://arxiv.org/abs/2512.21482</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21482</guid>
      <description>arXiv:2512.21482v1 Announce Type: new 
Abstract: Sophisticated text-centric forgeries, fueled by rapid AIGC advancements, pose a significant threat to societal security and information authenticity. Current methods for text-centric forgery analysis are often limited to coarse-grained visual analysis...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, image, GPT, RAG, zero-shot | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>image</category>
      <category>GPT</category>
    </item>
    <item>
      <title>Statistical vs. Deep Learning Models for Estimating Substance Overdose Excess Mortality in the US</title>
      <link>https://arxiv.org/abs/2512.21456</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21456</guid>
      <description>arXiv:2512.21456v1 Announce Type: new 
Abstract: Substance overdose mortality in the United States claimed over 80,000 lives in 2023, with the COVID-19 pandemic exacerbating existing trends through healthcare disruptions and behavioral changes. Estimating excess mortality, defined as deaths beyond e...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; attention, arxiv, transformer, RAG, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>attention</category>
      <category>arxiv</category>
      <category>transformer</category>
    </item>
    <item>
      <title>Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech</title>
      <link>https://arxiv.org/abs/2512.21706</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21706</guid>
      <description>arXiv:2512.21706v1 Announce Type: new 
Abstract: Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this causal pathway is key to building natural full-duplex interactive systems. We introduce a framework that enables reasoning over conver...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, framework, transformer, experiment, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>framework</category>
      <category>transformer</category>
    </item>
    <item>
      <title>AMS-IO-Bench and AMS-IO-Agent: Benchmarking and Structured Reasoning for Analog and Mixed-Signal Integrated Circuit Input/Output Design</title>
      <link>https://arxiv.org/abs/2512.21613</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21613</guid>
      <description>arXiv:2512.21613v1 Announce Type: new 
Abstract: In this paper, we propose AMS-IO-Agent, a domain-specialized LLM-based agent for structure-aware input/output (I/O) subsystem generation in analog and mixed-signal (AMS) integrated circuits (ICs). The central contribution of this work is a framework t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, paper, knowledge base, reasoning, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>paper</category>
      <category>knowledge base</category>
    </item>
    <item>
      <title>A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers</title>
      <link>https://arxiv.org/abs/2512.21365</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21365</guid>
      <description>arXiv:2512.21365v1 Announce Type: new 
Abstract: This paper analyzes the behavior of solving Life-and-Death (L&amp;amp;amp;D) problems in the game of Go using current state-of-the-art computer Go solvers with two techniques: the Relevance-Zone Based Search (RZS) and the relevance-zone pattern table. We exam...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, paper, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>paper</category>
      <category>study</category>
    </item>
    <item>
      <title>Three-way decision with incomplete information based on similarity and satisfiability</title>
      <link>https://arxiv.org/abs/2512.21421</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21421</guid>
      <description>arXiv:2512.21421v1 Announce Type: new 
Abstract: Three-way decision is widely applied with rough set theory to learn classification or decision rules. The approaches dealing with complete information are well established in the literature, including the two complementary computational and conceptual...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, paper, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>paper</category>
      <category>study</category>
    </item>
    <item>
      <title>RLLaVA: An RL-central Framework for Language and Vision Assistants</title>
      <link>https://arxiv.org/abs/2512.21450</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21450</guid>
      <description>arXiv:2512.21450v1 Announce Type: new 
Abstract: We present an RL-central framework for Language and Vision Assistants (RLLaVA) with its formulation of Markov decision process (MDP). RLLaVA decouples RL algorithmic logic from model architecture and distributed execution, supporting researchers in im...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, arxiv, experiment, vision, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>DeepCQ: General-Purpose Deep-Surrogate Framework for Lossy Compression Quality Prediction</title>
      <link>https://arxiv.org/abs/2512.21433</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21433</guid>
      <description>arXiv:2512.21433v1 Announce Type: new 
Abstract: Error-bounded lossy compression techniques have become vital for scientific data management and analytics, given the ever-increasing volume of data generated by modern scientific simulations and instruments. Nevertheless, assessing data quality post-c...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, analysis, compression, model, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>analysis</category>
      <category>compression</category>
    </item>
    <item>
      <title>When Bayesian Tensor Completion Meets Multioutput Gaussian Processes: Functional Universality and Rank Learning</title>
      <link>https://arxiv.org/abs/2512.21486</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.21486</guid>
      <description>arXiv:2512.21486v1 Announce Type: new 
Abstract: Functional tensor decomposition can analyze multi-dimensional data with real-valued indices, paving the path for applications in machine learning and signal processing. A limitation of existing approaches is the assumption that the tensor rank-a criti...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, framework, model, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>framework</category>
      <category>model</category>
    </item>
  </channel>
</rss>