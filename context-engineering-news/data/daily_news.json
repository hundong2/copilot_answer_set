{
  "generated_at": "2025-10-15T20:06:12.022707",
  "total_items": 46,
  "items": [
    {
      "title": "PHANTOM RECALL: When Familiar Puzzles Fool Smart Models",
      "url": "https://arxiv.org/abs/2510.11812",
      "description": "arXiv:2510.11812v1 Announce Type: new \nAbstract: Large language models (LLMs) such as GPT, Gemini, and Claude often appear adept at solving classic logic puzzles--but how much genuine reasoning underlies their answers? Recent evidence suggests that these models frequently rely on memorized templates...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "framework",
        "large language model",
        "arxiv",
        "template",
        "context",
        "reasoning",
        "prompt",
        "RAG",
        "LLM",
        "GPT",
        "tool",
        "model",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "R-WoM: Retrieval-augmented World Model For Computer-use Agents",
      "url": "https://arxiv.org/abs/2510.11892",
      "description": "arXiv:2510.11892v1 Announce Type: new \nAbstract: Large Language Models (LLMs) can serve as world models to enhance agent decision-making in digital environments by simulating future states and predicting action outcomes, potentially eliminating costly trial-and-error exploration. However, this capab...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "API",
        "arxiv",
        "augmented",
        "model",
        "alignment",
        "LLM",
        "analysis",
        "experiment",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "LLM Knowledge is Brittle: Truthfulness Representations Rely on Superficial Resemblance",
      "url": "https://arxiv.org/abs/2510.11905",
      "description": "arXiv:2510.11905v1 Announce Type: new \nAbstract: For Large Language Models (LLMs) to be reliable, they must learn robust knowledge that can be generally applied in diverse settings -- often unlike those seen during training. Yet, extensive research has shown that LLM performance can be brittle, with...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "large language model",
        "arxiv",
        "model",
        "LLM",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens",
      "url": "https://arxiv.org/abs/2510.11919",
      "description": "arXiv:2510.11919v1 Announce Type: new \nAbstract: Large reasoning models (LRMs) have led to new possibilities in terms of problem-solving, through the devising of a natural language thought process prior to answering a query. While their capabilities are well known across mathematics and coding tasks...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "CoT",
        "fine-tuning",
        "reasoning",
        "prompt",
        "model",
        "LLM",
        "step-by-step",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "TopoAlign: A Framework for Aligning Code to Math via Topological Decomposition",
      "url": "https://arxiv.org/abs/2510.11944",
      "description": "arXiv:2510.11944v1 Announce Type: new \nAbstract: Large Language Models (LLMs) excel at both informal and formal (e.g. Lean 4) mathematical reasoning but still struggle with autoformalisation, the task of transforming informal into formal mathematical statements. Autoformalisation helps pair the info...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "framework",
        "large language model",
        "arxiv",
        "reasoning",
        "model",
        "instruction",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "GRAVITY: A Framework for Personalized Text Generation via Profile-Grounded Synthetic Preferences",
      "url": "https://arxiv.org/abs/2510.11952",
      "description": "arXiv:2510.11952v1 Announce Type: new \nAbstract: Personalization in LLMs often relies on costly human feedback or interaction logs, limiting scalability and neglecting deeper user attributes. To reduce the reliance on human annotations, we introduce GRAVITY (Generative Response with Aligned Values, ...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "framework",
        "arxiv",
        "fine-tuning",
        "prompt",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Evaluating Retrieval-Augmented Generation Systems on Unanswerable, Uncheatable, Realistic, Multi-hop Queries",
      "url": "https://arxiv.org/abs/2510.11956",
      "description": "arXiv:2510.11956v1 Announce Type: new \nAbstract: Real-world use cases often present RAG systems with complex queries for which relevant information is missing from the corpus or is incomplete. In these settings, RAG systems must be able to reject unanswerable, out-of-scope queries and identify failu...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "augmented",
        "reasoning",
        "RAG",
        "LLM",
        "experiment",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Direct Multi-Token Decoding",
      "url": "https://arxiv.org/abs/2510.11958",
      "description": "arXiv:2510.11958v1 Announce Type: new \nAbstract: Decoder-only transformers have become the standard architecture for large language models (LLMs) due to their strong performance. Recent studies suggest that, in pre-trained LLMs, early, middle, and late layers may serve distinct roles: Early layers f...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "arxiv",
        "context",
        "model",
        "LLM",
        "analysis",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "Scaling Long-Horizon LLM Agent via Context-Folding",
      "url": "https://arxiv.org/abs/2510.11967",
      "description": "arXiv:2510.11967v1 Announce Type: new \nAbstract: Large language model (LLM) agents are fundamentally constrained by context length on long-horizon tasks. We introduce Context-Folding, a framework that empowers agents to actively manage their working context. An agent can procedurally branch into a s...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "research",
        "large language model",
        "arxiv",
        "context",
        "RAG",
        "model",
        "LLM",
        "summarization"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond Consensus: Mitigating the Agreeableness Bias in LLM Judge Evaluations",
      "url": "https://arxiv.org/abs/2510.11822",
      "description": "arXiv:2510.11822v1 Announce Type: new \nAbstract: New Large Language Models (LLMs) become available every few weeks, and modern application developers confronted with the unenviable task of having to decide if they should switch to a new model. While human evaluation remains the gold standard, it is ...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "large language model",
        "arxiv",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent Evaluation",
      "url": "https://arxiv.org/abs/2510.11977",
      "description": "arXiv:2510.11977v1 Announce Type: new \nAbstract: AI agents have been developed for complex real-world tasks from coding to customer service. But AI agent evaluations suffer from many challenges that undermine our understanding of how well agents really work. We introduce the Holistic Agent Leaderboa...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "reasoning",
        "model",
        "LLM",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "CGBench: Benchmarking Language Model Scientific Reasoning for Clinical Genetics Research",
      "url": "https://arxiv.org/abs/2510.11985",
      "description": "arXiv:2510.11985v1 Announce Type: new \nAbstract: Variant and gene interpretation are fundamental to personalized medicine and translational biomedicine. However, traditional approaches are manual and labor-intensive. Generative language models (LMs) can facilitate this process, accelerating the tran...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "arxiv",
        "reasoning",
        "model",
        "instruction",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Asking Clarifying Questions for Preference Elicitation With Large Language Models",
      "url": "https://arxiv.org/abs/2510.12015",
      "description": "arXiv:2510.12015v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have made it possible for recommendation systems to interact with users in open-ended conversational interfaces. In order to personalize LLM responses, it is crucial to elicit user preferences, especially when there is lim...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "LLM",
        "large language model",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Do Large Language Models Respect Contracts? Evaluating and Enforcing Contract-Adherence in Code Generation",
      "url": "https://arxiv.org/abs/2510.12047",
      "description": "arXiv:2510.12047v1 Announce Type: new \nAbstract: Prevailing code generation benchmarks, such as HumanEval+ and MBPP+, primarily evaluate large language models (LLMs) with pass@k on functional correctness using well-formed inputs. However, they ignore a crucial aspect of real-world software: adherenc...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "framework",
        "large language model",
        "arxiv",
        "prompt",
        "model",
        "LLM",
        "prompting",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Empowering LLM Agents with Geospatial Awareness: Toward Grounded Reasoning for Wildfire Response",
      "url": "https://arxiv.org/abs/2510.12061",
      "description": "arXiv:2510.12061v1 Announce Type: new \nAbstract: Effective disaster response is essential for safeguarding lives and property. Existing statistical approaches often lack semantic context, generalize poorly across events, and offer limited interpretability. While Large language models (LLMs) provide ...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "framework",
        "few-shot",
        "large language model",
        "arxiv",
        "context",
        "reasoning",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization",
      "url": "https://arxiv.org/abs/2510.12063",
      "description": "arXiv:2510.12063v1 Announce Type: new \nAbstract: Large Reasoning Models (LRMs) are powerful, but they still suffer from inefficient and off-target reasoning. Currently, training-free methods are limited to either rigid heuristics or descriptive, non-actionable analyses. In this paper, we introduce T...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "example",
        "arxiv",
        "reasoning",
        "model",
        "instruction",
        "analysis",
        "experiment",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "AI Agents as Universal Task Solvers",
      "url": "https://arxiv.org/abs/2510.12066",
      "description": "arXiv:2510.12066v1 Announce Type: new \nAbstract: AI reasoning agents are already able to solve a variety of tasks by deploying tools, simulating outcomes of multiple hypotheses and reflecting on them. In doing so, they perform computation, although not in the classical sense -- there is no program b...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "arxiv",
        "context",
        "reasoning",
        "model",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Enhanced Urban Traffic Management Using CCTV Surveillance Videos and Multi-Source Data Current State Prediction and Frequent Episode Mining",
      "url": "https://arxiv.org/abs/2510.09644",
      "description": "arXiv:2510.09644v1 Announce Type: new \nAbstract: Rapid urbanization has intensified traffic congestion, environmental strain, and inefficiencies in transportation systems, creating an urgent need for intelligent and adaptive traffic management solutions. Conventional systems relying on static signal...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "research",
        "API",
        "arxiv",
        "model",
        "analysis",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "Gradient-Sign Masking for Task Vector Transport Across Pre-Trained Models",
      "url": "https://arxiv.org/abs/2510.09658",
      "description": "arXiv:2510.09658v1 Announce Type: new \nAbstract: When a new release of a foundation model is published, practitioners typically need to repeat full fine-tuning, even if the same task has already been solved in the previous version. A promising alternative is to reuse the parameter changes (i.e., tas...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "few-shot",
        "vision",
        "arxiv",
        "fine-tuning",
        "RAG",
        "model",
        "release",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "LMCache: An Efficient KV Cache Layer for Enterprise-Scale LLM Inference",
      "url": "https://arxiv.org/abs/2510.09665",
      "description": "arXiv:2510.09665v1 Announce Type: new \nAbstract: Today's LLM inference systems treat individual engines and queries independently for simplicity, but this causes significant resource inefficiencies. While there are proposals to avoid redundant computation by reusing KV caches across queries and to i...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "compression",
        "arxiv",
        "RAG",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "context window",
        "context",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "CoT",
        "reasoning",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "context",
        "prompt",
        "model",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "framework",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "knowledge base",
        "reasoning",
        "RAG",
        "model",
        "LLM",
        "retrieval",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "LLM",
        "tool",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "augmented",
        "RAG",
        "retrieval",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "prompt",
        "platform",
        "LLM",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "framework",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "CausalTrace: A Neurosymbolic Causal Analysis Agent for Smart Manufacturing",
      "url": "https://arxiv.org/abs/2510.12033",
      "description": "arXiv:2510.12033v1 Announce Type: new \nAbstract: Modern manufacturing environments demand not only accurate predictions but also interpretable insights to process anomalies, root causes, and potential interventions. Existing AI systems often function as isolated black boxes, lacking the seamless int...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "reasoning",
        "RAG",
        "analysis"
      ],
      "score": 0.8
    },
    {
      "title": "Direct Routing Gradient (DRGrad): A Personalized Information Surgery for Multi-Task Learning (MTL) Recommendations",
      "url": "https://arxiv.org/abs/2510.09643",
      "description": "arXiv:2510.09643v1 Announce Type: new \nAbstract: Multi-task learning (MTL) has emerged as a successful strategy in industrial-scale recommender systems, offering significant advantages such as capturing diverse users' interests and accurately detecting different behaviors like ``click\" or ``dwell ti...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "RAG",
        "model",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "Generative Models for Helmholtz Equation Solutions: A Dataset of Acoustic Materials",
      "url": "https://arxiv.org/abs/2510.09657",
      "description": "arXiv:2510.09657v1 Announce Type: new \nAbstract: Accurate simulation of wave propagation in complex acoustic materials is crucial for applications in sound design, noise control, and material engineering. Traditional numerical solvers, such as finite element methods, are computationally expensive, e...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "API",
        "arxiv",
        "RAG",
        "model",
        "image"
      ],
      "score": 0.8
    },
    {
      "title": "Heterogeneous Point Set Transformers for Segmentation of Multiple View Particle Detectors",
      "url": "https://arxiv.org/abs/2510.09659",
      "description": "arXiv:2510.09659v1 Announce Type: new \nAbstract: NOvA is a long-baseline neutrino oscillation experiment that detects neutrino particles from the NuMI beam at Fermilab. Before data from this experiment can be used in analyses, raw hits in the detector must be matched to their source particles, and t...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "ICL",
        "model",
        "experiment",
        "memory",
        "transformer",
        "image"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "API",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Discrepancy Detection at the Data Level: Toward Consistent Multilingual Question Answering",
      "url": "https://arxiv.org/abs/2510.11928",
      "description": "arXiv:2510.11928v1 Announce Type: new \nAbstract: Multilingual question answering (QA) systems must ensure factual consistency across languages, especially for objective queries such as What is jaundice?, while also accounting for cultural variation in subjective responses. We propose MIND, a user-in...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "knowledge base",
        "context",
        "release"
      ],
      "score": 0.6
    },
    {
      "title": "AI Agents for the Dhumbal Card Game: A Comparative Study",
      "url": "https://arxiv.org/abs/2510.11736",
      "description": "arXiv:2510.11736v1 Announce Type: new \nAbstract: This study evaluates Artificial Intelligence (AI) agents for Dhumbal, a culturally significant multiplayer card game with imperfect information, through a systematic comparison of rule-based, search-based, and learning-based strategies. We formalize D...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "research",
        "arxiv",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "Assessment of different loss functions for fitting equivalent circuit models to electrochemical impedance spectroscopy data",
      "url": "https://arxiv.org/abs/2510.09662",
      "description": "arXiv:2510.09662v1 Announce Type: new \nAbstract: Electrochemical impedance spectroscopy (EIS) data is typically modeled using an equivalent circuit model (ECM), with parameters obtained by minimizing a loss function via nonlinear least squares fitting. This paper introduces two new loss functions, l...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "analysis",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Semantic-Cohesive Knowledge Distillation for Deep Cross-modal Hashing",
      "url": "https://arxiv.org/abs/2510.09664",
      "description": "arXiv:2510.09664v1 Announce Type: new \nAbstract: Recently, deep supervised cross-modal hashing methods have achieve compelling success by learning semantic information in a self-supervised way. However, they still suffer from the key limitation that the multi-label semantic extraction process fail t...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "multimodal",
        "image",
        "arxiv",
        "cross-modal",
        "prompt",
        "model",
        "experiment",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Spatial Uncertainty Quantification in Wildfire Forecasting for Climate-Resilient Emergency Planning",
      "url": "https://arxiv.org/abs/2510.09666",
      "description": "arXiv:2510.09666v1 Announce Type: new \nAbstract: Climate change is intensifying wildfire risks globally, making reliable forecasting critical for adaptation strategies. While machine learning shows promise for wildfire prediction from Earth observation data, current approaches lack uncertainty quant...",
      "published_date": "2025-10-15T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "multimodal",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}