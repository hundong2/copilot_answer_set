{
  "generated_at": "2025-10-03T20:05:40.567599",
  "total_items": 46,
  "items": [
    {
      "title": "Uncovering Implicit Bias in Large Language Models with Concept Learning Dataset",
      "url": "https://arxiv.org/abs/2510.01219",
      "description": "arXiv:2510.01219v1 Announce Type: new \nAbstract: We introduce a dataset of concept learning tasks that helps uncover implicit biases in large language models. Using in-context concept learning experiments, we found that language models may have a bias toward upward monotonicity in quantifiers; such ...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "in-context",
        "experiment",
        "large language model",
        "prompt",
        "prompting",
        "context",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Discourse vs emissions: Analysis of corporate narratives, symbolic practices, and mimicry through LLMs",
      "url": "https://arxiv.org/abs/2510.01222",
      "description": "arXiv:2510.01222v1 Announce Type: new \nAbstract: Climate change has increased demands for transparent and comparable corporate climate disclosures, yet imitation and symbolic reporting often undermine their value. This paper develops a multidimensional framework to assess disclosure maturity among 8...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "API",
        "large language model",
        "framework",
        "LLM",
        "arxiv",
        "analysis",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Context Matters: Comparison of commercial large language tools in veterinary medicine",
      "url": "https://arxiv.org/abs/2510.01224",
      "description": "arXiv:2510.01224v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly used in clinical settings, yet their performance in veterinary medicine remains underexplored. We evaluated three commercially available veterinary-focused LLM summarization tools (Product 1 [Hachiko] and ...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "product",
        "tool",
        "large language model",
        "framework",
        "LLM",
        "context",
        "summarization",
        "arxiv",
        "model",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "ClaimCheck: Real-Time Fact-Checking with Small Language Models",
      "url": "https://arxiv.org/abs/2510.01226",
      "description": "arXiv:2510.01226v1 Announce Type: new \nAbstract: We introduce ClaimCheck, an LLM-guided automatic fact-checking system designed to verify real-world claims using live Web evidence and small language models. Unlike prior systems that rely on large, closed-source models and static knowledge stores, Cl...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "GPT",
        "prompt",
        "LLM",
        "prompting",
        "retrieval",
        "summarization",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "EEFSUVA: A New Mathematical Olympiad Benchmark",
      "url": "https://arxiv.org/abs/2510.01227",
      "description": "arXiv:2510.01227v1 Announce Type: new \nAbstract: Recent breakthroughs have spurred claims that large language models (LLMs) match gold medal Olympiad to graduate level proficiency on mathematics benchmarks. In this work, we examine these claims in detail and assess the extent to which current benchm...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "large language model",
        "reasoning",
        "LLM",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Who is In Charge? Dissecting Role Conflicts in Instruction Following",
      "url": "https://arxiv.org/abs/2510.01228",
      "description": "arXiv:2510.01228v1 Announce Type: new \nAbstract: Large language models should follow hierarchical instructions where system prompts override user inputs, yet recent work shows they often ignore this rule while strongly obeying social cues such as authority or consensus. We extend these behavioral fi...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "instruction",
        "experiment",
        "alignment",
        "large language model",
        "prompt",
        "vector",
        "arxiv",
        "model",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing Transformer-Based Rerankers with Synthetic Data and LLM-Based Supervision",
      "url": "https://arxiv.org/abs/2510.01229",
      "description": "arXiv:2510.01229v1 Announce Type: new \nAbstract: Effective document reranking is essential for improving search relevance across diverse applications. While Large Language Models (LLMs) excel at reranking due to their deep semantic understanding and reasoning, their high computational cost makes the...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "transformer",
        "vision",
        "experiment",
        "large language model",
        "reasoning",
        "LLM",
        "arxiv",
        "fine-tuning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Trustworthy Summarization via Uncertainty Quantification and Risk Awareness in Large Language Models",
      "url": "https://arxiv.org/abs/2510.01231",
      "description": "arXiv:2510.01231v1 Announce Type: new \nAbstract: This study addresses the reliability of automatic summarization in high-risk scenarios and proposes a large language model framework that integrates uncertainty quantification and risk-aware mechanisms. Starting from the demands of information overloa...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "compression",
        "experiment",
        "study",
        "large language model",
        "framework",
        "prompt",
        "summarization",
        "arxiv",
        "model",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "OR-Toolformer: Modeling and Solving Operations Research Problems with Tool Augmented Large Language Models",
      "url": "https://arxiv.org/abs/2510.01253",
      "description": "arXiv:2510.01253v1 Announce Type: new \nAbstract: Large language models (LLMs) demonstrate strong mathematical reasoning, but reliance on closed-source APIs for OR tasks raises privacy concerns, and training open-source models from scratch incurs high compute costs. We introduce OR-Toolformer, which ...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "zero-shot",
        "tool",
        "API",
        "large language model",
        "reasoning",
        "LLM",
        "arxiv",
        "fine-tuning",
        "model",
        "RAG",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Modeling Others' Minds as Code",
      "url": "https://arxiv.org/abs/2510.01272",
      "description": "arXiv:2510.01272v1 Announce Type: new \nAbstract: Accurate prediction of human behavior is essential for robust and safe human-AI collaboration. However, existing approaches for modeling people are often data-hungry and brittle because they either make unrealistic assumptions about rationality or are...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "API",
        "large language model",
        "reasoning",
        "LLM",
        "arxiv",
        "model",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Cyber Academia-Chemical Engineering (CA-ChemE): A Living Digital Town for Self-Directed Research Evolution and Emergent Scientific Discovery",
      "url": "https://arxiv.org/abs/2510.01293",
      "description": "arXiv:2510.01293v1 Announce Type: new \nAbstract: The rapid advancement of artificial intelligence (AI) has demonstrated substantial potential in chemical engineering, yet existing AI systems remain limited in interdisciplinary collaboration and exploration of uncharted problems. To address these iss...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "API",
        "knowledge base",
        "study",
        "reasoning",
        "prompt",
        "prompting",
        "arxiv",
        "RAG",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "The Social Laboratory: A Psychometric Framework for Multi-Agent LLM Evaluation",
      "url": "https://arxiv.org/abs/2510.01295",
      "description": "arXiv:2510.01295v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) transition from static tools to autonomous agents, traditional evaluation benchmarks that measure performance on downstream tasks are becoming insufficient. These methods fail to capture the emergent social and cognitiv...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "release",
        "vision",
        "instruction",
        "tool",
        "API",
        "alignment",
        "large language model",
        "framework",
        "LLM",
        "arxiv",
        "analysis",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "MEMTRACK: Evaluating Long-Term Memory and State Tracking in Multi-Platform Dynamic Agent Environments",
      "url": "https://arxiv.org/abs/2510.01353",
      "description": "arXiv:2510.01353v1 Announce Type: new \nAbstract: Recent works on context and memory benchmarking have primarily focused on conversational instances but the need for evaluating memory in dynamic enterprise environments is crucial for its effective application. We introduce MEMTRACK, a benchmark desig...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "augmented",
        "product",
        "memory",
        "experiment",
        "framework",
        "LLM",
        "context",
        "arxiv",
        "model",
        "platform",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Retrieval-Augmented Framework for LLM-Based Clinical Decision Support",
      "url": "https://arxiv.org/abs/2510.01363",
      "description": "arXiv:2510.01363v1 Announce Type: new \nAbstract: The increasing complexity of clinical decision-making, alongside the rapid expansion of electronic health records (EHR), presents both opportunities and challenges for delivering data-informed care. This paper proposes a clinical decision support syst...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "tool",
        "API",
        "alignment",
        "large language model",
        "framework",
        "retrieval",
        "LLM",
        "context",
        "arxiv",
        "model",
        "paper",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Is It Thinking or Cheating? Detecting Implicit Reward Hacking by Measuring Reasoning Effort",
      "url": "https://arxiv.org/abs/2510.01367",
      "description": "arXiv:2510.01367v1 Announce Type: new \nAbstract: Reward hacking, where a reasoning model exploits loopholes in a reward function to achieve high rewards without solving the intended task, poses a significant threat. This behavior may be explicit, i.e. verbalized in the model's chain-of-thought (CoT)...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "arxiv",
        "CoT",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Fine-tuning with RAG for Improving LLM Learning of New Skills",
      "url": "https://arxiv.org/abs/2510.01375",
      "description": "arXiv:2510.01375v1 Announce Type: new \nAbstract: Large language model (LLM) agents deployed for multi-step tasks frequently fail in predictable ways: attempting actions with unmet preconditions, issuing redundant commands, or mishandling environment constraints. While retrieval-augmented generation ...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "large language model",
        "retrieval",
        "LLM",
        "arxiv",
        "fine-tuning",
        "model",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Control the Temperature: Selective Sampling for Diverse and High-Quality LLM Outputs",
      "url": "https://arxiv.org/abs/2510.01218",
      "description": "arXiv:2510.01218v1 Announce Type: new \nAbstract: Diversity is an essential metric for evaluating the creativity of outputs generated by language models. Temperature-based sampling is a common strategy to increase diversity. However, for tasks that require high precision, e.g., mathematical reasoning...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "reasoning",
        "LLM",
        "arxiv",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Automated Extraction of Material Properties using LLM-based AI Agents",
      "url": "https://arxiv.org/abs/2510.01235",
      "description": "arXiv:2510.01235v1 Announce Type: new \nAbstract: The rapid discovery of materials is constrained by the lack of large, machine-readable datasets that couple performance metrics with structural context. Existing databases are either small, manually curated, or biased toward first principles results, ...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "GPT",
        "release",
        "experiment",
        "API",
        "study",
        "large language model",
        "ICL",
        "LLM",
        "context",
        "arxiv",
        "analysis",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "RSAVQ: Riemannian Sensitivity-Aware Vector Quantization for Large Language Models",
      "url": "https://arxiv.org/abs/2510.01240",
      "description": "arXiv:2510.01240v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, their exponentially increasing parameters pose significant challenges for deployment on resource-constrained devic...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "zero-shot",
        "experiment",
        "large language model",
        "framework",
        "LLM",
        "vector",
        "arxiv",
        "analysis",
        "model",
        "paper",
        "RAG",
        "example"
      ],
      "score": 1.0
    },
    {
      "title": "RSTGCN: Railway-centric Spatio-Temporal Graph Convolutional Network for Train Delay Prediction",
      "url": "https://arxiv.org/abs/2510.01262",
      "description": "arXiv:2510.01262v1 Announce Type: new \nAbstract: Accurate prediction of train delays is critical for efficient railway operations, enabling better scheduling and dispatching decisions. While earlier approaches have largely focused on forecasting the exact delays of individual trains, recent studies ...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "release",
        "experiment",
        "arxiv",
        "attention",
        "model",
        "paper",
        "RAG",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "RLP: Reinforcement as a Pretraining Objective",
      "url": "https://arxiv.org/abs/2510.01265",
      "description": "arXiv:2510.01265v1 Announce Type: new \nAbstract: The dominant paradigm for training large reasoning models starts with pre-training using next-token prediction loss on vast amounts of data. Reinforcement learning, while powerful in scaling reasoning, is introduced only as the very last phase of post...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "context",
        "arxiv",
        "fine-tuning",
        "model",
        "paper",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context",
        "prompt",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "reasoning",
        "audio",
        "CoT",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "API",
        "prompt",
        "LLM",
        "context",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "context",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "knowledge base",
        "reasoning",
        "framework",
        "retrieval",
        "LLM",
        "vector",
        "model",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "LLM",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "product",
        "API",
        "retrieval",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "prompt",
        "LLM",
        "vector",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Towards Open-Ended Discovery for Low-Resource NLP",
      "url": "https://arxiv.org/abs/2510.01220",
      "description": "arXiv:2510.01220v1 Announce Type: new \nAbstract: Natural Language Processing (NLP) for low-resource languages remains fundamentally constrained by the lack of textual corpora, standardized orthographies, and scalable annotation pipelines. While recent advances in large language models have improved ...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "vision",
        "memory",
        "large language model",
        "framework",
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "Geometric Structures and Patterns of Meaning: A PHATE Manifold Analysis of Chinese Character Embeddings",
      "url": "https://arxiv.org/abs/2510.01230",
      "description": "arXiv:2510.01230v1 Announce Type: new \nAbstract: We systematically investigate geometric patterns in Chinese character embeddings using PHATE manifold analysis. Through cross-validation across seven embedding models and eight dimensionality reduction methods, we observe clustering patterns for conte...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "embedding",
        "arxiv",
        "analysis",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Agentic Jigsaw Interaction Learning for Enhancing Visual Perception and Reasoning in Vision-Language Models",
      "url": "https://arxiv.org/abs/2510.01304",
      "description": "arXiv:2510.01304v1 Announce Type: new \nAbstract: Although current large Vision-Language Models (VLMs) have advanced in multimodal understanding and reasoning, their fundamental perceptual and reasoning abilities remain limited. Specifically, even on simple jigsaw tasks, existing VLMs perform near ra...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "vision",
        "experiment",
        "reasoning",
        "multimodal",
        "arxiv",
        "model",
        "RAG"
      ],
      "score": 0.8
    },
    {
      "title": "Budgeted Broadcast: An Activity-Dependent Pruning Rule for Neural Network Efficiency",
      "url": "https://arxiv.org/abs/2510.01263",
      "description": "arXiv:2510.01263v1 Announce Type: new \nAbstract: Most pruning methods remove parameters ranked by impact on loss (e.g., magnitude or gradient). We propose Budgeted Broadcast (BB), which gives each unit a local traffic budget (the product of its long-term on-rate $a_i$ and fan-out $k_i$). A constrain...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "product",
        "transformer",
        "image",
        "arxiv",
        "analysis"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "context",
        "tool",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Introducing RTEB: A New Standard for Retrieval Evaluation",
      "url": "https://huggingface.co/blog/rteb",
      "description": "...",
      "published_date": "2025-10-01T00:00:00",
      "source": "Hugging Face Blog",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Adaptive Federated Learning Defences via Trust-Aware Deep Q-Networks",
      "url": "https://arxiv.org/abs/2510.01261",
      "description": "arXiv:2510.01261v1 Announce Type: new \nAbstract: Federated learning is vulnerable to poisoning and backdoor attacks under partial observability. We formulate defence as a partially observable sequential decision problem and introduce a trust-aware Deep Q-Network that integrates multi-signal evidence...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "A Framework for Scalable Heterogeneous Multi-Agent Adversarial Reinforcement Learning in IsaacLab",
      "url": "https://arxiv.org/abs/2510.01264",
      "description": "arXiv:2510.01264v1 Announce Type: new \nAbstract: Multi-Agent Reinforcement Learning (MARL) is central to robotic systems cooperating in dynamic environments. While prior work has focused on these collaborative settings, adversarial interactions are equally critical for real-world applications such a...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "experiment",
        "framework",
        "arxiv",
        "model",
        "platform"
      ],
      "score": 0.4
    },
    {
      "title": "Safe Reinforcement Learning-Based Vibration Control: Overcoming Training Risks with LQR Guidance",
      "url": "https://arxiv.org/abs/2510.01269",
      "description": "arXiv:2510.01269v1 Announce Type: new \nAbstract: Structural vibrations induced by external excitations pose significant risks, including safety hazards for occupants, structural damage, and increased maintenance costs. While conventional model-based control strategies, such as Linear Quadratic Regul...",
      "published_date": "2025-10-03T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "study",
        "framework",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}