{
  "generated_at": "2025-11-24T20:06:02.145215",
  "total_items": 45,
  "items": [
    {
      "title": "Towards Hyper-Efficient RAG Systems in VecDBs: Distributed Parallel Multi-Resolution Vector Search",
      "url": "https://arxiv.org/abs/2511.16681",
      "description": "arXiv:2511.16681v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) systems have become a dominant approach to augment large language models (LLMs) with external knowledge. However, existing vector database (VecDB) retrieval pipelines rely on flat or single-resolution indexing stru...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "memory",
        "product",
        "retrieval",
        "multimodal",
        "vector search",
        "context",
        "embedding",
        "vector",
        "RAG",
        "model",
        "large language model",
        "framework",
        "LLM",
        "augmented",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Bench360: Benchmarking Local LLM Inference from 360{\\deg}",
      "url": "https://arxiv.org/abs/2511.16682",
      "description": "arXiv:2511.16682v1 Announce Type: new \nAbstract: Running large language models (LLMs) locally is becoming increasingly common. While the growing availability of small open-source models and inference engines has lowered the entry barrier, users now face an overwhelming number of configuration choice...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "summarization",
        "reasoning",
        "platform",
        "model",
        "large language model",
        "framework",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "How Well Do LLMs Understand Tunisian Arabic?",
      "url": "https://arxiv.org/abs/2511.16683",
      "description": "arXiv:2511.16683v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are the engines driving today's AI agents. The better these models understand human languages, the more natural and user-friendly the interaction with AI becomes, from everyday devices like computers and smartwatches to an...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "tool",
        "model",
        "large language model",
        "LLM",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Prompt-Based Value Steering of Large Language Models",
      "url": "https://arxiv.org/abs/2511.16688",
      "description": "arXiv:2511.16688v1 Announce Type: new \nAbstract: Large language models are increasingly used in applications where alignment with human values is critical. While model fine-tuning is often employed to ensure safe responses, this technique is static and does not lend itself to everyday situations inv...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "alignment",
        "model",
        "large language model",
        "prompt",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "Concept-Based Interpretability for Toxicity Detection",
      "url": "https://arxiv.org/abs/2511.16689",
      "description": "arXiv:2511.16689v1 Announce Type: new \nAbstract: The rise of social networks has not only facilitated communication but also allowed the spread of harmful content. Although significant advances have been made in detecting toxic language in textual data, the exploration of concept-based explanations ...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "alignment",
        "model",
        "RAG",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Falsely Accused: How AI Detectors Misjudge Slightly Polished Arabic Articles",
      "url": "https://arxiv.org/abs/2511.16690",
      "description": "arXiv:2511.16690v1 Announce Type: new \nAbstract: Many AI detection models have been developed to counter the presence of articles created by artificial intelligence (AI). However, if a human-authored article is slightly polished by AI, a shift will occur in the borderline decision of these AI detect...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "ICL",
        "paper",
        "model",
        "large language model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Reproducibility Report: Test-Time Training on Nearest Neighbors for Large Language Models",
      "url": "https://arxiv.org/abs/2511.16691",
      "description": "arXiv:2511.16691v1 Announce Type: new \nAbstract: We reproduce the central claims of Test-Time Training on Nearest Neighbors for Large Language Models (Hardt and Sun, 2024), which proposes adapting a language model at inference time by fine-tuning on retrieved nearest-neighbor sequences. Using pretra...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "experiment",
        "memory",
        "reasoning",
        "retrieval",
        "embedding",
        "model",
        "GPT",
        "large language model",
        "fine-tuning",
        "augmented",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "How Language Directions Align with Token Geometry in Multilingual LLMs",
      "url": "https://arxiv.org/abs/2511.16693",
      "description": "arXiv:2511.16693v1 Announce Type: new \nAbstract: Multilingual LLMs demonstrate strong performance across diverse languages, yet there has been limited systematic analysis of how language information is structured within their internal representation space and how it emerges across layers. We conduct...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "ICL",
        "arxiv",
        "analysis",
        "embedding",
        "alignment",
        "model",
        "transformer",
        "LLM",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Stable diffusion models reveal a persisting human and AI gap in visual creativity",
      "url": "https://arxiv.org/abs/2511.16814",
      "description": "arXiv:2511.16814v1 Announce Type: new \nAbstract: While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "product",
        "context",
        "research",
        "model",
        "GPT",
        "large language model",
        "prompt",
        "image",
        "prompting",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs",
      "url": "https://arxiv.org/abs/2511.16837",
      "description": "arXiv:2511.16837v1 Announce Type: new \nAbstract: Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "memory",
        "reasoning",
        "model",
        "large language model",
        "prompt",
        "LLM",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Fantastic Bugs and Where to Find Them in AI Benchmarks",
      "url": "https://arxiv.org/abs/2511.16842",
      "description": "arXiv:2511.16842v1 Announce Type: new \nAbstract: Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottlen...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "model",
        "RAG",
        "vision",
        "framework",
        "LLM",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists",
      "url": "https://arxiv.org/abs/2511.16997",
      "description": "arXiv:2511.16997v1 Announce Type: new \nAbstract: The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. However, current approaches largely conceptualize scientific discovery as a solitary optimization or search process, overlooking that knowledge pro...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "memory",
        "reasoning",
        "product",
        "retrieval",
        "context",
        "research",
        "model",
        "RAG",
        "framework",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Budget-Aware Tool-Use Enables Effective Agent Scaling",
      "url": "https://arxiv.org/abs/2511.17006",
      "description": "arXiv:2511.17006v1 Announce Type: new \nAbstract: Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only \"thinking\" in tokens but also \"acting\" via to...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "tool",
        "RAG",
        "model",
        "large language model",
        "framework",
        "LLM",
        "augmented",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "The Belief-Desire-Intention Ontology for modelling mental reality and agency",
      "url": "https://arxiv.org/abs/2511.17162",
      "description": "arXiv:2511.17162v1 Announce Type: new \nAbstract: The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. Th...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "paper",
        "reasoning",
        "platform",
        "model",
        "large language model",
        "LLM",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "When Structure Doesn't Help: LLMs Do Not Read Text-Attributed Graphs as Effectively as We Expected",
      "url": "https://arxiv.org/abs/2511.16767",
      "description": "arXiv:2511.16767v1 Announce Type: new \nAbstract: Graphs provide a unified representation of semantic content and relational structure, making them a natural fit for domains such as molecular modeling, citation networks, and social graphs. Meanwhile, large language models (LLMs) have excelled at unde...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "product",
        "reasoning",
        "RAG",
        "template",
        "cross-modal",
        "large language model",
        "model",
        "LLM",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "GCL-OT: Graph Contrastive Learning with Optimal Transport for Heterophilic Text-Attributed Graphs",
      "url": "https://arxiv.org/abs/2511.16778",
      "description": "arXiv:2511.16778v1 Announce Type: new \nAbstract: Recently, structure-text contrastive learning has shown promising performance on text-attributed graphs by leveraging the complementary strengths of graph neural networks and language models. However, existing methods typically rely on homophily assum...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "framework",
        "embedding",
        "alignment",
        "model",
        "RAG",
        "vision",
        "prompt",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Revisiting Multimodal KV Cache Compression: A Frequency-Domain-Guided Outlier-KV-Aware Approach",
      "url": "https://arxiv.org/abs/2511.16786",
      "description": "arXiv:2511.16786v1 Announce Type: new \nAbstract: Multimodal large language models suffer from substantial inference overhead since multimodal KV Cache grows proportionally with the visual input length. Existing multimodal KV Cache compression methods mostly rely on attention score to reduce cache si...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "arxiv",
        "experiment",
        "memory",
        "multimodal",
        "compression",
        "attention",
        "vector",
        "model",
        "large language model",
        "framework",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "A Robust Federated Learning Approach for Combating Attacks Against IoT Systems Under non-IID Challenges",
      "url": "https://arxiv.org/abs/2511.16822",
      "description": "arXiv:2511.16822v1 Announce Type: new \nAbstract: In the context of the growing proliferation of user devices and the concurrent surge in data volumes, the complexities arising from the substantial increase in data have posed formidable challenges to conventional machine learning model training. Part...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "context",
        "research",
        "model",
        "study",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Monte Carlo Expected Threat (MOCET) Scoring",
      "url": "https://arxiv.org/abs/2511.16823",
      "description": "arXiv:2511.16823v1 Announce Type: new \nAbstract: Evaluating and measuring AI Safety Level (ASL) threats are crucial for guiding stakeholders to implement safeguards that keep risks within acceptable limits. ASL-3+ models present a unique risk in their ability to uplift novice non-state actors, espec...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "API",
        "arxiv",
        "context",
        "model",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "ManifoldFormer: Geometric Deep Learning for Neural Dynamics on Riemannian Manifolds",
      "url": "https://arxiv.org/abs/2511.16828",
      "description": "arXiv:2511.16828v1 Announce Type: new \nAbstract: Existing EEG foundation models mainly treat neural signals as generic time series in Euclidean space, ignoring the intrinsic geometric structure of neural dynamics that constrains brain activity to low-dimensional manifolds. This fundamental mismatch ...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "attention",
        "embedding",
        "model",
        "RAG",
        "transformer",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Analysis of heart failure patient trajectories using sequence modeling",
      "url": "https://arxiv.org/abs/2511.16839",
      "description": "arXiv:2511.16839v1 Announce Type: new \nAbstract: Transformers have defined the state-of-the-art for clinical prediction tasks involving electronic health records (EHRs). The recently introduced Mamba architecture outperformed an advanced Transformer (Transformer++) based on Llama in handling long co...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "analysis",
        "context",
        "model",
        "transformer",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "context",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "CoT",
        "framework",
        "audio"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "context",
        "tool",
        "model",
        "prompt",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "reasoning",
        "retrieval",
        "knowledge base",
        "vector",
        "model",
        "RAG",
        "framework",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "product",
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "platform",
        "framework",
        "prompt",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving",
      "url": "https://arxiv.org/abs/2511.16916",
      "description": "arXiv:2511.16916v1 Announce Type: new \nAbstract: In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for po...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "ICL",
        "arxiv",
        "experiment",
        "paper",
        "framework",
        "analysis"
      ],
      "score": 0.8
    },
    {
      "title": "Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks",
      "url": "https://arxiv.org/abs/2511.17056",
      "description": "arXiv:2511.17056v1 Announce Type: new \nAbstract: Electronic health records (EHRs) form an invaluable resource for training clinical decision support systems. To leverage the potential of such systems in high-risk applications, we need large, structured tabular datasets on which we can build transpar...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "arxiv",
        "model",
        "augmented"
      ],
      "score": 0.8
    },
    {
      "title": "DDTime: Dataset Distillation with Spectral Alignment and Information Bottleneck for Time-Series Forecasting",
      "url": "https://arxiv.org/abs/2511.16715",
      "description": "arXiv:2511.16715v1 Announce Type: new \nAbstract: Time-series forecasting is fundamental across many domains, yet training accurate models often requires large-scale datasets and substantial computational resources. Dataset distillation offers a promising alternative by synthesizing compact datasets ...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "release",
        "alignment",
        "model",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "API",
        "model",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Shona spaCy: A Morphological Analyzer for an Under-Resourced Bantu Language",
      "url": "https://arxiv.org/abs/2511.16680",
      "description": "arXiv:2511.16680v1 Announce Type: new \nAbstract: Despite rapid advances in multilingual natural language processing (NLP), the Bantu language Shona remains under-served in terms of morphological analysis and language-aware tools. This paper presents Shona spaCy, an open-source, rule-based morphologi...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "arxiv",
        "paper",
        "release",
        "tool",
        "model",
        "template",
        "framework",
        "analysis"
      ],
      "score": 0.6
    },
    {
      "title": "DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing",
      "url": "https://arxiv.org/abs/2511.17038",
      "description": "arXiv:2511.17038v1 Announce Type: new \nAbstract: From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding the likelihood with the prior to guide the sampling process. However, this formulation fails to explain its practical behavior: the prior off...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "embedding",
        "arxiv",
        "framework",
        "image"
      ],
      "score": 0.6
    },
    {
      "title": "Joint Design of Protein Surface and Structure Using a Diffusion Bridge Model",
      "url": "https://arxiv.org/abs/2511.16675",
      "description": "arXiv:2511.16675v1 Announce Type: new \nAbstract: Protein-protein interactions (PPIs) are governed by surface complementarity and hydrophobic interactions at protein interfaces. However, designing diverse and physically realistic protein structure and surfaces that precisely complement target recepto...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "framework",
        "alignment",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "A Vector Symbolic Approach to Multiple Instance Learning",
      "url": "https://arxiv.org/abs/2511.16795",
      "description": "arXiv:2511.16795v1 Announce Type: new \nAbstract: Multiple Instance Learning (MIL) tasks impose a strict logical constraint: a bag is labeled positive if and only if at least one instance within it is positive. While this iff constraint aligns with many real-world applications, recent work has shown ...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "arxiv",
        "framework",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Comparing verbal, visual and combined explanations for Bayesian Network inferences",
      "url": "https://arxiv.org/abs/2511.16961",
      "description": "arXiv:2511.16961v1 Announce Type: new \nAbstract: Bayesian Networks (BNs) are an important tool for assisting probabilistic reasoning, but despite being considered transparent models, people have trouble understanding them. Further, current User Interfaces (UIs) still do not clarify the reasoning of ...",
      "published_date": "2025-11-24T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "reasoning",
        "tool",
        "model",
        "study"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}