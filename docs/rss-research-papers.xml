<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>GMTRouter: Personalized LLM Router over Multi-turn User Interactions</title>
      <link>https://arxiv.org/abs/2511.08590</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08590</guid>
      <description>arXiv:2511.08590v1 Announce Type: new 
Abstract: Large Language Model (LLM) routing has demonstrated strong capability in balancing response quality with computational cost. As users exhibit diverse preferences, personalization has attracted increasing attention in LLM routing, since even identical ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, fine-tuning, model, attention, ICL | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>fine-tuning</category>
      <category>model</category>
    </item>
    <item>
      <title>The Collective Turing Test: Large Language Models Can Generate Realistic Multi-User Discussions</title>
      <link>https://arxiv.org/abs/2511.08592</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08592</guid>
      <description>arXiv:2511.08592v1 Announce Type: new 
Abstract: Large Language Models (LLMs) offer new avenues to simulate online communities and social media. Potential applications range from testing the design of content recommendation algorithms to estimating the effects of content policies and interventions. ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, model, large language model, LLM, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>GPT</category>
      <category>model</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Knowledge Graph Analysis of Legal Understanding and Violations in LLMs</title>
      <link>https://arxiv.org/abs/2511.08593</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08593</guid>
      <description>arXiv:2511.08593v1 Announce Type: new 
Abstract: The rise of Large Language Models (LLMs) offers transformative potential for interpreting complex legal frameworks, such as Title 18 Section 175 of the US Code, which governs biological weapons. These systems hold promise for advancing legal analysis ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; instruction, analysis, model, research, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>instruction</category>
      <category>analysis</category>
      <category>model</category>
    </item>
    <item>
      <title>Diverse Preference Learning for Capabilities and Alignment</title>
      <link>https://arxiv.org/abs/2511.08594</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08594</guid>
      <description>arXiv:2511.08594v1 Announce Type: new 
Abstract: The ability of LLMs to represent diverse perspectives is critical as they increasingly impact society. However, recent studies reveal that alignment algorithms such as RLHF and DPO significantly reduce the diversity of LLM outputs. Not only do aligned...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, LLM, alignment, arxiv, RLHF | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>LLM</category>
      <category>alignment</category>
    </item>
    <item>
      <title>What About the Scene with the Hitler Reference? HAUNT: A Framework to Probe LLMs&amp;#x27; Self-consistency Via Adversarial Nudge</title>
      <link>https://arxiv.org/abs/2511.08596</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08596</guid>
      <description>arXiv:2511.08596v1 Announce Type: new 
Abstract: Hallucinations pose a critical challenge to the real-world deployment of large language models (LLMs) in high-stakes domains. In this paper, we present a framework for stress testing factual fidelity in LLMs in the presence of adversarial nudge. Our f...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, model, large language model, paper, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>GPT</category>
      <category>model</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Self-HarmLLM: Can Large Language Model Harm Itself?</title>
      <link>https://arxiv.org/abs/2511.08597</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08597</guid>
      <description>arXiv:2511.08597v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are generally equipped with guardrails to block the generation of harmful responses. However, existing defenses always assume that an external attacker crafts the harmful query, and the possibility of a model&amp;#x27;s own output ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, GPT, model, zero-shot, vector | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>GPT</category>
      <category>model</category>
    </item>
    <item>
      <title>Analysing Environmental Efficiency in AI for X-Ray Diagnosis</title>
      <link>https://arxiv.org/abs/2511.07436</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07436</guid>
      <description>arXiv:2511.07436v1 Announce Type: new 
Abstract: The integration of AI tools into medical applications has aimed to improve the efficiency of diagnosis. The emergence of large language models (LLMs), such as ChatGPT and Claude, has expanded this integration even further. Because of LLM versatility a...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, knowledge base, tool, model, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>GPT</category>
      <category>knowledge base</category>
      <category>tool</category>
    </item>
    <item>
      <title>Agentic Educational Content Generation for African Languages on Edge Devices</title>
      <link>https://arxiv.org/abs/2511.07437</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07437</guid>
      <description>arXiv:2511.07437v1 Announce Type: new 
Abstract: Addressing educational inequity in Sub-Saharan Africa, this research presents an autonomous agent-orchestrated framework for decentralized, culturally adaptive educational content generation on edge devices. The system leverages four specialized agent...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, RAG, platform, experiment, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>RAG</category>
      <category>platform</category>
    </item>
    <item>
      <title>Procedural Knowledge Improves Agentic LLM Workflows</title>
      <link>https://arxiv.org/abs/2511.07568</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07568</guid>
      <description>arXiv:2511.07568v1 Announce Type: new 
Abstract: Large language models (LLMs) often struggle when performing agentic tasks without substantial tool support, prom-pt engineering, or fine tuning. Despite research showing that domain-dependent, procedural knowledge can dramatically increase planning ef...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; tool, model, research, RAG, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>tool</category>
      <category>model</category>
      <category>research</category>
    </item>
    <item>
      <title>AIA Forecaster: Technical Report</title>
      <link>https://arxiv.org/abs/2511.07678</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07678</guid>
      <description>arXiv:2511.07678v1 Announce Type: new 
Abstract: This technical report describes the AIA Forecaster, a Large Language Model (LLM)-based system for judgmental forecasting using unstructured data. The AIA Forecaster approach combines three core elements: agentic search over high-quality news sources, ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, research, large language model, LLM, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>research</category>
      <category>large language model</category>
    </item>
    <item>
      <title>ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents</title>
      <link>https://arxiv.org/abs/2511.07685</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07685</guid>
      <description>arXiv:2511.07685v1 Announce Type: new 
Abstract: Deep Research (DR) is an emerging agent application that leverages large language models (LLMs) to address open-ended queries. It requires the integration of several capabilities, including multi-step reasoning, cross-document synthesis, and the gener...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, research, prompt, RAG, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>research</category>
      <category>prompt</category>
    </item>
    <item>
      <title>Benevolent Dictators? On LLM Agent Behavior in Dictator Games</title>
      <link>https://arxiv.org/abs/2511.08721</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08721</guid>
      <description>arXiv:2511.08721v1 Announce Type: new 
Abstract: In behavioral sciences, experiments such as the ultimatum game are conducted to assess preferences for fairness or self-interest of study participants. In the dictator game, a simplified version of the ultimatum game where only one of two players make...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, instruction, model, prompt, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>instruction</category>
      <category>model</category>
    </item>
    <item>
      <title>Macroscopic Emission Modeling of Urban Traffic Using Probe Vehicle Data: A Machine Learning Approach</title>
      <link>https://arxiv.org/abs/2511.08722</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08722</guid>
      <description>arXiv:2511.08722v1 Announce Type: new 
Abstract: Urban congestions cause inefficient movement of vehicles and exacerbate greenhouse gas emissions and urban air pollution. Macroscopic emission fundamental diagram (eMFD)captures an orderly relationship among emission and aggregated traffic variables a...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, model, RAG, ICL, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>model</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Accelerating Training Speed of Tiny Recursive Models via Curriculum Guided Adaptive Recursion</title>
      <link>https://arxiv.org/abs/2511.08653</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08653</guid>
      <description>arXiv:2511.08653v1 Announce Type: new 
Abstract: Recursive reasoning models achieve remarkable performance on complex reasoning tasks through iterative refinement, enabling tiny networks to match large language models thousands of times their size. However, training remains computationally expensive...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, research, reasoning, large language model, vision | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>research</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>Gromov-Wasserstein Graph Coarsening</title>
      <link>https://arxiv.org/abs/2511.08733</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08733</guid>
      <description>arXiv:2511.08733v1 Announce Type: new 
Abstract: We study the problem of graph coarsening within the Gromov-Wasserstein geometry. Specifically, we propose two algorithms that leverage a novel representation of the distortion induced by merging pairs of nodes. The first method, termed Greedy Pair Coa...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, arxiv, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>arxiv</category>
      <category>study</category>
    </item>
    <item>
      <title>Hey Pentti, We Did (More of) It!: A Vector-Symbolic Lisp With Residue Arithmetic</title>
      <link>https://arxiv.org/abs/2511.08767</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08767</guid>
      <description>arXiv:2511.08767v1 Announce Type: new 
Abstract: Using Frequency-domain Holographic Reduced Representations (FHRRs), we extend a Vector-Symbolic Architecture (VSA) encoding of Lisp 1.5 with primitives for arithmetic operations using Residue Hyperdimensional Computing (RHC). Encoding a Turing-complet...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, vector | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>vector</category>
    </item>
    <item>
      <title>Where did you get that? Towards Summarization Attribution for Analysts</title>
      <link>https://arxiv.org/abs/2511.08589</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.08589</guid>
      <description>arXiv:2511.08589v1 Announce Type: new 
Abstract: Analysts require attribution, as nothing can be reported without knowing the source of the information. In this paper, we will focus on automatic methods for attribution, linking each sentence in the summary to a portion of the source text, which may ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; summarization, paper, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 13 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>summarization</category>
      <category>paper</category>
      <category>arxiv</category>
    </item>
  </channel>
</rss>