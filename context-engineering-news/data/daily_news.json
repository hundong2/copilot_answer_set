{
  "generated_at": "2025-08-06T20:05:49.016004",
  "total_items": 47,
  "items": [
    {
      "title": "Clinically Grounded Agent-based Report Evaluation: An Interpretable Metric for Radiology Report Generation",
      "url": "https://arxiv.org/abs/2508.02808",
      "description": "arXiv:2508.02808v1 Announce Type: new \nAbstract: Radiological imaging is central to diagnosis, treatment planning, and clinical decision-making. Vision-language foundation models have spurred interest in automated radiology report generation (RRG), but safe deployment requires reliable clinical eval...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "framework",
        "vision",
        "large language model",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Modeling Annotator Disagreement with Demographic-Aware Experts and Synthetic Perspectives",
      "url": "https://arxiv.org/abs/2508.02853",
      "description": "arXiv:2508.02853v1 Announce Type: new \nAbstract: We present an approach to modeling annotator disagreement in subjective NLP tasks through both architectural and data-centric innovations. Our model, DEM-MoE (Demographic-Aware Mixture of Experts), routes inputs to expert subnetworks based on annotato...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "RAG",
        "LLM",
        "zero-shot",
        "prompting",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Highlight & Summarize: RAG without the jailbreaks",
      "url": "https://arxiv.org/abs/2508.02872",
      "description": "arXiv:2508.02872v1 Announce Type: new \nAbstract: Preventing jailbreaking and model hijacking of Large Language Models (LLMs) is an important yet challenging task. For example, when interacting with a chatbot, malicious users can input specially crafted prompts to cause the LLM to generate undesirabl...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "prompt",
        "RAG",
        "LLM",
        "retrieval",
        "example",
        "large language model",
        "paper",
        "augmented",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Coherent Multimodal Reasoning with Iterative Self-Evaluation for Vision-Language Models",
      "url": "https://arxiv.org/abs/2508.02886",
      "description": "arXiv:2508.02886v1 Announce Type: new \nAbstract: Despite significant advancements, current large language models (LLMs) and vision-language models (LVLMs) continue to struggle with complex, multi-step, cross-modal common sense reasoning tasks, often exhibiting a lack of \"deliberative thinking.\" They...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "RAG",
        "LLM",
        "framework",
        "context",
        "cross-modal",
        "vision",
        "large language model",
        "multimodal",
        "arxiv",
        "step-by-step",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Can LLMs Generate High-Quality Task-Specific Conversations?",
      "url": "https://arxiv.org/abs/2508.02931",
      "description": "arXiv:2508.02931v1 Announce Type: new \nAbstract: This paper introduces a parameterization framework for controlling conversation quality in large language models. We explore nine key parameters across six dimensions that enable precise specification of dialogue properties. Through experiments with s...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "framework",
        "large language model",
        "paper",
        "experiment",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors",
      "url": "https://arxiv.org/abs/2508.02997",
      "description": "arXiv:2508.02997v1 Announce Type: new \nAbstract: The widespread use of Large Language Models (LLMs) in many applications marks a significant advance in research and practice. However, their complexity and hard-to-understand nature make them vulnerable to attacks, especially jailbreaks designed to pr...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "RAG",
        "LLM",
        "model",
        "context",
        "large language model",
        "CoT",
        "paper",
        "ICL",
        "arxiv",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "When Algorithms Meet Artists: Topic Modeling the AI-Art Debate, 2013-2025",
      "url": "https://arxiv.org/abs/2508.03037",
      "description": "arXiv:2508.03037v1 Announce Type: new \nAbstract: As generative AI continues to reshape artistic production and alternate modes of human expression, artists whose livelihoods are most directly affected have raised urgent concerns about consent, transparency, and the future of creative labor. However,...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "alignment",
        "analysis",
        "ICL",
        "multimodal",
        "research",
        "arxiv",
        "product",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Privacy-Aware Decoding: Mitigating Privacy Leakage of Large Language Models in Retrieval-Augmented Generation",
      "url": "https://arxiv.org/abs/2508.03098",
      "description": "arXiv:2508.03098v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) enhances the factual accuracy of large language models (LLMs) by conditioning outputs on external knowledge sources. However, when retrieval involves private or sensitive data, RAG systems are susceptible to extrac...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "LLM",
        "context",
        "large language model",
        "experiment",
        "augmented",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Efficient Agents: Building Effective Agents While Reducing Cost",
      "url": "https://arxiv.org/abs/2508.02694",
      "description": "arXiv:2508.02694v1 Announce Type: new \nAbstract: The remarkable capabilities of Large Language Model (LLM)-driven agents have enabled sophisticated systems to tackle complex, multi-step tasks, but their escalating costs threaten scalability and accessibility. This work presents the first systematic ...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "framework",
        "study",
        "analysis",
        "large language model",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Recovering Individual-Level Activity Sequences from Location-Based Service Data Using a Novel Transformer-Based Model",
      "url": "https://arxiv.org/abs/2508.02734",
      "description": "arXiv:2508.02734v1 Announce Type: new \nAbstract: Location-Based Service (LBS) data provides critical insights into human mobility, yet its sparsity often yields incomplete trip and activity sequences, making accurate inferences about trips and activities difficult. We raise a research problem: Can w...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "study",
        "analysis",
        "transformer",
        "research",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Large Language Model-based Data Science Agent: A Survey",
      "url": "https://arxiv.org/abs/2508.02744",
      "description": "arXiv:2508.02744v1 Announce Type: new \nAbstract: The rapid advancement of Large Language Models (LLMs) has driven novel applications across diverse domains, with LLM-based agents emerging as a crucial area of exploration. This survey presents a comprehensive analysis of LLM-based agents designed for...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "framework",
        "analysis",
        "large language model",
        "API",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science",
      "url": "https://arxiv.org/abs/2508.02789",
      "description": "arXiv:2508.02789v1 Announce Type: new \nAbstract: The capacity for artificial intelligence (AI) to formulate, evolve, and test altered thought patterns under dynamic conditions indicates advanced cognition that is crucial for scientific discovery. The existing AI development landscape falls into two ...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "LLM",
        "framework",
        "large language model",
        "arxiv",
        "GPT",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering",
      "url": "https://arxiv.org/abs/2508.02841",
      "description": "arXiv:2508.02841v1 Announce Type: new \nAbstract: Radiology visual question answering (RVQA) provides precise answers to questions about chest X-ray images, alleviating radiologists' workload. While recent methods based on multimodal large language models (MLLMs) and retrieval-augmented generation (R...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "LLM",
        "image",
        "study",
        "context",
        "cross-modal",
        "alignment",
        "large language model",
        "multimodal",
        "experiment",
        "augmented",
        "arxiv",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game",
      "url": "https://arxiv.org/abs/2508.02900",
      "description": "arXiv:2508.02900v1 Announce Type: new \nAbstract: There is a broad consensus that the inability to form long-term plans is one of the key limitations of current foundational models and agents. However, the existing planning benchmarks remain woefully inadequate to truly measure their planning capabil...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "LLM",
        "analysis",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing Japanese Large Language Models with Reasoning Vectors",
      "url": "https://arxiv.org/abs/2508.02913",
      "description": "arXiv:2508.02913v1 Announce Type: new \nAbstract: Post-training methods have improved the performance and enhanced the reasoning capability for mainstream large language models (LLMs), but the same is challenging for Japanese LLMs to achieve due to the amount of resources required. Inspired by task v...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "LLM",
        "large language model",
        "vector",
        "arxiv",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "PentestJudge: Judging Agent Behavior Against Operational Requirements",
      "url": "https://arxiv.org/abs/2508.02921",
      "description": "arXiv:2508.02921v1 Announce Type: new \nAbstract: We introduce PentestJudge, a system for evaluating the operations of penetration testing agents. PentestJudge is a large language model (LLM)-as-judge with access to tools that allow it to consume arbitrary trajectories of agent states and tool call h...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "model",
        "large language model",
        "tool",
        "arxiv",
        "product",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "AQUAH: Automatic Quantification and Unified Agent in Hydrology",
      "url": "https://arxiv.org/abs/2508.02936",
      "description": "arXiv:2508.02936v1 Announce Type: new \nAbstract: We introduce AQUAH, the first end-to-end language-based agent designed specifically for hydrologic modeling. Starting from a simple natural-language prompt (e.g., 'simulate floods for the Little Bighorn basin from 2020 to 2022'), AQUAH autonomously re...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "LLM",
        "vision",
        "large language model",
        "experiment",
        "tool",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "A Bayesian Hybrid Parameter-Efficient Fine-Tuning Method for Large Language Models",
      "url": "https://arxiv.org/abs/2508.02711",
      "description": "arXiv:2508.02711v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated transformative potential in reshaping the world. As these models are pretrained on general corpora, they often require domain-specific fine-tuning to optimize performance in specialized business applicati...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "analysis",
        "transformer",
        "large language model",
        "API",
        "fine-tuning",
        "arxiv",
        "reasoning",
        "attention",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Forecasting NCAA Basketball Outcomes with Deep Learning: A Comparative Study of LSTM and Transformer Models",
      "url": "https://arxiv.org/abs/2508.02725",
      "description": "arXiv:2508.02725v1 Announce Type: new \nAbstract: In this research, I explore advanced deep learning methodologies to forecast the outcomes of the 2025 NCAA Division 1 Men's and Women's Basketball tournaments. Leveraging historical NCAA game data, I implement two sophisticated sequence-based models: ...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "framework",
        "study",
        "model",
        "analysis",
        "memory",
        "vision",
        "transformer",
        "augmented",
        "arxiv",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "SmallKV: Small Model Assisted Compensation of KV Cache Compression for Efficient LLM Inference",
      "url": "https://arxiv.org/abs/2508.02751",
      "description": "arXiv:2508.02751v1 Announce Type: new \nAbstract: KV cache eviction has emerged as an effective solution to alleviate resource constraints faced by LLMs in long-context scenarios. However, existing token-level eviction methods often overlook two critical aspects: (1) their irreversible eviction strat...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "LLM",
        "context",
        "compression",
        "experiment",
        "arxiv",
        "attention",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "context",
        "context window",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "audio",
        "CoT",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "framework",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "LLM",
        "attention",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "LLM",
        "knowledge base",
        "framework",
        "vector",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "fine-tuning",
        "model",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "API",
        "augmented",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "platform",
        "LLM",
        "framework",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "framework",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "DeepGB-TB: A Risk-Balanced Cross-Attention Gradient-Boosted Convolutional Network for Rapid, Interpretable Tuberculosis Screening",
      "url": "https://arxiv.org/abs/2508.02741",
      "description": "arXiv:2508.02741v1 Announce Type: new \nAbstract: Large-scale tuberculosis (TB) screening is limited by the high cost and operational complexity of traditional diagnostics, creating a need for artificial-intelligence solutions. We propose DeepGB-TB, a non-invasive system that instantly assigns TB ris...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "cross-modal",
        "audio",
        "API",
        "tool",
        "arxiv",
        "attention",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "tool",
        "model",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "SLIM-LLMs: Modeling of Style-Sensory Language RelationshipsThrough Low-Dimensional Representations",
      "url": "https://arxiv.org/abs/2508.02901",
      "description": "arXiv:2508.02901v1 Announce Type: new \nAbstract: Sensorial language -- the language connected to our senses including vision, sound, touch, taste, smell, and interoception, plays a fundamental role in how we communicate experiences and perceptions. We explore the relationship between sensorial langu...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "arxiv",
        "LLM",
        "vision",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "ECGTwin: Personalized ECG Generation Using Controllable Diffusion Model",
      "url": "https://arxiv.org/abs/2508.02720",
      "description": "arXiv:2508.02720v1 Announce Type: new \nAbstract: Personalized electrocardiogram (ECG) generation is to simulate a patient's ECG digital twins tailored to specific conditions. It has the potential to transform traditional healthcare into a more accurate individualized paradigm, while preserving the k...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "paper",
        "experiment",
        "arxiv",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Embedding-Enhanced Probabilistic Modeling of Ferroelectric Field Effect Transistors (FeFETs)",
      "url": "https://arxiv.org/abs/2508.02737",
      "description": "arXiv:2508.02737v1 Announce Type: new \nAbstract: FeFETs hold strong potential for advancing memory and logic technologies, but their inherent randomness arising from both operational cycling and fabrication variability poses significant challenges for accurate and reliable modeling. Capturing this v...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "memory",
        "embedding",
        "arxiv",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Considering Spatial Structure of the Road Network in Pavement Deterioration Modeling",
      "url": "https://arxiv.org/abs/2508.02749",
      "description": "arXiv:2508.02749v1 Announce Type: new \nAbstract: Pavement deterioration modeling is important in providing information regarding the future state of the road network and in determining the needs of preventive maintenance or rehabilitation treatments. This research incorporated spatial dependence of ...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "model",
        "research"
      ],
      "score": 0.6
    },
    {
      "title": "Pulse Shape Discrimination Algorithms: Survey and Benchmark",
      "url": "https://arxiv.org/abs/2508.02750",
      "description": "arXiv:2508.02750v1 Announce Type: new \nAbstract: This review presents a comprehensive survey and benchmark of pulse shape discrimination (PSD) algorithms for radiation detection, classifying nearly sixty methods into statistical (time-domain, frequency-domain, neural network-based) and prior-knowled...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "release",
        "analysis",
        "tool",
        "company",
        "research",
        "arxiv",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Welcome GPT OSS, the new open-source model family from OpenAI!",
      "url": "https://huggingface.co/blog/welcome-openai-gpt-oss",
      "description": "...",
      "published_date": "2025-08-05T00:00:00",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "GPT",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "paper",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Merge-based syntax is mediated by distinct neurocognitive mechanisms: A clustering analysis of comprehension abilities in 84,000 individuals with language deficits across nine languages",
      "url": "https://arxiv.org/abs/2508.02885",
      "description": "arXiv:2508.02885v1 Announce Type: new \nAbstract: In the modern language sciences, the core computational operation of syntax, 'Merge', is defined as an operation that combines two linguistic units (e.g., 'brown', 'cat') to form a categorized structure ('brown cat', a Noun Phrase). This can then be f...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis"
      ],
      "score": 0.4
    },
    {
      "title": "ZetA: A Riemann Zeta-Scaled Extension of Adam for Deep Learning",
      "url": "https://arxiv.org/abs/2508.02719",
      "description": "arXiv:2508.02719v1 Announce Type: new \nAbstract: This work introduces ZetA, a novel deep learning optimizer that extends Adam by incorporating dynamic scaling based on the Riemann zeta function. To the best of our knowledge, ZetA is the first optimizer to apply zeta-based gradient scaling within dee...",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Mathematical Foundations of Geometric Deep Learning",
      "url": "https://arxiv.org/abs/2508.02723",
      "description": "arXiv:2508.02723v1 Announce Type: new \nAbstract: We review the key mathematical concepts necessary for studying Geometric Deep Learning....",
      "published_date": "2025-08-06T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}