<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Discourse vs emissions: Analysis of corporate narratives, symbolic practices, and mimicry through LLMs</title>
      <link>https://arxiv.org/abs/2510.01222</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01222</guid>
      <description>arXiv:2510.01222v1 Announce Type: new 
Abstract: Climate change has increased demands for transparent and comparable corporate climate disclosures, yet imitation and symbolic reporting often undermine their value. This paper develops a multidimensional framework to assess disclosure maturity among 8...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; API, large language model, framework, LLM, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>API</category>
      <category>large language model</category>
      <category>framework</category>
    </item>
    <item>
      <title>Enhancing Transformer-Based Rerankers with Synthetic Data and LLM-Based Supervision</title>
      <link>https://arxiv.org/abs/2510.01229</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01229</guid>
      <description>arXiv:2510.01229v1 Announce Type: new 
Abstract: Effective document reranking is essential for improving search relevance across diverse applications. While Large Language Models (LLMs) excel at reranking due to their deep semantic understanding and reasoning, their high computational cost makes the...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; transformer, vision, experiment, large language model, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>transformer</category>
      <category>vision</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Trustworthy Summarization via Uncertainty Quantification and Risk Awareness in Large Language Models</title>
      <link>https://arxiv.org/abs/2510.01231</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01231</guid>
      <description>arXiv:2510.01231v1 Announce Type: new 
Abstract: This study addresses the reliability of automatic summarization in high-risk scenarios and proposes a large language model framework that integrates uncertainty quantification and risk-aware mechanisms. Starting from the demands of information overloa...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; compression, experiment, study, large language model, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>compression</category>
      <category>experiment</category>
      <category>study</category>
    </item>
    <item>
      <title>Cyber Academia-Chemical Engineering (CA-ChemE): A Living Digital Town for Self-Directed Research Evolution and Emergent Scientific Discovery</title>
      <link>https://arxiv.org/abs/2510.01293</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01293</guid>
      <description>arXiv:2510.01293v1 Announce Type: new 
Abstract: The rapid advancement of artificial intelligence (AI) has demonstrated substantial potential in chemical engineering, yet existing AI systems remain limited in interdisciplinary collaboration and exploration of uncharted problems. To address these iss...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; API, knowledge base, study, reasoning, prompt | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>API</category>
      <category>knowledge base</category>
      <category>study</category>
    </item>
    <item>
      <title>MEMTRACK: Evaluating Long-Term Memory and State Tracking in Multi-Platform Dynamic Agent Environments</title>
      <link>https://arxiv.org/abs/2510.01353</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01353</guid>
      <description>arXiv:2510.01353v1 Announce Type: new 
Abstract: Recent works on context and memory benchmarking have primarily focused on conversational instances but the need for evaluating memory in dynamic enterprise environments is crucial for its effective application. We introduce MEMTRACK, a benchmark desig...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, augmented, product, memory, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>GPT</category>
      <category>augmented</category>
      <category>product</category>
    </item>
    <item>
      <title>Control the Temperature: Selective Sampling for Diverse and High-Quality LLM Outputs</title>
      <link>https://arxiv.org/abs/2510.01218</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01218</guid>
      <description>arXiv:2510.01218v1 Announce Type: new 
Abstract: Diversity is an essential metric for evaluating the creativity of outputs generated by language models. Temperature-based sampling is a common strategy to increase diversity. However, for tasks that require high precision, e.g., mathematical reasoning...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, reasoning, LLM, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>reasoning</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Automated Extraction of Material Properties using LLM-based AI Agents</title>
      <link>https://arxiv.org/abs/2510.01235</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01235</guid>
      <description>arXiv:2510.01235v1 Announce Type: new 
Abstract: The rapid discovery of materials is constrained by the lack of large, machine-readable datasets that couple performance metrics with structural context. Existing databases are either small, manually curated, or biased toward first principles results, ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, release, experiment, API, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>GPT</category>
      <category>release</category>
      <category>experiment</category>
    </item>
    <item>
      <title>RSAVQ: Riemannian Sensitivity-Aware Vector Quantization for Large Language Models</title>
      <link>https://arxiv.org/abs/2510.01240</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01240</guid>
      <description>arXiv:2510.01240v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, their exponentially increasing parameters pose significant challenges for deployment on resource-constrained devic...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; zero-shot, experiment, large language model, framework, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>zero-shot</category>
      <category>experiment</category>
      <category>large language model</category>
    </item>
    <item>
      <title>RSTGCN: Railway-centric Spatio-Temporal Graph Convolutional Network for Train Delay Prediction</title>
      <link>https://arxiv.org/abs/2510.01262</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01262</guid>
      <description>arXiv:2510.01262v1 Announce Type: new 
Abstract: Accurate prediction of train delays is critical for efficient railway operations, enabling better scheduling and dispatching decisions. While earlier approaches have largely focused on forecasting the exact delays of individual trains, recent studies ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; release, experiment, arxiv, attention, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>release</category>
      <category>experiment</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Towards Open-Ended Discovery for Low-Resource NLP</title>
      <link>https://arxiv.org/abs/2510.01220</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01220</guid>
      <description>arXiv:2510.01220v1 Announce Type: new 
Abstract: Natural Language Processing (NLP) for low-resource languages remains fundamentally constrained by the lack of textual corpora, standardized orthographies, and scalable annotation pipelines. While recent advances in large language models have improved ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vision, memory, large language model, framework, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>vision</category>
      <category>memory</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Geometric Structures and Patterns of Meaning: A PHATE Manifold Analysis of Chinese Character Embeddings</title>
      <link>https://arxiv.org/abs/2510.01230</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01230</guid>
      <description>arXiv:2510.01230v1 Announce Type: new 
Abstract: We systematically investigate geometric patterns in Chinese character embeddings using PHATE manifold analysis. Through cross-validation across seven embedding models and eight dimensionality reduction methods, we observe clustering patterns for conte...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, embedding, arxiv, analysis, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>embedding</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Budgeted Broadcast: An Activity-Dependent Pruning Rule for Neural Network Efficiency</title>
      <link>https://arxiv.org/abs/2510.01263</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01263</guid>
      <description>arXiv:2510.01263v1 Announce Type: new 
Abstract: Most pruning methods remove parameters ranked by impact on loss (e.g., magnitude or gradient). We propose Budgeted Broadcast (BB), which gives each unit a local traffic budget (the product of its long-term on-rate $a_i$ and fan-out $k_i$). A constrain...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; product, transformer, image, arxiv, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>product</category>
      <category>transformer</category>
      <category>image</category>
    </item>
    <item>
      <title>Adaptive Federated Learning Defences via Trust-Aware Deep Q-Networks</title>
      <link>https://arxiv.org/abs/2510.01261</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01261</guid>
      <description>arXiv:2510.01261v1 Announce Type: new 
Abstract: Federated learning is vulnerable to poisoning and backdoor attacks under partial observability. We formulate defence as a partially observable sequential decision problem and introduce a trust-aware Deep Q-Network that integrates multi-signal evidence...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Safe Reinforcement Learning-Based Vibration Control: Overcoming Training Risks with LQR Guidance</title>
      <link>https://arxiv.org/abs/2510.01269</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.01269</guid>
      <description>arXiv:2510.01269v1 Announce Type: new 
Abstract: Structural vibrations induced by external excitations pose significant risks, including safety hazards for occupants, structural damage, and increased maintenance costs. While conventional model-based control strategies, such as Linear Quadratic Regul...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, study, framework, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 03 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>study</category>
      <category>framework</category>
    </item>
  </channel>
</rss>