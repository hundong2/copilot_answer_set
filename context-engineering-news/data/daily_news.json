{
  "generated_at": "2025-12-17T20:06:10.958408",
  "total_items": 45,
  "items": [
    {
      "title": "FiNERweb: Datasets and Artifacts for Scalable Multilingual Named Entity Recognition",
      "url": "https://arxiv.org/abs/2512.13884",
      "description": "arXiv:2512.13884v1 Announce Type: new \nAbstract: Recent multilingual named entity recognition (NER) work has shown that large language models (LLMs) can provide effective synthetic supervision, yet such datasets have mostly appeared as by-products of broader experiments rather than as systematic, re...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "research",
        "large language model",
        "product",
        "LLM",
        "vision",
        "arxiv",
        "company",
        "release",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Olmo 3",
      "url": "https://arxiv.org/abs/2512.13961",
      "description": "arXiv:2512.13961v1 Announce Type: new \nAbstract: We introduce Olmo 3, a family of state-of-the-art, fully-open language models at the 7B and 32B parameter scales. Olmo 3 model construction targets long-context reasoning, function calling, coding, instruction following, general chat, and knowledge re...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "instruction",
        "arxiv",
        "release",
        "reasoning",
        "context",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Structure-Aware Decoding Mechanisms for Complex Entity Extraction with Large-Scale Language Models",
      "url": "https://arxiv.org/abs/2512.13980",
      "description": "arXiv:2512.13980v1 Announce Type: new \nAbstract: This paper proposes a structure-aware decoding method based on large language models to address the difficulty of traditional approaches in maintaining both semantic integrity and structural consistency in nested and overlapping entity extraction task...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "large language model",
        "arxiv",
        "context",
        "attention",
        "experiment",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "What Affects the Effective Depth of Large Language Models?",
      "url": "https://arxiv.org/abs/2512.14064",
      "description": "arXiv:2512.14064v1 Announce Type: new \nAbstract: The scaling of large language models (LLMs) emphasizes increasing depth, yet performance gains diminish with added layers. Prior work introduces the concept of \"effective depth\", arguing that deeper models fail to fully utilize their layers for meanin...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "CoT",
        "study",
        "large language model",
        "LLM",
        "arxiv",
        "release",
        "reasoning",
        "context",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed",
      "url": "https://arxiv.org/abs/2512.14067",
      "description": "arXiv:2512.14067v1 Announce Type: new \nAbstract: Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, non-autoregressive generation, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, w...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "attention",
        "RAG",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "A Unified Sparse Attention via Multi-Granularity Compression",
      "url": "https://arxiv.org/abs/2512.14082",
      "description": "arXiv:2512.14082v1 Announce Type: new \nAbstract: Efficient long-context understanding and reasoning are increasingly vital for large language model (LLM) applications such as multi-turn dialogue and program analysis. However, the core self-attention mechanism scales quadratically with sequence lengt...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "compression",
        "analysis",
        "large language model",
        "LLM",
        "arxiv",
        "cross-modal",
        "reasoning",
        "context",
        "attention",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study",
      "url": "https://arxiv.org/abs/2512.14085",
      "description": "arXiv:2512.14085v1 Announce Type: new \nAbstract: We present a multilingual, continuous backchannel prediction model for Japanese, English, and Chinese, and use it to investigate cross-linguistic timing behavior. The model is Transformer-based and operates at the frame level, jointly trained with aux...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "zero-shot",
        "arxiv",
        "transformer",
        "context",
        "RAG",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2512.14118",
      "description": "arXiv:2512.14118v1 Announce Type: new \nAbstract: Large language models (LLMs) excel at single-turn reasoning but often lose accuracy and coherence over extended, multi-turn interactions. Recent evaluations such as TurnBench highlight recurring failure modes-reasoning bias, task drift, hallucination,...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "experiment",
        "large language model",
        "memory",
        "LLM",
        "arxiv",
        "reasoning",
        "context",
        "attention",
        "augmented",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents",
      "url": "https://arxiv.org/abs/2512.14142",
      "description": "arXiv:2512.14142v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pa...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "API",
        "experiment",
        "large language model",
        "memory",
        "LLM",
        "arxiv",
        "RAG",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "A Comparative Analysis of Retrieval-Augmented Generation Techniques for Bengali Standard-to-Dialect Machine Translation Using LLMs",
      "url": "https://arxiv.org/abs/2512.14179",
      "description": "arXiv:2512.14179v1 Announce Type: new \nAbstract: Translating from a standard language to its regional dialects is a significant NLP challenge due to scarce data and linguistic variation, a problem prominent in the Bengali language. This paper proposes and compares two novel RAG pipelines for standar...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "analysis",
        "audio",
        "LLM",
        "arxiv",
        "fine-tuning",
        "GPT",
        "augmented",
        "context",
        "RAG",
        "retrieval",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Leveraging LLMs for Structured Data Extraction from Unstructured Patient Records",
      "url": "https://arxiv.org/abs/2512.13700",
      "description": "arXiv:2512.13700v1 Announce Type: new \nAbstract: Manual chart review remains an extremely time-consuming and resource-intensive component of clinical research, requiring experts to extract often complex information from unstructured electronic health record (EHR) narratives. We present a secure, mod...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "research",
        "large language model",
        "LLM",
        "arxiv",
        "augmented",
        "RAG",
        "retrieval",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Blind Radio Mapping via Spatially Regularized Bayesian Trajectory Inference",
      "url": "https://arxiv.org/abs/2512.13701",
      "description": "arXiv:2512.13701v1 Announce Type: new \nAbstract: Radio maps enable intelligent wireless applications by capturing the spatial distribution of channel characteristics. However, conventional construction methods demand extensive location-labeled data, which are costly and impractical in many real-worl...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "vision",
        "arxiv",
        "framework",
        "RAG",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Adjudicator: Correcting Noisy Labels with a KG-Informed Council of LLM Agents",
      "url": "https://arxiv.org/abs/2512.13704",
      "description": "arXiv:2512.13704v1 Announce Type: new \nAbstract: The performance of production machine learning systems is fundamentally limited by the quality of their training data. In high-stakes industrial applications, noisy labels can degrade performance and erode user trust. This paper presents Adjudicator, ...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "large language model",
        "product",
        "LLM",
        "arxiv",
        "context",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms",
      "url": "https://arxiv.org/abs/2512.13713",
      "description": "arXiv:2512.13713v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly being utilized as autonomous agents, yet their ability to coordinate in distributed systems remains poorly understood. We introduce \\textbf{LoopBench}, a benchmark to evaluate LLM reasoning in distributed ...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "large language model",
        "LLM",
        "arxiv",
        "reasoning",
        "memory",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach",
      "url": "https://arxiv.org/abs/2512.13714",
      "description": "arXiv:2512.13714v1 Announce Type: new \nAbstract: LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that ne...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "paper",
        "LLM",
        "vision",
        "arxiv",
        "fine-tuning",
        "reasoning",
        "model",
        "framework",
        "RLHF"
      ],
      "score": 1.0
    },
    {
      "title": "ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making",
      "url": "https://arxiv.org/abs/2512.13716",
      "description": "arXiv:2512.13716v1 Announce Type: new \nAbstract: Personalized decision-making is essential for human-AI interaction, enabling AI agents to act in alignment with individual users' value preferences. As AI systems expand into real-world applications, adapting to personalized values beyond task complet...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "alignment",
        "LLM",
        "arxiv",
        "GPT",
        "context",
        "tool",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy",
      "url": "https://arxiv.org/abs/2512.13725",
      "description": "arXiv:2512.13725v1 Announce Type: new \nAbstract: Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quant...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "compression",
        "study",
        "large language model",
        "experiment",
        "arxiv",
        "augmented",
        "reasoning",
        "RAG",
        "retrieval",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "State-Dependent Refusal and Learned Incapacity in RLHF-Aligned Language Models",
      "url": "https://arxiv.org/abs/2512.13762",
      "description": "arXiv:2512.13762v1 Announce Type: new \nAbstract: Large language models (LLMs) are widely deployed as general-purpose tools, yet extended interaction can reveal behavioral patterns not captured by standard quantitative benchmarks. We present a qualitative case-study methodology for auditing policy-li...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "study",
        "large language model",
        "alignment",
        "LLM",
        "arxiv",
        "context",
        "model",
        "tool",
        "framework",
        "RLHF"
      ],
      "score": 1.0
    },
    {
      "title": "Predictive Modeling of Flood-Prone Areas Using SAR and Environmental Variables",
      "url": "https://arxiv.org/abs/2512.13710",
      "description": "arXiv:2512.13710v1 Announce Type: new \nAbstract: Flooding is one of the most destructive natural hazards worldwide, posing serious risks to ecosystems, infrastructure, and human livelihoods. This study combines Synthetic Aperture Radar (SAR) imagery with environmental and hydrological data to model ...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "study",
        "vector",
        "arxiv",
        "image",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Delete and Retain: Efficient Unlearning for Document Classification",
      "url": "https://arxiv.org/abs/2512.13711",
      "description": "arXiv:2512.13711v1 Announce Type: new \nAbstract: Machine unlearning aims to efficiently remove the influence of specific training data from a model without full retraining. While much progress has been made in unlearning for LLMs, document classification models remain relatively understudied. In thi...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "vector",
        "product",
        "LLM",
        "arxiv",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Federated Few-Shot Learning for Epileptic Seizure Detection Under Privacy Constraints",
      "url": "https://arxiv.org/abs/2512.13717",
      "description": "arXiv:2512.13717v1 Announce Type: new \nAbstract: Many deep learning approaches have been developed for EEG-based seizure detection; however, most rely on access to large centralized annotated datasets. In clinical practice, EEG data are often scarce, patient-specific distributed across institutions,...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "few-shot learning",
        "few-shot",
        "arxiv",
        "transformer",
        "fine-tuning",
        "RAG",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Time-Constrained Recommendations: Reinforcement Learning Strategies for E-Commerce",
      "url": "https://arxiv.org/abs/2512.13726",
      "description": "arXiv:2512.13726v1 Announce Type: new \nAbstract: Unlike traditional recommendation tasks, finite user time budgets introduce a critical resource constraint, requiring the recommender system to balance item relevance and evaluation cost. For example, in a mobile shopping interface, users interact wit...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "framework",
        "example",
        "context",
        "experiment",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing",
      "url": "https://arxiv.org/abs/2512.13727",
      "description": "arXiv:2512.13727v1 Announce Type: new \nAbstract: Ride-hailing platforms face the challenge of balancing passenger waiting times with overall system efficiency under highly uncertain supply-demand conditions. Adaptive delayed matching creates a trade-off between matching and pickup delays by deciding...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "arxiv",
        "attention",
        "RAG",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context window",
        "prompt",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "chain-of-thought",
        "reasoning",
        "audio",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "chain-of-thought",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "vector",
        "LLM",
        "reasoning",
        "knowledge base",
        "RAG",
        "retrieval",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "product",
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "platform",
        "LLM",
        "prompt",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Scaling and Transferability of Annealing Strategies in Large Language Model Training",
      "url": "https://arxiv.org/abs/2512.13705",
      "description": "arXiv:2512.13705v1 Announce Type: new \nAbstract: Learning rate scheduling is crucial for training large language models, yet understanding the optimal annealing strategies across different model configurations remains challenging. In this work, we investigate the transferability of annealing dynamic...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "arxiv",
        "experiment",
        "model",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "Prediction of Respiratory Syncytial Virus-Associated Hospitalizations Using Machine Learning Models Based on Environmental Data",
      "url": "https://arxiv.org/abs/2512.13712",
      "description": "arXiv:2512.13712v1 Announce Type: new \nAbstract: Respiratory syncytial virus (RSV) is a leading cause of hospitalization among young children, with outbreaks strongly influenced by environmental conditions. This study developed a machine learning framework to predict RSV-associated hospitalizations ...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "analysis",
        "study",
        "arxiv",
        "model",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "model",
        "tool",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN",
      "url": "https://arxiv.org/abs/2512.13715",
      "description": "arXiv:2512.13715v1 Announce Type: new \nAbstract: The increasing complexity of modern applications demands wireless networks capable of real time adaptability and efficient resource management. The Open Radio Access Network (O-RAN) architecture, with its RAN Intelligent Controller (RIC) modules, has ...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "framework",
        "model",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Physics-Guided Deep Learning for Heat Pump Stress Detection: A Comprehensive Analysis on When2Heat Dataset",
      "url": "https://arxiv.org/abs/2512.13696",
      "description": "arXiv:2512.13696v1 Announce Type: new \nAbstract: Heat pump systems are critical components in modern energy-efficient buildings, yet their operational stress detection remains challenging due to complex thermodynamic interactions and limited real-world data. This paper presents a novel Physics-Guide...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "product",
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Mitigating Catastrophic Forgetting in Mathematical Reasoning Finetuning through Mixed Training",
      "url": "https://arxiv.org/abs/2512.13706",
      "description": "arXiv:2512.13706v1 Announce Type: new \nAbstract: When finetuning large language models for specialized tasks such as mathematical reasoning, models exhibit catastrophic forgetting, losing previously learned capabilities. We investigate this by finetuning Flan-T5-Base (250M parameters) on the DeepMin...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "large language model",
        "arxiv",
        "reasoning",
        "example",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Mathematics and Coding are Universal AI Benchmarks",
      "url": "https://arxiv.org/abs/2512.13764",
      "description": "arXiv:2512.13764v1 Announce Type: new \nAbstract: We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with fo...",
      "published_date": "2025-12-17T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}