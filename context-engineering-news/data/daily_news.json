{
  "generated_at": "2025-09-29T20:05:45.312008",
  "total_items": 45,
  "items": [
    {
      "title": "A Novel Differential Feature Learning for Effective Hallucination Detection and Classification",
      "url": "https://arxiv.org/abs/2509.21357",
      "description": "arXiv:2509.21357v1 Announce Type: new \nAbstract: Large language model hallucination represents a critical challenge where outputs deviate from factual accuracy due to distributional biases in training data. While recent investigations establish that specific hidden layers exhibit differences between...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "large language model",
        "model",
        "analysis",
        "summarization"
      ],
      "score": 1.0
    },
    {
      "title": "Influence Guided Context Selection for Effective Retrieval-Augmented Generation",
      "url": "https://arxiv.org/abs/2509.21359",
      "description": "arXiv:2509.21359v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) addresses large language model (LLM) hallucinations by grounding responses in external knowledge, but its effectiveness is compromised by poor-quality retrieved contexts containing irrelevant or noisy information. ...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "alignment",
        "RAG",
        "experiment",
        "context",
        "arxiv",
        "large language model",
        "LLM",
        "model",
        "vision",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs",
      "url": "https://arxiv.org/abs/2509.21361",
      "description": "arXiv:2509.21361v1 Announce Type: new \nAbstract: Large language model (LLM) providers boast big numbers for maximum context window sizes. To test the real world use of context windows, we 1) define a concept of maximum effective context window, 2) formulate a testing method of a context window's eff...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "context window",
        "arxiv",
        "context",
        "large language model",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning",
      "url": "https://arxiv.org/abs/2509.21443",
      "description": "arXiv:2509.21443v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly deployed in multilingual and multicultural environments where moral reasoning is essential for generating ethically appropriate responses. Yet, the dominant pretraining of LLMs on English-language data rai...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "alignment",
        "research",
        "study",
        "context",
        "reasoning",
        "arxiv",
        "large language model",
        "LLM",
        "analysis",
        "model",
        "zero-shot",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "LLM-Based Support for Diabetes Diagnosis: Opportunities, Scenarios, and Challenges with GPT-5",
      "url": "https://arxiv.org/abs/2509.21450",
      "description": "arXiv:2509.21450v1 Announce Type: new \nAbstract: Diabetes mellitus is a major global health challenge, affecting over half a billion adults worldwide with prevalence projected to rise. Although the American Diabetes Association (ADA) provides clear diagnostic thresholds, early recognition remains di...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "alignment",
        "multimodal",
        "study",
        "tool",
        "arxiv",
        "GPT",
        "large language model",
        "transformer",
        "LLM",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Diagnosing the Performance Trade-off in Moral Alignment: A Case Study on Gender Stereotypes",
      "url": "https://arxiv.org/abs/2509.21456",
      "description": "arXiv:2509.21456v1 Announce Type: new \nAbstract: Moral alignment has emerged as a widely adopted approach for regulating the behavior of pretrained language models (PLMs), typically through fine-tuning or model editing on curated datasets. However, this process often comes at the cost of degraded do...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "alignment",
        "study",
        "context",
        "arxiv",
        "model",
        "analysis",
        "paper",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Learning to Reason with Mixture of Tokens",
      "url": "https://arxiv.org/abs/2509.21482",
      "description": "arXiv:2509.21482v1 Announce Type: new \nAbstract: Reinforcement learning with verifiable rewards (RLVR) has become a leading approach for improving large language model (LLM) reasoning capabilities. Most current methods follow variants of Group Relative Policy Optimization, which samples multiple rea...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "embedding",
        "reasoning",
        "chain-of-thought",
        "arxiv",
        "large language model",
        "LLM",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Dual-Head Reasoning Distillation: Improving Classifier Accuracy with Train-Time-Only Reasoning",
      "url": "https://arxiv.org/abs/2509.21487",
      "description": "arXiv:2509.21487v1 Announce Type: new \nAbstract: Chain-of-Thought (CoT) prompting often improves classification accuracy, but it introduces a significant throughput penalty with rationale generation (Wei et al., 2022; Cheng and Van Durme, 2024). To resolve this trade-off, we introduce Dual-Head Reas...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "reasoning",
        "chain-of-thought",
        "prompting",
        "arxiv",
        "model",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Towards mitigating information leakage when evaluating safety monitors",
      "url": "https://arxiv.org/abs/2509.21344",
      "description": "arXiv:2509.21344v1 Announce Type: new \nAbstract: White box monitors that analyze model internals offer promising advantages for detecting potentially harmful behaviors in large language models, including lower computational costs and integration into layered defense systems.However, training and eva...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "study",
        "experiment",
        "reasoning",
        "arxiv",
        "prompting",
        "large language model",
        "model",
        "prompt",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Correct Reasoning Paths Visit Shared Decision Pivots",
      "url": "https://arxiv.org/abs/2509.21549",
      "description": "arXiv:2509.21549v1 Announce Type: new \nAbstract: Chain-of-thought (CoT) reasoning exposes the intermediate thinking process of large language models (LLMs), yet verifying those traces at scale remains unsolved. In response, we introduce the idea of decision pivots-minimal, verifiable checkpoints tha...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "experiment",
        "reasoning",
        "chain-of-thought",
        "arxiv",
        "large language model",
        "LLM",
        "model",
        "CoT",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "AutoClimDS: Climate Data Science Agentic AI -- A Knowledge Graph is All You Need",
      "url": "https://arxiv.org/abs/2509.21553",
      "description": "arXiv:2509.21553v1 Announce Type: new \nAbstract: Climate data science faces persistent barriers stemming from the fragmented nature of data sources, heterogeneous formats, and the steep technical expertise required to identify, acquire, and process datasets. These challenges limit participation, slo...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "tool",
        "arxiv",
        "analysis",
        "paper",
        "API",
        "RAG",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks",
      "url": "https://arxiv.org/abs/2509.21567",
      "description": "arXiv:2509.21567v1 Announce Type: new \nAbstract: Prediction of consumer behavior is one of the important purposes in marketing, cognitive neuroscience, and human-computer interaction. The electroencephalography (EEG) data can help analyze the decision process by providing detailed information about ...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "study",
        "arxiv",
        "vector",
        "model",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models",
      "url": "https://arxiv.org/abs/2509.21593",
      "description": "arXiv:2509.21593v1 Announce Type: new \nAbstract: Geospatial modeling provides critical solutions for pressing global challenges such as sustainability and climate change. Existing large language model (LLM)-based algorithm discovery frameworks, such as AlphaEvolve, excel at evolving generic code but...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "knowledge base",
        "RAG",
        "reasoning",
        "arxiv",
        "large language model",
        "LLM",
        "model",
        "retrieval",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization",
      "url": "https://arxiv.org/abs/2509.21718",
      "description": "arXiv:2509.21718v1 Announce Type: new \nAbstract: Developing high-quality text-to-speech (TTS) systems for low-resource languages is challenging due to the scarcity of paired text and speech data. In contrast, automatic speech recognition (ASR) models for such languages are often more accessible, owi...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "audio",
        "fine-tuning",
        "alignment",
        "experiment",
        "arxiv",
        "model",
        "prompt",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LLMs for Bayesian Optimization in Scientific Domains: Are We There Yet?",
      "url": "https://arxiv.org/abs/2509.21403",
      "description": "arXiv:2509.21403v1 Announce Type: new \nAbstract: Large language models (LLMs) have recently been proposed as general-purpose agents for experimental design, with claims that they can perform in-context experimental design. We evaluate this hypothesis using both open- and closed-source instruction-tu...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "instruction",
        "experiment",
        "context",
        "reasoning",
        "arxiv",
        "large language model",
        "LLM",
        "model",
        "in-context",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Null-Space Filtering for Data-Free Continual Model Merging: Preserving Transparency, Promoting Fidelity",
      "url": "https://arxiv.org/abs/2509.21413",
      "description": "arXiv:2509.21413v1 Announce Type: new \nAbstract: Data-free continual model merging (DFCMM) aims to fuse independently fine-tuned models into a single backbone that evolves with incoming tasks without accessing task data. This paper formulate two fundamental desiderata for DFCMM: transparency, avoidi...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "alignment",
        "vector",
        "arxiv",
        "model",
        "paper",
        "vision",
        "RAG",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Forecasting Seismic Waveforms: A Deep Learning Approach for Einstein Telescope",
      "url": "https://arxiv.org/abs/2509.21446",
      "description": "arXiv:2509.21446v1 Announce Type: new \nAbstract: We introduce \\textit{SeismoGPT}, a transformer-based model for forecasting three-component seismic waveforms in the context of future gravitational wave detectors like the Einstein Telescope. The model is trained in an autoregressive setting and can o...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "context",
        "GPT",
        "model",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "d2: Improved Techniques for Training Reasoning Diffusion Language Models",
      "url": "https://arxiv.org/abs/2509.21474",
      "description": "arXiv:2509.21474v1 Announce Type: new \nAbstract: While diffusion language models (DLMs) have achieved competitive performance in text generation, improving their reasoning ability with reinforcement learning remains an active research area. Here, we introduce d2, a reasoning framework tailored for m...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "fine-tuning",
        "research",
        "study",
        "arxiv",
        "reasoning",
        "model",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "context",
        "context window",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "reasoning",
        "chain-of-thought",
        "CoT",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "tool",
        "LLM",
        "model",
        "API",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "knowledge base",
        "RAG",
        "vector",
        "reasoning",
        "LLM",
        "model",
        "retrieval",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "fine-tuning",
        "model",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "product",
        "API",
        "retrieval",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "vector",
        "LLM",
        "prompt",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "framework",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Can AI Perceive Physical Danger and Intervene?",
      "url": "https://arxiv.org/abs/2509.21651",
      "description": "arXiv:2509.21651v1 Announce Type: new \nAbstract: When AI interacts with the physical world -- as a robot or an assistive agent -- new safety challenges emerge beyond those of purely ``digital AI\". In such interactions, the potential for physical harm is direct and immediate. How well do state-of-the...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "instruction",
        "release",
        "reasoning",
        "image",
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "Retrieval-of-Thought: Efficient Reasoning via Reusing Thoughts",
      "url": "https://arxiv.org/abs/2509.21743",
      "description": "arXiv:2509.21743v1 Announce Type: new \nAbstract: Large reasoning models improve accuracy by producing long reasoning traces, but this inflates latency and cost, motivating inference-time efficiency. We propose Retrieval-of-Thought (RoT), which reuses prior reasoning as composable ``thought\" steps to...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "template",
        "reasoning",
        "arxiv",
        "model",
        "prompt",
        "memory",
        "retrieval"
      ],
      "score": 0.8
    },
    {
      "title": "Score-based Idempotent Distillation of Diffusion Models",
      "url": "https://arxiv.org/abs/2509.21470",
      "description": "arXiv:2509.21470v1 Announce Type: new \nAbstract: Idempotent generative networks (IGNs) are a new line of generative models based on idempotent mapping to a target manifold. IGNs support both single-and multi-step generation, allowing for a flexible trade-off between computational cost and sample qua...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "image",
        "model",
        "analysis",
        "zero-shot"
      ],
      "score": 0.8
    },
    {
      "title": "Are Hallucinations Bad Estimations?",
      "url": "https://arxiv.org/abs/2509.21473",
      "description": "arXiv:2509.21473v1 Announce Type: new \nAbstract: We formalize hallucinations in generative models as failures to link an estimate to any plausible cause. Under this interpretation, we show that even loss-minimizing optimal estimators still hallucinate. We confirm this with a general high probability...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "alignment",
        "experiment",
        "arxiv",
        "image",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "model",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "How Large Language Models Need Symbolism",
      "url": "https://arxiv.org/abs/2509.21404",
      "description": "arXiv:2509.21404v1 Announce Type: new \nAbstract: We argue that AI's future requires more than scaling. To unlock genuine discovery, large language models need a compass: human-crafted symbols to guide their powerful but blind intuition....",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "large language model",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "Discovering and Analyzing Stochastic Processes to Reduce Waste in Food Retail",
      "url": "https://arxiv.org/abs/2509.21322",
      "description": "arXiv:2509.21322v1 Announce Type: new \nAbstract: This paper proposes a novel method for analyzing food retail processes with a focus on reducing food waste. The approach integrates object-centric process mining (OCPM) with stochastic process discovery and analysis. First, a stochastic process in the...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "product",
        "arxiv",
        "model",
        "analysis",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Object Identification Under Known Dynamics: A PIRNN Approach for UAV Classification",
      "url": "https://arxiv.org/abs/2509.21405",
      "description": "arXiv:2509.21405v1 Announce Type: new \nAbstract: This work addresses object identification under known dynamics in unmanned aerial vehicle applications, where learning and classification are combined through a physics-informed residual neural network. The proposed framework leverages physics-informe...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "ICL",
        "arxiv",
        "RAG",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "Talking Trees: Reasoning-Assisted Induction of Decision Trees for Tabular Data",
      "url": "https://arxiv.org/abs/2509.21465",
      "description": "arXiv:2509.21465v1 Announce Type: new \nAbstract: Tabular foundation models are becoming increasingly popular for low-resource tabular problems. These models make up for small training datasets by pretraining on large volumes of synthetic data. The prior knowledge obtained via pretraining provides th...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "reasoning",
        "tool",
        "model",
        "LLM"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "paper",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "Automated and Interpretable Survival Analysis from Multimodal Data",
      "url": "https://arxiv.org/abs/2509.21600",
      "description": "arXiv:2509.21600v1 Announce Type: new \nAbstract: Accurate and interpretable survival analysis remains a core challenge in oncology. With growing multimodal data and the clinical need for transparent models to support validation and trust, this challenge increases in complexity. We propose an interpr...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "multimodal",
        "arxiv",
        "model",
        "analysis",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "Impact of Loss Weight and Model Complexity on Physics-Informed Neural Networks for Computational Fluid Dynamics",
      "url": "https://arxiv.org/abs/2509.21393",
      "description": "arXiv:2509.21393v1 Announce Type: new \nAbstract: Physics Informed Neural Networks offer a mesh free framework for solving PDEs but are highly sensitive to loss weight selection. We propose two dimensional analysis based weighting schemes, one based on quantifiable terms, and another also incorporati...",
      "published_date": "2025-09-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "model",
        "framework"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}