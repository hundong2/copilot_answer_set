{
  "generated_at": "2025-07-28T20:05:58.769853",
  "total_items": 46,
  "items": [
    {
      "title": "Specification Self-Correction: Mitigating In-Context Reward Hacking Through Test-Time Refinement",
      "url": "https://arxiv.org/abs/2507.18742",
      "description": "arXiv:2507.18742v1 Announce Type: new \nAbstract: Language models (LMs) are susceptible to in-context reward hacking, where they exploit flaws in tainted or faulty written specifications or rubrics to achieve high scores without fulfilling the user's true intent. We introduce Specification Self-Corre...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "model",
        "in-context",
        "arxiv",
        "framework",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "The Role of Orthographic Consistency in Multilingual Embedding Models for Text Classification in Arabic-Script Languages",
      "url": "https://arxiv.org/abs/2507.18762",
      "description": "arXiv:2507.18762v1 Announce Type: new \nAbstract: In natural language processing, multilingual models like mBERT and XLM-RoBERTa promise broad coverage but often struggle with languages that share a script yet differ in orthographic norms and cultural context. This issue is especially notable in Arab...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "model",
        "arxiv",
        "context",
        "RAG",
        "embedding",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Evaluating Code-Mixing in LLMs Across 18 Languages",
      "url": "https://arxiv.org/abs/2507.18791",
      "description": "arXiv:2507.18791v1 Announce Type: new \nAbstract: Code-mixing, the practice of switching between languages within a conversation, presents unique challenges for traditional natural language processing. Existing benchmarks, such as LinCE and GLUECoS, are limited by narrow language pairings and tasks, ...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "prompt",
        "paper",
        "LLM",
        "model",
        "arxiv",
        "research",
        "context",
        "few-shot",
        "GPT",
        "few-shot learning",
        "large language model",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "PrismRAG: Boosting RAG Factuality with Distractor Resilience and Strategized Reasoning",
      "url": "https://arxiv.org/abs/2507.18857",
      "description": "arXiv:2507.18857v1 Announce Type: new \nAbstract: Retrieval-augmented generation (RAG) often falls short when retrieved context includes confusing semi-relevant passages, or when answering questions require deep contextual understanding and reasoning. We propose an efficient fine-tuning framework, ca...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "retrieval",
        "LLM",
        "model",
        "framework",
        "arxiv",
        "context",
        "fine-tuning",
        "instruction",
        "reasoning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service",
      "url": "https://arxiv.org/abs/2507.18884",
      "description": "arXiv:2507.18884v1 Announce Type: new \nAbstract: High-quality dialogue is crucial for e-commerce customer service, yet traditional intent-based systems struggle with dynamic, multi-turn interactions. We present MindFlow+, a self-evolving dialogue agent that learns domain-specific behavior by combini...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "augmented",
        "experiment",
        "LLM",
        "model",
        "arxiv",
        "demonstration",
        "context",
        "tool",
        "large language model",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "SLoW: Select Low-frequency Words! Automatic Dictionary Selection for Translation on Large Language Models",
      "url": "https://arxiv.org/abs/2507.18902",
      "description": "arXiv:2507.18902v1 Announce Type: new \nAbstract: There are more than 7,000 languages around the world, and current Large Language Models (LLMs) only support hundreds of languages. Dictionary-based prompting methods can enhance translation on them, but most methods use all the available dictionaries,...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "prompt",
        "experiment",
        "paper",
        "LLM",
        "model",
        "arxiv",
        "GPT",
        "large language model",
        "prompting"
      ],
      "score": 1.0
    },
    {
      "title": "Simulation-Driven Reinforcement Learning in Queuing Network Routing Optimization",
      "url": "https://arxiv.org/abs/2507.18795",
      "description": "arXiv:2507.18795v1 Announce Type: new \nAbstract: This study focuses on the development of a simulation-driven reinforcement learning (RL) framework for optimizing routing decisions in complex queueing network systems, with a particular emphasis on manufacturing and communication applications. Recogn...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "model",
        "arxiv",
        "framework",
        "API",
        "RAG",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "A Neuroscience-Inspired Dual-Process Model of Compositional Generalization",
      "url": "https://arxiv.org/abs/2507.18868",
      "description": "arXiv:2507.18868v1 Announce Type: new \nAbstract: Systematic compositional generalization - constructing and understanding novel combinations of known building blocks - remains a core challenge for AI systems. Human cognition achieves this flexibility via the interplay of the hippocampus (HPC) and pr...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "transformer",
        "memory",
        "model",
        "framework",
        "arxiv",
        "API",
        "reasoning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Towards Improving Long-Tail Entity Predictions in Temporal Knowledge Graphs through Global Similarity and Weighted Sampling",
      "url": "https://arxiv.org/abs/2507.18977",
      "description": "arXiv:2507.18977v1 Announce Type: new \nAbstract: Temporal Knowledge Graph (TKG) completion models traditionally assume access to the entire graph during training. This overlooks challenges stemming from the evolving nature of TKGs, such as: (i) the model's requirement to generalize and assimilate ne...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "paper",
        "model",
        "framework",
        "arxiv",
        "context",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation",
      "url": "https://arxiv.org/abs/2507.19089",
      "description": "arXiv:2507.19089v1 Announce Type: new \nAbstract: Fine-grained traffic management and prediction are fundamental to key applications such as autonomous driving, lane change guidance, and traffic signal control. However, obtaining lane-level traffic data has become a critical bottleneck for data-drive...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "model",
        "arxiv",
        "framework",
        "research",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?",
      "url": "https://arxiv.org/abs/2507.19132",
      "description": "arXiv:2507.19132v1 Announce Type: new \nAbstract: Computer-using agents have shown strong potential to boost human productivity and enable new application forms across platforms. While recent advances have led to usable applications, existing benchmarks fail to account for the internal task heterogen...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "experiment",
        "platform",
        "arxiv",
        "research",
        "product",
        "reasoning",
        "ICL",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "Efficient Knowledge Tracing Leveraging Higher-Order Information in Integrated Graphs",
      "url": "https://arxiv.org/abs/2507.18668",
      "description": "arXiv:2507.18668v1 Announce Type: new \nAbstract: The rise of online learning has led to the development of various knowledge tracing (KT) methods. However, existing methods have overlooked the problem of increasing computational cost when utilizing large graphs and long learning sequences. To addres...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "experiment",
        "memory",
        "model",
        "arxiv",
        "attention",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Innovator: Scientific Continued Pretraining with Fine-grained MoE Upcycling",
      "url": "https://arxiv.org/abs/2507.18671",
      "description": "arXiv:2507.18671v1 Announce Type: new \nAbstract: A large language model (LLM) with knowledge in both scientific and general tasks is the foundation of science general intelligence. However, directly continued pretraining an LLM using science data usually leads to catastrophic forgetting, which indic...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "LLM",
        "model",
        "arxiv",
        "large language model",
        "reasoning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Market Making Strategies with Reinforcement Learning",
      "url": "https://arxiv.org/abs/2507.18680",
      "description": "arXiv:2507.18680v1 Announce Type: new \nAbstract: This thesis presents the results of a comprehensive research project focused on applying Reinforcement Learning (RL) to the problem of market making in financial markets. Market makers (MMs) play a fundamental role in providing liquidity, yet face sig...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "arxiv",
        "research",
        "API",
        "RAG",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Exploitation Over Exploration: Unmasking the Bias in Linear Bandit Recommender Offline Evaluation",
      "url": "https://arxiv.org/abs/2507.18756",
      "description": "arXiv:2507.18756v1 Announce Type: new \nAbstract: Multi-Armed Bandit (MAB) algorithms are widely used in recommender systems that require continuous, incremental learning. A core aspect of MABs is the exploration-exploitation trade-off: choosing between exploiting items likely to be enjoyed and explo...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "framework",
        "research",
        "context",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Ralts: Robust Aggregation for Enhancing Graph Neural Network Resilience on Bit-flip Errors",
      "url": "https://arxiv.org/abs/2507.18804",
      "description": "arXiv:2507.18804v1 Announce Type: new \nAbstract: Graph neural networks (GNNs) have been widely applied in safety-critical applications, such as financial and medical networks, in which compromised predictions may cause catastrophic consequences. While existing research on GNN robustness has primaril...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "model",
        "arxiv",
        "research",
        "RAG",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Fishers for Free? Approximating the Fisher Information Matrix by Recycling the Squared Gradient Accumulator",
      "url": "https://arxiv.org/abs/2507.18807",
      "description": "arXiv:2507.18807v1 Announce Type: new \nAbstract: The diagonal of a model's Fisher Information Matrix (the \"Fisher diagonal\") has frequently been used as a way to measure parameter sensitivity. Typically, the Fisher diagonal is estimated via squared sampled gradients of the model's likelihood with re...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "paper",
        "example",
        "model",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt engineering",
        "prompt",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "framework",
        "chain-of-thought",
        "CoT",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "framework",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "LLM",
        "attention",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "LLM",
        "model",
        "framework",
        "knowledge base",
        "reasoning",
        "RAG",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "fine-tuning",
        "LLM",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "retrieval",
        "product",
        "API",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "platform",
        "LLM",
        "framework",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "framework",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "REPRO-Bench: Can Agentic AI Systems Assess the Reproducibility of Social Science Research?",
      "url": "https://arxiv.org/abs/2507.18901",
      "description": "arXiv:2507.18901v1 Announce Type: new \nAbstract: Assessing the reproducibility of social science papers is essential for promoting rigor in research processes, but manual assessment is costly. With recent advances in agentic AI systems (i.e., AI agents), we seek to evaluate their capability to autom...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "paper",
        "arxiv",
        "research",
        "product",
        "ICL"
      ],
      "score": 0.8
    },
    {
      "title": "Initial Steps in Integrating Large Reasoning and Action Models for Service Composition",
      "url": "https://arxiv.org/abs/2507.18775",
      "description": "arXiv:2507.18775v1 Announce Type: new \nAbstract: Service composition remains a central challenge in building adaptive and intelligent software systems, often constrained by limited reasoning capabilities or brittle execution mechanisms. This paper explores the integration of two emerging paradigms e...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "model",
        "arxiv",
        "framework",
        "large language model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Success in Humanoid Reinforcement Learning under Partial Observation",
      "url": "https://arxiv.org/abs/2507.18883",
      "description": "arXiv:2507.18883v1 Announce Type: new \nAbstract: Reinforcement learning has been widely applied to robotic control, but effective policy learning under partial observability remains a major challenge, especially in high-dimensional tasks like humanoid locomotion. To date, no prior work has demonstra...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "research",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "model",
        "API",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "ylmmcl at Multilingual Text Detoxification 2025: Lexicon-Guided Detoxification and Classifier-Gated Rewriting",
      "url": "https://arxiv.org/abs/2507.18769",
      "description": "arXiv:2507.18769v1 Announce Type: new \nAbstract: In this work, we introduce our solution for the Multilingual Text Detoxification Task in the PAN-2025 competition for the ylmmcl team: a robust multilingual text detoxification pipeline that integrates lexicon-guided tagging, a fine-tuned sequence-to-...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "RAG",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "CueBuddy: helping non-native English speakers navigate English-centric STEM education",
      "url": "https://arxiv.org/abs/2507.18827",
      "description": "arXiv:2507.18827v1 Announce Type: new \nAbstract: Students across the world in STEM classes, especially in the Global South, fall behind their peers who are more fluent in English, despite being at par with them in terms of scientific prerequisites. While many of them are able to follow everyday Engl...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "model",
        "arxiv",
        "research"
      ],
      "score": 0.6
    },
    {
      "title": "Faster Lifting for Ordered Domains with Predecessor Relations",
      "url": "https://arxiv.org/abs/2507.19182",
      "description": "arXiv:2507.19182v1 Announce Type: new \nAbstract: We investigate lifted inference on ordered domains with predecessor relations, where the elements of the domain respect a total (cyclic) order, and every element has a distinct (clockwise) predecessor. Previous work has explored this problem through w...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "model",
        "arxiv",
        "experiment"
      ],
      "score": 0.6
    },
    {
      "title": "Diffusion Models for Solving Inverse Problems via Posterior Sampling with Piecewise Guidance",
      "url": "https://arxiv.org/abs/2507.18654",
      "description": "arXiv:2507.18654v1 Announce Type: new \nAbstract: Diffusion models are powerful tools for sampling from high-dimensional distributions by progressively transforming pure noise into structured data through a denoising process. When equipped with a guidance mechanism, these models can also generate sam...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "image",
        "experiment",
        "paper",
        "model",
        "arxiv",
        "framework",
        "tool"
      ],
      "score": 0.6
    },
    {
      "title": "Concept Probing: Where to Find Human-Defined Concepts (Extended Version)",
      "url": "https://arxiv.org/abs/2507.18681",
      "description": "arXiv:2507.18681v1 Announce Type: new \nAbstract: Concept probing has recently gained popularity as a way for humans to peek into what is encoded within artificial neural networks. In concept probing, additional classifiers are trained to map the internal representations of a model into human-defined...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "analysis",
        "arxiv",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "The Right to be Forgotten in Pruning: Unveil Machine Unlearning on Sparse Models",
      "url": "https://arxiv.org/abs/2507.18725",
      "description": "arXiv:2507.18725v1 Announce Type: new \nAbstract: Machine unlearning aims to efficiently eliminate the memory about deleted data from trained models and address the right to be forgotten. Despite the success of existing unlearning algorithms, unlearning in sparse models has not yet been well studied....",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "paper",
        "release",
        "memory",
        "model",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "NUTMEG: Separating Signal From Noise in Annotator Disagreement",
      "url": "https://arxiv.org/abs/2507.18890",
      "description": "arXiv:2507.18890v1 Announce Type: new \nAbstract: NLP models often rely on human-labeled data for training and evaluation. Many approaches crowdsource this data from a large number of annotators with varying skills, backgrounds, and motivations, resulting in conflicting annotations. These conflicts h...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring",
      "url": "https://arxiv.org/abs/2507.19172",
      "description": "arXiv:2507.19172v1 Announce Type: new \nAbstract: Robust and unobtrusive in-vehicle physiological monitoring is crucial for ensuring driving safety and user experience. While remote physiological measurement (RPM) offers a promising non-invasive solution, its translation to real-world driving scenari...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "vision",
        "release",
        "arxiv",
        "research",
        "tool",
        "multimodal",
        "ICL"
      ],
      "score": 0.4
    },
    {
      "title": "CLEAR: Unlearning Spurious Style-Content Associations with Contrastive LEarning with Anti-contrastive Regularization",
      "url": "https://arxiv.org/abs/2507.18794",
      "description": "arXiv:2507.18794v1 Announce Type: new \nAbstract: Learning representations unaffected by superficial characteristics is important to ensure that shifts in these characteristics at test time do not compromise downstream prediction performance. For instance, in healthcare applications, we might like to...",
      "published_date": "2025-07-28T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "image",
        "experiment",
        "arxiv",
        "framework",
        "ICL"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}