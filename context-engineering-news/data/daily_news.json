{
  "generated_at": "2025-08-19T20:05:38.338292",
  "total_items": 49,
  "items": [
    {
      "title": "Deep Language Geometry: Constructing a Metric Space from LLM Weights",
      "url": "https://arxiv.org/abs/2508.11676",
      "description": "arXiv:2508.11676v1 Announce Type: new \nAbstract: We introduce a novel framework that utilizes the internal weight activations of modern Large Language Models (LLMs) to construct a metric space of languages. Unlike traditional approaches based on hand-crafted linguistic features, our method automatic...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "framework",
        "arxiv",
        "ICL",
        "model",
        "large language model",
        "tool",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Can we Evaluate RAGs with Synthetic Data?",
      "url": "https://arxiv.org/abs/2508.11758",
      "description": "arXiv:2508.11758v1 Announce Type: new \nAbstract: We investigate whether synthetic question-answer (QA) data generated by large language models (LLMs) can serve as an effective proxy for human-labeled benchmarks when such data is unavailable. We assess the reliability of synthetic benchmarks across t...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "RAG",
        "arxiv",
        "model",
        "large language model",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "A Multi-Task Evaluation of LLMs' Processing of Academic Text Input",
      "url": "https://arxiv.org/abs/2508.11779",
      "description": "arXiv:2508.11779v1 Announce Type: new \nAbstract: How much large language models (LLMs) can aid scientific discovery, notably in assisting academic peer review, is in heated debate. Between a literature digest and a human-comparable research assistant lies their practical application potential. We or...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "LLM",
        "arxiv",
        "ICL",
        "instruction",
        "model",
        "large language model",
        "prompt",
        "product",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "LLM-Guided Planning and Summary-Based Scientific Text Simplification: DS@GT at CLEF 2025 SimpleText",
      "url": "https://arxiv.org/abs/2508.11816",
      "description": "arXiv:2508.11816v1 Announce Type: new \nAbstract: In this paper, we present our approach for the CLEF 2025 SimpleText Task 1, which addresses both sentence-level and document-level scientific text simplification. For sentence-level simplification, our methodology employs large language models (LLMs) ...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "RAG",
        "framework",
        "arxiv",
        "context",
        "model",
        "large language model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Hallucination Detection and Mitigation in Scientific Text Simplification using Ensemble Approaches: DS@GT at CLEF 2025 SimpleText",
      "url": "https://arxiv.org/abs/2508.11823",
      "description": "arXiv:2508.11823v1 Announce Type: new \nAbstract: In this paper, we describe our methodology for the CLEF 2025 SimpleText Task 2, which focuses on detecting and evaluating creative generation and information distortion in scientific text simplification. Our solution integrates multiple strategies: we...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "RAG",
        "reasoning",
        "framework",
        "arxiv",
        "model",
        "large language model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "A Survey of Idiom Datasets for Psycholinguistic and Computational Research",
      "url": "https://arxiv.org/abs/2508.11828",
      "description": "arXiv:2508.11828v1 Announce Type: new \nAbstract: Idioms are figurative expressions whose meanings often cannot be inferred from their individual words, making them difficult to process computationally and posing challenges for human experimental studies. This survey reviews datasets developed in psy...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "arxiv",
        "study",
        "model",
        "experiment",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Every 28 Days the AI Dreams of Soft Skin and Burning Stars: Scaffolding AI Agents with Hormones and Emotions",
      "url": "https://arxiv.org/abs/2508.11829",
      "description": "arXiv:2508.11829v1 Announce Type: new \nAbstract: Despite significant advances, AI systems struggle with the frame problem: determining what information is contextually relevant from an exponentially large possibility space. We hypothesize that biological rhythms, particularly hormonal cycles, serve ...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "analysis",
        "context",
        "model",
        "large language model",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "When Does Language Transfer Help? Sequential Fine-Tuning for Cross-Lingual Euphemism Detection",
      "url": "https://arxiv.org/abs/2508.11831",
      "description": "arXiv:2508.11831v1 Announce Type: new \nAbstract: Euphemisms are culturally variable and often ambiguous, posing challenges for language models, especially in low-resource settings. This paper investigates how cross-lingual transfer via sequential fine-tuning affects euphemism detection across five l...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "arxiv",
        "fine-tuning",
        "model",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models",
      "url": "https://arxiv.org/abs/2508.11850",
      "description": "arXiv:2508.11850v1 Announce Type: new \nAbstract: Integer programming lies at the heart of crucial combinatorial optimization tasks but remains challenging due to its NP-hard nature. An effective approach for practically solving integer programs is the manual design of acceleration cuts, i.e. inequal...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "framework",
        "arxiv",
        "model",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework",
      "url": "https://arxiv.org/abs/2508.11860",
      "description": "arXiv:2508.11860v1 Announce Type: new \nAbstract: Large language model (LLM) agent evaluators leverage specialized tools to ground the rational decision-making of LLMs, making them well-suited to aid in scientific discoveries, such as constrained retrosynthesis planning. Constrained retrosynthesis pl...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "RAG",
        "reasoning",
        "framework",
        "arxiv",
        "model",
        "large language model",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "QuarkMed Medical Foundation Model Technical Report",
      "url": "https://arxiv.org/abs/2508.11894",
      "description": "arXiv:2508.11894v1 Announce Type: new \nAbstract: Recent advancements in large language models have significantly accelerated their adoption in healthcare applications, including AI-powered medical consultations, diagnostic report assistance, and medical search tools. However, medical tasks often dem...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "arxiv",
        "retrieval",
        "model",
        "large language model",
        "augmented",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs",
      "url": "https://arxiv.org/abs/2508.11944",
      "description": "arXiv:2508.11944v1 Announce Type: new \nAbstract: Game-playing ability serves as an indicator for evaluating the strategic reasoning capability of large language models (LLMs). While most existing studies rely on utility performance metrics, which are not robust enough due to variations in opponent b...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "reasoning",
        "framework",
        "arxiv",
        "model",
        "large language model",
        "experiment",
        "tool",
        "research",
        "memory"
      ],
      "score": 1.0
    },
    {
      "title": "Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models",
      "url": "https://arxiv.org/abs/2508.11953",
      "description": "arXiv:2508.11953v1 Announce Type: new \nAbstract: Optimizing data mixtures for supervised fine-tuning (SFT) of large language models (LLMs) is critical for developing general-purpose models, yet this area remains underexplored. In this paper, we frame data mixing as an optimization problem and introd...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "RAG",
        "arxiv",
        "fine-tuning",
        "model",
        "large language model",
        "experiment",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting",
      "url": "https://arxiv.org/abs/2508.11954",
      "description": "arXiv:2508.11954v1 Announce Type: new \nAbstract: Time series forecasting is a foundational task across domains, such as finance, healthcare, and environmental monitoring. While recent advances in Time Series Foundation Models (TSFMs) have demonstrated strong generalisation through large-scale pretra...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "cross-modal",
        "RAG",
        "prompting",
        "framework",
        "arxiv",
        "context",
        "multimodal",
        "model",
        "prompt",
        "vision",
        "experiment",
        "embedding",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction",
      "url": "https://arxiv.org/abs/2508.11987",
      "description": "arXiv:2508.11987v1 Announce Type: new \nAbstract: Future prediction is a complex task for LLM agents, requiring a high level of analytical thinking, information gathering, contextual understanding, and decision-making under uncertainty. Agents must not only gather and interpret vast amounts of dynami...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "reasoning",
        "arxiv",
        "context",
        "model",
        "tool",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Sparse Attention across Multiple-context KV Cache",
      "url": "https://arxiv.org/abs/2508.11661",
      "description": "arXiv:2508.11661v1 Announce Type: new \nAbstract: Large language models face significant cost challenges in long-sequence inference. To address this, reusing historical Key-Value (KV) Cache for improved inference efficiency has become a mainstream approach. Recent advances further enhance throughput ...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "attention",
        "arxiv",
        "retrieval",
        "context",
        "model",
        "large language model",
        "augmented",
        "experiment",
        "memory",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Assessing Representation Stability for Transformer Models",
      "url": "https://arxiv.org/abs/2508.11667",
      "description": "arXiv:2508.11667v1 Announce Type: new \nAbstract: Adversarial text attacks remain a persistent threat to transformer models, yet existing defenses are typically attack-specific or require costly model retraining. We introduce Representation Stability (RS), a model-agnostic detection framework that id...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "example",
        "framework",
        "arxiv",
        "model",
        "transformer",
        "experiment",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning",
      "url": "https://arxiv.org/abs/2508.11673",
      "description": "arXiv:2508.11673v1 Announce Type: new \nAbstract: Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for handling diverse tasks and modalities in the biomedical domain, as training separate models for each modality or task significantly increases inference costs. Existing increment...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "RAG",
        "image",
        "arxiv",
        "fine-tuning",
        "ICL",
        "multimodal",
        "model",
        "vision",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems",
      "url": "https://arxiv.org/abs/2508.11679",
      "description": "arXiv:2508.11679v1 Announce Type: new \nAbstract: Deep learning has been extensively explored to solve vehicle routing problems (VRPs), which yields a range of data-driven neural solvers with promising outcomes. However, most neural solvers are trained to tackle VRP instances in a relatively monotono...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "framework",
        "arxiv",
        "ICL",
        "context",
        "transformer",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics",
      "url": "https://arxiv.org/abs/2508.11680",
      "description": "arXiv:2508.11680v1 Announce Type: new \nAbstract: Demographic shifts, influenced by globalization, economic conditions, geopolitical events, and environmental factors, pose significant challenges for policymakers and researchers. Accurate demographic forecasting is essential for informed decision-mak...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "arxiv",
        "fine-tuning",
        "study",
        "analysis",
        "model",
        "experiment",
        "research",
        "memory"
      ],
      "score": 1.0
    },
    {
      "title": "From Heuristics to Data: Quantifying Site Planning Layout Indicators with Deep Learning and Multi-Modal Data",
      "url": "https://arxiv.org/abs/2508.11723",
      "description": "arXiv:2508.11723v1 Announce Type: new \nAbstract: The spatial layout of urban sites shapes land-use efficiency and spatial organization. Traditional site planning often relies on experiential judgment and single-source data, limiting systematic quantification of multifunctional layouts. We propose a ...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "image",
        "framework",
        "arxiv",
        "retrieval",
        "multimodal",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "Causal Structure Learning in Hawkes Processes with Complex Latent Confounder Networks",
      "url": "https://arxiv.org/abs/2508.11727",
      "description": "arXiv:2508.11727v1 Announce Type: new \nAbstract: Multivariate Hawkes process provides a powerful framework for modeling temporal dependencies and event-driven interactions in complex systems. While existing methods primarily focus on uncovering causal structures among observed subprocesses, real-wor...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "framework",
        "arxiv",
        "model",
        "experiment",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification",
      "url": "https://arxiv.org/abs/2508.11732",
      "description": "arXiv:2508.11732v1 Announce Type: new \nAbstract: Existing deep learning models for functional MRI-based classification have limitations in network architecture determination (relying on experience) and feature space fusion (mostly simple concatenation, lacking mutual learning). Inspired by the human...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "attention",
        "framework",
        "arxiv",
        "model",
        "transformer",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "context window",
        "prompt",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "audio",
        "framework",
        "chain-of-thought",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "LLM",
        "attention",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "LLM",
        "RAG",
        "reasoning",
        "framework",
        "retrieval",
        "knowledge base",
        "model",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "tool",
        "model",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "RAG",
        "retrieval",
        "augmented",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "framework",
        "platform",
        "prompt",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "RAG",
        "retrieval",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index",
      "url": "https://arxiv.org/abs/2508.11959",
      "description": "arXiv:2508.11959v1 Announce Type: new \nAbstract: Feature attribution methods based on game theory are ubiquitous in the field of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous feature attribution using logic-based explanations, specifically targeting high-stakes uses of ma...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "example",
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering",
      "url": "https://arxiv.org/abs/2508.11975",
      "description": "arXiv:2508.11975v1 Announce Type: new \nAbstract: Vision Language Models (VLMs) often struggle with chart understanding tasks, particularly in accurate chart description and complex reasoning. Synthetic data generation is a promising solution, while usually facing the challenge of noise labels. To ad...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "reasoning",
        "arxiv",
        "context",
        "model",
        "vision",
        "experiment"
      ],
      "score": 0.8
    },
    {
      "title": "Scalable Geospatial Data Generation Using AlphaEarth Foundations Model",
      "url": "https://arxiv.org/abs/2508.11739",
      "description": "arXiv:2508.11739v1 Announce Type: new \nAbstract: High-quality labeled geospatial datasets are essential for extracting insights and understanding our planet. Unfortunately, these datasets often do not span the entire globe and are limited to certain geographic regions where data was collected. Googl...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "release",
        "arxiv",
        "study",
        "ICL",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "tool",
        "model",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Limitation Learning: Catching Adverse Dialog with GAIL",
      "url": "https://arxiv.org/abs/2508.11767",
      "description": "arXiv:2508.11767v1 Announce Type: new \nAbstract: Imitation learning is a proven method for creating a policy in the absence of rewards, by leveraging expert demonstrations. In this work, we apply imitation learning to conversation. In doing so, we recover a policy capable of talking to a user given ...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "RAG",
        "arxiv",
        "model",
        "prompt",
        "demonstration"
      ],
      "score": 0.6
    },
    {
      "title": "Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset",
      "url": "https://arxiv.org/abs/2508.11669",
      "description": "arXiv:2508.11669v1 Announce Type: new \nAbstract: Noninvasive arterial blood pressure (ABP) monitoring is essential for patient management in critical care and perioperative settings, providing continuous assessment of cardiovascular hemodynamics with minimal risks. Numerous deep learning models have...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "model",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video",
      "url": "https://arxiv.org/abs/2508.11836",
      "description": "arXiv:2508.11836v1 Announce Type: new \nAbstract: World models are defined as a compressed spatial and temporal learned representation of an environment. The learned representation is typically a neural network, making transfer of the learned environment dynamics and explainability a challenge. In th...",
      "published_date": "2025-08-19T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Generate Images with Claude and Hugging Face",
      "url": "https://huggingface.co/blog/claude-and-mcp",
      "description": "...",
      "published_date": "2025-08-19T00:00:00",
      "source": "Hugging Face Blog",
      "category": "multimodal_context",
      "keywords": [
        "image"
      ],
      "score": 0.2
    },
    {
      "title": "From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels",
      "url": "https://huggingface.co/blog/kernel-builder",
      "description": "...",
      "published_date": "2025-08-18T00:00:00",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "product"
      ],
      "score": 0.2
    },
    {
      "title": "MCP for Research: How to Connect AI to Research Tools",
      "url": "https://huggingface.co/blog/mcp-for-research",
      "description": "...",
      "published_date": "2025-08-18T00:00:00",
      "source": "Hugging Face Blog",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "research"
      ],
      "score": 0.2
    }
  ]
}