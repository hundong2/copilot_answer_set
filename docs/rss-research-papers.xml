<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>GRIP: In-Parameter Graph Reasoning through Fine-Tuning Large Language Models</title>
      <link>https://arxiv.org/abs/2511.07457</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07457</guid>
      <description>arXiv:2511.07457v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in modeling sequential textual data and generalizing across diverse tasks. However, adapting LLMs to effectively handle structural data, such as knowledge graphs or web data, remai...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; alignment, model, fine-tuning, arxiv, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>alignment</category>
      <category>model</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>It Takes Two: A Dual Stage Approach for Terminology-Aware Translation</title>
      <link>https://arxiv.org/abs/2511.07461</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07461</guid>
      <description>arXiv:2511.07461v1 Announce Type: new 
Abstract: This paper introduces DuTerm, a novel two-stage architecture for terminology-constrained machine translation. Our system combines a terminology-aware NMT model, adapted via fine-tuning on large-scale synthetic data, with a prompt-based LLM for post-ed...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, model, fine-tuning, arxiv, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>model</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>Focusing on Language: Revealing and Exploiting Language Attention Heads in Multilingual Large Language Models</title>
      <link>https://arxiv.org/abs/2511.07498</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07498</guid>
      <description>arXiv:2511.07498v1 Announce Type: new 
Abstract: Large language models (LLMs) increasingly support multilingual understanding and generation. Meanwhile, efforts to interpret their internal mechanisms have emerged, offering insights to enhance multilingual performance. While multi-head self-attention...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, study, model, arxiv, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>study</category>
      <category>model</category>
    </item>
    <item>
      <title>LLMs vs. Traditional Sentiment Tools in Psychology: An Evaluation on Belgian-Dutch Narratives</title>
      <link>https://arxiv.org/abs/2511.07641</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07641</guid>
      <description>arXiv:2511.07641v1 Announce Type: new 
Abstract: Understanding emotional nuances in everyday language is crucial for computational linguistics and emotion research. While traditional lexicon-based tools like LIWC and Pattern have served as foundational instruments, Large Language Models (LLMs) promi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, model, fine-tuning, arxiv, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>model</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>Revisiting NLI: Towards Cost-Effective and Human-Aligned Metrics for Evaluating LLMs in Question Answering</title>
      <link>https://arxiv.org/abs/2511.07659</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07659</guid>
      <description>arXiv:2511.07659v1 Announce Type: new 
Abstract: Evaluating answers from state-of-the-art large language models (LLMs) is challenging: lexical metrics miss semantic nuances, whereas &amp;quot;LLM-as-Judge&amp;quot; scoring is computationally expensive. We re-evaluate a lightweight alternative -- off-the-shelf Natural...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; augmented, alignment, GPT, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>augmented</category>
      <category>alignment</category>
      <category>GPT</category>
    </item>
    <item>
      <title>Analysing Environmental Efficiency in AI for X-Ray Diagnosis</title>
      <link>https://arxiv.org/abs/2511.07436</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07436</guid>
      <description>arXiv:2511.07436v1 Announce Type: new 
Abstract: The integration of AI tools into medical applications has aimed to improve the efficiency of diagnosis. The emergence of large language models (LLMs), such as ChatGPT and Claude, has expanded this integration even further. Because of LLM versatility a...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; API, study, knowledge base, GPT, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>API</category>
      <category>study</category>
      <category>knowledge base</category>
    </item>
    <item>
      <title>Agentic Educational Content Generation for African Languages on Edge Devices</title>
      <link>https://arxiv.org/abs/2511.07437</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07437</guid>
      <description>arXiv:2511.07437v1 Announce Type: new 
Abstract: Addressing educational inequity in Sub-Saharan Africa, this research presents an autonomous agent-orchestrated framework for decentralized, culturally adaptive educational content generation on edge devices. The system leverages four specialized agent...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, arxiv, platform, framework, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>arxiv</category>
      <category>platform</category>
    </item>
    <item>
      <title>Procedural Knowledge Improves Agentic LLM Workflows</title>
      <link>https://arxiv.org/abs/2511.07568</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07568</guid>
      <description>arXiv:2511.07568v1 Announce Type: new 
Abstract: Large language models (LLMs) often struggle when performing agentic tasks without substantial tool support, prom-pt engineering, or fine tuning. Despite research showing that domain-dependent, procedural knowledge can dramatically increase planning ef...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, RAG, large language model, arxiv, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>RAG</category>
      <category>large language model</category>
    </item>
    <item>
      <title>AIA Forecaster: Technical Report</title>
      <link>https://arxiv.org/abs/2511.07678</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07678</guid>
      <description>arXiv:2511.07678v1 Announce Type: new 
Abstract: This technical report describes the AIA Forecaster, a Large Language Model (LLM)-based system for judgmental forecasting using unstructured data. The AIA Forecaster approach combines three core elements: agentic search over high-quality news sources, ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, arxiv, large language model, research, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>arxiv</category>
      <category>large language model</category>
    </item>
    <item>
      <title>ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents</title>
      <link>https://arxiv.org/abs/2511.07685</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07685</guid>
      <description>arXiv:2511.07685v1 Announce Type: new 
Abstract: Deep Research (DR) is an emerging agent application that leverages large language models (LLMs) to address open-ended queries. It requires the integration of several capabilities, including multi-step reasoning, cross-document synthesis, and the gener...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, release, model, arxiv, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>release</category>
      <category>model</category>
    </item>
    <item>
      <title>Optimizing Classification of Infrequent Labels by Reducing Variability in Label Distribution</title>
      <link>https://arxiv.org/abs/2511.07459</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07459</guid>
      <description>arXiv:2511.07459v1 Announce Type: new 
Abstract: This paper presents a novel solution, LEVER, designed to address the challenges posed by underperforming infrequent categories in Extreme Classification (XC) tasks. Infrequent categories, often characterized by sparse samples, suffer from high label i...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, RAG, research, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>RAG</category>
      <category>research</category>
    </item>
    <item>
      <title>Towards Personalized Quantum Federated Learning for Anomaly Detection</title>
      <link>https://arxiv.org/abs/2511.07471</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07471</guid>
      <description>arXiv:2511.07471v1 Announce Type: new 
Abstract: Anomaly detection has a significant impact on applications such as video surveillance, medical diagnostics, and industrial monitoring, where anomalies frequently depend on context and anomaly-labeled data are limited. Quantum federated learning (QFL) ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, model, arxiv, framework, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>model</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Comparing Reconstruction Attacks on Pretrained Versus Full Fine-tuned Large Language Model Embeddings on Homo Sapiens Splice Sites Genomic Data</title>
      <link>https://arxiv.org/abs/2511.07481</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07481</guid>
      <description>arXiv:2511.07481v1 Announce Type: new 
Abstract: This study investigates embedding reconstruction attacks in large language models (LLMs) applied to genomic sequences, with a specific focus on how fine-tuning affects vulnerability to these attacks. Building upon Pan et al.&amp;#x27;s seminal work demonstrati...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; API, study, GPT, model, fine-tuning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>API</category>
      <category>study</category>
      <category>GPT</category>
    </item>
    <item>
      <title>Alignment-Constrained Dynamic Pruning for LLMs: Identifying and Preserving Alignment-Critical Circuits</title>
      <link>https://arxiv.org/abs/2511.07482</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07482</guid>
      <description>arXiv:2511.07482v1 Announce Type: new 
Abstract: Large Language Models require substantial computational resources for inference, posing deployment challenges. While dynamic pruning offers superior efficiency over static methods through adaptive circuit selection, it exacerbates alignment degradatio...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; alignment, model, arxiv, large language model, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>alignment</category>
      <category>model</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Counterfactual Forecasting of Human Behavior using Generative AI and Causal Graphs</title>
      <link>https://arxiv.org/abs/2511.07484</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07484</guid>
      <description>arXiv:2511.07484v1 Announce Type: new 
Abstract: This study presents a novel framework for counterfactual user behavior forecasting that combines structural causal models with transformer-based generative artificial intelligence. To model fictitious situations, the method creates causal graphs that ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, model, arxiv, framework, transformer | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>model</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Provably Efficient Sample Complexity for Robust CMDP</title>
      <link>https://arxiv.org/abs/2511.07486</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07486</guid>
      <description>arXiv:2511.07486v1 Announce Type: new 
Abstract: We study the problem of learning policies that maximize cumulative reward while satisfying safety constraints, even when the real environment differs from a simulator or nominal model. We focus on robust constrained Markov decision processes (RCMDPs),...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, augmented, model, arxiv, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>augmented</category>
      <category>model</category>
    </item>
    <item>
      <title>When Are Learning Biases Equivalent? A Unifying Framework for Fairness, Robustness, and Distribution Shift</title>
      <link>https://arxiv.org/abs/2511.07485</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.07485</guid>
      <description>arXiv:2511.07485v1 Announce Type: new 
Abstract: Machine learning systems exhibit diverse failure modes: unfairness toward protected groups, brittleness to spurious correlations, poor performance on minority sub-populations, which are typically studied in isolation by distinct research communities. ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, framework, research, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>framework</category>
      <category>research</category>
    </item>
  </channel>
</rss>