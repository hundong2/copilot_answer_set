<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Context Engineering Daily</title>
    <link>https://your-username.github.io/context-engineering-news</link>
    <description>Daily news and research updates in AI Context Engineering, Prompt Engineering, RAG, and LLM development</description>
    <language>en-us</language>
    <copyright>Copyright 2025 Context Engineering Daily</copyright>
    <generator>Context Engineering News Generator</generator>
    <lastBuildDate>Thu, 14 Aug 2025 20:06:13 +0000</lastBuildDate>
    <atom:link href="https://your-username.github.io/context-engineering-news/rss.xml" rel="self" type="application/rss+xml"/>
    <category>Technology</category>
    <category>Artificial Intelligence</category>
    <category>Machine Learning</category>
    <item>
      <title>ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2508.09303</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09303</guid>
      <description>arXiv:2508.09303v1 Announce Type: new 
Abstract: Reasoning-augmented search agents such as Search-R1, trained via reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable capabilities in multi-step information retrieval from external knowledge sources. These agents address the l...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, memory, experiment, arxiv, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>RAG</category>
      <category>memory</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Leveraging Large Language Models for Rare Disease Named Entity Recognition</title>
      <link>https://arxiv.org/abs/2508.09323</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09323</guid>
      <description>arXiv:2508.09323v1 Announce Type: new 
Abstract: Named Entity Recognition (NER) in the rare disease domain poses unique challenges due to limited labeled data, semantic ambiguity between entity types, and long-tail distributions. In this study, we evaluate the capabilities of GPT-4o for rare disease...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; zero-shot, large language model, LLM, context, prompting | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Prompt Engineering</category>
      <category>zero-shot</category>
      <category>large language model</category>
      <category>LLM</category>
    </item>
    <item>
      <title>TEN: Table Explicitization, Neurosymbolically</title>
      <link>https://arxiv.org/abs/2508.09324</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09324</guid>
      <description>arXiv:2508.09324v1 Announce Type: new 
Abstract: We present a neurosymbolic approach, TEN, for extracting tabular data from semistructured input text. This task is particularly challenging for text input that does not use special delimiters consistently to separate columns and rows. Purely neural ap...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, prompting, experiment, chain-of-thought, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>prompting</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Decoding Neural Emotion Patterns through Natural Language Processing Embeddings</title>
      <link>https://arxiv.org/abs/2508.09337</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09337</guid>
      <description>arXiv:2508.09337v1 Announce Type: new 
Abstract: Understanding how emotional expression in language relates to brain function is a challenge in computational neuroscience and affective computing. Traditional neuroimaging is costly and lab-bound, but abundant digital text offers new avenues for emoti...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, experiment, arxiv, framework, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>experiment</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains</title>
      <link>https://arxiv.org/abs/2508.09349</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09349</guid>
      <description>arXiv:2508.09349v1 Announce Type: new 
Abstract: Expert consensus plays a critical role in domains where evidence is complex, conflicting, or insufficient for direct prescription. Traditional methods, such as Delphi studies, consensus conferences, and systematic guideline synthesis, offer structure ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, study, RAG, arxiv, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>study</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Flow-SLM: Joint Learning of Linguistic and Acoustic Information for Spoken Language Modeling</title>
      <link>https://arxiv.org/abs/2508.09350</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09350</guid>
      <description>arXiv:2508.09350v1 Announce Type: new 
Abstract: Textless spoken language models (SLMs) are generative models of speech that do not rely on text supervision. Most textless SLMs learn to predict the next semantic token, a discrete representation of linguistic content, and rely on a separate vocoder t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, study, vector, arxiv, prompt | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>study</category>
      <category>vector</category>
    </item>
    <item>
      <title>APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification</title>
      <link>https://arxiv.org/abs/2508.09378</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09378</guid>
      <description>arXiv:2508.09378v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, several approaches have been proposed to engineer prompts ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompting, chain-of-thought, arxiv, research, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Prompt Engineering</category>
      <category>prompting</category>
      <category>chain-of-thought</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models</title>
      <link>https://arxiv.org/abs/2508.09403</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09403</guid>
      <description>arXiv:2508.09403v1 Announce Type: new 
Abstract: Expanding the abbreviated column names of tables, such as ``esal&amp;#x27;&amp;#x27; to ``employee salary&amp;#x27;&amp;#x27;, is critical for numerous downstream data tasks. This problem arises in enterprises, domain sciences, government agencies, and more. In this paper we make three ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, product, analysis, experiment, chain-of-thought | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>product</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Leveraging Zipformer Model for Effective Language Identification in Code-Switched Child-Directed Speech</title>
      <link>https://arxiv.org/abs/2508.09430</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09430</guid>
      <description>arXiv:2508.09430v1 Announce Type: new 
Abstract: Code-switching and language identification in child-directed scenarios present significant challenges, particularly in bilingual environments. This paper addresses this challenge by using Zipformer to handle the nuances of speech, which contains two i...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, RAG, arxiv, paper, transformer | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>RAG</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>From Charts to Fair Narratives: Uncovering and Mitigating Geo-Economic Biases in Chart-to-Text</title>
      <link>https://arxiv.org/abs/2508.09450</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09450</guid>
      <description>arXiv:2508.09450v1 Announce Type: new 
Abstract: Charts are very common for exploring data and communicating insights, but extracting key takeaways from charts and articulating them in natural language can be challenging. The chart-to-text task aims to automate this process by generating textual sum...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, analysis, arxiv, attention, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>GPT</category>
      <category>analysis</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants</title>
      <link>https://arxiv.org/abs/2508.09507</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09507</guid>
      <description>arXiv:2508.09507v1 Announce Type: new 
Abstract: With the rapid development of mobile intelligent assistant technologies, multi-modal AI assistants have become essential interfaces for daily user interactions. However, current evaluation methods face challenges including high manual costs, inconsist...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, arxiv, paper, API, fine-tuning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>arxiv</category>
      <category>paper</category>
    </item>
    <item>
      <title>EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making</title>
      <link>https://arxiv.org/abs/2508.09586</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09586</guid>
      <description>arXiv:2508.09586v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, including programming, planning, and decision-making. However, their performance often degrades when faced with highly complex problem instances that requir...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, arxiv, reasoning, framework, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>arxiv</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement</title>
      <link>https://arxiv.org/abs/2508.09670</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09670</guid>
      <description>arXiv:2508.09670v1 Announce Type: new 
Abstract: Recent advances demonstrate that reinforcement learning with verifiable rewards (RLVR) significantly enhances the reasoning capabilities of large language models (LLMs). However, standard RLVR faces challenges with reward sparsity, where zero rewards ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, experiment, arxiv, reasoning, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>experiment</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge</title>
      <link>https://arxiv.org/abs/2508.09724</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09724</guid>
      <description>arXiv:2508.09724v1 Announce Type: new 
Abstract: Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but it is prone to preference bias, where judges systematically favor certain outputs, such as their own. This bias leads to inconsistent and skewed rankings across different ju...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, experiment, arxiv, alignment, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>experiment</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?</title>
      <link>https://arxiv.org/abs/2508.09762</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09762</guid>
      <description>arXiv:2508.09762v1 Announce Type: new 
Abstract: As Large Language Models (LLMs) become increasingly autonomous and integrated into critical societal functions, the focus of AI safety must evolve from mitigating harmful content to evaluating underlying behavioral alignment. Current safety benchmarks...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, arxiv, alignment, tool, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>GPT</category>
      <category>arxiv</category>
      <category>alignment</category>
    </item>
    <item>
      <title>Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation</title>
      <link>https://arxiv.org/abs/2508.09860</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09860</guid>
      <description>arXiv:2508.09860v1 Announce Type: new 
Abstract: Human-aligned AI is a critical component of co-creativity, as it enables models to accurately interpret human intent and generate controllable outputs that align with design goals in collaborative content creation. This direction is especially relevan...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vision, experiment, arxiv, paper, tool | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>vision</category>
      <category>experiment</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Efficient Real-Time Aircraft ETA Prediction via Feature Tokenization Transformer</title>
      <link>https://arxiv.org/abs/2508.09144</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09144</guid>
      <description>arXiv:2508.09144v1 Announce Type: new 
Abstract: Estimated time of arrival (ETA) for airborne aircraft in real-time is crucial for arrival management in aviation, particularly for runway sequencing. Given the rapidly changing airspace context, the ETA prediction efficiency is as important as its acc...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, study, experiment, arxiv, attention | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>study</category>
      <category>experiment</category>
    </item>
    <item>
      <title>MoLAN: A Unified Modality-Aware Noise Dynamic Editing Framework for Multimodal Sentiment Analysis</title>
      <link>https://arxiv.org/abs/2508.09145</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09145</guid>
      <description>arXiv:2508.09145v1 Announce Type: new 
Abstract: Multimodal Sentiment Analysis aims to integrate information from various modalities, such as audio, visual, and text, to make complementary predictions. However, it often struggles with irrelevant or misleading visual and auditory information. Most ex...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, RAG, experiment, audio, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Multimodal Context</category>
      <category>analysis</category>
      <category>RAG</category>
      <category>experiment</category>
    </item>
    <item>
      <title>To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA</title>
      <link>https://arxiv.org/abs/2508.09146</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09146</guid>
      <description>arXiv:2508.09146v1 Announce Type: new 
Abstract: The binary exponential backoff scheme is widely used in WiFi 7 and still incurs poor throughput performance under dynamic channel environments. Recent model-based approaches (e.g., non-persistent and $p$-persistent CSMA) simply optimize backoff strate...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, in-context, experiment, arxiv, transformer | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>In Context Learning</category>
      <category>context</category>
      <category>in-context</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Motif 2.6B Technical Report</title>
      <link>https://arxiv.org/abs/2508.09148</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09148</guid>
      <description>arXiv:2508.09148v1 Announce Type: new 
Abstract: Recent advancements in Large Language Models (LLMs) have revolutionized artificial intelligence, yet developing an effective foundational LLM that balances high performance with computational efficiency remains challenging, especially for emerging res...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, in-context, experiment, arxiv, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>in-context</category>
      <category>experiment</category>
    </item>
    <item>
      <title>JustDense: Just using Dense instead of Sequence Mixer for Time Series analysis</title>
      <link>https://arxiv.org/abs/2508.09153</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09153</guid>
      <description>arXiv:2508.09153v1 Announce Type: new 
Abstract: Sequence and channel mixers, the core mechanism in sequence models, have become the de facto standard in time series analysis (TSA). However, recent studies have questioned the necessity of complex sequence mixers, such as attention mechanisms, demons...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, analysis, experiment, arxiv, research | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>analysis</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Context-Engineering - &amp;quot;Context engineering is the delicate art and science of filling the context window with just the right information for the next step.&amp;quot; — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.</title>
      <link>https://github.com/davidkimai/Context-Engineering</link>
      <guid isPermaLink="false">https://github.com/davidkimai/Context-Engineering</guid>
      <description>&amp;quot;Context engineering is the delicate art and science of filling the context window with just the right information for the next step.&amp;quot; — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, prompt, context window, prompt engineering | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 29 Jun 2025 00:16:36 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>context</category>
      <category>prompt</category>
      <category>context window</category>
    </item>
    <item>
      <title>ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.</title>
      <link>https://github.com/FunAudioLLM/ThinkSound</link>
      <guid isPermaLink="false">https://github.com/FunAudioLLM/ThinkSound</guid>
      <description>PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; audio, chain-of-thought, reasoning, framework, CoT | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 27 Jun 2025 02:27:00 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>audio</category>
      <category>chain-of-thought</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code</title>
      <link>https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-</link>
      <guid isPermaLink="false">https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-</guid>
      <description>A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, framework, chain-of-thought | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 18 Feb 2025 15:45:30 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>context</category>
      <category>framework</category>
      <category>chain-of-thought</category>
    </item>
    <item>
      <title>MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs</title>
      <link>https://github.com/MoonshotAI/MoBA</link>
      <guid isPermaLink="false">https://github.com/MoonshotAI/MoBA</guid>
      <description>MoBA: Mixture of Block Attention for Long-Context LLMs&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, attention, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 17 Feb 2025 13:27:30 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Context Management</category>
      <category>context</category>
      <category>attention</category>
      <category>LLM</category>
    </item>
    <item>
      <title>LightRAG - &amp;quot;LightRAG: Simple and Fast Retrieval-Augmented Generation&amp;quot;</title>
      <link>https://github.com/HKUDS/LightRAG</link>
      <guid isPermaLink="false">https://github.com/HKUDS/LightRAG</guid>
      <description>&amp;quot;LightRAG: Simple and Fast Retrieval-Augmented Generation&amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; retrieval, RAG, augmented | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 02 Oct 2024 11:57:54 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>retrieval</category>
      <category>RAG</category>
      <category>augmented</category>
    </item>
    <item>
      <title>KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&amp;amp;A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.</title>
      <link>https://github.com/OpenSPG/KAG</link>
      <guid isPermaLink="false">https://github.com/OpenSPG/KAG</guid>
      <description>KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&amp;amp;A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, vector, reasoning, knowledge base, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sat, 21 Sep 2024 13:56:44 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>RAG</category>
      <category>vector</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.</title>
      <link>https://github.com/Kiln-AI/Kiln</link>
      <guid isPermaLink="false">https://github.com/Kiln-AI/Kiln</guid>
      <description>The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, tool, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 23 Jul 2024 23:10:13 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>fine-tuning</category>
      <category>tool</category>
      <category>LLM</category>
    </item>
    <item>
      <title>graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system</title>
      <link>https://github.com/microsoft/graphrag</link>
      <guid isPermaLink="false">https://github.com/microsoft/graphrag</guid>
      <description>A modular graph-based Retrieval-Augmented Generation (RAG) system&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; retrieval, RAG, augmented | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 27 Mar 2024 17:57:52 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>retrieval</category>
      <category>RAG</category>
      <category>augmented</category>
    </item>
    <item>
      <title>R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.</title>
      <link>https://github.com/SciPhi-AI/R2R</link>
      <guid isPermaLink="false">https://github.com/SciPhi-AI/R2R</guid>
      <description>SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; product, RAG, API, augmented, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 12 Feb 2024 03:24:27 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>product</category>
      <category>RAG</category>
      <category>API</category>
    </item>
    <item>
      <title>openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.</title>
      <link>https://github.com/openlit/openlit</link>
      <guid isPermaLink="false">https://github.com/openlit/openlit</guid>
      <description>Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, framework, LLM, platform, prompt | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 23 Jan 2024 17:40:59 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>vector</category>
      <category>framework</category>
      <category>LLM</category>
    </item>
    <item>
      <title>AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation &amp;amp; Optimization with AutoML-Style Automation</title>
      <link>https://github.com/Marker-Inc-Korea/AutoRAG</link>
      <guid isPermaLink="false">https://github.com/Marker-Inc-Korea/AutoRAG</guid>
      <description>AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation &amp;amp; Optimization with AutoML-Style Automation&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, retrieval, RAG, augmented | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 10 Jan 2024 12:25:00 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>framework</category>
      <category>retrieval</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2508.09277</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09277</guid>
      <description>arXiv:2508.09277v1 Announce Type: new 
Abstract: Value function initialization (VFI) is an effective way to achieve a jumpstart in reinforcement learning (RL) by leveraging value estimates from prior tasks. While this approach is well established in tabular settings, extending it to deep reinforceme...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, RAG, arxiv, knowledge base, demonstration | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>experiment</category>
      <category>RAG</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards</title>
      <link>https://arxiv.org/abs/2508.09292</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09292</guid>
      <description>arXiv:2508.09292v1 Announce Type: new 
Abstract: The ability to rapidly adapt to novel and unforeseen environmental changes is a cornerstone of artificial general intelligence (AGI), yet it remains a critical blind spot in most existing AI benchmarks. Traditional evaluation largely focuses on optimi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, arxiv, research, API, tool | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>analysis</category>
      <category>arxiv</category>
      <category>research</category>
    </item>
    <item>
      <title>Peer Effect Estimation in the Presence of Simultaneous Feedback and Unobserved Confounders</title>
      <link>https://arxiv.org/abs/2508.09154</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09154</guid>
      <description>arXiv:2508.09154v1 Announce Type: new 
Abstract: Estimating peer causal effects within complex real-world networks such as social networks is challenging, primarily due to simultaneous feedback between peers and unobserved confounders. Existing methods either address unobserved confounders while ign...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, arxiv, paper, augmented, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>RAG</category>
      <category>arxiv</category>
      <category>paper</category>
    </item>
    <item>
      <title>Presenting DiaData for Research on Type 1 Diabetes</title>
      <link>https://arxiv.org/abs/2508.09160</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09160</guid>
      <description>arXiv:2508.09160v1 Announce Type: new 
Abstract: Type 1 diabetes (T1D) is an autoimmune disorder that leads to the destruction of insulin-producing cells, resulting in insulin deficiency, as to why the affected individuals depend on external insulin injections. However, insulin can decrease blood gl...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, analysis, arxiv, research, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>analysis</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!</title>
      <link>https://github.com/tadata-org/fastapi_mcp</link>
      <guid isPermaLink="false">https://github.com/tadata-org/fastapi_mcp</guid>
      <description>Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, tool, API, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sat, 08 Mar 2025 11:15:43 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>context</category>
      <category>tool</category>
      <category>API</category>
    </item>
    <item>
      <title>cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.</title>
      <link>https://github.com/nvidia-cosmos/cosmos-reason1</link>
      <guid isPermaLink="false">https://github.com/nvidia-cosmos/cosmos-reason1</guid>
      <description>Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; reasoning, model, chain-of-thought | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 02 Mar 2025 15:23:55 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>reasoning</category>
      <category>model</category>
      <category>chain-of-thought</category>
    </item>
    <item>
      <title>A Rolling Stone Gathers No Moss: Adaptive Policy Optimization for Stable Self-Evaluation in Large Multimodal Models</title>
      <link>https://arxiv.org/abs/2508.09155</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09155</guid>
      <description>arXiv:2508.09155v1 Announce Type: new 
Abstract: Self-evaluation, a model&amp;#x27;s ability to assess the correctness of its own output, is crucial for Large Multimodal Models (LMMs) to achieve self-improvement in multi-turn conversations, yet largely absent in foundation models. Recent work has employed re...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, arxiv, reasoning, multimodal, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>arxiv</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>Physics-Constrained Fine-Tuning of Flow-Matching Models for Generation and Inverse Problems</title>
      <link>https://arxiv.org/abs/2508.09156</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09156</guid>
      <description>arXiv:2508.09156v1 Announce Type: new 
Abstract: We present a framework for fine-tuning flow-matching generative models to enforce physical constraints and solve inverse problems in scientific systems. Starting from a model trained on low-fidelity or observational data, we apply a differentiable pos...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, augmented, fine-tuning, framework, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>arxiv</category>
      <category>augmented</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>excel-mcp-server - A Model Context Protocol server for Excel file manipulation</title>
      <link>https://github.com/haris-musa/excel-mcp-server</link>
      <guid isPermaLink="false">https://github.com/haris-musa/excel-mcp-server</guid>
      <description>A Model Context Protocol server for Excel file manipulation&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 12 Feb 2025 06:39:48 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Industry News</category>
      <category>context</category>
      <category>model</category>
    </item>
    <item>
      <title>mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns</title>
      <link>https://github.com/lastmile-ai/mcp-agent</link>
      <guid isPermaLink="false">https://github.com/lastmile-ai/mcp-agent</guid>
      <description>Build effective agents using Model Context Protocol and simple workflow patterns&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 18 Dec 2024 01:55:10 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Industry News</category>
      <category>context</category>
      <category>model</category>
    </item>
    <item>
      <title>AlphaCodium - Official implementation for the paper: &amp;quot;Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering&amp;quot;&amp;quot;</title>
      <link>https://github.com/Codium-ai/AlphaCodium</link>
      <guid isPermaLink="false">https://github.com/Codium-ai/AlphaCodium</guid>
      <description>Official implementation for the paper: &amp;quot;Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering&amp;quot;&amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, paper, prompt engineering | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 14 Jan 2024 15:17:18 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>prompt</category>
      <category>paper</category>
      <category>prompt engineering</category>
    </item>
    <item>
      <title>UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles</title>
      <link>https://arxiv.org/abs/2508.09639</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09639</guid>
      <description>arXiv:2508.09639v1 Announce Type: new 
Abstract: Explainable Artificial Intelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP), have become essential tools for interpreting complex ensemble tree-based models, especially in high-stakes domains such as healthcare analytics. Howeve...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; tool, experiment, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>tool</category>
      <category>experiment</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete</title>
      <link>https://arxiv.org/abs/2508.09784</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09784</guid>
      <description>arXiv:2508.09784v1 Announce Type: new 
Abstract: Logics for reasoning about knowledge and actions have seen many applications in various domains of multi-agent systems, including epistemic planning. Change of knowledge based on observations about the surroundings forms a key aspect in such planning ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; announcement, arxiv, reasoning, knowledge base, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Industry News</category>
      <category>announcement</category>
      <category>arxiv</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving</title>
      <link>https://arxiv.org/abs/2508.09158</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.09158</guid>
      <description>arXiv:2508.09158v1 Announce Type: new 
Abstract: Autonomous driving faces significant challenges in achieving human-like iterative decision-making, which continuously generates, evaluates, and refines trajectory proposals. Current generation-evaluation frameworks isolate trajectory generation from q...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, arxiv, API, framework, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 14 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>experiment</category>
      <category>arxiv</category>
      <category>API</category>
    </item>
    <item>
      <title>TextQuests: How Good are LLMs at Text-Based Video Games?</title>
      <link>https://huggingface.co/blog/textquests</link>
      <guid isPermaLink="false">https://huggingface.co/blog/textquests</guid>
      <description>...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; Hugging Face Blog | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 12 Aug 2025 00:00:00 </pubDate>
      <author>noreply@contextengineering.news (Hugging Face Blog)</author>
      <category>Prompt Engineering</category>
      <category>LLM</category>
    </item>
    <item>
      <title>🇵🇭 FilBench - Can LLMs Understand and Generate Filipino?</title>
      <link>https://huggingface.co/blog/filbench</link>
      <guid isPermaLink="false">https://huggingface.co/blog/filbench</guid>
      <description>...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; Hugging Face Blog | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 12 Aug 2025 00:00:00 </pubDate>
      <author>noreply@contextengineering.news (Hugging Face Blog)</author>
      <category>Prompt Engineering</category>
      <category>LLM</category>
    </item>
    <item>
      <title>optillm - Optimizing inference proxy for LLMs</title>
      <link>https://github.com/codelion/optillm</link>
      <guid isPermaLink="false">https://github.com/codelion/optillm</guid>
      <description>Optimizing inference proxy for LLMs&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 22 Aug 2024 19:46:07 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>LLM</category>
    </item>
  </channel>
</rss>