{
  "generated_at": "2025-09-04T20:05:46.186970",
  "total_items": 47,
  "items": [
    {
      "title": "DrDiff: Dynamic Routing Diffusion with Hierarchical Attention for Breaking the Efficiency-Quality Trade-off",
      "url": "https://arxiv.org/abs/2509.02785",
      "description": "arXiv:2509.02785v1 Announce Type: new \nAbstract: This paper introduces DrDiff, a novel framework for long-text generation that overcomes the efficiency-quality trade-off through three core technologies. First, we design a dynamic expert scheduling mechanism that intelligently allocates computational...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "experiment",
        "attention",
        "framework",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "SSVD: Structured SVD for Parameter-Efficient Fine-Tuning and Benchmarking under Domain Shift in ASR",
      "url": "https://arxiv.org/abs/2509.02830",
      "description": "arXiv:2509.02830v1 Announce Type: new \nAbstract: Parameter-efficient fine-tuning (PEFT) has emerged as a scalable solution for adapting large foundation models. While low-rank adaptation (LoRA) is widely used in speech applications, its state-of-the-art variants, e.g., VeRA, DoRA, PiSSA, and SVFT, a...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "model",
        "release",
        "vision",
        "fine-tuning",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Clustering Discourses: Racial Biases in Short Stories about Women Generated by Large Language Models",
      "url": "https://arxiv.org/abs/2509.02834",
      "description": "arXiv:2509.02834v1 Announce Type: new \nAbstract: This study investigates how large language models, in particular LLaMA 3.2-3B, construct narratives about Black and white women in short stories generated in Portuguese. From 2100 texts, we applied computational methods to group semantically similar s...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "model",
        "analysis",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "IDEAlign: Comparing Large Language Models to Human Experts in Open-ended Interpretive Annotations",
      "url": "https://arxiv.org/abs/2509.02855",
      "description": "arXiv:2509.02855v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly applied to open-ended, interpretive annotation tasks, such as thematic analysis by researchers or generating feedback on student work by teachers. These tasks involve free-text annotations requiring expert...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "prompt",
        "instruction",
        "model",
        "analysis",
        "prompting",
        "large language model",
        "LLM",
        "research",
        "vector",
        "alignment",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Advancing Minority Stress Detection with Transformers: Insights from the Social Media Datasets",
      "url": "https://arxiv.org/abs/2509.02908",
      "description": "arXiv:2509.02908v1 Announce Type: new \nAbstract: Individuals from sexual and gender minority groups experience disproportionately high rates of poor health outcomes and mental disorders compared to their heterosexual and cisgender counterparts, largely as a consequence of minority stress as describe...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "few-shot",
        "ICL",
        "study",
        "arxiv",
        "model",
        "analysis",
        "augmented",
        "zero-shot",
        "experiment",
        "few-shot learning",
        "transformer",
        "context",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "English Pronunciation Evaluation without Complex Joint Training: LoRA Fine-tuned Speech Multimodal LLM",
      "url": "https://arxiv.org/abs/2509.02915",
      "description": "arXiv:2509.02915v1 Announce Type: new \nAbstract: This study demonstrates that a Multimodal Large Language Model (MLLM) adapted via Low-Rank Adaptation (LoRA) can perform both Automatic Pronunciation Assessment (APA) and Mispronunciation Detection and Diagnosis (MDD) simultaneously. Leveraging Micros...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "model",
        "research",
        "large language model",
        "audio",
        "multimodal",
        "LLM",
        "fine-tuning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "ProMQA-Assembly: Multimodal Procedural QA Dataset on Assembly",
      "url": "https://arxiv.org/abs/2509.02949",
      "description": "arXiv:2509.02949v1 Announce Type: new \nAbstract: Assistants on assembly tasks have a large potential to benefit humans from everyday tasks to industrial settings. However, no testbeds support application-oriented system evaluation in a practical setting, especially in assembly. To foster the develop...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "ICL",
        "arxiv",
        "instruction",
        "model",
        "experiment",
        "multimodal",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "DiaCBT: A Long-Periodic Dialogue Corpus Guided by Cognitive Conceptualization Diagram for CBT-based Psychological Counseling",
      "url": "https://arxiv.org/abs/2509.02999",
      "description": "arXiv:2509.02999v1 Announce Type: new \nAbstract: Psychotherapy reaches only a small fraction of individuals suffering from mental disorders due to social stigma and the limited availability of therapists. Large language models (LLMs), when equipped with professional psychotherapeutic skills, offer a...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "model",
        "large language model",
        "framework",
        "LLM",
        "paper",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "The Future of Artificial Intelligence and the Mathematical and Physical Sciences (AI+MPS)",
      "url": "https://arxiv.org/abs/2509.02661",
      "description": "arXiv:2509.02661v1 Announce Type: new \nAbstract: This community paper developed out of the NSF Workshop on the Future of Artificial Intelligence (AI) and the Mathematical and Physics Sciences (MPS), which was held in March 2025 with the goal of understanding how the MPS domains (Astronomy, Chemistry...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "RAG",
        "paper",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics",
      "url": "https://arxiv.org/abs/2509.02751",
      "description": "arXiv:2509.02751v1 Announce Type: new \nAbstract: With advances in large language models (LLMs), researchers are creating new systems that can perform AI-driven analytics over large unstructured datasets. Recent work has explored executing such analytics queries using semantic operators -- a declarat...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "large language model",
        "tool",
        "vision",
        "LLM",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Do LLM Modules Generalize? A Study on Motion Generation for Autonomous Driving",
      "url": "https://arxiv.org/abs/2509.02754",
      "description": "arXiv:2509.02754v1 Announce Type: new \nAbstract: Recent breakthroughs in large language models (LLMs) have not only advanced natural language processing but also inspired their application in domains with structurally similar problems--most notably, autonomous driving motion generation. Both domains...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "study",
        "arxiv",
        "model",
        "experiment",
        "large language model",
        "context",
        "LLM",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Plan Verification for LLM-Based Embodied Task Completion Agents",
      "url": "https://arxiv.org/abs/2509.02761",
      "description": "arXiv:2509.02761v1 Announce Type: new \nAbstract: Large language model (LLM) based task plans and corresponding human demonstrations for embodied AI may be noisy, with unnecessary actions, redundant navigation, and logical errors that reduce policy quality. We propose an iterative verification framew...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "prompt",
        "model",
        "prompting",
        "large language model",
        "framework",
        "demonstration",
        "vision",
        "LLM",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Latent Variable Modeling in Multi-Agent Reinforcement Learning via Expectation-Maximization for UAV-Based Wildlife Protection",
      "url": "https://arxiv.org/abs/2509.02579",
      "description": "arXiv:2509.02579v1 Announce Type: new \nAbstract: Protecting endangered wildlife from illegal poaching presents a critical challenge, particularly in vast and partially observable environments where real-time response is essential. This paper introduces a novel Expectation-Maximization (EM) based lat...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "ICL",
        "arxiv",
        "model",
        "experiment",
        "framework",
        "context",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Preference Robustness for DPO with Applications to Public Health",
      "url": "https://arxiv.org/abs/2509.02709",
      "description": "arXiv:2509.02709v1 Announce Type: new \nAbstract: We study an LLM fine-tuning task for designing reward functions for sequential resource allocation problems in public health, guided by human preferences expressed in natural language. This setting presents a challenging testbed for alignment due to c...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "arxiv",
        "experiment",
        "LLM",
        "fine-tuning",
        "alignment"
      ],
      "score": 1.0
    },
    {
      "title": "LExI: Layer-Adaptive Active Experts for Efficient MoE Model Inference",
      "url": "https://arxiv.org/abs/2509.02753",
      "description": "arXiv:2509.02753v1 Announce Type: new \nAbstract: Mixture-of-Experts (MoE) models scale efficiently by activating only a subset of experts per token, offering a computationally sparse alternative to dense architectures. While prior post-training optimizations, such as inter- and intra-expert pruning,...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "memory",
        "arxiv",
        "model",
        "experiment",
        "example",
        "framework",
        "vision",
        "LLM",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "The Transparent Earth: A Multimodal Foundation Model for the Earth's Subsurface",
      "url": "https://arxiv.org/abs/2509.02783",
      "description": "arXiv:2509.02783v1 Announce Type: new \nAbstract: We present the Transparent Earth, a transformer-based architecture for reconstructing subsurface properties from heterogeneous datasets that vary in sparsity, resolution, and modality, where each modality represents a distinct type of observation (e.g...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "in-context",
        "arxiv",
        "model",
        "multimodal",
        "transformer",
        "context",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Learning Laplacian Eigenvectors: a Pre-training Method for Graph Neural Networks",
      "url": "https://arxiv.org/abs/2509.02803",
      "description": "arXiv:2509.02803v1 Announce Type: new \nAbstract: We propose a novel framework for pre-training Graph Neural Networks (GNNs) by inductively learning Laplacian eigenvectors. Traditional Message Passing Neural Networks (MPNNs) often struggle to capture global and regional graph structure due to over-sm...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "model",
        "framework",
        "vector",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "prompt engineering",
        "prompt",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "chain-of-thought",
        "framework",
        "audio",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "model",
        "tool",
        "context",
        "LLM",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "model",
        "knowledge base",
        "framework",
        "LLM",
        "vector",
        "RAG",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "tool",
        "fine-tuning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "product",
        "augmented",
        "RAG",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "framework",
        "platform",
        "LLM",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "framework",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation",
      "url": "https://arxiv.org/abs/2509.02864",
      "description": "arXiv:2509.02864v1 Announce Type: new \nAbstract: We present an end-to-end, self-evolving adversarial workflow for long-context Question-Answer (QA) Generation in Arabic. By orchestrating multiple specialized LVLMs: a question generator, an evaluator, and a swarm of answer generators, our system iter...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "arxiv",
        "model",
        "release",
        "vision",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "Can Media Act as a Soft Regulator of Safe AI Development? A Game Theoretical Analysis",
      "url": "https://arxiv.org/abs/2509.02650",
      "description": "arXiv:2509.02650v1 Announce Type: new \nAbstract: When developers of artificial intelligence (AI) products need to decide between profit and safety for the users, they likely choose profit. Untrustworthy AI technology must come packaged with tangible negative consequences. Here, we envisage those con...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "product",
        "RAG",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "tool",
        "model",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Planning with Reasoning using Vision Language World Model",
      "url": "https://arxiv.org/abs/2509.02722",
      "description": "arXiv:2509.02722v1 Announce Type: new \nAbstract: Effective planning requires strong world models, but high-level world models that can understand and reason about actions with semantic and temporal abstraction remain largely underdeveloped. We introduce the Vision Language World Model (VLWM), a foun...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "model",
        "vision",
        "LLM",
        "reasoning"
      ],
      "score": 0.6
    },
    {
      "title": "Accountability Framework for Healthcare AI Systems: Towards Joint Accountability in Decision Making",
      "url": "https://arxiv.org/abs/2509.03286",
      "description": "arXiv:2509.03286v1 Announce Type: new \nAbstract: AI is transforming the healthcare domain and is increasingly helping practitioners to make health-related decisions. Therefore, accountability becomes a crucial concern for critical AI-driven decisions. Although regulatory bodies, such as the EU commi...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "analysis",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "The Lifecycle Principle: Stabilizing Dynamic Neural Networks with State Memory",
      "url": "https://arxiv.org/abs/2509.02575",
      "description": "arXiv:2509.02575v1 Announce Type: new \nAbstract: I investigate a stronger form of regularization by deactivating neurons for extended periods, a departure from the temporary changes of methods like Dropout. However, this long-term dynamism introduces a critical challenge: severe training instability...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "memory",
        "arxiv",
        "image",
        "analysis",
        "experiment"
      ],
      "score": 0.6
    },
    {
      "title": "Structured Basis Function Networks: Loss-Centric Multi-Hypothesis Ensembles with Controllable Diversity",
      "url": "https://arxiv.org/abs/2509.02792",
      "description": "arXiv:2509.02792v1 Announce Type: new \nAbstract: Existing approaches to predictive uncertainty rely either on multi-hypothesis prediction, which promotes diversity but lacks principled aggregation, or on ensemble learning, which improves accuracy but rarely captures the structured ambiguity. This im...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "study",
        "experiment"
      ],
      "score": 0.6
    },
    {
      "title": "Welcome EmbeddingGemma, Google's new efficient embedding model",
      "url": "https://huggingface.co/blog/embeddinggemma",
      "description": "...",
      "published_date": "2025-09-04T00:00:00",
      "source": "Hugging Face Blog",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "embedding"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Decoding the Rule Book: Extracting Hidden Moderation Criteria from Reddit Communities",
      "url": "https://arxiv.org/abs/2509.02926",
      "description": "arXiv:2509.02926v1 Announce Type: new \nAbstract: Effective content moderation systems require explicit classification criteria, yet online communities like subreddits often operate with diverse, implicit standards. This work introduces a novel approach to identify and extract these implicit criteria...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Key Principles in Cross-Domain Hyper-Heuristic Performance",
      "url": "https://arxiv.org/abs/2509.02782",
      "description": "arXiv:2509.02782v1 Announce Type: new \nAbstract: Cross-domain selection hyper-heuristics aim to distill decades of research on problem-specific heuristic search algorithms into adaptable general-purpose search strategies. In this respect, existing selection hyper-heuristics primarily focus on an ada...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "company",
        "research",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Uncertainty-driven Adaptive Exploration",
      "url": "https://arxiv.org/abs/2509.03219",
      "description": "arXiv:2509.03219v1 Announce Type: new \nAbstract: Adaptive exploration methods propose ways to learn complex policies via alternating between exploration and exploitation. An important question for such methods is to determine the appropriate moment to switch between exploration and exploitation and ...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Beyond Synthetic Augmentation: Group-Aware Threshold Calibration for Robust Balanced Accuracy in Imbalanced Learning",
      "url": "https://arxiv.org/abs/2509.02592",
      "description": "arXiv:2509.02592v1 Announce Type: new \nAbstract: Class imbalance remains a fundamental challenge in machine learning, with traditional solutions often creating as many problems as they solve. We demonstrate that group-aware threshold calibration--setting different decision thresholds for different d...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "augmented",
        "model",
        "arxiv",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Imitate Optimal Policy: Prevail and Induce Action Collapse in Policy Gradient",
      "url": "https://arxiv.org/abs/2509.02737",
      "description": "arXiv:2509.02737v1 Announce Type: new \nAbstract: Policy gradient (PG) methods in reinforcement learning frequently utilize deep neural networks (DNNs) to learn a shared backbone of feature representations used to compute likelihoods in an action selection layer. Numerous studies have been conducted ...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Mentality: A Mamba-based Approach towards Foundation Models for EEG",
      "url": "https://arxiv.org/abs/2509.02746",
      "description": "arXiv:2509.02746v1 Announce Type: new \nAbstract: This work explores the potential of foundation models, specifically a Mamba-based selective state space model, for enhancing EEG analysis in neurological disorder diagnosis. EEG, crucial for diagnosing conditions like epilepsy, presents significant ch...",
      "published_date": "2025-09-04T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "analysis"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}