<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Context Engineering Daily</title>
    <link>https://your-username.github.io/context-engineering-news</link>
    <description>Daily news and research updates in AI Context Engineering, Prompt Engineering, RAG, and LLM development</description>
    <language>en-us</language>
    <copyright>Copyright 2025 Context Engineering Daily</copyright>
    <generator>Context Engineering News Generator</generator>
    <lastBuildDate>Fri, 05 Dec 2025 20:05:49 +0000</lastBuildDate>
    <atom:link href="https://your-username.github.io/context-engineering-news/rss.xml" rel="self" type="application/rss+xml"/>
    <category>Technology</category>
    <category>Artificial Intelligence</category>
    <category>Machine Learning</category>
    <item>
      <title>On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral</title>
      <link>https://arxiv.org/abs/2512.04220</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04220</guid>
      <description>arXiv:2512.04220v1 Announce Type: new 
Abstract: Tool-integrated (TI) reinforcement learning (RL) enables large language models (LLMs) to perform multi-step reasoning by interacting with external tools such as search engines and retrievers. Group Relative Policy Optimization (GRPO), exemplified by t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, model, reasoning, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Chain Of Thought</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>Computational Linguistics Meets Libyan Dialect: A Study on Dialect Identification</title>
      <link>https://arxiv.org/abs/2512.04257</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04257</guid>
      <description>arXiv:2512.04257v1 Announce Type: new 
Abstract: This study investigates logistic regression, linear support vector machine, multinomial Naive Bayes, and Bernoulli Naive Bayes for classifying Libyan dialect utterances gathered from Twitter. The dataset used is the QADI corpus, which consists of 540,...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, study, arxiv, analysis, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>study</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>SQuARE: Structured Query &amp;amp; Adaptive Retrieval Engine For Tabular Formats</title>
      <link>https://arxiv.org/abs/2512.04292</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04292</guid>
      <description>arXiv:2512.04292v1 Announce Type: new 
Abstract: Accurate question answering over real spreadsheets remains difficult due to multirow headers, merged cells, and unit annotations that disrupt naive chunking, while rigid SQL views fail on files lacking consistent schemas. We present SQuARE, a hybrid r...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, arxiv, model, retrieval, GPT | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>framework</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle</title>
      <link>https://arxiv.org/abs/2512.04324</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04324</guid>
      <description>arXiv:2512.04324v1 Announce Type: new 
Abstract: Real-world enterprise data intelligence workflows encompass data engineering that turns raw sources into analytical-ready tables and data analysis that convert those tables into decision-oriented insights. We introduce DAComp, a benchmark of 210 tasks...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, arxiv, LLM, analysis, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>arxiv</category>
      <category>LLM</category>
    </item>
    <item>
      <title>ClusterFusion: Hybrid Clustering with Embedding Guidance and LLM Adaptation</title>
      <link>https://arxiv.org/abs/2512.04350</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04350</guid>
      <description>arXiv:2512.04350v1 Announce Type: new 
Abstract: Text clustering is a fundamental task in natural language processing, yet traditional clustering algorithms with pre-trained embeddings often struggle in domain-specific contexts without costly fine-tuning. Large language models (LLMs) provide strong ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, framework, release, LLM, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>RAG</category>
      <category>framework</category>
      <category>release</category>
    </item>
    <item>
      <title>MASE: Interpretable NLP Models via Model-Agnostic Saliency Estimation</title>
      <link>https://arxiv.org/abs/2512.04386</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04386</guid>
      <description>arXiv:2512.04386v1 Announce Type: new 
Abstract: Deep neural networks (DNNs) have made significant strides in Natural Language Processing (NLP), yet their interpretability remains elusive, particularly when evaluating their intricate decision-making processes. Traditional methods often rely on post-...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, framework, arxiv, model, embedding | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Rag Retrieval</category>
      <category>RAG</category>
      <category>framework</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>RapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning</title>
      <link>https://arxiv.org/abs/2512.04457</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04457</guid>
      <description>arXiv:2512.04457v1 Announce Type: new 
Abstract: Removing specific data influence from large language models (LLMs) remains challenging, as retraining is costly and existing approximate unlearning methods are often unstable. The challenge is exacerbated when the forget set is small or imbalanced. We...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, API, arxiv, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>framework</category>
      <category>API</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>MSME: A Multi-Stage Multi-Expert Framework for Zero-Shot Stance Detection</title>
      <link>https://arxiv.org/abs/2512.04492</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04492</guid>
      <description>arXiv:2512.04492v1 Announce Type: new 
Abstract: LLM-based approaches have recently achieved impressive results in zero-shot stance detection. However, they still struggle in complex real-world scenarios, where stance understanding requires dynamic background knowledge, target definitions involve co...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, zero-shot, framework, LLM, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>zero-shot</category>
      <category>framework</category>
    </item>
    <item>
      <title>Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation</title>
      <link>https://arxiv.org/abs/2512.03048</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.03048</guid>
      <description>arXiv:2512.03048v1 Announce Type: new 
Abstract: I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contr...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, paper, framework, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>paper</category>
      <category>framework</category>
    </item>
    <item>
      <title>When Do Symbolic Solvers Enhance Reasoning in Large Language Models?</title>
      <link>https://arxiv.org/abs/2512.03272</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.03272</guid>
      <description>arXiv:2512.03272v1 Announce Type: new 
Abstract: Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models &amp;quot;overthink&amp;quot; by producing lengthy rea...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; CoT, RAG, paper, LLM, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>CoT</category>
      <category>RAG</category>
      <category>paper</category>
    </item>
    <item>
      <title>Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia</title>
      <link>https://arxiv.org/abs/2512.03318</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.03318</guid>
      <description>arXiv:2512.03318v1 Announce Type: new 
Abstract: Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, zero-shot, LLM, arxiv, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>zero-shot</category>
      <category>LLM</category>
    </item>
    <item>
      <title>PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks</title>
      <link>https://arxiv.org/abs/2512.03549</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.03549</guid>
      <description>arXiv:2512.03549v1 Announce Type: new 
Abstract: We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own acti...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, context, analysis, experiment, instruction | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>context</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks</title>
      <link>https://arxiv.org/abs/2512.03560</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.03560</guid>
      <description>arXiv:2512.03560v1 Announce Type: new 
Abstract: Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent a...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context window, RAG, arxiv, context, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>context window</category>
      <category>RAG</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>ASCIIBench: Evaluating Language-Model-Based Understanding of Visually-Oriented Text</title>
      <link>https://arxiv.org/abs/2512.04125</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04125</guid>
      <description>arXiv:2512.04125v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated several emergent behaviors with scale, including reasoning and fluency in long-form text generation. However, they continue to struggle with tasks requiring precise spatial and positional reasoning. ASCII...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; release, LLM, embedding, image, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Multimodal Context</category>
      <category>release</category>
      <category>LLM</category>
      <category>embedding</category>
    </item>
    <item>
      <title>Fine-Tuning ChemBERTa for Predicting Inhibitory Activity Against TDP1 Using Deep Learning</title>
      <link>https://arxiv.org/abs/2512.04252</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04252</guid>
      <description>arXiv:2512.04252v1 Announce Type: new 
Abstract: Predicting the inhibitory potency of small molecules against Tyrosyl-DNA Phosphodiesterase 1 (TDP1)-a key target in overcoming cancer chemoresistance-remains a critical challenge in early drug discovery. We present a deep learning framework for the qu...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, framework, arxiv, transformer, fine-tuning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>RAG</category>
      <category>framework</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>The Initialization Determines Whether In-Context Learning Is Gradient Descent</title>
      <link>https://arxiv.org/abs/2512.04268</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04268</guid>
      <description>arXiv:2512.04268v1 Announce Type: new 
Abstract: In-context learning (ICL) in large language models (LLMs) is a striking phenomenon, yet its underlying mechanisms remain only partially understood. Previous work connects linear self-attention (LSA) to gradient descent (GD), this connection has primar...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; attention, in-context, LLM, arxiv, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>In Context Learning</category>
      <category>attention</category>
      <category>in-context</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Context-Engineering - &amp;quot;Context engineering is the delicate art and science of filling the context window with just the right information for the next step.&amp;quot; â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.</title>
      <link>https://github.com/davidkimai/Context-Engineering</link>
      <guid isPermaLink="false">https://github.com/davidkimai/Context-Engineering</guid>
      <description>&amp;quot;Context engineering is the delicate art and science of filling the context window with just the right information for the next step.&amp;quot; â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context window, prompt engineering, prompt, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 29 Jun 2025 00:16:36 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>context window</category>
      <category>prompt engineering</category>
      <category>prompt</category>
    </item>
    <item>
      <title>ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.</title>
      <link>https://github.com/FunAudioLLM/ThinkSound</link>
      <guid isPermaLink="false">https://github.com/FunAudioLLM/ThinkSound</guid>
      <description>[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; CoT, framework, audio, reasoning, chain-of-thought | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 27 Jun 2025 02:27:00 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>CoT</category>
      <category>framework</category>
      <category>audio</category>
    </item>
    <item>
      <title>mcp-context-forge - A Model Context Protocol (MCP) Gateway &amp;amp; Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).</title>
      <link>https://github.com/IBM/mcp-context-forge</link>
      <guid isPermaLink="false">https://github.com/IBM/mcp-context-forge</guid>
      <description>A Model Context Protocol (MCP) Gateway &amp;amp; Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM, prompt, context, model, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 08 May 2025 08:16:59 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>LLM</category>
      <category>prompt</category>
      <category>context</category>
    </item>
    <item>
      <title>Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code</title>
      <link>https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-</link>
      <guid isPermaLink="false">https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-</guid>
      <description>A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; chain-of-thought, framework, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 18 Feb 2025 15:45:30 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>chain-of-thought</category>
      <category>framework</category>
      <category>context</category>
    </item>
    <item>
      <title>airweave - Context retrieval for AI agents across apps and databases</title>
      <link>https://github.com/airweave-ai/airweave</link>
      <guid isPermaLink="false">https://github.com/airweave-ai/airweave</guid>
      <description>Context retrieval for AI agents across apps and databases&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; retrieval, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 24 Dec 2024 10:00:06 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>retrieval</category>
      <category>context</category>
    </item>
    <item>
      <title>LightRAG - [EMNLP2025] &amp;quot;LightRAG: Simple and Fast Retrieval-Augmented Generation&amp;quot;</title>
      <link>https://github.com/HKUDS/LightRAG</link>
      <guid isPermaLink="false">https://github.com/HKUDS/LightRAG</guid>
      <description>[EMNLP2025] &amp;quot;LightRAG: Simple and Fast Retrieval-Augmented Generation&amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; retrieval, augmented, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 02 Oct 2024 11:57:54 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>retrieval</category>
      <category>augmented</category>
      <category>RAG</category>
    </item>
    <item>
      <title>KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&amp;amp;A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.</title>
      <link>https://github.com/OpenSPG/KAG</link>
      <guid isPermaLink="false">https://github.com/OpenSPG/KAG</guid>
      <description>KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&amp;amp;A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; knowledge base, RAG, framework, LLM, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sat, 21 Sep 2024 13:56:44 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>knowledge base</category>
      <category>RAG</category>
      <category>framework</category>
    </item>
    <item>
      <title>Kiln - Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.</title>
      <link>https://github.com/Kiln-AI/Kiln</link>
      <guid isPermaLink="false">https://github.com/Kiln-AI/Kiln</guid>
      <description>Easily build AI systems with Evals, RAG, Agents, fine-tuning, synthetic data, and more.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 23 Jul 2024 23:10:13 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>fine-tuning</category>
      <category>RAG</category>
    </item>
    <item>
      <title>graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system</title>
      <link>https://github.com/microsoft/graphrag</link>
      <guid isPermaLink="false">https://github.com/microsoft/graphrag</guid>
      <description>A modular graph-based Retrieval-Augmented Generation (RAG) system&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; retrieval, augmented, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 27 Mar 2024 17:57:52 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>retrieval</category>
      <category>augmented</category>
      <category>RAG</category>
    </item>
    <item>
      <title>R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.</title>
      <link>https://github.com/SciPhi-AI/R2R</link>
      <guid isPermaLink="false">https://github.com/SciPhi-AI/R2R</guid>
      <description>SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, product, augmented, retrieval, API | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 12 Feb 2024 03:24:27 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Rag Retrieval</category>
      <category>RAG</category>
      <category>product</category>
      <category>augmented</category>
    </item>
    <item>
      <title>openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.</title>
      <link>https://github.com/openlit/openlit</link>
      <guid isPermaLink="false">https://github.com/openlit/openlit</guid>
      <description>Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; platform, framework, LLM, prompt, vector | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 23 Jan 2024 17:40:59 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>platform</category>
      <category>framework</category>
      <category>LLM</category>
    </item>
    <item>
      <title>LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving</title>
      <link>https://arxiv.org/abs/2512.04374</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04374</guid>
      <description>arXiv:2512.04374v1 Announce Type: new 
Abstract: Our work presents a novel reinforcement learning (RL) based framework to optimize heuristic selection within the conflict-driven clause learning (CDCL) process, improving the efficiency of Boolean satisfia- bility (SAT) solving. The proposed system, L...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; platform, framework, arxiv, context, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>platform</category>
      <category>framework</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Sarcasm Detection on Reddit Using Classical Machine Learning and Feature Engineering</title>
      <link>https://arxiv.org/abs/2512.04396</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04396</guid>
      <description>arXiv:2512.04396v1 Announce Type: new 
Abstract: Sarcasm is common in online discussions, yet difficult for machines to identify because the intended meaning often contradicts the literal wording. In this work, I study sarcasm detection using only classical machine learning methods and explicit feat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, study, arxiv, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>study</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI</title>
      <link>https://arxiv.org/abs/2512.03072</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.03072</guid>
      <description>arXiv:2512.03072v1 Announce Type: new 
Abstract: Current AI paradigms, as &amp;quot;architects of experience,&amp;quot; face fundamental challenges in explainability and value alignment. This paper introduces &amp;quot;Weight-Calculatism,&amp;quot; a novel cognitive architecture grounded in first principles, and demonstrates its poten...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, arxiv, model, reasoning, alignment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Multimodal Reinforcement Learning with Agentic Verifier for AI Agents</title>
      <link>https://arxiv.org/abs/2512.03438</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.03438</guid>
      <description>arXiv:2512.03438v1 Announce Type: new 
Abstract: Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capable, yet they are almost universally optimized using sparse, outcome-based rewards computed based on the final answers. Richer rewards computed...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, paper, arxiv, model, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>paper</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths</title>
      <link>https://arxiv.org/abs/2512.03571</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.03571</guid>
      <description>arXiv:2512.03571v1 Announce Type: new 
Abstract: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, arxiv, LLM, model, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>arxiv</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Mitigating the Curse of Detail: Scaling Arguments for Feature Learning and Sample Complexity</title>
      <link>https://arxiv.org/abs/2512.04165</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04165</guid>
      <description>arXiv:2512.04165v1 Announce Type: new 
Abstract: Two pressing topics in the theory of deep learning are the interpretation of feature learning mechanisms and the determination of implicit bias of networks in the rich regime. Current theories of rich feature learning effects revolve around networks w...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; attention, arxiv, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>attention</category>
      <category>arxiv</category>
      <category>analysis</category>
    </item>
    <item>
      <title>BEP: A Binary Error Propagation Algorithm for Binary Neural Networks Training</title>
      <link>https://arxiv.org/abs/2512.04189</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04189</guid>
      <description>arXiv:2512.04189v1 Announce Type: new 
Abstract: Binary Neural Networks (BNNs), which constrain both weights and activations to binary values, offer substantial reductions in computational complexity, memory footprint, and energy consumption. These advantages make them particularly well suited for d...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, release, arxiv, memory, vector | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>release</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Studying Various Activation Functions and Non-IID Data for Machine Learning Model Robustness</title>
      <link>https://arxiv.org/abs/2512.04264</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04264</guid>
      <description>arXiv:2512.04264v1 Announce Type: new 
Abstract: Adversarial training is an effective method to improve the machine learning (ML) model robustness. Most existing studies typically consider the Rectified linear unit (ReLU) activation function and centralized training environments. In this paper, we s...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, study, arxiv, model, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>study</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!</title>
      <link>https://github.com/tadata-org/fastapi_mcp</link>
      <guid isPermaLink="false">https://github.com/tadata-org/fastapi_mcp</guid>
      <description>Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; API, model, tool, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sat, 08 Mar 2025 11:15:43 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Tools Frameworks</category>
      <category>API</category>
      <category>model</category>
      <category>tool</category>
    </item>
    <item>
      <title>cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.</title>
      <link>https://github.com/nvidia-cosmos/cosmos-reason1</link>
      <guid isPermaLink="false">https://github.com/nvidia-cosmos/cosmos-reason1</guid>
      <description>Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, chain-of-thought, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 02 Mar 2025 15:23:55 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Chain Of Thought</category>
      <category>model</category>
      <category>chain-of-thought</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>Prior preferences in active inference agents: soft, hard, and goal shaping</title>
      <link>https://arxiv.org/abs/2512.03293</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.03293</guid>
      <description>arXiv:2512.03293v1 Announce Type: new 
Abstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; API, attention, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Context Management</category>
      <category>API</category>
      <category>attention</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>MechDetect: Detecting Data-Dependent Errors</title>
      <link>https://arxiv.org/abs/2512.04138</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04138</guid>
      <description>arXiv:2512.04138v1 Announce Type: new 
Abstract: Data quality monitoring is a core challenge in modern information processing systems. While many approaches to detect data errors or shifts have been proposed, few studies investigate the mechanisms governing error generation. We argue that knowing ho...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, study, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>study</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Network of Theseus (like the ship)</title>
      <link>https://arxiv.org/abs/2512.04198</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04198</guid>
      <description>arXiv:2512.04198v1 Announce Type: new 
Abstract: A standard assumption in deep learning is that the inductive bias introduced by a neural network architecture must persist from training through inference. The architecture you train with is the architecture you deploy. This assumption constrains the ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, arxiv, example | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>In Context Learning</category>
      <category>GPT</category>
      <category>arxiv</category>
      <category>example</category>
    </item>
    <item>
      <title>mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns</title>
      <link>https://github.com/lastmile-ai/mcp-agent</link>
      <guid isPermaLink="false">https://github.com/lastmile-ai/mcp-agent</guid>
      <description>Build effective agents using Model Context Protocol and simple workflow patterns&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Wed, 18 Dec 2024 01:55:10 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Industry News</category>
      <category>model</category>
      <category>context</category>
    </item>
    <item>
      <title>AlphaCodium - Official implementation for the paper: &amp;quot;Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering&amp;quot;&amp;quot;</title>
      <link>https://github.com/Codium-ai/AlphaCodium</link>
      <guid isPermaLink="false">https://github.com/Codium-ai/AlphaCodium</guid>
      <description>Official implementation for the paper: &amp;quot;Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering&amp;quot;&amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, prompt engineering, prompt | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Sun, 14 Jan 2024 15:17:18 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>paper</category>
      <category>prompt engineering</category>
      <category>prompt</category>
    </item>
    <item>
      <title>Decoding Large Language Diffusion Models with Foreseeing Movement</title>
      <link>https://arxiv.org/abs/2512.04135</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04135</guid>
      <description>arXiv:2512.04135v1 Announce Type: new 
Abstract: Large Language Diffusion Models (LLDMs) benefit from a flexible decoding mechanism that enables parallelized inference and controllable generations over autoregressive models. Yet such flexibility introduces a critical challenge: inference performance...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>ActVAE: Modelling human activity schedules with a deep conditional generative approach</title>
      <link>https://arxiv.org/abs/2512.04223</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2512.04223</guid>
      <description>arXiv:2512.04223v1 Announce Type: new 
Abstract: Modelling the complexity and diversity of human activity scheduling behaviour is inherently challenging. We demonstrate a deep conditional-generative machine learning approach for the modelling of realistic activity schedules depending on input labels...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; API, framework, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 05 Dec 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Tools Frameworks</category>
      <category>API</category>
      <category>framework</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>We Got Claude to Fine-Tune an Open Source LLM</title>
      <link>https://huggingface.co/blog/hf-skills-training</link>
      <guid isPermaLink="false">https://huggingface.co/blog/hf-skills-training</guid>
      <description>...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; Hugging Face Blog | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 04 Dec 2025 00:00:00 </pubDate>
      <author>noreply@contextengineering.news (Hugging Face Blog)</author>
      <category>Prompt Engineering</category>
      <category>LLM</category>
    </item>
    <item>
      <title>optillm - Optimizing inference proxy for LLMs</title>
      <link>https://github.com/algorithmicsuperintelligence/optillm</link>
      <guid isPermaLink="false">https://github.com/algorithmicsuperintelligence/optillm</guid>
      <description>Optimizing inference proxy for LLMs&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; GitHub | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Thu, 22 Aug 2024 19:46:07 +0000</pubDate>
      <author>noreply@contextengineering.news (GitHub)</author>
      <category>Prompt Engineering</category>
      <category>LLM</category>
    </item>
  </channel>
</rss>