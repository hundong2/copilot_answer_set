{
  "generated_at": "2025-10-21T20:06:13.448982",
  "total_items": 49,
  "items": [
    {
      "title": "Quantum NLP models on Natural Language Inference",
      "url": "https://arxiv.org/abs/2510.15972",
      "description": "arXiv:2510.15972v1 Announce Type: new \nAbstract: Quantum natural language processing (QNLP) offers a novel approach to semantic modeling by embedding compositional structure directly into quantum circuits. This paper investigates the application of QNLP models to the task of Natural Language Inferen...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "paper",
        "framework",
        "transformer",
        "embedding",
        "model",
        "few-shot",
        "library"
      ],
      "score": 1.0
    },
    {
      "title": "Fusion-Augmented Large Language Models: Boosting Diagnostic Trustworthiness via Model Consensus",
      "url": "https://arxiv.org/abs/2510.16057",
      "description": "arXiv:2510.16057v1 Announce Type: new \nAbstract: This study presents a novel multi-model fusion framework leveraging two state-of-the-art large language models (LLMs), ChatGPT and Claude, to enhance the reliability of chest X-ray interpretation on the CheXpert dataset. From the full CheXpert corpus ...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "GPT",
        "prompt",
        "experiment",
        "framework",
        "LLM",
        "RAG",
        "large language model",
        "image",
        "template",
        "augmented",
        "study",
        "model",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs",
      "url": "https://arxiv.org/abs/2510.16062",
      "description": "arXiv:2510.16062v1 Announce Type: new \nAbstract: Self-correction of large language models (LLMs) emerges as a critical component for enhancing their reasoning performance. Although various self-correction methods have been proposed, a comprehensive evaluation of these methods remains largely unexplo...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "CoT",
        "LLM",
        "reasoning",
        "large language model",
        "chain-of-thought",
        "study",
        "model",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle",
      "url": "https://arxiv.org/abs/2510.16079",
      "description": "arXiv:2510.16079v1 Announce Type: new \nAbstract: Current Large Language Model (LLM) agents show strong performance in tool use, but lack the crucial capability to systematically learn from their own experiences. While existing frameworks mainly focus on mitigating external knowledge gaps, they fail ...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "framework",
        "LLM",
        "large language model",
        "tool",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Evaluating Prompting Strategies and Large Language Models in Systematic Literature Review Screening: Relevance and Task-Stage Classification",
      "url": "https://arxiv.org/abs/2510.16091",
      "description": "arXiv:2510.16091v1 Announce Type: new \nAbstract: This study quantifies how prompting strategies interact with large language models (LLMs) to automate the screening stage of systematic literature reviews (SLRs). We evaluate six LLMs (GPT-4o, GPT-4o-mini, DeepSeek-Chat-V3, Gemini-2.5-Flash, Claude-3....",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "CoT",
        "GPT",
        "analysis",
        "prompt",
        "LLM",
        "zero-shot",
        "large language model",
        "chain-of-thought",
        "prompting",
        "study",
        "model",
        "few-shot"
      ],
      "score": 1.0
    },
    {
      "title": "Facts in Stats: Impacts of Pretraining Diversity on Language Model Generalization",
      "url": "https://arxiv.org/abs/2510.16096",
      "description": "arXiv:2510.16096v1 Announce Type: new \nAbstract: Language models are pretrained on sequences that blend statistical regularities (making text fluent) with factual associations between specific tokens (knowledge of facts). While recent work suggests that the variability of their interaction, such as ...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "arxiv",
        "analysis",
        "paper",
        "framework",
        "experiment",
        "embedding",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "In Generative AI We (Dis)Trust? Computational Analysis of Trust and Distrust in Reddit Discussions",
      "url": "https://arxiv.org/abs/2510.16173",
      "description": "arXiv:2510.16173v1 Announce Type: new \nAbstract: The rise of generative AI (GenAI) has impacted many aspects of human life. As these systems become embedded in everyday practices, understanding public trust in them also becomes essential for responsible adoption and governance. Prior work on trust i...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "analysis",
        "API",
        "framework",
        "LLM",
        "paper",
        "release",
        "large language model",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "EgMM-Corpus: A Multimodal Vision-Language Dataset for Egyptian Culture",
      "url": "https://arxiv.org/abs/2510.16198",
      "description": "arXiv:2510.16198v1 Announce Type: new \nAbstract: Despite recent advances in AI, multimodal culturally diverse datasets are still limited, particularly for regions in the Middle East and Africa. In this paper, we introduce EgMM-Corpus, a multimodal dataset dedicated to Egyptian culture. By designing ...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "context",
        "vision",
        "arxiv",
        "paper",
        "zero-shot",
        "image",
        "model",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Towards Low-Resource Alignment to Diverse Perspectives with Sparse Feedback",
      "url": "https://arxiv.org/abs/2510.16257",
      "description": "arXiv:2510.16257v1 Announce Type: new \nAbstract: As language models have a greater impact on society, it is important to ensure they are aligned to a diverse range of perspectives and are able to reflect nuance in human values. However, the most popular training paradigms for modern language models ...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "arxiv",
        "zero-shot",
        "alignment",
        "model",
        "few-shot"
      ],
      "score": 1.0
    },
    {
      "title": "VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search",
      "url": "https://arxiv.org/abs/2510.15948",
      "description": "arXiv:2510.15948v1 Announce Type: new \nAbstract: Large Vision-Language Models (LVLMs) have achieved remarkable progress in multimodal perception and generation, yet their safety alignment remains a critical challenge.Existing defenses and vulnerable to multimodal jailbreaks, as visual inputs introdu...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "arxiv",
        "vision",
        "cross-modal",
        "prompt",
        "experiment",
        "framework",
        "reasoning",
        "alignment",
        "model",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding",
      "url": "https://arxiv.org/abs/2510.15952",
      "description": "arXiv:2510.15952v1 Announce Type: new \nAbstract: Large language models exhibit intelligence without genuine epistemic understanding, exposing a key gap: the absence of epistemic architecture. This paper introduces the Structured Cognitive Loop (SCL) as an executable epistemological framework for eme...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "prompt",
        "paper",
        "framework",
        "experiment",
        "large language model",
        "memory",
        "model",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency",
      "url": "https://arxiv.org/abs/2510.15966",
      "description": "arXiv:2510.15966v1 Announce Type: new \nAbstract: Memory systems are fundamental to AI agents, yet existing work often lacks adaptability to diverse tasks and overlooks the constructive and task-oriented role of AI agent memory. Drawing from Piaget's theory of cognitive development, we propose PISA, ...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "analysis",
        "RAG",
        "reasoning",
        "memory",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games",
      "url": "https://arxiv.org/abs/2510.15974",
      "description": "arXiv:2510.15974v1 Announce Type: new \nAbstract: Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in performance on solving puzzles beyond certain perplexity thresholds. In subsequent discourse, questions have arisen as to whether the nature of the task muddles an evaluation...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "analysis",
        "prompt",
        "framework",
        "LLM",
        "reasoning",
        "large language model",
        "tool",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition",
      "url": "https://arxiv.org/abs/2510.15980",
      "description": "arXiv:2510.15980v1 Announce Type: new \nAbstract: We propose \\textbf{Cognitive Load Traces} (CLTs) as a mid-level interpretability framework for deep models, inspired by Cognitive Load Theory in human cognition. CLTs are defined as symbolic, temporally varying functions that quantify model-internal r...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "attention",
        "analysis",
        "experiment",
        "framework",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization",
      "url": "https://arxiv.org/abs/2510.15981",
      "description": "arXiv:2510.15981v1 Announce Type: new \nAbstract: Proof autoformalization, the task of translating natural language theorems and proofs into machine-verifiable code, is a critical step for integrating large language models into rigorous mathematical workflows. Current approaches focus on producing ex...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "step-by-step",
        "experiment",
        "RAG",
        "large language model",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Lean Finder: Semantic Search for Mathlib That Understands User Intents",
      "url": "https://arxiv.org/abs/2510.15940",
      "description": "arXiv:2510.15940v1 Announce Type: new \nAbstract: We present Lean Finder, a semantic search engine for Lean and mathlib that understands and aligns with the intents of mathematicians. Progress in formal theorem proving is often hindered by the difficulty of locating relevant theorems and the steep le...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "arxiv",
        "GPT",
        "LLM",
        "reasoning",
        "embedding",
        "retrieval",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "BEACON: Bayesian Optimal Stopping for Efficient LLM Sampling",
      "url": "https://arxiv.org/abs/2510.15945",
      "description": "arXiv:2510.15945v1 Announce Type: new \nAbstract: Sampling multiple responses is a common way to improve LLM output quality, but it comes at the cost of additional computation. The key challenge is deciding when to stop generating new samples to balance accuracy gains against efficiency. To address t...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "framework",
        "LLM",
        "RAG",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Learning from Mistakes: Enhancing Harmful Meme Detection via Misjudgment Risk Patterns",
      "url": "https://arxiv.org/abs/2510.15946",
      "description": "arXiv:2510.15946v1 Announce Type: new \nAbstract: Internet memes have emerged as a popular multimodal medium, yet they are increasingly weaponized to convey harmful opinions through subtle rhetorical devices like irony and metaphor. Existing detection approaches, including MLLM-based techniques, stru...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "experiment",
        "LLM",
        "RAG",
        "reasoning",
        "multimodal",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "WaveNet's Precision in EEG Classification",
      "url": "https://arxiv.org/abs/2510.15947",
      "description": "arXiv:2510.15947v1 Announce Type: new \nAbstract: This study introduces a WaveNet-based deep learning model designed to automate the classification of EEG signals into physiological, pathological, artifact, and noise categories. Traditional methods for EEG signal classification, which rely on expert ...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "audio",
        "ICL",
        "study",
        "model",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Cross-dataset Multivariate Time-series Model for Parkinson's Diagnosis via Keyboard Dynamics",
      "url": "https://arxiv.org/abs/2510.15950",
      "description": "arXiv:2510.15950v1 Announce Type: new \nAbstract: Parkinson's disease (PD) presents a growing global challenge, affecting over 10 million individuals, with prevalence expected to double by 2040. Early diagnosis remains difficult due to the late emergence of motor symptoms and limitations of tradition...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "RAG",
        "transformer",
        "study",
        "model",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "How Good Are LLMs at Processing Tool Outputs?",
      "url": "https://arxiv.org/abs/2510.15955",
      "description": "arXiv:2510.15955v1 Announce Type: new \nAbstract: Most realistic task automation problems require large language models (LLMs) to call tools, which often return complex JSON responses. These responses must be further processed to derive the information necessary for task completion. The ability of LL...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "prompt",
        "paper",
        "LLM",
        "reasoning",
        "large language model",
        "tool",
        "prompting",
        "study",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Interpretable Graph-Language Modeling for Detecting Youth Illicit Drug Use",
      "url": "https://arxiv.org/abs/2510.15961",
      "description": "arXiv:2510.15961v1 Announce Type: new \nAbstract: Illicit drug use among teenagers and young adults (TYAs) remains a pressing public health concern, with rising prevalence and long-term impacts on health and well-being. To detect illicit drug use among TYAs, researchers analyze large-scale surveys su...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment",
        "framework",
        "large language model",
        "model",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "context window",
        "prompt",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "CoT",
        "framework",
        "reasoning",
        "audio",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "prompt",
        "API",
        "LLM",
        "tool",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "vector",
        "LLM",
        "RAG",
        "reasoning",
        "retrieval",
        "model",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "fine-tuning",
        "LLM",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "RAG",
        "product",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "prompt",
        "framework",
        "vector",
        "LLM",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "framework",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Exploring the Potential of Citiverses for Regulatory Learning",
      "url": "https://arxiv.org/abs/2510.15959",
      "description": "arXiv:2510.15959v1 Announce Type: new \nAbstract: Citiverses hold the potential to support regulatory learning by offering immersive, virtual environments for experimenting with policy scenarios and technologies. This paper proposes a science-for-policy agenda to explore the potential of citiverses a...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "experiment",
        "platform",
        "model",
        "research"
      ],
      "score": 0.8
    },
    {
      "title": "Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science",
      "url": "https://arxiv.org/abs/2510.15983",
      "description": "arXiv:2510.15983v1 Announce Type: new \nAbstract: An essential component for evaluating and comparing physical and cognitive capabilities between populations is the testing of various factors related to human performance. As a core part of sports science research, testing motor performance enables th...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "vision",
        "analysis",
        "paper",
        "model",
        "research"
      ],
      "score": 0.8
    },
    {
      "title": "A Non-overlap-based Conflict Measure for Random Permutation Sets",
      "url": "https://arxiv.org/abs/2510.16001",
      "description": "arXiv:2510.16001v1 Announce Type: new \nAbstract: Random permutation set (RPS) is a new formalism for reasoning with uncertainty involving order information. Measuring the conflict between two pieces of evidence represented by permutation mass functions remains an urgent research topic in order-struc...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "example",
        "arxiv",
        "analysis",
        "paper",
        "reasoning",
        "research"
      ],
      "score": 0.8
    },
    {
      "title": "PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction",
      "url": "https://arxiv.org/abs/2510.16004",
      "description": "arXiv:2510.16004v1 Announce Type: new \nAbstract: Neural surrogates have shown great potential in simulating dynamical systems, while offering real-time capabilities. We envision Neural Twins as a progression of neural surrogates, aiming to create digital replicas of real systems. A neural twin consu...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "vision",
        "arxiv",
        "analysis",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Fire-EnSF: Wildfire Spread Data Assimilation using Ensemble Score Filter",
      "url": "https://arxiv.org/abs/2510.15954",
      "description": "arXiv:2510.15954v1 Announce Type: new \nAbstract: As wildfires become increasingly destructive and expensive to control, effective management of active wildfires requires accurate, real-time fire spread predictions. To enhance the forecasting accuracy of active fires, data assimilation plays a vital ...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "RAG",
        "ICL",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "model",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "model",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "What Can String Probability Tell Us About Grammaticality?",
      "url": "https://arxiv.org/abs/2510.16227",
      "description": "arXiv:2510.16227v1 Announce Type: new \nAbstract: What have language models (LMs) learned about grammar? This question remains hotly debated, with major ramifications for linguistic theory. However, since probability and grammaticality are distinct notions in linguistics, it is not obvious what strin...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "framework",
        "analysis"
      ],
      "score": 0.4
    },
    {
      "title": "Lyapunov-Stable Adaptive Control for Multimodal Concept Drift",
      "url": "https://arxiv.org/abs/2510.15944",
      "description": "arXiv:2510.15944v1 Announce Type: new \nAbstract: Multimodal learning systems often struggle in non-stationary environments due to concept drift, where changing data distributions can degrade performance. Modality-specific drifts and the lack of mechanisms for continuous, stable adaptation compound t...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "paper",
        "framework",
        "model",
        "multimodal"
      ],
      "score": 0.4
    },
    {
      "title": "Hydrogen production from blended waste biomass: pyrolysis, thermodynamic-kinetic analysis and AI-based modelling",
      "url": "https://arxiv.org/abs/2510.15960",
      "description": "arXiv:2510.15960v1 Announce Type: new \nAbstract: This work contributes to advancing sustainable energy and waste management strategies by investigating the thermochemical conversion of food-based biomass through pyrolysis, highlighting the role of artificial intelligence (AI) in enhancing process mo...",
      "published_date": "2025-10-21T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "product",
        "analysis",
        "model"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Supercharge your OCR Pipelines with Open Models",
      "url": "https://huggingface.co/blog/ocr-open-models",
      "description": "...",
      "published_date": "2025-10-21T00:00:00",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model"
      ],
      "score": 0.2
    },
    {
      "title": "Unlock the power of images with AI Sheets",
      "url": "https://huggingface.co/blog/aisheets-unlock-images",
      "description": "...",
      "published_date": "2025-10-21T00:00:00",
      "source": "Hugging Face Blog",
      "category": "multimodal_context",
      "keywords": [
        "image"
      ],
      "score": 0.2
    }
  ]
}