{
  "generated_at": "2025-10-29T20:06:11.765539",
  "total_items": 44,
  "items": [
    {
      "title": "Evaluating Long-Term Memory for Long-Context Question Answering",
      "url": "https://arxiv.org/abs/2510.23730",
      "description": "arXiv:2510.23730v1 Announce Type: new \nAbstract: In order for large language models to achieve true conversational continuity and benefit from experiential learning, they need memory. While research has focused on the development of complex memory systems, it remains unclear which types of memory ar...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "research",
        "model",
        "retrieval",
        "large language model",
        "reasoning",
        "RAG",
        "instruction",
        "augmented",
        "prompt",
        "prompting",
        "LLM",
        "in-context",
        "arxiv",
        "memory",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "BitSkip: An Empirical Analysis of Quantization and Early Exit Composition",
      "url": "https://arxiv.org/abs/2510.23766",
      "description": "arXiv:2510.23766v1 Announce Type: new \nAbstract: The pursuit of efficient Large Language Models (LLMs) has led to increasingly complex techniques like extreme quantization and dynamic routing. While individual benefits of these methods are well-documented, their compositional effects remain poorly u...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "framework",
        "large language model",
        "analysis",
        "LLM",
        "arxiv",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural Processing of Figurative Language",
      "url": "https://arxiv.org/abs/2510.23828",
      "description": "arXiv:2510.23828v1 Announce Type: new \nAbstract: We present a comprehensive evaluation of the ability of large language models (LLMs) to process culturally grounded language, specifically to understand and pragmatically use figurative expressions that encode local knowledge and cultural nuance. Usin...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "model",
        "large language model",
        "reasoning",
        "RAG",
        "release",
        "LLM",
        "arxiv",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "How Pragmatics Shape Articulation: A Computational Case Study in STEM ASL Discourse",
      "url": "https://arxiv.org/abs/2510.23842",
      "description": "arXiv:2510.23842v1 Announce Type: new \nAbstract: Most state-of-the-art sign language models are trained on interpreter or isolated vocabulary data, which overlooks the variability that characterizes natural dialogue. However, human communication dynamically adapts to contexts and interlocutors throu...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "study",
        "analysis",
        "RAG",
        "arxiv",
        "ICL",
        "embedding",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Temporal Blindness in Multi-Turn LLM Agents: Misaligned Tool Use vs. Human Time Perception",
      "url": "https://arxiv.org/abs/2510.23853",
      "description": "arXiv:2510.23853v1 Announce Type: new \nAbstract: Large language model agents are increasingly used in multi-turn conversational settings to interact with and execute tasks in dynamic environments. However, a key limitation is their temporal blindness: they, by default, operate with a stationary cont...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "alignment",
        "study",
        "large language model",
        "analysis",
        "prompt",
        "LLM",
        "arxiv",
        "tool",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural Language Representations of Text-to-SQL System Outputs",
      "url": "https://arxiv.org/abs/2510.23854",
      "description": "arXiv:2510.23854v1 Announce Type: new \nAbstract: In modern industry systems like multi-turn chat agents, Text-to-SQL technology bridges natural language (NL) questions and database (DB) querying. The conversion of tabular DB results into NL representations (NLRs) enables the chat-based interaction. ...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "alignment",
        "framework",
        "large language model",
        "LLM",
        "arxiv",
        "company",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Language Models for Longitudinal Clinical Prediction",
      "url": "https://arxiv.org/abs/2510.23884",
      "description": "arXiv:2510.23884v1 Announce Type: new \nAbstract: We explore a lightweight framework that adapts frozen large language models to analyze longitudinal clinical data. The approach integrates patient history and context within the language model space to generate accurate forecasts without model fine-tu...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "framework",
        "large language model",
        "fine-tuning",
        "arxiv",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "AfriMTEB and AfriE5: Benchmarking and Adapting Text Embedding Models for African Languages",
      "url": "https://arxiv.org/abs/2510.23896",
      "description": "arXiv:2510.23896v1 Announce Type: new \nAbstract: Text embeddings are an essential building component of several NLP tasks such as retrieval-augmented generation which is crucial for preventing hallucinations in LLMs. Despite the recent release of massively multilingual MTEB (MMTEB), African language...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "retrieval",
        "augmented",
        "instruction",
        "release",
        "LLM",
        "arxiv",
        "embedding",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra",
      "url": "https://arxiv.org/abs/2510.23746",
      "description": "arXiv:2510.23746v1 Announce Type: new \nAbstract: Tandem Mass Spectrometry enables the identification of unknown compounds in crucial fields such as metabolomics, natural product discovery and environmental analysis. However, current methods rely on database matching from previously observed molecule...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "transformer",
        "framework",
        "analysis",
        "RAG",
        "product",
        "experiment",
        "fine-tuning",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents",
      "url": "https://arxiv.org/abs/2510.23822",
      "description": "arXiv:2510.23822v1 Announce Type: new \nAbstract: Long-horizon tasks requiring multi-step reasoning and dynamic re-planning remain challenging for large language models (LLMs). Sequential prompting methods are prone to context drift, loss of goal information, and recurrent failure cycles, while hiera...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "model",
        "alignment",
        "large language model",
        "framework",
        "reasoning",
        "prompt",
        "prompting",
        "LLM",
        "experiment",
        "arxiv",
        "memory",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models",
      "url": "https://arxiv.org/abs/2510.23824",
      "description": "arXiv:2510.23824v1 Announce Type: new \nAbstract: Coordinating multiple autonomous agents in shared environments under decentralized conditions is a long-standing challenge in robotics and artificial intelligence. This work addresses the problem of decentralized goal assignment for multi-agent path p...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "model",
        "large language model",
        "reasoning",
        "prompt",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "From Benchmarks to Business Impact: Deploying IBM Generalist Agent in Enterprise Production",
      "url": "https://arxiv.org/abs/2510.23856",
      "description": "arXiv:2510.23856v1 Announce Type: new \nAbstract: Agents are rapidly advancing in automating digital work, but enterprises face a harder challenge: moving beyond prototypes to deployed systems that deliver measurable business value. This path is complicated by fragmented frameworks, slow development,...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "API",
        "framework",
        "RAG",
        "product",
        "arxiv",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "An Enhanced Dual Transformer Contrastive Network for Multimodal Sentiment Analysis",
      "url": "https://arxiv.org/abs/2510.23617",
      "description": "arXiv:2510.23617v1 Announce Type: new \nAbstract: Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by jointly analyzing data from multiple modalities typically text and images offering a richer and more accurate interpretation than unimodal approaches. In this paper, we first pr...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "model",
        "cross-modal",
        "transformer",
        "analysis",
        "arxiv",
        "multimodal",
        "image",
        "context",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media",
      "url": "https://arxiv.org/abs/2510.23626",
      "description": "arXiv:2510.23626v1 Announce Type: new \nAbstract: Social media user-generated content (UGC) provides real-time, self-reported indicators of mental health conditions such as depression, offering a valuable source for predictive analytics. While prior studies integrate medical knowledge to improve pred...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "vision",
        "model",
        "framework",
        "large language model",
        "LLM",
        "arxiv",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Chain of Execution Supervision Promotes General Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2510.23629",
      "description": "arXiv:2510.23629v1 Announce Type: new \nAbstract: Building robust and general reasoning ability is a central goal in the development of large language models (LLMs). Recent efforts increasingly turn to code as a rich training source, given its inherent logical structure and diverse reasoning paradigm...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "vision",
        "model",
        "chain-of-thought",
        "step-by-step",
        "large language model",
        "reasoning",
        "RAG",
        "instruction",
        "experiment",
        "LLM",
        "fine-tuning",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "NUM2EVENT: Interpretable Event Reasoning from Numerical time-series",
      "url": "https://arxiv.org/abs/2510.23630",
      "description": "arXiv:2510.23630v1 Announce Type: new \nAbstract: Large language models (LLMs) have recently demonstrated impressive multimodal reasoning capabilities, yet their understanding of purely numerical time-series signals remains limited. Existing approaches mainly focus on forecasting or trend description...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "alignment",
        "large language model",
        "framework",
        "reasoning",
        "experiment",
        "LLM",
        "fine-tuning",
        "arxiv",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling",
      "url": "https://arxiv.org/abs/2510.23631",
      "description": "arXiv:2510.23631v1 Announce Type: new \nAbstract: Alignment of large language models (LLMs) has predominantly relied on pairwise preference optimization, where annotators select the better of two responses to a prompt. While simple, this approach overlooks the opportunity to learn from richer forms o...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "model",
        "alignment",
        "large language model",
        "framework",
        "RAG",
        "prompt",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data Compression",
      "url": "https://arxiv.org/abs/2510.23632",
      "description": "arXiv:2510.23632v1 Announce Type: new \nAbstract: The rapid growth of high-resolution scientific simulations and observation systems is generating massive spatiotemporal datasets, making efficient, error-bounded compression increasingly important. Meanwhile, decoder-only large language models (LLMs) ...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "transformer",
        "API",
        "large language model",
        "analysis",
        "RAG",
        "compression",
        "experiment",
        "LLM",
        "arxiv",
        "embedding",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models",
      "url": "https://arxiv.org/abs/2510.23633",
      "description": "arXiv:2510.23633v1 Announce Type: new \nAbstract: Pretrained diffusion models have demonstrated strong capabilities in zero-shot inverse problem solving by incorporating observation information into the generation process of the diffusion models. However, this presents an inherent dilemma: excessive ...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "model",
        "vector",
        "compression",
        "zero-shot",
        "arxiv",
        "image"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt",
        "prompt engineering",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "chain-of-thought",
        "framework",
        "reasoning",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "API",
        "prompt",
        "LLM",
        "tool",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "framework",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "vector",
        "retrieval",
        "framework",
        "reasoning",
        "RAG",
        "knowledge base",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "LLM",
        "fine-tuning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "retrieval",
        "product",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "framework",
        "prompt",
        "platform",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "framework",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL Reasoning",
      "url": "https://arxiv.org/abs/2510.23870",
      "description": "arXiv:2510.23870v1 Announce Type: new \nAbstract: We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge 2025, a bilingual benchmark requiring complex reasoning such as arithmetic, commonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding the second-best syst...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "framework",
        "reasoning",
        "prompt",
        "prompting",
        "LLM",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents",
      "url": "https://arxiv.org/abs/2510.23691",
      "description": "arXiv:2510.23691v1 Announce Type: new \nAbstract: We present Game-TARS, a generalist game agent trained with a unified, scalable action space anchored to human-aligned native keyboard-mouse inputs. Unlike API- or GUI-based approaches, this paradigm enables large-scale continual pre-training across he...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "GPT",
        "API",
        "reasoning",
        "experiment",
        "arxiv",
        "multimodal"
      ],
      "score": 0.8
    },
    {
      "title": "Why Foundation Models in Pathology Are Failing",
      "url": "https://arxiv.org/abs/2510.23807",
      "description": "arXiv:2510.23807v1 Announce Type: new \nAbstract: In non-medical domains, foundation models (FMs) have revolutionized computer vision and language processing through large-scale self-supervised and multimodal learning. Consequently, their rapid adoption in computational pathology was expected to deli...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "vision",
        "model",
        "API",
        "retrieval",
        "arxiv",
        "multimodal",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "API",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Adversarially-Aware Architecture Design for Robust Medical AI Systems",
      "url": "https://arxiv.org/abs/2510.23622",
      "description": "arXiv:2510.23622v1 Announce Type: new \nAbstract: Adversarial attacks pose a severe risk to AI systems used in healthcare, capable of misleading models into dangerous misclassifications that can delay treatments or cause misdiagnoses. These attacks, often imperceptible to human perception, threaten p...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "study",
        "experiment",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "DiNo and RanBu: Lightweight Predictions from Shallow Random Forests",
      "url": "https://arxiv.org/abs/2510.23624",
      "description": "arXiv:2510.23624v1 Announce Type: new \nAbstract: Random Forest ensembles are a strong baseline for tabular prediction tasks, but their reliance on hundreds of deep trees often results in high inference latency and memory demands, limiting deployment in latency-sensitive or resource-constrained envir...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "vector",
        "arxiv",
        "memory"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt",
        "prompt engineering",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "AI and the Decentering of Disciplinary Creativity",
      "url": "https://arxiv.org/abs/2510.23734",
      "description": "arXiv:2510.23734v1 Announce Type: new \nAbstract: This paper examines the role of artificial intelligence in scientific problem-solving, with a focus on its implications for disciplinary creativity. Drawing on recent work in the philosophy of creativity, I distinguish between creative approaches and ...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "product",
        "arxiv",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions",
      "url": "https://arxiv.org/abs/2510.23772",
      "description": "arXiv:2510.23772v1 Announce Type: new \nAbstract: The rapid advancement of Generative AI has raised significant questions regarding its ability to produce creative and novel outputs. Our recent work investigates this question within the domain of chess puzzles and presents an AI system designed to ge...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "API",
        "arxiv",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "Generating Creative Chess Puzzles",
      "url": "https://arxiv.org/abs/2510.23881",
      "description": "arXiv:2510.23881v1 Announce Type: new \nAbstract: While Generative AI rapidly advances in various domains, generating truly creative, aesthetic, and counter-intuitive outputs remains a challenge. This paper presents an approach to tackle these difficulties in the domain of chess puzzles. We start by ...",
      "published_date": "2025-10-29T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "API",
        "framework",
        "arxiv",
        "paper"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}