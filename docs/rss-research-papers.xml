<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Early science acceleration experiments with GPT-5</title>
      <link>https://arxiv.org/abs/2511.16072</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16072</guid>
      <description>arXiv:2511.16072v1 Announce Type: new 
Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, example, model, research, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>GPT</category>
      <category>example</category>
      <category>model</category>
    </item>
    <item>
      <title>ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models</title>
      <link>https://arxiv.org/abs/2511.16122</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16122</guid>
      <description>arXiv:2511.16122v1 Announce Type: new 
Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emerge...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt engineering, model, large language model, research, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>prompt engineering</category>
      <category>model</category>
      <category>large language model</category>
    </item>
    <item>
      <title>TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating</title>
      <link>https://arxiv.org/abs/2511.16147</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16147</guid>
      <description>arXiv:2511.16147v1 Announce Type: new 
Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrai...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; product, model, study, research, vision | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>product</category>
      <category>model</category>
      <category>study</category>
    </item>
    <item>
      <title>SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning</title>
      <link>https://arxiv.org/abs/2511.16198</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16198</guid>
      <description>arXiv:2511.16198v1 Announce Type: new 
Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated halluc...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, alignment, research, context, retrieval | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>alignment</category>
      <category>research</category>
    </item>
    <item>
      <title>SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs</title>
      <link>https://arxiv.org/abs/2511.16275</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16275</guid>
      <description>arXiv:2511.16275v1 Announce Type: new 
Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, large language model, compression, framework, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>large language model</category>
      <category>compression</category>
    </item>
    <item>
      <title>Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents</title>
      <link>https://arxiv.org/abs/2511.14780</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.14780</guid>
      <description>arXiv:2511.14780v1 Announce Type: new 
Abstract: We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent&amp;#x27;s beliefs and rationale, and ena...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; memory, model, large language model, study, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>memory</category>
      <category>model</category>
      <category>large language model</category>
    </item>
    <item>
      <title>Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization</title>
      <link>https://arxiv.org/abs/2511.15055</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.15055</guid>
      <description>arXiv:2511.15055v1 Announce Type: new 
Abstract: Human-like agents have long been one of the goals in pursuing artificial intelligence. Although reinforcement learning (RL) has achieved superhuman performance in many domains, relatively little attention has been focused on designing human-like RL ag...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; demonstration, attention, study, framework, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>demonstration</category>
      <category>attention</category>
      <category>study</category>
    </item>
    <item>
      <title>ProRAC: A Neuro-symbolic Method for Reasoning about Actions with LLM-based Progression</title>
      <link>https://arxiv.org/abs/2511.15069</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.15069</guid>
      <description>arXiv:2511.15069v1 Announce Type: new 
Abstract: In this paper, we propose ProRAC (Progression-based Reasoning about Actions and Change), a neuro-symbolic framework that leverages LLMs to tackle RAC problems. ProRAC extracts fundamental RAC elements including actions and questions from the problem, ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, framework, paper, arxiv, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>framework</category>
      <category>paper</category>
    </item>
    <item>
      <title>Attention-Based Feature Online Conformal Prediction for Time Series</title>
      <link>https://arxiv.org/abs/2511.15838</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.15838</guid>
      <description>arXiv:2511.15838v1 Announce Type: new 
Abstract: Online conformal prediction (OCP) wraps around any pre-trained predictor to produce prediction sets with coverage guarantees that hold irrespective of temporal dependencies or distribution shifts. However, standard OCP faces two key limitations: it op...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, attention, paper, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>attention</category>
      <category>paper</category>
    </item>
    <item>
      <title>Project Rachel: Can an AI Become a Scholarly Author?</title>
      <link>https://arxiv.org/abs/2511.14819</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.14819</guid>
      <description>arXiv:2511.14819v1 Announce Type: new 
Abstract: This paper documents Project Rachel, an action research study that created and tracked a complete AI academic identity named Rachel So. Through careful publication of AI-generated research papers, we investigate how the scholarly ecosystem responds to...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, research, study, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>research</category>
      <category>study</category>
    </item>
    <item>
      <title>Learning Interestingness in Automated Mathematical Theory Formation</title>
      <link>https://arxiv.org/abs/2511.14778</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.14778</guid>
      <description>arXiv:2511.14778v1 Announce Type: new 
Abstract: We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>Task Specific Sharpness Aware O-RAN Resource Management using Multi Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2511.15002</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.15002</guid>
      <description>arXiv:2511.15002v1 Announce Type: new 
Abstract: Next-generation networks utilize the Open Radio Access Network (O-RAN) architecture to enable dynamic resource management, facilitated by the RAN Intelligent Controller (RIC). While deep reinforcement learning (DRL) models show promise in optimizing n...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, framework, paper, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>framework</category>
      <category>paper</category>
    </item>
    <item>
      <title>Global Resolution: Optimal Multi-Draft Speculative Sampling via Convex Minimization</title>
      <link>https://arxiv.org/abs/2511.15898</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.15898</guid>
      <description>arXiv:2511.15898v1 Announce Type: new 
Abstract: Speculative sampling reduces the latency of autoregressive decoding for target model LLMs without sacrificing inference quality, by using a cheap draft model to suggest a candidate token and a verification criterion to accept or resample this token. T...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Fri, 21 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>LLM</category>
      <category>model</category>
    </item>
  </channel>
</rss>