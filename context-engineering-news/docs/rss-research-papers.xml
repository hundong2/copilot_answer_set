<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>A Novel Differential Feature Learning for Effective Hallucination Detection and Classification</title>
      <link>https://arxiv.org/abs/2509.21357</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21357</guid>
      <description>arXiv:2509.21357v1 Announce Type: new 
Abstract: Large language model hallucination represents a critical challenge where outputs deviate from factual accuracy due to distributional biases in training data. While recent investigations establish that specific hidden layers exhibit differences between...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, arxiv, large language model, model, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>arxiv</category>
      <category>large language model</category>
    </item>
    <item>
      <title>One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning</title>
      <link>https://arxiv.org/abs/2509.21443</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21443</guid>
      <description>arXiv:2509.21443v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly deployed in multilingual and multicultural environments where moral reasoning is essential for generating ethically appropriate responses. Yet, the dominant pretraining of LLMs on English-language data rai...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; alignment, research, study, context, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>alignment</category>
      <category>research</category>
      <category>study</category>
    </item>
    <item>
      <title>Diagnosing the Performance Trade-off in Moral Alignment: A Case Study on Gender Stereotypes</title>
      <link>https://arxiv.org/abs/2509.21456</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21456</guid>
      <description>arXiv:2509.21456v1 Announce Type: new 
Abstract: Moral alignment has emerged as a widely adopted approach for regulating the behavior of pretrained language models (PLMs), typically through fine-tuning or model editing on curated datasets. However, this process often comes at the cost of degraded do...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, alignment, study, context, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>fine-tuning</category>
      <category>alignment</category>
      <category>study</category>
    </item>
    <item>
      <title>Towards mitigating information leakage when evaluating safety monitors</title>
      <link>https://arxiv.org/abs/2509.21344</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21344</guid>
      <description>arXiv:2509.21344v1 Announce Type: new 
Abstract: White box monitors that analyze model internals offer promising advantages for detecting potentially harmful behaviors in large language models, including lower computational costs and integration into layered defense systems.However, training and eva...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, study, experiment, reasoning, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>fine-tuning</category>
      <category>study</category>
      <category>experiment</category>
    </item>
    <item>
      <title>AutoClimDS: Climate Data Science Agentic AI -- A Knowledge Graph is All You Need</title>
      <link>https://arxiv.org/abs/2509.21553</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21553</guid>
      <description>arXiv:2509.21553v1 Announce Type: new 
Abstract: Climate data science faces persistent barriers stemming from the fragmented nature of data sources, heterogeneous formats, and the steep technical expertise required to identify, acquire, and process datasets. These challenges limit participation, slo...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, tool, arxiv, analysis, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>tool</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2509.21567</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21567</guid>
      <description>arXiv:2509.21567v1 Announce Type: new 
Abstract: Prediction of consumer behavior is one of the important purposes in marketing, cognitive neuroscience, and human-computer interaction. The electroencephalography (EEG) data can help analyze the decision process by providing detailed information about ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, study, arxiv, vector, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>study</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization</title>
      <link>https://arxiv.org/abs/2509.21718</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21718</guid>
      <description>arXiv:2509.21718v1 Announce Type: new 
Abstract: Developing high-quality text-to-speech (TTS) systems for low-resource languages is challenging due to the scarcity of paired text and speech data. In contrast, automatic speech recognition (ASR) models for such languages are often more accessible, owi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; audio, fine-tuning, alignment, experiment, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>audio</category>
      <category>fine-tuning</category>
      <category>alignment</category>
    </item>
    <item>
      <title>LLMs for Bayesian Optimization in Scientific Domains: Are We There Yet?</title>
      <link>https://arxiv.org/abs/2509.21403</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21403</guid>
      <description>arXiv:2509.21403v1 Announce Type: new 
Abstract: Large language models (LLMs) have recently been proposed as general-purpose agents for experimental design, with claims that they can perform in-context experimental design. We evaluate this hypothesis using both open- and closed-source instruction-tu...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; instruction, experiment, context, reasoning, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>instruction</category>
      <category>experiment</category>
      <category>context</category>
    </item>
    <item>
      <title>Null-Space Filtering for Data-Free Continual Model Merging: Preserving Transparency, Promoting Fidelity</title>
      <link>https://arxiv.org/abs/2509.21413</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21413</guid>
      <description>arXiv:2509.21413v1 Announce Type: new 
Abstract: Data-free continual model merging (DFCMM) aims to fuse independently fine-tuned models into a single backbone that evolves with incoming tasks without accessing task data. This paper formulate two fundamental desiderata for DFCMM: transparency, avoidi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, alignment, vector, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>fine-tuning</category>
      <category>alignment</category>
      <category>vector</category>
    </item>
    <item>
      <title>Forecasting Seismic Waveforms: A Deep Learning Approach for Einstein Telescope</title>
      <link>https://arxiv.org/abs/2509.21446</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21446</guid>
      <description>arXiv:2509.21446v1 Announce Type: new 
Abstract: We introduce \textit{SeismoGPT}, a transformer-based model for forecasting three-component seismic waveforms in the context of future gravitational wave detectors like the Einstein Telescope. The model is trained in an autoregressive setting and can o...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, context, GPT, model, transformer | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>context</category>
      <category>GPT</category>
    </item>
    <item>
      <title>d2: Improved Techniques for Training Reasoning Diffusion Language Models</title>
      <link>https://arxiv.org/abs/2509.21474</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21474</guid>
      <description>arXiv:2509.21474v1 Announce Type: new 
Abstract: While diffusion language models (DLMs) have achieved competitive performance in text generation, improving their reasoning ability with reinforcement learning remains an active research area. Here, we introduce d2, a reasoning framework tailored for m...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; fine-tuning, research, study, arxiv, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>fine-tuning</category>
      <category>research</category>
      <category>study</category>
    </item>
    <item>
      <title>Can AI Perceive Physical Danger and Intervene?</title>
      <link>https://arxiv.org/abs/2509.21651</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21651</guid>
      <description>arXiv:2509.21651v1 Announce Type: new 
Abstract: When AI interacts with the physical world -- as a robot or an assistive agent -- new safety challenges emerge beyond those of purely ``digital AI&amp;quot;. In such interactions, the potential for physical harm is direct and immediate. How well do state-of-the...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; instruction, release, reasoning, image, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>instruction</category>
      <category>release</category>
      <category>reasoning</category>
    </item>
    <item>
      <title>Score-based Idempotent Distillation of Diffusion Models</title>
      <link>https://arxiv.org/abs/2509.21470</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21470</guid>
      <description>arXiv:2509.21470v1 Announce Type: new 
Abstract: Idempotent generative networks (IGNs) are a new line of generative models based on idempotent mapping to a target manifold. IGNs support both single-and multi-step generation, allowing for a flexible trade-off between computational cost and sample qua...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, image, model, analysis, zero-shot | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>image</category>
      <category>model</category>
    </item>
    <item>
      <title>Are Hallucinations Bad Estimations?</title>
      <link>https://arxiv.org/abs/2509.21473</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21473</guid>
      <description>arXiv:2509.21473v1 Announce Type: new 
Abstract: We formalize hallucinations in generative models as failures to link an estimate to any plausible cause. Under this interpretation, we show that even loss-minimizing optimal estimators still hallucinate. We confirm this with a general high probability...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; alignment, experiment, arxiv, image, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>alignment</category>
      <category>experiment</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>How Large Language Models Need Symbolism</title>
      <link>https://arxiv.org/abs/2509.21404</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21404</guid>
      <description>arXiv:2509.21404v1 Announce Type: new 
Abstract: We argue that AI&amp;#x27;s future requires more than scaling. To unlock genuine discovery, large language models need a compass: human-crafted symbols to guide their powerful but blind intuition....&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, large language model, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>large language model</category>
      <category>model</category>
    </item>
    <item>
      <title>Discovering and Analyzing Stochastic Processes to Reduce Waste in Food Retail</title>
      <link>https://arxiv.org/abs/2509.21322</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21322</guid>
      <description>arXiv:2509.21322v1 Announce Type: new 
Abstract: This paper proposes a novel method for analyzing food retail processes with a focus on reducing food waste. The approach integrates object-centric process mining (OCPM) with stochastic process discovery and analysis. First, a stochastic process in the...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; product, arxiv, model, analysis, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>product</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Automated and Interpretable Survival Analysis from Multimodal Data</title>
      <link>https://arxiv.org/abs/2509.21600</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21600</guid>
      <description>arXiv:2509.21600v1 Announce Type: new 
Abstract: Accurate and interpretable survival analysis remains a core challenge in oncology. With growing multimodal data and the clinical need for transparent models to support validation and trust, this challenge increases in complexity. We propose an interpr...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; multimodal, arxiv, model, analysis, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>multimodal</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
    <item>
      <title>Impact of Loss Weight and Model Complexity on Physics-Informed Neural Networks for Computational Fluid Dynamics</title>
      <link>https://arxiv.org/abs/2509.21393</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2509.21393</guid>
      <description>arXiv:2509.21393v1 Announce Type: new 
Abstract: Physics Informed Neural Networks offer a mesh free framework for solving PDEs but are highly sensitive to loss weight selection. We propose two dimensional analysis based weighting schemes, one based on quantifiable terms, and another also incorporati...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; analysis, arxiv, model, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 29 Sep 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>analysis</category>
      <category>arxiv</category>
      <category>model</category>
    </item>
  </channel>
</rss>