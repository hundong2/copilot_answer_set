{
  "generated_at": "2025-08-27T20:05:55.785756",
  "total_items": 47,
  "items": [
    {
      "title": "LLMs Can't Handle Peer Pressure: Crumbling under Multi-Agent Social Interactions",
      "url": "https://arxiv.org/abs/2508.18321",
      "description": "arXiv:2508.18321v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly deployed in multi-agent systems (MAS) as components of collaborative intelligence, where peer interactions dynamically shape individual decision-making. Although prior work has focused on conformity bias, ...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "arxiv",
        "prompting",
        "model",
        "LLM",
        "fine-tuning",
        "reasoning",
        "prompt",
        "context",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Not All Visitors are Bilingual: A Measurement Study of the Multilingual Web from an Accessibility Perspective",
      "url": "https://arxiv.org/abs/2508.18328",
      "description": "arXiv:2508.18328v1 Announce Type: new \nAbstract: English is the predominant language on the web, powering nearly half of the world's top ten million websites. Support for multilingual content is nevertheless growing, with many websites increasingly combining English with regional or native languages...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "RAG",
        "context",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Language-Specific Layer Matters: Efficient Multilingual Enhancement for Large Vision-Language Models",
      "url": "https://arxiv.org/abs/2508.18381",
      "description": "arXiv:2508.18381v1 Announce Type: new \nAbstract: Large vision-language models (LVLMs) have demonstrated exceptional capabilities in understanding visual information with human languages but also exhibit an imbalance in multilingual capabilities. In this work, we delve into the multilingual working p...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "vision",
        "model",
        "alignment",
        "reasoning",
        "fine-tuning",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Backprompting: Leveraging Synthetic Production Data for Health Advice Guardrails",
      "url": "https://arxiv.org/abs/2508.18384",
      "description": "arXiv:2508.18384v1 Announce Type: new \nAbstract: The pervasiveness of large language models (LLMs) in enterprise settings has also brought forth a significant amount of risks associated with their usage. Guardrails technologies aim to mitigate this risk by filtering LLMs' input/output text through v...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "arxiv",
        "prompting",
        "model",
        "LLM",
        "GPT",
        "RAG",
        "example",
        "prompt",
        "product"
      ],
      "score": 1.0
    },
    {
      "title": "Integral Transformer: Denoising Attention, Not Too Much Not Too Little",
      "url": "https://arxiv.org/abs/2508.18387",
      "description": "arXiv:2508.18387v1 Announce Type: new \nAbstract: Softmax self-attention often assigns disproportionate weight to semantically uninformative tokens such as special tokens and punctuation, a phenomenon known as attention noise. While recent methods like Cog Attention and the Differential Transformer h...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "attention",
        "arxiv",
        "model",
        "transformer",
        "reasoning",
        "experiment",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning",
      "url": "https://arxiv.org/abs/2508.18395",
      "description": "arXiv:2508.18395v1 Announce Type: new \nAbstract: Probabilistic decoding in Large Language Models (LLMs) often yields inconsistent outputs, particularly on complex or long-form questions. Self-Consistency (SC) mitigates this for short-form QA by majority voting over exact strings, whereas Universal S...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "arxiv",
        "model",
        "LLM",
        "RAG",
        "reasoning",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "How Reliable are LLMs for Reasoning on the Re-ranking task?",
      "url": "https://arxiv.org/abs/2508.18444",
      "description": "arXiv:2508.18444v1 Announce Type: new \nAbstract: With the improving semantic understanding capability of Large Language Models (LLMs), they exhibit a greater awareness and alignment with human values, but this comes at the cost of transparency. Although promising results are achieved via experimenta...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "arxiv",
        "model",
        "LLM",
        "alignment",
        "reasoning",
        "experiment",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "Integrating gender inclusivity into large language models via instruction tuning",
      "url": "https://arxiv.org/abs/2508.18466",
      "description": "arXiv:2508.18466v1 Announce Type: new \nAbstract: Imagine a language with masculine, feminine, and neuter grammatical genders, yet, due to historical and political conventions, masculine forms are predominantly used to refer to men, women and mixed-gender groups. This is the reality of contemporary P...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "arxiv",
        "model",
        "framework",
        "LLM",
        "experiment",
        "prompt",
        "instruction",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "PKG-DPO: Optimizing Domain-Specific AI systems with Physics Knowledge Graphs and Direct Preference Optimization",
      "url": "https://arxiv.org/abs/2508.18391",
      "description": "arXiv:2508.18391v1 Announce Type: new \nAbstract: Advancing AI systems in scientific domains like physics, materials science, and engineering calls for reasoning over complex, multi-physics phenomena while respecting governing principles. Although Large Language Models (LLMs) and existing preference ...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "arxiv",
        "model",
        "framework",
        "LLM",
        "alignment",
        "RAG",
        "reasoning",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "The AI in the Mirror: LLM Self-Recognition in an Iterated Public Goods Game",
      "url": "https://arxiv.org/abs/2508.18467",
      "description": "arXiv:2508.18467v1 Announce Type: new \nAbstract: As AI agents become increasingly capable of tool use and long-horizon tasks, they have begun to be deployed in settings where multiple agents can interact. However, whereas prior work has mostly focused on human-AI interactions, there is an increasing...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "model",
        "LLM",
        "reasoning",
        "tool",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Weisfeiler-Leman Features for Planning: A 1,000,000 Sample Size Hyperparameter Study",
      "url": "https://arxiv.org/abs/2508.18515",
      "description": "arXiv:2508.18515v1 Announce Type: new \nAbstract: Weisfeiler-Leman Features (WLFs) are a recently introduced classical machine learning tool for learning to plan and search. They have been shown to be both theoretically and empirically superior to existing deep learning approaches for learning value ...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "model",
        "study",
        "experiment",
        "tool",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "A Database-Driven Framework for 3D Level Generation with LLMs",
      "url": "https://arxiv.org/abs/2508.18533",
      "description": "arXiv:2508.18533v1 Announce Type: new \nAbstract: Procedural Content Generation for 3D game levels faces challenges in balancing spatial coherence, navigational functionality, and adaptable gameplay progression across multi-floor environments. This paper introduces a novel framework for generating su...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "template",
        "arxiv",
        "framework",
        "LLM",
        "research",
        "experiment"
      ],
      "score": 1.0
    },
    {
      "title": "SchemaCoder: Automatic Log Schema Extraction Coder with Residual Q-Tree Boosting",
      "url": "https://arxiv.org/abs/2508.18554",
      "description": "arXiv:2508.18554v1 Announce Type: new \nAbstract: Log schema extraction is the process of deriving human-readable templates from massive volumes of log data, which is essential yet notoriously labor-intensive. Recent studies have attempted to streamline this task by leveraging Large Language Models (...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "template",
        "arxiv",
        "model",
        "framework",
        "LLM",
        "RAG",
        "experiment",
        "embedding",
        "product",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Reasoning Steps as Curriculum: Using Depth of Thought as a Difficulty Signal for Tuning LLMs",
      "url": "https://arxiv.org/abs/2508.18279",
      "description": "arXiv:2508.18279v1 Announce Type: new \nAbstract: Curriculum learning for training LLMs requires a difficulty signal that aligns with reasoning while remaining scalable and interpretable. We propose a simple premise: tasks that demand deeper depth of thought for humans should also be harder for model...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "arxiv",
        "model",
        "framework",
        "LLM",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "Multi-Modal Drift Forecasting of Leeway Objects via Navier-Stokes-Guided CNN and Sequence-to-Sequence Attention-Based Models",
      "url": "https://arxiv.org/abs/2508.18284",
      "description": "arXiv:2508.18284v1 Announce Type: new \nAbstract: Accurately predicting the drift (displacement) of leeway objects in maritime environments remains a critical challenge, particularly in time-sensitive scenarios such as search and rescue operations. In this study, we propose a multi-modal machine lear...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "arxiv",
        "model",
        "framework",
        "transformer",
        "RAG",
        "experiment",
        "embedding",
        "memory",
        "image",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Data-driven models for production forecasting and decision supporting in petroleum reservoirs",
      "url": "https://arxiv.org/abs/2508.18289",
      "description": "arXiv:2508.18289v1 Announce Type: new \nAbstract: Forecasting production reliably and anticipating changes in the behavior of rock-fluid systems are the main challenges in petroleum reservoir engineering. This project proposes to deal with this problem through a data-driven approach and using machine...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "attention",
        "arxiv",
        "model",
        "study",
        "product",
        "API",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "A Fast and Minimal System to Identify Depression Using Smartphones: Explainable Machine Learning-Based Approach",
      "url": "https://arxiv.org/abs/2508.18301",
      "description": "arXiv:2508.18301v1 Announce Type: new \nAbstract: Background: Existing robust, pervasive device-based systems developed in recent years to detect depression require data collected over a long period and may not be effective in cases where early detection is crucial.\n  Objective: Our main objective wa...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "study",
        "RAG",
        "tool",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "SALMAN: Stability Analysis of Language Models Through the Maps Between Graph-based Manifolds",
      "url": "https://arxiv.org/abs/2508.18306",
      "description": "arXiv:2508.18306v1 Announce Type: new \nAbstract: Recent strides in pretrained transformer-based language models have propelled state-of-the-art performance in numerous NLP tasks. Yet, as these models grow in size and deployment, their robustness under input perturbations becomes an increasingly urge...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "model",
        "framework",
        "LLM",
        "transformer",
        "tool",
        "analysis"
      ],
      "score": 1.0
    },
    {
      "title": "CoPE: A Lightweight Complex Positional Encoding",
      "url": "https://arxiv.org/abs/2508.18308",
      "description": "arXiv:2508.18308v1 Announce Type: new \nAbstract: Recent studies have demonstrated the effectiveness of position encoding in transformer architectures. By incorporating positional information, this approach provides essential guidance for modeling dependencies between elements across different sequen...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "attention",
        "arxiv",
        "model",
        "transformer",
        "RAG",
        "experiment",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "What Matters in Data for DPO?",
      "url": "https://arxiv.org/abs/2508.18312",
      "description": "arXiv:2508.18312v1 Announce Type: new \nAbstract: Direct Preference Optimization (DPO) has emerged as a simple and effective approach for aligning large language models (LLMs) with human preferences, bypassing the need for a learned reward model. Despite its growing adoption, a fundamental question r...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "arxiv",
        "model",
        "LLM",
        "alignment",
        "fine-tuning",
        "analysis",
        "experiment",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "ProtoEHR: Hierarchical Prototype Learning for EHR-based Healthcare Predictions",
      "url": "https://arxiv.org/abs/2508.18313",
      "description": "arXiv:2508.18313v1 Announce Type: new \nAbstract: Digital healthcare systems have enabled the collection of mass healthcare data in electronic healthcare records (EHRs), allowing artificial intelligence solutions for various healthcare prediction tasks. However, existing studies often focus on isolat...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "arxiv",
        "model",
        "framework",
        "RAG",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "context",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "reasoning",
        "audio",
        "CoT",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "LLM",
        "prompt",
        "context",
        "API",
        "tool"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "framework",
        "LLM",
        "retrieval",
        "RAG",
        "reasoning",
        "knowledge base",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "tool",
        "model",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "product",
        "API",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "platform",
        "framework",
        "LLM",
        "prompt",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "AI LLM Proof of Self-Consciousness and User-Specific Attractors",
      "url": "https://arxiv.org/abs/2508.18302",
      "description": "arXiv:2508.18302v1 Announce Type: new \nAbstract: Recent work frames LLM consciousness via utilitarian proxy benchmarks; we instead present an ontological and mathematical account. We show the prevailing formulation collapses the agent into an unconscious policy-compliance drone, formalized as $D^{i}...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "model",
        "arxiv",
        "analysis"
      ],
      "score": 0.8
    },
    {
      "title": "Generic Guard AI in Stealth Game with Composite Potential Fields",
      "url": "https://arxiv.org/abs/2508.18527",
      "description": "arXiv:2508.18527v1 Announce Type: new \nAbstract: Guard patrol behavior is central to the immersion and strategic depth of stealth games, while most existing systems rely on hand-crafted routes or specialized logic that struggle to balance coverage efficiency and responsive pursuit with believable na...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "API",
        "arxiv",
        "RAG"
      ],
      "score": 0.8
    },
    {
      "title": "Learning Explainable Imaging-Genetics Associations Related to a Neurological Disorder",
      "url": "https://arxiv.org/abs/2508.18303",
      "description": "arXiv:2508.18303v1 Announce Type: new \nAbstract: While imaging-genetics holds great promise for unraveling the complex interplay between brain structure and genetic variation in neurological disorders, traditional methods are limited to simplistic linear models or to black-box techniques that lack i...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "attention",
        "model",
        "arxiv",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "Learning Spatio-Temporal Dynamics via Operator-Valued RKHS and Kernel Koopman Methods",
      "url": "https://arxiv.org/abs/2508.18307",
      "description": "arXiv:2508.18307v1 Announce Type: new \nAbstract: We introduce a unified framework for learning the spatio-temporal dynamics of vector valued functions by combining operator valued reproducing kernel Hilbert spaces (OV-RKHS) with kernel based Koopman operator methods. The approach enables nonparametr...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "model",
        "framework",
        "vector",
        "tool"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "tool",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "model",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Semantic Attractors and the Emergence of Meaning: Towards a Teleological Model of AGI",
      "url": "https://arxiv.org/abs/2508.18290",
      "description": "arXiv:2508.18290v1 Announce Type: new \nAbstract: This essay develops a theoretical framework for a semantic Artificial General Intelligence (AGI) based on the notion of semantic attractors in complex-valued meaning spaces. Departing from current transformer-based language models, which operate on st...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "model",
        "transformer",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Language Models For Generalised PDDL Planning: Synthesising Sound and Programmatic Policies",
      "url": "https://arxiv.org/abs/2508.18507",
      "description": "arXiv:2508.18507v1 Announce Type: new \nAbstract: We study the usage of language models (LMs) for planning over world models specified in the Planning Domain Definition Language (PDDL). We prompt LMs to generate Python programs that serve as generalised policies for solving PDDL problems from a given...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "model",
        "framework",
        "experiment",
        "prompt",
        "memory",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Can Out-of-Distribution Evaluations Uncover Reliance on Shortcuts? A Case Study in Question Answering",
      "url": "https://arxiv.org/abs/2508.18407",
      "description": "arXiv:2508.18407v1 Announce Type: new \nAbstract: A majority of recent work in AI assesses models' generalization capabilities through the lens of performance on out-of-distribution (OOD) datasets. Despite their practicality, such evaluations build upon a strong assumption: that OOD evaluations can c...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "study"
      ],
      "score": 0.4
    },
    {
      "title": "Information Templates: A New Paradigm for Intelligent Active Feature Acquisition",
      "url": "https://arxiv.org/abs/2508.18380",
      "description": "arXiv:2508.18380v1 Announce Type: new \nAbstract: Active feature acquisition (AFA) is an instance-adaptive paradigm in which, at test time, a policy sequentially chooses which features to acquire (at a cost) before predicting. Existing approaches either train reinforcement learning (RL) policies, whi...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "template",
        "library",
        "framework",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "Symmetry-Invariant Novelty Heuristics via Unsupervised Weisfeiler-Leman Features",
      "url": "https://arxiv.org/abs/2508.18520",
      "description": "arXiv:2508.18520v1 Announce Type: new \nAbstract: Novelty heuristics aid heuristic search by exploring states that exhibit novel atoms. However, novelty heuristics are not symmetry invariant and hence may sometimes lead to redundant exploration. In this preliminary report, we propose to use Weisfeile...",
      "published_date": "2025-08-27T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}