{
  "generated_at": "2025-07-23T20:05:38.888067",
  "total_items": 47,
  "items": [
    {
      "title": "eSapiens's DEREK Module: Deep Extraction & Reasoning Engine for Knowledge with LLMs",
      "url": "https://arxiv.org/abs/2507.15863",
      "description": "arXiv:2507.15863v1 Announce Type: new \nAbstract: We present the DEREK (Deep Extraction & Reasoning Engine for Knowledge) Module, a secure and scalable Retrieval-Augmented Generation pipeline designed specifically for enterprise document question answering. Designed and implemented by eSapiens, the s...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "LLM",
        "vector",
        "arxiv",
        "API",
        "product",
        "prompt",
        "GPT",
        "prompt engineering",
        "context",
        "reasoning",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "Small Edits, Big Consequences: Telling Good from Bad Robustness in Large Language Models",
      "url": "https://arxiv.org/abs/2507.15868",
      "description": "arXiv:2507.15868v1 Announce Type: new \nAbstract: Large language models (LLMs) now write code in settings where misreading a single word can break safety or cost money, yet we still expect them to overlook stray typos. To probe where useful robustness ends and harmful insensitivity begins, we compile...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "LLM",
        "arxiv",
        "large language model",
        "prompt",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Enhancing Hindi NER in Low Context: A Comparative study of Transformer-based models with vs. without Retrieval Augmentation",
      "url": "https://arxiv.org/abs/2507.16002",
      "description": "arXiv:2507.16002v1 Announce Type: new \nAbstract: One major challenge in natural language processing is named entity recognition (NER), which identifies and categorises named entities in textual input. In order to improve NER, this study investigates a Hindi NER technique that makes use of Hindi-spec...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "transformer",
        "arxiv",
        "study",
        "GPT",
        "few-shot",
        "context",
        "augmented",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Learning without training: The implicit dynamics of in-context learning",
      "url": "https://arxiv.org/abs/2507.16003",
      "description": "arXiv:2507.16003v1 Announce Type: new \nAbstract: One of the most striking features of Large Language Models (LLM) is their ability to learn in context. Namely at inference time an LLM is able to learn new patterns without any additional weight update when these patterns are presented in the form of ...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "LLM",
        "transformer",
        "in-context",
        "example",
        "arxiv",
        "attention",
        "large language model",
        "prompt",
        "experiment",
        "context",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Help Me Write a Story: Evaluating LLMs' Ability to Generate Writing Feedback",
      "url": "https://arxiv.org/abs/2507.16007",
      "description": "arXiv:2507.16007v1 Announce Type: new \nAbstract: Can LLMs provide support to creative writers by giving meaningful writing feedback? In this paper, we explore the challenges and limitations of model-generated writing feedback by defining a new task, dataset, and evaluation frameworks. To study model...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "LLM",
        "framework",
        "arxiv",
        "study",
        "analysis",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "mRAKL: Multilingual Retrieval-Augmented Knowledge Graph Construction for Low-Resourced Languages",
      "url": "https://arxiv.org/abs/2507.16011",
      "description": "arXiv:2507.16011v1 Announce Type: new \nAbstract: Knowledge Graphs represent real-world entities and the relationships between them. Multilingual Knowledge Graph Construction (mKGC) refers to the task of automatically constructing or predicting missing entities and links for knowledge graphs in a mul...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "arxiv",
        "RAG",
        "experiment",
        "context",
        "augmented",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "AutoMeet: a proof-of-concept study of genAI to automate meetings in automotive engineering",
      "url": "https://arxiv.org/abs/2507.16054",
      "description": "arXiv:2507.16054v1 Announce Type: new \nAbstract: In large organisations, knowledge is mainly shared in meetings, which takes up significant amounts of work time. Additionally, frequent in-person meetings produce inconsistent documentation -- official minutes, personal notes, presentations may or may...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "arxiv",
        "study",
        "tool",
        "large language model",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Deep Researcher with Test-Time Diffusion",
      "url": "https://arxiv.org/abs/2507.16075",
      "description": "arXiv:2507.16075v1 Announce Type: new \nAbstract: Deep research agents, powered by Large Language Models (LLMs), are rapidly advancing; yet, their performance often plateaus when generating complex, long-form research reports using generic test-time scaling algorithms. Drawing inspiration from the it...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "retrieval",
        "vision",
        "LLM",
        "framework",
        "arxiv",
        "API",
        "large language model",
        "reasoning",
        "research",
        "context",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "The Prompt Makes the Person(a): A Systematic Evaluation of Sociodemographic Persona Prompting for Large Language Models",
      "url": "https://arxiv.org/abs/2507.16076",
      "description": "arXiv:2507.16076v1 Announce Type: new \nAbstract: Persona prompting is increasingly used in large language models (LLMs) to simulate views of various sociodemographic groups. However, how a persona prompt is formulated can significantly affect outcomes, raising concerns about the fidelity of such sim...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "LLM",
        "arxiv",
        "alignment",
        "large language model",
        "prompt",
        "prompting",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "From Reasoning to Super-Intelligence: A Search-Theoretic Perspective",
      "url": "https://arxiv.org/abs/2507.15865",
      "description": "arXiv:2507.15865v1 Announce Type: new \nAbstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing the problem-solving capabilities of large language models (LLMs). However, the theoretical foundations of learning from CoT data remain underdeveloped, and existing approach...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "LLM",
        "framework",
        "arxiv",
        "fine-tuning",
        "model",
        "tool",
        "large language model",
        "CoT",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "Why Braking? Scenario Extraction and Reasoning Utilizing LLM",
      "url": "https://arxiv.org/abs/2507.15874",
      "description": "arXiv:2507.15874v1 Announce Type: new \nAbstract: The growing number of ADAS-equipped vehicles has led to a dramatic increase in driving data, yet most of them capture routine driving behavior. Identifying and understanding safety-critical corner cases within this vast dataset remains a significant c...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "paper",
        "retrieval",
        "experiment",
        "LLM",
        "framework",
        "arxiv",
        "RAG",
        "large language model",
        "embedding",
        "reasoning",
        "ICL",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Differential Multimodal Transformers",
      "url": "https://arxiv.org/abs/2507.15875",
      "description": "arXiv:2507.15875v1 Announce Type: new \nAbstract: Small language models have gained significant popularity due to their efficiency and growing capabilities. However, incorporating additional modalities, such as vision, can exacerbate the challenge of limited context windows by introducing noise. Rece...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "retrieval",
        "vision",
        "transformer",
        "arxiv",
        "multimodal",
        "fine-tuning",
        "attention",
        "experiment",
        "context",
        "context window",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning",
      "url": "https://arxiv.org/abs/2507.15877",
      "description": "arXiv:2507.15877v1 Announce Type: new \nAbstract: We run a controlled compositional generalization experiment in the ARC-AGI domain: an open-world problem domain in which the ability to generalize out-of-distribution is, by design, an essential characteristic for success. We compare neural program sy...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "fine-tuning",
        "LLM",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture",
      "url": "https://arxiv.org/abs/2507.15880",
      "description": "arXiv:2507.15880v1 Announce Type: new \nAbstract: Intelligence-biological, artificial, or collective-requires structural coherence across recursive reasoning processes to scale effectively. As complex systems grow, coherence becomes fragile unless a higher-order structure ensures semantic consistency...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "alignment",
        "RAG",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation",
      "url": "https://arxiv.org/abs/2507.15901",
      "description": "arXiv:2507.15901v1 Announce Type: new \nAbstract: The implementation of Artificial Intelligence (AI) in household environments, especially in the form of proactive autonomous agents, brings about possibilities of comfort and attention as well as it comes with intra or extramural ethical challenges. T...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "study",
        "attention",
        "analysis",
        "context",
        "ICL"
      ],
      "score": 1.0
    },
    {
      "title": "Quantifying Holistic Review: A Multi-Modal Approach to College Admissions Prediction",
      "url": "https://arxiv.org/abs/2507.15862",
      "description": "arXiv:2507.15862v1 Announce Type: new \nAbstract: This paper introduces the Comprehensive Applicant Profile Score (CAPS), a novel multi-modal framework designed to quantitatively model and interpret holistic college admissions evaluations. CAPS decomposes applicant profiles into three interpretable c...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "paper",
        "transformer",
        "LLM",
        "framework",
        "arxiv",
        "RAG",
        "embedding",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Prompt Smart, Pay Less: Cost-Aware APO for Real-World Applications",
      "url": "https://arxiv.org/abs/2507.15884",
      "description": "arXiv:2507.15884v1 Announce Type: new \nAbstract: Prompt design is a critical factor in the effectiveness of Large Language Models (LLMs), yet remains largely heuristic, manual, and difficult to scale. This paper presents the first comprehensive evaluation of Automatic Prompt Optimization (APO) metho...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "vision",
        "LLM",
        "framework",
        "arxiv",
        "multimodal",
        "product",
        "large language model",
        "prompt",
        "research",
        "API",
        "ICL",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Towards Mitigation of Hallucination for LLM-empowered Agents: Progressive Generalization Bound Exploration and Watchdog Monitor",
      "url": "https://arxiv.org/abs/2507.15903",
      "description": "arXiv:2507.15903v1 Announce Type: new \nAbstract: Empowered by large language models (LLMs), intelligent agents have become a popular paradigm for interacting with open environments to facilitate AI deployment. However, hallucinations generated by LLMs-where outputs are inconsistent with facts-pose a...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "framework",
        "arxiv",
        "large language model",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Foundation Models and Transformers for Anomaly Detection: A Survey",
      "url": "https://arxiv.org/abs/2507.15905",
      "description": "arXiv:2507.15905v1 Announce Type: new \nAbstract: In line with the development of deep learning, this survey examines the transformative role of Transformers and foundation models in advancing visual anomaly detection (VAD). We explore how these architectures, with their global receptive fields and a...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "transformer",
        "arxiv",
        "RAG",
        "attention",
        "few-shot",
        "context",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Towards Reliable, Uncertainty-Aware Alignment",
      "url": "https://arxiv.org/abs/2507.15906",
      "description": "arXiv:2507.15906v1 Announce Type: new \nAbstract: Alignment of large language models (LLMs) typically involves training a reward model on preference data, followed by policy optimization with respect to the reward model. However, optimizing policies with respect to a single reward model estimate can ...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "framework",
        "arxiv",
        "study",
        "alignment",
        "large language model",
        "experiment",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "context window",
        "prompt engineering",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "CoT",
        "reasoning",
        "audio",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "framework",
        "chain-of-thought"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "context",
        "LLM",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "LLM",
        "framework",
        "vector",
        "knowledge base",
        "RAG",
        "reasoning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "fine-tuning",
        "LLM",
        "tool",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "product",
        "RAG",
        "API",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "framework",
        "prompt",
        "platform",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "framework",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "ADEPTS: A Capability Framework for Human-Centered Agent Design",
      "url": "https://arxiv.org/abs/2507.15885",
      "description": "arXiv:2507.15885v1 Announce Type: new \nAbstract: Large language models have paved the way to powerful and flexible AI agents, assisting humans by increasingly integrating into their daily life. This flexibility, potential, and growing adoption demands a holistic and cross-disciplinary approach to de...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "arxiv",
        "large language model",
        "research",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture",
      "url": "https://arxiv.org/abs/2507.15895",
      "description": "arXiv:2507.15895v1 Announce Type: new \nAbstract: Reinforcement Learning is a machine learning methodology that has demonstrated strong performance across a variety of tasks. In particular, it plays a central role in the development of artificial autonomous agents. As these agents become increasingly...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "example",
        "framework",
        "arxiv",
        "study",
        "API",
        "experiment",
        "reasoning",
        "research"
      ],
      "score": 0.8
    },
    {
      "title": "Improving the Generation of VAEs with High Dimensional Latent Spaces by the use of Hyperspherical Coordinates",
      "url": "https://arxiv.org/abs/2507.15900",
      "description": "arXiv:2507.15900v1 Announce Type: new \nAbstract: Variational autoencoders (VAE) encode data into lower-dimensional latent vectors before decoding those vectors back to data. Once trained, decoding a random latent vector from the prior usually does not produce meaningful data, at least when the laten...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "vector",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "API",
        "tool",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "model",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "Adversarial Demonstration Learning for Low-resource NER Using Dual Similarity",
      "url": "https://arxiv.org/abs/2507.15864",
      "description": "arXiv:2507.15864v1 Announce Type: new \nAbstract: We study the problem of named entity recognition (NER) based on demonstration learning in low-resource scenarios. We identify two issues in demonstration construction and model training. Firstly, existing methods for selecting demonstration examples p...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "example",
        "demonstration",
        "arxiv",
        "study",
        "experiment",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "RDMA: Cost Effective Agent-Driven Rare Disease Discovery within Electronic Health Record Systems",
      "url": "https://arxiv.org/abs/2507.15867",
      "description": "arXiv:2507.15867v1 Announce Type: new \nAbstract: Rare diseases affect 1 in 10 Americans, yet standard ICD coding systems fail to capture these conditions in electronic health records (EHR), leaving crucial information buried in clinical notes. Current approaches struggle with medical abbreviations, ...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "reasoning",
        "framework",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "Purchase and Production Optimization in a Meat Processing Plant",
      "url": "https://arxiv.org/abs/2507.15866",
      "description": "arXiv:2507.15866v1 Announce Type: new \nAbstract: The food production industry, especially the meat production sector, faces many challenges that have even escalated due to the recent outbreak of the energy crisis in the European Union. Therefore, efficient use of input materials is an essential aspe...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "company",
        "paper",
        "product",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach",
      "url": "https://arxiv.org/abs/2507.15876",
      "description": "arXiv:2507.15876v1 Announce Type: new \nAbstract: Commodity Trading Advisors (CTAs) have historically relied on trend-following rules that operate on vastly different horizons from long-term breakouts that capture major directional moves to short-term momentum signals that thrive in fast-moving marke...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "model",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "An open dataset of neural networks for hypernetwork research",
      "url": "https://arxiv.org/abs/2507.15869",
      "description": "arXiv:2507.15869v1 Announce Type: new \nAbstract: Despite the transformative potential of AI, the concept of neural networks that can produce other neural networks by generating model weights (hypernetworks) has been largely understudied. One of the possible reasons is the lack of available research ...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "research",
        "model",
        "image"
      ],
      "score": 0.4
    },
    {
      "title": "ReDi: Rectified Discrete Flow",
      "url": "https://arxiv.org/abs/2507.15897",
      "description": "arXiv:2507.15897v1 Announce Type: new \nAbstract: Discrete Flow-based Models (DFMs) are powerful generative models for high-quality discrete data but typically suffer from slow sampling speeds due to their reliance on iterative decoding processes. This reliance on a multi-step process originates from...",
      "published_date": "2025-07-23T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "arxiv",
        "model",
        "image"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "TimeScope: How Long Can Your Video Large Multimodal Model Go?",
      "url": "https://huggingface.co/blog/timescope-video-lmm-benchmark",
      "description": "...",
      "published_date": "2025-07-23T00:00:00",
      "source": "Hugging Face Blog",
      "category": "multimodal_context",
      "keywords": [
        "multimodal",
        "model"
      ],
      "score": 0.2
    }
  ]
}