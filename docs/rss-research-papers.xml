<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>How Well Do LLMs Understand Tunisian Arabic?</title>
      <link>https://arxiv.org/abs/2511.16683</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16683</guid>
      <description>arXiv:2511.16683v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are the engines driving today&amp;#x27;s AI agents. The better these models understand human languages, the more natural and user-friendly the interaction with AI becomes, from everyday devices like computers and smartwatches to an...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, analysis, tool, model, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>analysis</category>
      <category>tool</category>
    </item>
    <item>
      <title>Prompt-Based Value Steering of Large Language Models</title>
      <link>https://arxiv.org/abs/2511.16688</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16688</guid>
      <description>arXiv:2511.16688v1 Announce Type: new 
Abstract: Large language models are increasingly used in applications where alignment with human values is critical. While model fine-tuning is often employed to ensure safe responses, this technique is static and does not lend itself to everyday situations inv...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, paper, alignment, model, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>paper</category>
      <category>alignment</category>
    </item>
    <item>
      <title>Concept-Based Interpretability for Toxicity Detection</title>
      <link>https://arxiv.org/abs/2511.16689</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16689</guid>
      <description>arXiv:2511.16689v1 Announce Type: new 
Abstract: The rise of social networks has not only facilitated communication but also allowed the spread of harmful content. Although significant advances have been made in detecting toxic language in textual data, the exploration of concept-based explanations ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, alignment, model, RAG, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>alignment</category>
      <category>model</category>
    </item>
    <item>
      <title>Falsely Accused: How AI Detectors Misjudge Slightly Polished Arabic Articles</title>
      <link>https://arxiv.org/abs/2511.16690</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16690</guid>
      <description>arXiv:2511.16690v1 Announce Type: new 
Abstract: Many AI detection models have been developed to counter the presence of articles created by artificial intelligence (AI). However, if a human-authored article is slightly polished by AI, a shift will occur in the borderline decision of these AI detect...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, ICL, paper, model, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>ICL</category>
      <category>paper</category>
    </item>
    <item>
      <title>How Language Directions Align with Token Geometry in Multilingual LLMs</title>
      <link>https://arxiv.org/abs/2511.16693</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16693</guid>
      <description>arXiv:2511.16693v1 Announce Type: new 
Abstract: Multilingual LLMs demonstrate strong performance across diverse languages, yet there has been limited systematic analysis of how language information is structured within their internal representation space and how it emerges across layers. We conduct...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; ICL, arxiv, analysis, embedding, alignment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>ICL</category>
      <category>arxiv</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Stable diffusion models reveal a persisting human and AI gap in visual creativity</title>
      <link>https://arxiv.org/abs/2511.16814</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16814</guid>
      <description>arXiv:2511.16814v1 Announce Type: new 
Abstract: While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, product, context, research, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>product</category>
      <category>context</category>
    </item>
    <item>
      <title>Fantastic Bugs and Where to Find Them in AI Benchmarks</title>
      <link>https://arxiv.org/abs/2511.16842</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16842</guid>
      <description>arXiv:2511.16842v1 Announce Type: new 
Abstract: Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottlen...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, model, RAG, vision | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>model</category>
    </item>
    <item>
      <title>The Belief-Desire-Intention Ontology for modelling mental reality and agency</title>
      <link>https://arxiv.org/abs/2511.17162</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.17162</guid>
      <description>arXiv:2511.17162v1 Announce Type: new 
Abstract: The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. Th...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, paper, reasoning, platform | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>paper</category>
    </item>
    <item>
      <title>When Structure Doesn&amp;#x27;t Help: LLMs Do Not Read Text-Attributed Graphs as Effectively as We Expected</title>
      <link>https://arxiv.org/abs/2511.16767</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16767</guid>
      <description>arXiv:2511.16767v1 Announce Type: new 
Abstract: Graphs provide a unified representation of semantic content and relational structure, making them a natural fit for domains such as molecular modeling, citation networks, and social graphs. Meanwhile, large language models (LLMs) have excelled at unde...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, product, reasoning, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>product</category>
    </item>
    <item>
      <title>GCL-OT: Graph Contrastive Learning with Optimal Transport for Heterophilic Text-Attributed Graphs</title>
      <link>https://arxiv.org/abs/2511.16778</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16778</guid>
      <description>arXiv:2511.16778v1 Announce Type: new 
Abstract: Recently, structure-text contrastive learning has shown promising performance on text-attributed graphs by leveraging the complementary strengths of graph neural networks and language models. However, existing methods typically rely on homophily assum...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, framework, embedding, alignment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>framework</category>
    </item>
    <item>
      <title>A Robust Federated Learning Approach for Combating Attacks Against IoT Systems Under non-IID Challenges</title>
      <link>https://arxiv.org/abs/2511.16822</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16822</guid>
      <description>arXiv:2511.16822v1 Announce Type: new 
Abstract: In the context of the growing proliferation of user devices and the concurrent surge in data volumes, the complexities arising from the substantial increase in data have posed formidable challenges to conventional machine learning model training. Part...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, context, research, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>context</category>
    </item>
    <item>
      <title>Analysis of heart failure patient trajectories using sequence modeling</title>
      <link>https://arxiv.org/abs/2511.16839</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16839</guid>
      <description>arXiv:2511.16839v1 Announce Type: new 
Abstract: Transformers have defined the state-of-the-art for clinical prediction tasks involving electronic health records (EHRs). The recently introduced Mamba architecture outperformed an advanced Transformer (Transformer++) based on Llama in handling long co...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, paper, analysis, context, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>paper</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving</title>
      <link>https://arxiv.org/abs/2511.16916</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16916</guid>
      <description>arXiv:2511.16916v1 Announce Type: new 
Abstract: In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for po...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; ICL, arxiv, experiment, paper, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>ICL</category>
      <category>arxiv</category>
      <category>experiment</category>
    </item>
    <item>
      <title>DDTime: Dataset Distillation with Spectral Alignment and Information Bottleneck for Time-Series Forecasting</title>
      <link>https://arxiv.org/abs/2511.16715</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16715</guid>
      <description>arXiv:2511.16715v1 Announce Type: new 
Abstract: Time-series forecasting is fundamental across many domains, yet training accurate models often requires large-scale datasets and substantial computational resources. Dataset distillation offers a promising alternative by synthesizing compact datasets ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, experiment, release, alignment, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>experiment</category>
      <category>release</category>
    </item>
    <item>
      <title>Comparing verbal, visual and combined explanations for Bayesian Network inferences</title>
      <link>https://arxiv.org/abs/2511.16961</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2511.16961</guid>
      <description>arXiv:2511.16961v1 Announce Type: new 
Abstract: Bayesian Networks (BNs) are an important tool for assisting probabilistic reasoning, but despite being considered transparent models, people have trouble understanding them. Further, current User Interfaces (UIs) still do not clarify the reasoning of ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, reasoning, tool, model, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 24 Nov 2025 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>reasoning</category>
      <category>tool</category>
    </item>
  </channel>
</rss>