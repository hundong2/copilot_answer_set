<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>Decomposing Attention To Find Context-Sensitive Neurons</title>
      <link>https://arxiv.org/abs/2510.03315</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03315</guid>
      <description>arXiv:2510.03315v1 Announce Type: new 
Abstract: We study transformer language models, analyzing attention heads whose attention patterns are spread out, and whose attention scores depend weakly on content. We argue that the softmax denominators of these heads are stable when the underlying token di...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, context, GPT, attention, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>context</category>
      <category>GPT</category>
    </item>
    <item>
      <title>Implicit Values Embedded in How Humans and LLMs Complete Subjective Everyday Tasks</title>
      <link>https://arxiv.org/abs/2510.03384</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03384</guid>
      <description>arXiv:2510.03384v1 Announce Type: new 
Abstract: Large language models (LLMs) can underpin AI assistants that help users with everyday tasks, such as by making recommendations or performing basic computation. Despite AI assistants&amp;#x27; promise, little is known about the implicit values these assistants ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, arxiv, large language model, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>arxiv</category>
      <category>large language model</category>
    </item>
    <item>
      <title>ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection</title>
      <link>https://arxiv.org/abs/2510.03502</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03502</guid>
      <description>arXiv:2510.03502v1 Announce Type: new 
Abstract: We introduce ALHD, the first large-scale comprehensive Arabic dataset explicitly designed to distinguish between human- and LLM-generated texts. ALHD spans three genres (news, social media, reviews), covering both MSA and dialectal Arabic, and contain...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, zero-shot, model, few-shot, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>zero-shot</category>
      <category>model</category>
    </item>
    <item>
      <title>TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning</title>
      <link>https://arxiv.org/abs/2510.03519</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03519</guid>
      <description>arXiv:2510.03519v1 Announce Type: new 
Abstract: Time series reasoning is crucial to decision-making in diverse domains, including finance, energy usage, traffic, weather, and scientific discovery. While existing time series foundation models (TSFMs) can capture low-level dynamic patterns and provid...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; instruction, alignment, vision, model, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>instruction</category>
      <category>alignment</category>
      <category>vision</category>
    </item>
    <item>
      <title>Identifying Financial Risk Information Using RAG with a Contrastive Insight</title>
      <link>https://arxiv.org/abs/2510.03521</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03521</guid>
      <description>arXiv:2510.03521v1 Announce Type: new 
Abstract: In specialized domains, humans often compare new problems against similar examples, highlight nuances, and draw conclusions instead of analyzing information in isolation. When applying reasoning in specialized contexts with LLMs on top of a RAG, the p...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, context, LLM, reasoning, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>context</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Know Thyself? On the Incapability and Implications of AI Self-Recognition</title>
      <link>https://arxiv.org/abs/2510.03399</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03399</guid>
      <description>arXiv:2510.03399v1 Announce Type: new 
Abstract: Self-recognition is a crucial metacognitive capability for AI systems, relevant not only for psychological analysis but also for safety, particularly in evaluative scenarios. Motivated by contradictory interpretations of whether models possess self-re...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, model, LLM, GPT, analysis | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>model</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification</title>
      <link>https://arxiv.org/abs/2510.03469</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03469</guid>
      <description>arXiv:2510.03469v1 Announce Type: new 
Abstract: We introduce a novel framework for evaluating the alignment between natural language plans and their expected behavior by converting them into Kripke structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs) and performing model ch...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, alignment, model, experiment, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>alignment</category>
      <category>model</category>
    </item>
    <item>
      <title>Understanding the Role of Training Data in Test-Time Scaling</title>
      <link>https://arxiv.org/abs/2510.03605</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03605</guid>
      <description>arXiv:2510.03605v1 Announce Type: new 
Abstract: Test-time scaling improves the reasoning capabilities of large language models (LLMs) by allocating extra compute to generate longer Chains-of-Thoughts (CoTs). This enables models to tackle more complex problem by breaking them down into additional st...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; CoT, in-context, model, context, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>CoT</category>
      <category>in-context</category>
      <category>model</category>
    </item>
    <item>
      <title>PARS: Low-Latency LLM Serving via Pairwise Learning-to-Rank</title>
      <link>https://arxiv.org/abs/2510.03243</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03243</guid>
      <description>arXiv:2510.03243v1 Announce Type: new 
Abstract: Efficient scheduling of LLM inference tasks is essential for achieving low latency and high throughput, particularly with the growing use of reasoning-capable LLMs. Traditional strategies like First-Come-First-Serve (FCFS) often suffer from Head-of-Li...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, experiment, prompt, LLM, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>experiment</category>
      <category>prompt</category>
    </item>
    <item>
      <title>Numerion: A Multi-Hypercomplex Model for Time Series Forecasting</title>
      <link>https://arxiv.org/abs/2510.03251</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03251</guid>
      <description>arXiv:2510.03251v1 Announce Type: new 
Abstract: Many methods aim to enhance time series forecasting by decomposing the series through intricate model structures and prior knowledge, yet they are inevitably limited by computational complexity and the robustness of the assumptions. Our research uncov...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, research, experiment, RAG, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>research</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Solving the Granularity Mismatch: Hierarchical Preference Learning for Long-Horizon LLM Agents</title>
      <link>https://arxiv.org/abs/2510.03253</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03253</guid>
      <description>arXiv:2510.03253v1 Announce Type: new 
Abstract: Large Language Models (LLMs) as autonomous agents are increasingly tasked with solving complex, long-horizon problems. Aligning these agents via preference-based offline methods like Direct Preference Optimization (DPO) is a promising direction, yet i...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, model, experiment, large language model, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>model</category>
      <category>experiment</category>
    </item>
    <item>
      <title>WAREX: Web Agent Reliability Evaluation on Existing Benchmarks</title>
      <link>https://arxiv.org/abs/2510.03285</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03285</guid>
      <description>arXiv:2510.03285v1 Announce Type: new 
Abstract: Recent advances in browser-based LLM agents have shown promise for automating tasks ranging from simple form filling to hotel booking or online shopping. Current benchmarks measure agent performance in controlled environments, such as containers or st...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, arxiv, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>arxiv</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Towards Policy-Compliant Agents: Learning Efficient Guardrails For Policy Violation Detection</title>
      <link>https://arxiv.org/abs/2510.03485</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03485</guid>
      <description>arXiv:2510.03485v1 Announce Type: new 
Abstract: Autonomous web agents need to operate under externally imposed or human-specified policies while generating long-horizon trajectories. However, little work has examined whether these trajectories comply with such policies, or whether policy violations...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; framework, model, context, product, study | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>framework</category>
      <category>model</category>
      <category>context</category>
    </item>
    <item>
      <title>Frequency-Aware Model Parameter Explorer: A new attribution method for improving explainability</title>
      <link>https://arxiv.org/abs/2510.03245</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03245</guid>
      <description>arXiv:2510.03245v1 Announce Type: new 
Abstract: Ensuring the reliability of deep neural networks (DNNs) in the presence of real world noise and intentional perturbations remains a significant challenge. To address this, attribution methods have been proposed, though their efficacy remains suboptima...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, RAG, arxiv, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>RAG</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Real-Time Brain Biomechanics Prediction with Neural Operators: Toward Clinically Deployable Traumatic Brain Injury Models</title>
      <link>https://arxiv.org/abs/2510.03248</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03248</guid>
      <description>arXiv:2510.03248v1 Announce Type: new 
Abstract: Traumatic brain injury (TBI) remains a major public health concern, with over 69 million cases annually worldwide. Finite element (FE) models offer high-fidelity predictions of brain deformation but are computationally expensive, requiring hours per s...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, API, arxiv, study, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>API</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Searching for the Most Human-like Emergent Language</title>
      <link>https://arxiv.org/abs/2510.03467</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03467</guid>
      <description>arXiv:2510.03467v1 Announce Type: new 
Abstract: In this paper, we design a signalling game-based emergent communication environment to generate state-of-the-art emergent languages in terms of similarity to human language. This is done with hyperparameter optimization, using XferBench as the objecti...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; arxiv, paper | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>arxiv</category>
      <category>paper</category>
    </item>
    <item>
      <title>Refined Iterated Pareto Greedy for Energy-aware Hybrid Flowshop Scheduling with Blocking Constraints</title>
      <link>https://arxiv.org/abs/2510.03377</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2510.03377</guid>
      <description>arXiv:2510.03377v1 Announce Type: new 
Abstract: The scarcity of non-renewable energy sources, geopolitical problems in its supply, increasing prices, and the impact of climate change, force the global economy to develop more energy-efficient solutions for their operations. The Manufacturing sector ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, augmented, arxiv, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 07 Oct 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>augmented</category>
      <category>arxiv</category>
    </item>
  </channel>
</rss>