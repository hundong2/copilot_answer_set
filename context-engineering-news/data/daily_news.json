{
  "generated_at": "2025-08-25T20:05:28.845618",
  "total_items": 44,
  "items": [
    {
      "title": "KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration",
      "url": "https://arxiv.org/abs/2508.15790",
      "description": "arXiv:2508.15790v1 Announce Type: new \nAbstract: Large Language Models (LLMs) face challenges in knowledge-intensive reasoning tasks like classic multi-hop question and answering, which involves reasoning across multiple facts. This difficulty arises because the chain of thoughts (CoTs) generated by...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "LLM",
        "experiment",
        "large language model",
        "arxiv",
        "model",
        "reasoning",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "InteChar: A Unified Oracle Bone Character List for Ancient Chinese Language Modeling",
      "url": "https://arxiv.org/abs/2508.15791",
      "description": "arXiv:2508.15791v1 Announce Type: new \nAbstract: Constructing historical language models (LMs) plays a crucial role in aiding archaeological provenance studies and understanding ancient cultures. However, existing resources present major challenges for training effective LMs on historical texts. Fir...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "experiment",
        "research",
        "arxiv",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "Format as a Prior: Quantifying and Analyzing Bias in LLMs for Heterogeneous Data",
      "url": "https://arxiv.org/abs/2508.15793",
      "description": "arXiv:2508.15793v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly employed in applications that require processing information from heterogeneous formats, including text, tables, infoboxes, and knowledge graphs. However, systematic biases toward particular formats may un...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "large language model",
        "research",
        "arxiv",
        "attention",
        "model",
        "reasoning",
        "paper",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "Benchmarking the Legal Reasoning of LLMs in Arabic Islamic Inheritance Cases",
      "url": "https://arxiv.org/abs/2508.15796",
      "description": "arXiv:2508.15796v1 Announce Type: new \nAbstract: Islamic inheritance domain holds significant importance for Muslims to ensure fair distribution of shares between heirs. Manual calculation of shares under numerous scenarios is complex, time-consuming, and error-prone. Recent advancements in Large La...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "alignment",
        "large language model",
        "analysis",
        "arxiv",
        "model",
        "reasoning",
        "study",
        "RAG",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Benchmarking the Medical Understanding and Reasoning of Large Language Models in Arabic Healthcare Tasks",
      "url": "https://arxiv.org/abs/2508.15797",
      "description": "arXiv:2508.15797v1 Announce Type: new \nAbstract: Recent progress in large language models (LLMs) has showcased impressive proficiency in numerous Arabic natural language processing (NLP) applications. Nevertheless, their effectiveness in Arabic medical NLP domains has received limited investigation....",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "alignment",
        "large language model",
        "research",
        "analysis",
        "arxiv",
        "context",
        "model",
        "reasoning",
        "RAG",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "Persuasiveness and Bias in LLM: Investigating the Impact of Persuasiveness and Reinforcement of Bias in Language Models",
      "url": "https://arxiv.org/abs/2508.15798",
      "description": "arXiv:2508.15798v1 Announce Type: new \nAbstract: Warning: This research studies AI persuasion and bias amplification that could be misused; all experiments are for safety evaluation. Large Language Models (LLMs) now generate convincing, human-like text and are widely used in content creation, decisi...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "alignment",
        "experiment",
        "large language model",
        "research",
        "arxiv",
        "model",
        "framework",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "A Framework for Processing Textual Descriptions of Business Processes using a Constrained Language -- Technical Report",
      "url": "https://arxiv.org/abs/2508.15799",
      "description": "arXiv:2508.15799v1 Announce Type: new \nAbstract: This report explores how (potentially constrained) natural language can be used to enable non-experts to develop process models by simply describing scenarios in plain text. To this end, a framework, called BeePath, is proposed. It allows users to wri...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "LLM",
        "large language model",
        "arxiv",
        "model",
        "framework",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "A BERT-based Hierarchical Classification Model with Applications in Chinese Commodity Classification",
      "url": "https://arxiv.org/abs/2508.15800",
      "description": "arXiv:2508.15800v1 Announce Type: new \nAbstract: Existing e-commerce platforms heavily rely on manual annotation for product categorization, which is inefficient and inconsistent. These platforms often employ a hierarchical structure for categorizing products; however, few studies have leveraged thi...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "fine-tuning",
        "arxiv",
        "model",
        "platform",
        "product",
        "transformer",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Generative Foundation Model for Structured and Unstructured Electronic Health Records",
      "url": "https://arxiv.org/abs/2508.16054",
      "description": "arXiv:2508.16054v1 Announce Type: new \nAbstract: Electronic health records (EHRs) are rich clinical data sources but complex repositories of patient data, spanning structured elements (demographics, vitals, lab results, codes), unstructured clinical notes and other modalities of data. Harnessing thi...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "LLM",
        "large language model",
        "fine-tuning",
        "arxiv",
        "attention",
        "model",
        "cross-modal",
        "transformer",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Urban Comfort Assessment in the Era of Digital Planning: A Multidimensional, Data-driven, and AI-assisted Framework",
      "url": "https://arxiv.org/abs/2508.16057",
      "description": "arXiv:2508.16057v1 Announce Type: new \nAbstract: Ensuring liveability and comfort is one of the fundamental objectives of urban planning. Numerous studies have employed computational methods to assess and quantify factors related to urban comfort such as greenery coverage, thermal comfort, and walka...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "analysis",
        "arxiv",
        "framework",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Integrating Time Series into LLMs via Multi-layer Steerable Embedding Fusion for Enhanced Forecasting",
      "url": "https://arxiv.org/abs/2508.16059",
      "description": "arXiv:2508.16059v1 Announce Type: new \nAbstract: Time series (TS) data are ubiquitous across various application areas, rendering time series forecasting (TSF) a fundamental task. With the astounding advances in large language models (LLMs), a variety of methods have been developed to adapt LLMs for...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "alignment",
        "experiment",
        "large language model",
        "embedding",
        "arxiv",
        "model",
        "framework",
        "few-shot",
        "paper",
        "vector",
        "RAG",
        "few-shot learning"
      ],
      "score": 1.0
    },
    {
      "title": "InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles",
      "url": "https://arxiv.org/abs/2508.16072",
      "description": "arXiv:2508.16072v1 Announce Type: new \nAbstract: LLMs have shown strong performance on human-centric reasoning tasks. While previous evaluations have explored whether LLMs can infer intentions or detect deception, they often overlook the individualized reasoning styles that influence how people inte...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "alignment",
        "arxiv",
        "context",
        "framework",
        "reasoning",
        "study",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "IR-Agent: Expert-Inspired LLM Agents for Structure Elucidation from Infrared Spectra",
      "url": "https://arxiv.org/abs/2508.16112",
      "description": "arXiv:2508.16112v1 Announce Type: new \nAbstract: Spectral analysis provides crucial clues for the elucidation of unknown materials. Among various techniques, infrared spectroscopy (IR) plays an important role in laboratory settings due to its high accessibility and low cost. However, existing approa...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "experiment",
        "analysis",
        "arxiv",
        "framework",
        "reasoning",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Extending FKG.in: Towards a Food Claim Traceability Network",
      "url": "https://arxiv.org/abs/2508.16117",
      "description": "arXiv:2508.16117v1 Announce Type: new \nAbstract: The global food landscape is rife with scientific, cultural, and commercial claims about what foods are, what they do, what they should not do, or should not do. These range from rigorously studied health benefits (probiotics improve gut health) and m...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "research",
        "arxiv",
        "context",
        "model",
        "paper",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Bridging the Gap in Ophthalmic AI: MM-Retinal-Reason Dataset and OphthaReason Model toward Dynamic Multimodal Reasoning",
      "url": "https://arxiv.org/abs/2508.16129",
      "description": "arXiv:2508.16129v1 Announce Type: new \nAbstract: Multimodal large language models (MLLMs) have recently demonstrated remarkable reasoning abilities with reinforcement learning paradigm. Although several multimodal reasoning models have been explored in the medical domain, most of them focus exclusiv...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "LLM",
        "step-by-step",
        "experiment",
        "large language model",
        "arxiv",
        "model",
        "reasoning",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "Z-Pruner: Post-Training Pruning of Large Language Models for Efficiency without Retraining",
      "url": "https://arxiv.org/abs/2508.15828",
      "description": "arXiv:2508.15828v1 Announce Type: new \nAbstract: Large language models (LLMs) have rapidly advanced in recent years, achieving remarkable performance across a wide range of natural language processing tasks. However, this progress has come at the cost of increasingly large model sizes, which pose si...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "API",
        "experiment",
        "large language model",
        "fine-tuning",
        "arxiv",
        "model",
        "ICL",
        "RAG",
        "zero-shot"
      ],
      "score": 1.0
    },
    {
      "title": "PGF-Net: A Progressive Gated-Fusion Framework for Efficient Multimodal Sentiment Analysis",
      "url": "https://arxiv.org/abs/2508.15852",
      "description": "arXiv:2508.15852v1 Announce Type: new \nAbstract: We introduce PGF-Net (Progressive Gated-Fusion Network), a novel deep learning framework designed for efficient and interpretable multimodal sentiment analysis. Our framework incorporates three primary innovations. Firstly, we propose a Progressive In...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "analysis",
        "fine-tuning",
        "arxiv",
        "attention",
        "context",
        "model",
        "framework",
        "audio",
        "transformer",
        "multimodal"
      ],
      "score": 1.0
    },
    {
      "title": "TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill \\& Decode Inference",
      "url": "https://arxiv.org/abs/2508.15881",
      "description": "arXiv:2508.15881v1 Announce Type: new \nAbstract: Multi-Head Latent Attention (MLA), introduced in DeepSeek-V2, compresses key-value states into a low-rank latent vector, caching only this vector to reduce memory. In tensor parallelism (TP), however, attention heads are computed across multiple devic...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "memory",
        "arxiv",
        "attention",
        "context",
        "model",
        "vector",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Transforming Causality: Transformer-Based Temporal Causal Discovery with Prior Knowledge Integration",
      "url": "https://arxiv.org/abs/2508.15928",
      "description": "arXiv:2508.15928v1 Announce Type: new \nAbstract: We introduce a novel framework for temporal causal discovery and inference that addresses two key challenges: complex nonlinear dependencies and spurious correlations. Our approach employs a multi-layer Transformer-based time-series forecaster to capt...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "analysis",
        "arxiv",
        "attention",
        "framework",
        "transformer"
      ],
      "score": 1.0
    },
    {
      "title": "Low-dimensional embeddings of high-dimensional data",
      "url": "https://arxiv.org/abs/2508.15929",
      "description": "arXiv:2508.15929v1 Announce Type: new \nAbstract: Large collections of high-dimensional data have become nearly ubiquitous across many academic fields and application domains, ranging from biology to the humanities. Since working directly with high-dimensional data poses challenges, the demand for al...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "research",
        "analysis",
        "embedding",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "An Efficient Hybridization of Graph Representation Learning and Metaheuristics for the Constrained Incremental Graph Drawing Problem",
      "url": "https://arxiv.org/abs/2508.15949",
      "description": "arXiv:2508.15949v1 Announce Type: new \nAbstract: Hybridizing machine learning techniques with metaheuristics has attracted significant attention in recent years. Many attempts employ supervised or reinforcement learning to support the decision-making of heuristic methods. However, in some cases, the...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "embedding",
        "arxiv",
        "attention",
        "paper"
      ],
      "score": 1.0
    },
    {
      "title": "Vector preference-based contextual bandits under distributional shifts",
      "url": "https://arxiv.org/abs/2508.15966",
      "description": "arXiv:2508.15966v1 Announce Type: new \nAbstract: We consider contextual bandit learning under distribution shift when reward vectors are ordered according to a given preference cone. We propose an adaptive-discretization and optimistic elimination based policy that self-tunes to the underlying distr...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "context",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "context",
        "context window"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "framework",
        "reasoning",
        "audio",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "context",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "LLM",
        "attention",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "LLM",
        "retrieval",
        "model",
        "framework",
        "reasoning",
        "vector",
        "RAG",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "tool",
        "fine-tuning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "API",
        "product",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "platform",
        "framework",
        "vector",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs",
      "url": "https://arxiv.org/abs/2508.16051",
      "description": "arXiv:2508.16051v1 Announce Type: new \nAbstract: Multimodal Multi-hop question answering requires integrating information from diverse sources, such as images and texts, to derive answers. Existing methods typically rely on sequential retrieval and reasoning, where each step builds on the previous o...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "retrieval",
        "experiment",
        "arxiv",
        "model",
        "framework",
        "reasoning",
        "image",
        "multimodal"
      ],
      "score": 0.8
    },
    {
      "title": "Advancing rail safety: An onboard measurement system of rolling stock wheel flange wear based on dynamic machine learning algorithms",
      "url": "https://arxiv.org/abs/2508.15963",
      "description": "arXiv:2508.15963v1 Announce Type: new \nAbstract: Rail and wheel interaction functionality is pivotal to the railway system safety, requiring accurate measurement systems for optimal safety monitoring operation. This paper introduces an innovative onboard measurement system for monitoring wheel flang...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "analysis",
        "arxiv",
        "model",
        "ICL",
        "paper"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "API",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "reasoning",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Bhav-Net: Knowledge Transfer for Cross-Lingual Antonym vs Synonym Distinction via Dual-Space Graph Transformers",
      "url": "https://arxiv.org/abs/2508.15792",
      "description": "arXiv:2508.15792v1 Announce Type: new \nAbstract: Antonym vs synonym distinction across multiple languages presents unique computational challenges due to the paradoxical nature of antonymous relationships words that share semantic domains while expressing opposite meanings. This work introduces Bhav...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "transformer",
        "arxiv",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "T-ILR: a Neurosymbolic Integration for LTLf",
      "url": "https://arxiv.org/abs/2508.15943",
      "description": "arXiv:2508.15943v1 Announce Type: new \nAbstract: State-of-the-art approaches for integrating symbolic knowledge with deep learning architectures have demonstrated promising results in static domains. However, methods to handle temporal logic specifications remain underexplored. The only existing app...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "arxiv",
        "image",
        "framework"
      ],
      "score": 0.6
    },
    {
      "title": "Physics-Based Explainable AI for ECG Segmentation: A Lightweight Model",
      "url": "https://arxiv.org/abs/2508.15872",
      "description": "arXiv:2508.15872v1 Announce Type: new \nAbstract: The heart's electrical activity, recorded through Electrocardiography (ECG), is essential for diagnosing various cardiovascular conditions. However, many existing ECG segmentation models rely on complex, multi-layered architectures such as BiLSTM, whi...",
      "published_date": "2025-08-25T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "study",
        "model",
        "analysis"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt engineering",
        "prompt"
      ],
      "score": 0.6
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}