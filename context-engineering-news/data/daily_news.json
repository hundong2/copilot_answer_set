{
  "generated_at": "2025-08-08T20:05:48.383066",
  "total_items": 46,
  "items": [
    {
      "title": "Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM",
      "url": "https://arxiv.org/abs/2508.04795",
      "description": "arXiv:2508.04795v1 Announce Type: new \nAbstract: In dialogue transcription pipelines, Large Language Models (LLMs) are frequently employed in post-processing to improve grammar, punctuation, and readability. We explore a complementary post-processing step: enriching transcribed dialogues by adding m...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "large language model",
        "RAG",
        "arxiv",
        "vector",
        "model",
        "audio",
        "fine-tuning",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History",
      "url": "https://arxiv.org/abs/2508.04826",
      "description": "arXiv:2508.04826v1 Announce Type: new \nAbstract: Large language models require consistent behavioral patterns for safe deployment, yet their personality-like traits remain poorly understood. We present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive evaluation framework testing 25...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "framework",
        "alignment",
        "arxiv",
        "model",
        "LLM",
        "chain-of-thought",
        "prompt",
        "instruction",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory",
      "url": "https://arxiv.org/abs/2508.04903",
      "description": "arXiv:2508.04903v1 Announce Type: new \nAbstract: Multi-agent large language model (LLM) systems have shown strong potential in complex reasoning and collaborative decision-making tasks. However, most existing coordination schemes rely on static or full-context routing strategies, which lead to exces...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "experiment",
        "arxiv",
        "model",
        "memory",
        "context",
        "LLM",
        "framework",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations",
      "url": "https://arxiv.org/abs/2508.04939",
      "description": "arXiv:2508.04939v1 Announce Type: new \nAbstract: This paper introduces a comprehensive benchmark for evaluating how Large Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic markers that can inadvertently reveal demographic attributes such as gender, social class, or regional...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "RAG",
        "arxiv",
        "model",
        "paper",
        "context",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering",
      "url": "https://arxiv.org/abs/2508.04945",
      "description": "arXiv:2508.04945v1 Announce Type: new \nAbstract: Evaluating visual activity recognition systems is challenging due to inherent ambiguities in verb semantics and image interpretation. When describing actions in images, synonymous verbs can refer to the same event (e.g., brushing vs. grooming), while ...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "RAG",
        "alignment",
        "arxiv",
        "analysis",
        "model",
        "vision",
        "framework",
        "image"
      ],
      "score": 1.0
    },
    {
      "title": "A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health",
      "url": "https://arxiv.org/abs/2508.05003",
      "description": "arXiv:2508.05003v1 Announce Type: new \nAbstract: Background: Understanding social determinants of health (SDoH) factors contributing to suicide incidents is crucial for early intervention and prevention. However, data-driven approaches to this goal face challenges such as long-tailed factor distribu...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "arxiv",
        "analysis",
        "model",
        "study",
        "fine-tuning",
        "context",
        "GPT",
        "framework",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Evaluation of LLMs in AMR Parsing",
      "url": "https://arxiv.org/abs/2508.05028",
      "description": "arXiv:2508.05028v1 Announce Type: new \nAbstract: Meaning Representation (AMR) is a semantic formalism that encodes sentence meaning as rooted, directed, acyclic graphs, where nodes represent concepts and edges denote semantic relations. Finetuning decoder only Large Language Models (LLMs) represent ...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "analysis",
        "arxiv",
        "model",
        "paper",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Prescriptive Agents based on Rag for Automated Maintenance (PARAM)",
      "url": "https://arxiv.org/abs/2508.04714",
      "description": "arXiv:2508.04714v1 Announce Type: new \nAbstract: Industrial machinery maintenance requires timely intervention to prevent catastrophic failures and optimize operational efficiency. This paper presents an integrated Large Language Model (LLM)-based intelligent system for prescriptive maintenance that...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "RAG",
        "experiment",
        "arxiv",
        "analysis",
        "vector",
        "model",
        "few-shot",
        "paper",
        "embedding",
        "context",
        "LLM",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Who is a Better Player: LLM against LLM",
      "url": "https://arxiv.org/abs/2508.04720",
      "description": "arXiv:2508.04720v1 Announce Type: new \nAbstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and intelligence, have long served as both a popular competitive activity and a benchmark for evaluating artificial intelligence (AI) systems. Building on this foundation, we pro...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "large language model",
        "experiment",
        "arxiv",
        "model",
        "platform",
        "LLM",
        "framework",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)",
      "url": "https://arxiv.org/abs/2508.04846",
      "description": "arXiv:2508.04846v1 Announce Type: new \nAbstract: Autonomous web-based geographical information systems (AWebGIS) aim to perform geospatial operations from natural language input, providing intuitive, intelligent, and hands-free interaction. However, most current solutions rely on cloud-based large l...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "RAG",
        "arxiv",
        "vector",
        "model",
        "study",
        "fine-tuning",
        "LLM"
      ],
      "score": 1.0
    },
    {
      "title": "Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning",
      "url": "https://arxiv.org/abs/2508.04848",
      "description": "arXiv:2508.04848v1 Announce Type: new \nAbstract: Reinforcement learning (RL) has become a key technique for enhancing the reasoning abilities of large language models (LLMs), with policy-gradient algorithms dominating the post-training stage because of their efficiency and effectiveness. However, mo...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "arxiv",
        "model",
        "release",
        "fine-tuning",
        "vision",
        "context",
        "LLM",
        "research",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses",
      "url": "https://arxiv.org/abs/2508.05009",
      "description": "arXiv:2508.05009v1 Announce Type: new \nAbstract: We explore the application of large language models (LLMs) to empower domain experts in integrating large, heterogeneous, and noisy urban spatial datasets. Traditional rule-based integration methods are unable to cover all edge cases, requiring manual...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "large language model",
        "arxiv",
        "analysis",
        "model",
        "study",
        "context",
        "LLM",
        "research",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models",
      "url": "https://arxiv.org/abs/2508.05083",
      "description": "arXiv:2508.05083v1 Announce Type: new \nAbstract: Recent advances in multimodal large language models (MLLMs) have significantly improved medical AI, enabling it to unify the understanding of visual and textual information. However, as medical knowledge continues to evolve, it is critical to allow th...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "large language model",
        "multimodal",
        "experiment",
        "arxiv",
        "model",
        "LLM",
        "image"
      ],
      "score": 1.0
    },
    {
      "title": "LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation",
      "url": "https://arxiv.org/abs/2508.04732",
      "description": "arXiv:2508.04732v1 Announce Type: new \nAbstract: Text-to-Image (T2I) generation has made significant advancements with diffusion models, yet challenges persist in handling complex instructions, ensuring fine-grained content control, and maintaining deep semantic consistency. Existing T2I models ofte...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "RAG",
        "arxiv",
        "model",
        "instruction",
        "cross-modal",
        "vision",
        "framework",
        "prompt",
        "image"
      ],
      "score": 1.0
    },
    {
      "title": "MissMecha: An All-in-One Python Package for Studying Missing Data Mechanisms",
      "url": "https://arxiv.org/abs/2508.04740",
      "description": "arXiv:2508.04740v1 Announce Type: new \nAbstract: Incomplete data is a persistent challenge in real-world datasets, often governed by complex and unobservable missing mechanisms. Simulating missingness has become a standard approach for understanding its impact on learning and analysis. However, exis...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "arxiv",
        "analysis",
        "study",
        "platform",
        "tool",
        "research"
      ],
      "score": 1.0
    },
    {
      "title": "A Foundational Multi-Modal Model for Few-Shot Learning",
      "url": "https://arxiv.org/abs/2508.04746",
      "description": "arXiv:2508.04746v1 Announce Type: new \nAbstract: Few-shot learning (FSL) is a machine learning paradigm that aims to generalize models from a small number of labeled examples, typically fewer than 10 per class. FSL is particularly crucial in biomedical, environmental, materials, and mechanical scien...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "example",
        "arxiv",
        "model",
        "few-shot",
        "few-shot learning",
        "study",
        "fine-tuning",
        "tool",
        "framework",
        "image"
      ],
      "score": 1.0
    },
    {
      "title": "AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models",
      "url": "https://arxiv.org/abs/2508.04748",
      "description": "arXiv:2508.04748v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown promise in assisting molecular property prediction tasks but often rely on human-crafted prompts and chain-of-thought templates. While recent advanced large reasoning models like DeepSeek-R1 employ reinforcement...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "large language model",
        "prompting",
        "RAG",
        "reasoning",
        "framework",
        "arxiv",
        "experiment",
        "model",
        "release",
        "fine-tuning",
        "template",
        "LLM",
        "chain-of-thought",
        "prompt",
        "instruction",
        "GPT"
      ],
      "score": 1.0
    },
    {
      "title": "PA-RNet: Perturbation-Aware Reasoning Network for Multimodal Time Series Forecasting",
      "url": "https://arxiv.org/abs/2508.04750",
      "description": "arXiv:2508.04750v1 Announce Type: new \nAbstract: In real-world applications, multimodal time series data often suffer from interference, especially in the textual modality. Existing methods for multimodal time series forecasting often neglect the inherent perturbations within textual data, where irr...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "multimodal_context",
      "keywords": [
        "multimodal",
        "framework",
        "arxiv",
        "experiment",
        "model",
        "cross-modal",
        "embedding",
        "attention",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle",
      "url": "https://arxiv.org/abs/2508.04755",
      "description": "arXiv:2508.04755v1 Announce Type: new \nAbstract: Reinforcement learning (RL)-based dynamic treatment regimes (DTRs) hold promise for automating complex clinical decision-making, yet their practical deployment remains hindered by the intensive engineering required to inject clinical knowledge and ens...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "chain_of_thought",
      "keywords": [
        "large language model",
        "prompt engineering",
        "arxiv",
        "model",
        "CoT",
        "study",
        "zero-shot",
        "LLM",
        "chain-of-thought",
        "prompt",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration",
      "url": "https://arxiv.org/abs/2508.04780",
      "description": "arXiv:2508.04780v1 Announce Type: new \nAbstract: The increasing frequency of extreme weather events, such as hurricanes, highlights the urgent need for efficient and equitable power system restoration. Many electricity providers make restoration decisions primarily based on the volume of power resto...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "experiment",
        "framework",
        "analysis",
        "arxiv",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "context",
        "prompt",
        "prompt engineering"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "framework",
        "CoT",
        "audio",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "MoBA - MoBA: Mixture of Block Attention for Long-Context LLMs",
      "url": "https://github.com/MoonshotAI/MoBA",
      "description": "MoBA: Mixture of Block Attention for Long-Context LLMs",
      "published_date": "2025-02-17T13:27:30+00:00",
      "source": "GitHub",
      "category": "context_management",
      "keywords": [
        "context",
        "LLM",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "\"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "vector",
        "model",
        "retrieval",
        "LLM",
        "framework",
        "knowledge base",
        "reasoning"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "model",
        "tool",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "augmented",
        "RAG",
        "product",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "vector",
        "platform",
        "LLM",
        "framework",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "GeoFlow: Agentic Workflow Automation for Geospatial Tasks",
      "url": "https://arxiv.org/abs/2508.04719",
      "description": "arXiv:2508.04719v1 Announce Type: new \nAbstract: We present GeoFlow, a method that automatically generates agentic workflows for geospatial tasks. Unlike prior work that focuses on reasoning decomposition and leaves API selection implicit, our method provides each agent with detailed tool-calling ob...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "API",
        "tool",
        "arxiv",
        "LLM",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis",
      "url": "https://arxiv.org/abs/2508.04915",
      "description": "arXiv:2508.04915v1 Announce Type: new \nAbstract: The efficacy of AI agents in healthcare research is hindered by their reliance on static, predefined strategies. This creates a critical limitation: agents can become better tool-users but cannot learn to become better strategic planners, a crucial sk...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "experiment",
        "framework",
        "arxiv",
        "analysis",
        "tool",
        "research",
        "knowledge base"
      ],
      "score": 0.8
    },
    {
      "title": "Edge-Assisted Collaborative Fine-Tuning for Multi-User Personalized Artificial Intelligence Generated Content (AIGC)",
      "url": "https://arxiv.org/abs/2508.04745",
      "description": "arXiv:2508.04745v1 Announce Type: new \nAbstract: Diffusion models (DMs) have emerged as powerful tools for high-quality content generation, yet their intensive computational requirements for inference pose challenges for resource-constrained edge devices. Cloud-based solutions aid in computation but...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "arxiv",
        "model",
        "fine-tuning",
        "tool",
        "framework",
        "prompt"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "tool",
        "model",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "chain-of-thought",
        "reasoning"
      ],
      "score": 0.8
    },
    {
      "title": "Pitch Accent Detection improves Pretrained Automatic Speech Recognition",
      "url": "https://arxiv.org/abs/2508.04814",
      "description": "arXiv:2508.04814v1 Announce Type: new \nAbstract: We show the performance of Automatic Speech Recognition (ASR) systems that use semi-supervised speech representations can be boosted by a complimentary pitch accent detection module, by introducing a joint ASR and pitch accent detection model. The pit...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "fine-tuning",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "NAEx: A Plug-and-Play Framework for Explaining Network Alignment",
      "url": "https://arxiv.org/abs/2508.04731",
      "description": "arXiv:2508.04731v1 Announce Type: new \nAbstract: Network alignment (NA) identifies corresponding nodes across multiple networks, with applications in domains like social networks, co-authorship, and biology. Despite advances in alignment models, their interpretability remains limited, making it diff...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "framework",
        "arxiv",
        "alignment"
      ],
      "score": 0.6
    },
    {
      "title": "Vision Language Model Alignment in TRL ⚡️",
      "url": "https://huggingface.co/blog/trl-vlm-alignment",
      "description": "...",
      "published_date": "2025-08-07T00:00:00",
      "source": "Hugging Face Blog",
      "category": "multimodal_context",
      "keywords": [
        "model",
        "vision",
        "alignment"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "context",
        "model"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning",
      "url": "https://arxiv.org/abs/2508.05023",
      "description": "arXiv:2508.05023v1 Announce Type: new \nAbstract: Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to extract all target-aspect-opinion-sentiment quadruples from a given multi-round, multi-participant dialogue. Existing methods typically learn word relations across entire dialogues...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "experiment",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding",
      "url": "https://arxiv.org/abs/2508.05006",
      "description": "arXiv:2508.05006v1 Announce Type: new \nAbstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the binding interactions between small-molecule ligands and protein pockets. However, current multi-task learning models for docking often show inferior performance in ligand dock...",
      "published_date": "2025-08-08T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "framework",
        "experiment",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Introducing AI Sheets: a tool to work with datasets using open AI models!",
      "url": "https://huggingface.co/blog/aisheets",
      "description": "...",
      "published_date": "2025-08-08T00:00:00",
      "source": "Hugging Face Blog",
      "category": "tools_frameworks",
      "keywords": [
        "tool",
        "model"
      ],
      "score": 0.2
    }
  ]
}