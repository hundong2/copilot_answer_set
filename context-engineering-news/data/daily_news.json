{
  "generated_at": "2025-09-30T20:05:49.345998",
  "total_items": 47,
  "items": [
    {
      "title": "AccessEval: Benchmarking Disability Bias in Large Language Models",
      "url": "https://arxiv.org/abs/2509.22703",
      "description": "arXiv:2509.22703v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly deployed across diverse domains but often exhibit disparities in how they handle real-life queries. To systematically investigate these effects within various disability contexts, we introduce \\textbf{Acce...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "LLM",
        "large language model",
        "model",
        "analysis",
        "ICL",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "RAR$^2$: Retrieval-Augmented Medical Reasoning via Thought-Driven Retrieval",
      "url": "https://arxiv.org/abs/2509.22713",
      "description": "arXiv:2509.22713v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown promising performance on diverse medical benchmarks, highlighting their potential in supporting real-world clinical tasks. Retrieval-Augmented Generation (RAG) has emerged as a key approach for mitigating knowle...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "LLM",
        "retrieval",
        "large language model",
        "augmented",
        "model",
        "experiment",
        "fine-tuning",
        "reasoning",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "TRUEBench: Can LLM Response Meet Real-world Constraints as Productivity Assistant?",
      "url": "https://arxiv.org/abs/2509.22715",
      "description": "arXiv:2509.22715v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly integral as productivity assistants, but existing benchmarks fall short in rigorously evaluating their real-world instruction-following capabilities. Current benchmarks often (i) lack sufficient multilingu...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "context",
        "LLM",
        "prompt",
        "large language model",
        "model",
        "experiment",
        "instruction",
        "product",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Multi-Modal Sentiment Analysis with Dynamic Attention Fusion",
      "url": "https://arxiv.org/abs/2509.22729",
      "description": "arXiv:2509.22729v1 Announce Type: new \nAbstract: Traditional sentiment analysis has long been a unimodal task, relying solely on text. This approach overlooks non-verbal cues such as vocal tone and prosody that are essential for capturing true emotional intent. We introduce Dynamic Attention Fusion ...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "embedding",
        "framework",
        "model",
        "analysis",
        "multimodal",
        "arxiv",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "Painless Activation Steering: An Automated, Lightweight Approach for Post-Training Large Language Models",
      "url": "https://arxiv.org/abs/2509.22739",
      "description": "arXiv:2509.22739v1 Announce Type: new \nAbstract: Language models (LMs) are typically post-trained for desired capabilities and behaviors via weight-based or prompt-based steering, but the former is time-consuming and expensive, and the latter is not precisely controllable and often requires manual t...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "context",
        "vector",
        "alignment",
        "in-context",
        "prompt",
        "large language model",
        "model",
        "fine-tuning",
        "ICL",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "MIRAGE: Multi-hop Reasoning with Ambiguity Evaluation for Illusory Questions",
      "url": "https://arxiv.org/abs/2509.22750",
      "description": "arXiv:2509.22750v1 Announce Type: new \nAbstract: Real-world Multi-hop Question Answering (QA) often involves ambiguity that is inseparable from the reasoning process itself. This ambiguity creates a distinct challenge, where multiple reasoning paths emerge from a single question, each requiring inde...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "instruction",
        "LLM",
        "large language model",
        "model",
        "research",
        "experiment",
        "example",
        "reasoning",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "ML2B: Multi-Lingual ML Benchmark For AutoML",
      "url": "https://arxiv.org/abs/2509.22768",
      "description": "arXiv:2509.22768v1 Announce Type: new \nAbstract: Large language models (LLMs) have recently demonstrated strong capabilities in generating machine learning (ML) code, enabling end-to-end pipeline construction from natural language instructions. However, existing benchmarks for ML code generation are...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "image",
        "framework",
        "LLM",
        "large language model",
        "model",
        "research",
        "instruction",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "ArFake: A Multi-Dialect Benchmark and Baselines for Arabic Spoof-Speech Detection",
      "url": "https://arxiv.org/abs/2509.22808",
      "description": "arXiv:2509.22808v1 Announce Type: new \nAbstract: With the rise of generative text-to-speech models, distinguishing between real and synthetic speech has become challenging, especially for Arabic that have received limited research attention. Most spoof detection efforts have focused on English, leav...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "embedding",
        "audio",
        "model",
        "research",
        "arxiv",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "Can Large Language Models Develop Gambling Addiction?",
      "url": "https://arxiv.org/abs/2509.22818",
      "description": "arXiv:2509.22818v1 Announce Type: new \nAbstract: This study explores whether large language models can exhibit behavioral patterns similar to human gambling addictions. As LLMs are increasingly utilized in financial decision-making domains such as asset management and commodity trading, understandin...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "prompt",
        "large language model",
        "study",
        "model",
        "analysis",
        "research",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Hilbert: Recursively Building Formal Proofs with Informal Reasoning",
      "url": "https://arxiv.org/abs/2509.22819",
      "description": "arXiv:2509.22819v1 Announce Type: new \nAbstract: Large Language Models (LLMs) demonstrate impressive mathematical reasoning abilities, but their solutions frequently contain errors that cannot be automatically verified. Formal theorem proving systems such as Lean 4 offer automated verification with ...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "LLM",
        "large language model",
        "model",
        "experiment",
        "ICL",
        "reasoning",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Toward a Theory of Generalizability in LLM Mechanistic Interpretability Research",
      "url": "https://arxiv.org/abs/2509.22831",
      "description": "arXiv:2509.22831v1 Announce Type: new \nAbstract: Research on Large Language Models (LLMs) increasingly focuses on identifying mechanistic explanations for their behaviors, yet the field lacks clear principles for determining when (and how) findings from one model instance generalize to another. This...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "LLM",
        "large language model",
        "model",
        "paper",
        "research",
        "arxiv",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "JE-IRT: A Geometric Lens on LLM Abilities through Joint Embedding Item Response Theory",
      "url": "https://arxiv.org/abs/2509.22888",
      "description": "arXiv:2509.22888v1 Announce Type: new \nAbstract: Standard LLM evaluation practices compress diverse abilities into single scores, obscuring their inherently multidimensional nature. We present JE-IRT, a geometric item-response framework that embeds both LLMs and questions in a shared space. For ques...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "embedding",
        "framework",
        "alignment",
        "LLM",
        "model",
        "experiment",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Not only a helper, but also a teacher: Interactive LLM Cascade",
      "url": "https://arxiv.org/abs/2509.22984",
      "description": "arXiv:2509.22984v1 Announce Type: new \nAbstract: Large Language Models (LLMs) vary widely in their capabilities, with larger models often having better performance but higher cost: choosing an LLM model often involves trading off performance and cost. The LLM Cascade is a paradigm that defers diffic...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "framework",
        "LLM",
        "in-context",
        "large language model",
        "model",
        "fine-tuning",
        "API",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Towards Strategic Persuasion with Language Models",
      "url": "https://arxiv.org/abs/2509.22989",
      "description": "arXiv:2509.22989v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated strong persuasive capabilities comparable to those of humans, offering promising benefits while raising societal concerns about their deployment. However, systematically evaluating the persuasive capabili...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "LLM",
        "large language model",
        "model",
        "paper",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Deceive, Detect, and Disclose: Large Language Models Play Mini-Mafia",
      "url": "https://arxiv.org/abs/2509.23023",
      "description": "arXiv:2509.23023v1 Announce Type: new \nAbstract: Mafia is a social deduction game where informed mafia compete against uninformed townsfolk. Its asymmetry of information and reliance on theory-of-mind reasoning mirror real-world multi-agent scenarios, making it a useful testbed for evaluating the so...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "LLM",
        "large language model",
        "study",
        "model",
        "experiment",
        "reasoning",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "In-Context Learning can Perform Continual Learning Like Humans",
      "url": "https://arxiv.org/abs/2509.22764",
      "description": "arXiv:2509.22764v1 Announce Type: new \nAbstract: Large language models (LLMs) can adapt to new tasks via in-context learning (ICL) without parameter updates, making them powerful learning engines for fast adaptation. While extensive research has examined ICL as a few-shot learner, whether it can ach...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "transformer",
        "LLM",
        "in-context",
        "prompt",
        "large language model",
        "model",
        "research",
        "experiment",
        "ICL",
        "few-shot",
        "memory",
        "arxiv",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "On the Capacity of Self-Attention",
      "url": "https://arxiv.org/abs/2509.22840",
      "description": "arXiv:2509.22840v1 Announce Type: new \nAbstract: While self-attention is known to learn relations among tokens, we lack a formal understanding of its capacity: how many distinct relations can a single layer reliably recover for a given budget?\n  To formalize this, we introduce Relational Graph Recog...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "embedding",
        "context",
        "framework",
        "model",
        "analysis",
        "experiment",
        "compression",
        "arxiv",
        "attention"
      ],
      "score": 1.0
    },
    {
      "title": "Boundary on the Table: Efficient Black-Box Decision-Based Attacks for Structured Data",
      "url": "https://arxiv.org/abs/2509.22850",
      "description": "arXiv:2509.22850v1 Announce Type: new \nAbstract: Adversarial robustness in structured data remains an underexplored frontier compared to vision and language domains. In this work, we introduce a novel black-box, decision-based adversarial attack tailored for tabular data. Our approach combines gradi...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "large language model",
        "model",
        "experiment",
        "vision",
        "arxiv"
      ],
      "score": 1.0
    },
    {
      "title": "Adaptive Margin RLHF via Preference over Preferences",
      "url": "https://arxiv.org/abs/2509.22851",
      "description": "arXiv:2509.22851v1 Announce Type: new \nAbstract: Margin-based optimization is fundamental to improving generalization and robustness in classification tasks. In the context of reward model learning from preferences within Reinforcement Learning from Human Feedback (RLHF), existing methods typically ...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "in_context_learning",
      "keywords": [
        "context",
        "alignment",
        "RLHF",
        "model",
        "example",
        "vision",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "From Noise to Knowledge: A Comparative Study of Acoustic Anomaly Detection Models in Pumped-storage Hydropower Plants",
      "url": "https://arxiv.org/abs/2509.22881",
      "description": "arXiv:2509.22881v1 Announce Type: new \nAbstract: In the context of industrial factories and energy producers, unplanned outages are highly costly and difficult to service. However, existing acoustic-anomaly detection studies largely rely on generic industrial or synthetic datasets, with few focused ...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "study",
        "model",
        "analysis",
        "paper",
        "arxiv",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles guide inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" — Andrej Karpathy. A frontier, first-principles guide inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt engineering",
        "prompt",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "framework",
        "reasoning",
        "chain-of-thought",
        "CoT"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "context",
        "LLM",
        "prompt",
        "model",
        "tool",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "context",
        "chain-of-thought",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "framework",
        "vector",
        "LLM",
        "retrieval",
        "knowledge base",
        "model",
        "reasoning",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "LLM",
        "tool",
        "fine-tuning"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "API",
        "retrieval",
        "augmented",
        "product",
        "RAG"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. 🚀💻 Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "framework",
        "vector",
        "LLM",
        "prompt",
        "platform"
      ],
      "score": 1.0
    },
    {
      "title": "AutoRAG - AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "description": "AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation",
      "published_date": "2024-01-10T12:25:00+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "augmented",
        "RAG",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "Enabling Approximate Joint Sampling in Diffusion LMs",
      "url": "https://arxiv.org/abs/2509.22738",
      "description": "arXiv:2509.22738v1 Announce Type: new \nAbstract: In autoregressive language models, each token is sampled by conditioning on all the past tokens; the overall string has thus been sampled from the correct underlying joint distribution represented by the model. In contrast, masked diffusion language m...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "paper",
        "instruction"
      ],
      "score": 0.8
    },
    {
      "title": "Mixture-of-Visual-Thoughts: Exploring Context-Adaptive Reasoning Mode Selection for General Visual Reasoning",
      "url": "https://arxiv.org/abs/2509.22746",
      "description": "arXiv:2509.22746v1 Announce Type: new \nAbstract: Current visual reasoning methods mainly focus on exploring specific reasoning modes. Although improvements can be achieved in particular domains, they struggle to develop general reasoning capabilities. Inspired by this, we propose a novel adaptive re...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "context",
        "framework",
        "model",
        "experiment",
        "reasoning",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Creative Adversarial Testing (CAT): A Novel Framework for Evaluating Goal-Oriented Agentic AI Systems",
      "url": "https://arxiv.org/abs/2509.23006",
      "description": "arXiv:2509.23006v1 Announce Type: new \nAbstract: Agentic AI represents a paradigm shift in enhancing the capabilities of generative AI models. While these systems demonstrate immense potential and power, current evaluation techniques primarily focus on assessing their efficacy in identifying appropr...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "audio",
        "framework",
        "alignment",
        "model",
        "paper",
        "tool",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "Observation-Free Attacks on Online Learning to Rank",
      "url": "https://arxiv.org/abs/2509.22855",
      "description": "arXiv:2509.22855v1 Announce Type: new \nAbstract: Online learning to rank (OLTR) plays a critical role in information retrieval and machine learning systems, with a wide range of applications in search engines and content recommenders. However, despite their extensive adoption, the susceptibility of ...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "retrieval",
        "arxiv",
        "analysis",
        "framework"
      ],
      "score": 0.8
    },
    {
      "title": "FedCF: Fair Federated Conformal Prediction",
      "url": "https://arxiv.org/abs/2509.22907",
      "description": "arXiv:2509.22907v1 Announce Type: new \nAbstract: Conformal Prediction (CP) is a widely used technique for quantifying uncertainty in machine learning models. In its standard form, CP offers probabilistic guarantees on the coverage of the true label, but it is agnostic to sensitive attributes in the ...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "model",
        "experiment",
        "arxiv",
        "RAG"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "tool",
        "context",
        "API"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "model",
        "reasoning",
        "chain-of-thought"
      ],
      "score": 0.8
    },
    {
      "title": "AI Noether -- Bridging the Gap Between Scientific Laws Derived by AI Systems and Canonical Knowledge via Abductive Inference",
      "url": "https://arxiv.org/abs/2509.23004",
      "description": "arXiv:2509.23004v1 Announce Type: new \nAbstract: A core goal in modern science is to harness recent advances in AI and computer processing to automate and accelerate the scientific method. Symbolic regression can fit interpretable models to data, but these models often sit outside established theory...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "model",
        "retrieval",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "Localizing Adversarial Attacks To Produces More Imperceptible Noise",
      "url": "https://arxiv.org/abs/2509.22710",
      "description": "arXiv:2509.22710v1 Announce Type: new \nAbstract: Adversarial attacks in machine learning traditionally focus on global perturbations to input data, yet the potential of localized adversarial noise remains underexplored. This study systematically evaluates localized adversarial attacks across widely-...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "analysis",
        "arxiv",
        "study"
      ],
      "score": 0.6
    },
    {
      "title": "Neighborhood Sampling Does Not Learn the Same Graph Neural Network",
      "url": "https://arxiv.org/abs/2509.22868",
      "description": "arXiv:2509.22868v1 Announce Type: new \nAbstract: Neighborhood sampling is an important ingredient in the training of large-scale graph neural networks. It suppresses the exponential growth of the neighborhood size across network layers and maintains feasible memory consumption and time costs. While ...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "analysis",
        "tool",
        "memory",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "excel-mcp-server - A Model Context Protocol server for Excel file manipulation",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "description": "A Model Context Protocol server for Excel file manipulation",
      "published_date": "2025-02-12T06:39:48+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "prompt engineering",
        "prompt",
        "paper"
      ],
      "score": 0.6
    },
    {
      "title": "Communication-Efficient and Interoperable Distributed Learning",
      "url": "https://arxiv.org/abs/2509.22823",
      "description": "arXiv:2509.22823v1 Announce Type: new \nAbstract: Collaborative learning across heterogeneous model architectures presents significant challenges in ensuring interoperability and preserving privacy. We propose a communication-efficient distributed learning framework that supports model heterogeneity ...",
      "published_date": "2025-09-30T04:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "arxiv",
        "framework",
        "experiment"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/codelion/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    },
    {
      "title": "Accelerating Qwen3-8B Agent on Intel® Core™ Ultra with Depth-Pruned Draft Models",
      "url": "https://huggingface.co/blog/intel-qwen3-agent",
      "description": "...",
      "published_date": "2025-09-29T00:00:00",
      "source": "Hugging Face Blog",
      "category": "industry_news",
      "keywords": [
        "model"
      ],
      "score": 0.2
    }
  ]
}