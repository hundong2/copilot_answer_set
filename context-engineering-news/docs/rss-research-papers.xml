<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>PTCBENCH: Benchmarking Contextual Stability of Personality Traits in LLM Systems</title>
      <link>https://arxiv.org/abs/2602.00016</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00016</guid>
      <description>arXiv:2602.00016v1 Announce Type: new 
Abstract: With the increasing deployment of large language models (LLMs) in affective agents and AI systems, maintaining a consistent and authentic LLM personality becomes critical for user trust and engagement. However, existing work overlooks a fundamental ps...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, LLM, model, arxiv, reasoning | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>LLM</category>
      <category>model</category>
    </item>
    <item>
      <title>Faithful-Patchscopes: Understanding and Mitigating Model Bias in Hidden Representations Explanation of Large Language Models</title>
      <link>https://arxiv.org/abs/2602.00300</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00300</guid>
      <description>arXiv:2602.00300v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated strong capabilities for hidden representation interpretation through Patchscopes, a framework that uses LLMs themselves to generate human-readable explanations by decoding from internal hidden representat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; prompt, example, RAG, context, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>prompt</category>
      <category>example</category>
      <category>RAG</category>
    </item>
    <item>
      <title>Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes</title>
      <link>https://arxiv.org/abs/2602.00053</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00053</guid>
      <description>arXiv:2602.00053v1 Announce Type: new 
Abstract: Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing req...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, RAG, experiment, analysis, product | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>RAG</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning</title>
      <link>https://arxiv.org/abs/2602.00298</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00298</guid>
      <description>arXiv:2602.00298v1 Announce Type: new 
Abstract: Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluatin...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, prompt, fine-tuning, paper, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>GPT</category>
      <category>prompt</category>
      <category>fine-tuning</category>
    </item>
    <item>
      <title>SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?</title>
      <link>https://arxiv.org/abs/2602.00327</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00327</guid>
      <description>arXiv:2602.00327v1 Announce Type: new 
Abstract: We explore the use of large language models (LLMs) for next-utterance prediction in human dialogue. Despite recent advances in LLMs demonstrating their ability to engage in natural conversations with users, we show that even leading models surprisingl...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, experiment, multimodal, LLM, model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>experiment</category>
      <category>multimodal</category>
    </item>
    <item>
      <title>MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants</title>
      <link>https://arxiv.org/abs/2602.00353</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00353</guid>
      <description>arXiv:2602.00353v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly applied in mental health support systems, where reliable recognition of high-risk states such as suicidal ideation and self-harm is safety-critical. However, existing evaluations primarily rely on aggregat...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; platform, LLM, analysis, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>platform</category>
      <category>LLM</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Measurement for Opaque Systems: Multi-source Triangulation with Interpretable Machine Learning</title>
      <link>https://arxiv.org/abs/2602.00022</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00022</guid>
      <description>arXiv:2602.00022v1 Announce Type: new 
Abstract: We propose a measurement framework for difficult-to-access contexts that uses indirect data traces, interpretable machine-learning models, and theory-guided triangulation to fill inaccessible measurement spaces. Many high-stakes systems of scientific ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, context, analysis, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>context</category>
      <category>analysis</category>
    </item>
    <item>
      <title>Representation Learning Enhanced Deep Reinforcement Learning for Optimal Operation of Hydrogen-based Multi-Energy Systems</title>
      <link>https://arxiv.org/abs/2602.00027</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00027</guid>
      <description>arXiv:2602.00027v1 Announce Type: new 
Abstract: Hydrogen-based multi-energy systems (HMES) have emerged as a promising low-carbon and energy-efficient solution, as it can enable the coordinated operation of electricity, heating and cooling supply and demand to enhance operational flexibility, impro...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, RAG, experiment, model, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>RAG</category>
      <category>experiment</category>
    </item>
    <item>
      <title>ELLMPEG: An Edge-based Agentic LLM Video Processing Tool</title>
      <link>https://arxiv.org/abs/2602.00028</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00028</guid>
      <description>arXiv:2602.00028v1 Announce Type: new 
Abstract: Large language models (LLMs), the foundation of generative AI systems like ChatGPT, are transforming many fields and applications, including multimedia, enabling more advanced content generation, analysis, and interaction. However, cloud-based LLM dep...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; GPT, prompt, augmented, paper, RAG | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>GPT</category>
      <category>prompt</category>
      <category>augmented</category>
    </item>
    <item>
      <title>Enhancing few-shot time series forecasting with LLM-guided diffusion</title>
      <link>https://arxiv.org/abs/2602.00040</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00040</guid>
      <description>arXiv:2602.00040v1 Announce Type: new 
Abstract: Time series forecasting in specialized domains is often constrained by limited data availability, where conventional models typically require large-scale datasets to effectively capture underlying temporal dynamics. To tackle this few-shot challenge, ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; experiment, LLM, few-shot, analysis, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>experiment</category>
      <category>LLM</category>
      <category>few-shot</category>
    </item>
    <item>
      <title>Lightweight Edge Learning via Dataset Pruning</title>
      <link>https://arxiv.org/abs/2602.00047</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00047</guid>
      <description>arXiv:2602.00047v1 Announce Type: new 
Abstract: Edge learning facilitates ubiquitous intelligence by enabling model training and adaptation directly on data-generating devices, thereby mitigating privacy risks and communication latency. However, the high computational and energy overhead of on-devi...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, RAG, experiment, image, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>RAG</category>
      <category>experiment</category>
    </item>
    <item>
      <title>SafeTalkCoach: Diversity-Driven Multi-Agent Simulation for Parent-Teen Health Conversations</title>
      <link>https://arxiv.org/abs/2602.00017</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00017</guid>
      <description>arXiv:2602.00017v1 Announce Type: new 
Abstract: The importance of effective parent-child communication about sexual health is widely acknowledged, but real-world data on these conversations is scarce and challenging to collect, due to their private and sensitive nature. Although LLMs have been wide...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; research, LLM, company, arxiv, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>research</category>
      <category>LLM</category>
      <category>company</category>
    </item>
    <item>
      <title>Reversible Diffusion Decoding for Diffusion Language Models</title>
      <link>https://arxiv.org/abs/2602.00150</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00150</guid>
      <description>arXiv:2602.00150v1 Announce Type: new 
Abstract: Diffusion language models enable parallel token generation through block-wise decoding, but their irreversible commitments can lead to stagnation, where the reverse diffusion process fails to make further progress under a suboptimal context.We propose...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; context, experiment, model, arxiv, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>context</category>
      <category>experiment</category>
      <category>model</category>
    </item>
    <item>
      <title>Distributional Reinforcement Learning for Condition-Based Maintenance of Multi-Pump Equipment</title>
      <link>https://arxiv.org/abs/2602.00051</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2602.00051</guid>
      <description>arXiv:2602.00051v1 Announce Type: new 
Abstract: Condition-Based Maintenance (CBM) signifies a paradigm shift from reactive to proactive equipment management strategies in modern industrial systems. Conventional time-based maintenance schedules frequently engender superfluous expenditures and unanti...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; study, arxiv, paper, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Tue, 03 Feb 2026 05:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>study</category>
      <category>arxiv</category>
      <category>paper</category>
    </item>
  </channel>
</rss>