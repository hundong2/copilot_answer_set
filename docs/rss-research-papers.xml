<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Context Engineering Daily - Research Papers</title>
    <link>https://your-username.github.io/context-engineering-news#research_papers</link>
    <description>Latest Research Papers news in Context Engineering</description>
    <language>en-us</language>
    <item>
      <title>PersonaTwin: A Multi-Tier Prompt Conditioning Framework for Generating and Evaluating Personalized Digital Twins</title>
      <link>https://arxiv.org/abs/2508.10906</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.10906</guid>
      <description>arXiv:2508.10906v1 Announce Type: new 
Abstract: While large language models (LLMs) afford new possibilities for user modeling and approximation of human behaviors, they often fail to capture the multidimensional nuances of individual users. In this work, we introduce PersonaTwin, a multi-tier promp...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, tool, analysis, experiment, GPT | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>tool</category>
      <category>analysis</category>
    </item>
    <item>
      <title>gpt-oss-120b &amp;amp; gpt-oss-20b Model Card</title>
      <link>https://arxiv.org/abs/2508.10925</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.10925</guid>
      <description>arXiv:2508.10925v1 Announce Type: new 
Abstract: We present gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models that push the frontier of accuracy and inference cost. The models use an efficient mixture-of-expert transformer architecture and are trained using large-scale distillation and ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, tool, research, reasoning, GPT | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>tool</category>
      <category>research</category>
    </item>
    <item>
      <title>Beyond the Rosetta Stone: Unification Forces in Generalization Dynamics</title>
      <link>https://arxiv.org/abs/2508.11017</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.11017</guid>
      <description>arXiv:2508.11017v1 Announce Type: new 
Abstract: Large language models (LLMs) struggle with cross-lingual knowledge transfer: they hallucinate when asked in one language about facts expressed in a different language during training. This work introduces a controlled setting to study the causes and d...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, study, LLM, transformer, large language model | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>study</category>
      <category>LLM</category>
    </item>
    <item>
      <title>Hell or High Water: Evaluating Agentic Recovery from External Failures</title>
      <link>https://arxiv.org/abs/2508.11027</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.11027</guid>
      <description>arXiv:2508.11027v1 Announce Type: new 
Abstract: As language model agents are applied to real world problems of increasing complexity, they will be expected to formulate plans across large search spaces. If those plans fail for reasons beyond their control, how well do language agents search for alt...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, analysis, study, context, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>analysis</category>
      <category>study</category>
    </item>
    <item>
      <title>BIPOLAR: Polarization-based granular framework for LLM bias evaluation</title>
      <link>https://arxiv.org/abs/2508.11061</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.11061</guid>
      <description>arXiv:2508.11061v1 Announce Type: new 
Abstract: Large language models (LLMs) are known to exhibit biases in downstream tasks, especially when dealing with sensitive topics such as political discourse, gender identity, ethnic relations, or national stereotypes. Although significant progress has been...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, analysis, study, GPT, framework | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>analysis</category>
      <category>study</category>
    </item>
    <item>
      <title>Learn to optimize for automatic proton PBS treatment planning for H&amp;amp;N cancers</title>
      <link>https://arxiv.org/abs/2508.11085</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.11085</guid>
      <description>arXiv:2508.11085v1 Announce Type: new 
Abstract: Proton PBS treatment planning for H&amp;amp;amp;N cancers involves numerous conflicting objectives, requiring significant effort from human planners to balance and satisfy multiple clinical goals during planning. To achieve this, experience-demanding objectiv...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, study, LLM, framework, context | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>study</category>
      <category>LLM</category>
    </item>
    <item>
      <title>On Strong and Weak Admissibility in Non-Flat Assumption-Based Argumentation</title>
      <link>https://arxiv.org/abs/2508.11182</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.11182</guid>
      <description>arXiv:2508.11182v1 Announce Type: new 
Abstract: In this work, we broaden the investigation of admissibility notions in the context of assumption-based argumentation (ABA). More specifically, we study two prominent alternatives to the standard notion of admissibility from abstract argumentation, nam...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, study, framework, context, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>study</category>
      <category>framework</category>
    </item>
    <item>
      <title>SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding</title>
      <link>https://arxiv.org/abs/2508.11347</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.11347</guid>
      <description>arXiv:2508.11347v1 Announce Type: new 
Abstract: Traditional knowledge graph (KG) embedding methods aim to represent entities and relations in a low-dimensional space, primarily focusing on static graphs. However, real-world KGs are dynamically evolving with the constant addition of entities, relati...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; paper, experiment, framework, ICL, embedding | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>paper</category>
      <category>experiment</category>
      <category>framework</category>
    </item>
    <item>
      <title>AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager</title>
      <link>https://arxiv.org/abs/2508.11416</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.11416</guid>
      <description>arXiv:2508.11416v1 Announce Type: new 
Abstract: Recent advances in mathematical reasoning and the long-term planning capabilities of large language models (LLMs) have precipitated the development of agents, which are being increasingly leveraged in business operations processes. Decision models to ...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, model, experiment, reasoning, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>model</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Retro-Expert: Collaborative Reasoning for Interpretable Retrosynthesis</title>
      <link>https://arxiv.org/abs/2508.10967</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.10967</guid>
      <description>arXiv:2508.10967v1 Announce Type: new 
Abstract: Retrosynthesis prediction aims to infer the reactant molecule based on a given product molecule, which is a fundamental task in chemical synthesis. However, existing models rely on static pattern-matching paradigm, which limits their ability to perfor...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, product, experiment, reasoning, LLM | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 100%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>product</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Zono-Conformal Prediction: Zonotope-Based Uncertainty Quantification for Regression and Classification Tasks</title>
      <link>https://arxiv.org/abs/2508.11025</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.11025</guid>
      <description>arXiv:2508.11025v1 Announce Type: new 
Abstract: Conformal prediction is a popular uncertainty quantification method that augments a base predictor with prediction sets with statistically valid coverage guarantees. However, current methods are often computationally expensive and data-intensive, as t...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; RAG, model, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 80%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>RAG</category>
      <category>model</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>From Individual to Multi-Agent Algorithmic Recourse: Minimizing the Welfare Gap via Capacitated Bipartite Matching</title>
      <link>https://arxiv.org/abs/2508.11070</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.11070</guid>
      <description>arXiv:2508.11070v1 Announce Type: new 
Abstract: Decision makers are increasingly relying on machine learning in sensitive situations. In such settings, algorithmic recourse aims to provide individuals with actionable and minimally costly steps to reverse unfavorable AI-driven decisions. While exist...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, experiment, research, framework, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>experiment</category>
      <category>research</category>
    </item>
    <item>
      <title>A Cooperative Game-Based Multi-Criteria Weighted Ensemble Approach for Multi-Class Classification</title>
      <link>https://arxiv.org/abs/2508.10926</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.10926</guid>
      <description>arXiv:2508.10926v1 Announce Type: new 
Abstract: Since the Fourth Industrial Revolution, AI technology has been widely used in many fields, but there are several limitations that need to be overcome, including overfitting/underfitting, class imbalance, and the limitations of representation (hypothes...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, paper, arxiv, experiment | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>paper</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>Towards Efficient Prompt-based Continual Learning in Distributed Medical AI</title>
      <link>https://arxiv.org/abs/2508.10954</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.10954</guid>
      <description>arXiv:2508.10954v1 Announce Type: new 
Abstract: Modern AI models achieve state-of-the-art performance with large-scale, high-quality datasets; however, ethical, social, and institutional constraints in the medical domain severely restrict data sharing, rendering centralized learning nearly impossib...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, image, experiment, study, release | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>image</category>
      <category>experiment</category>
    </item>
    <item>
      <title>Learning with Confidence</title>
      <link>https://arxiv.org/abs/2508.11037</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.11037</guid>
      <description>arXiv:2508.11037v1 Announce Type: new 
Abstract: We characterize a notion of confidence that arises in learning or updating beliefs: the amount of trust one has in incoming information and its impact on the belief state. This learner&amp;#x27;s confidence can be used alongside (and is easily mistaken for) pr...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; vector, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 60%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>vector</category>
      <category>arxiv</category>
    </item>
    <item>
      <title>CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks</title>
      <link>https://arxiv.org/abs/2508.11360</link>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.11360</guid>
      <description>arXiv:2508.11360v1 Announce Type: new 
Abstract: As autonomous agents become adept at understanding and interacting with graphical user interface (GUI) environments, a new era of automated task execution is emerging. Recent studies have demonstrated that Reinforcement Learning (RL) can effectively e...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;small&amp;gt;&amp;lt;strong&amp;gt;Source:&amp;lt;/strong&amp;gt; arXiv | &amp;lt;strong&amp;gt;Keywords:&amp;lt;/strong&amp;gt; model, experiment, framework, arxiv | &amp;lt;strong&amp;gt;Relevance:&amp;lt;/strong&amp;gt; 40%&amp;lt;/small&amp;gt;</description>
      <pubDate>Mon, 18 Aug 2025 04:00:00 </pubDate>
      <author>noreply@contextengineering.news (arXiv)</author>
      <category>Research Papers</category>
      <category>model</category>
      <category>experiment</category>
      <category>framework</category>
    </item>
  </channel>
</rss>