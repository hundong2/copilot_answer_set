{
  "generated_at": "2025-11-06T20:05:49.039382",
  "total_items": 43,
  "items": [
    {
      "title": "Cache Mechanism for Agent RAG Systems",
      "url": "https://arxiv.org/abs/2511.02919",
      "description": "arXiv:2511.02919v1 Announce Type: new \nAbstract: Recent advances in Large Language Model (LLM)-based agents have been propelled by Retrieval-Augmented Generation (RAG), which grants the models access to vast external knowledge bases. Despite RAG's success in improving agent performance, agent-level ...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "LLM",
        "retrieval",
        "RAG",
        "augmented",
        "model",
        "framework",
        "experiment",
        "arxiv",
        "knowledge base",
        "large language model",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation",
      "url": "https://arxiv.org/abs/2511.03001",
      "description": "arXiv:2511.03001v1 Announce Type: new \nAbstract: Despite recent progress in using Large Language Models (LLMs) for automatically generating 3D scenes, generated scenes often lack realistic spatial layouts and object attributes found in real-world environments. As this problem stems from insufficient...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "instruction",
        "tool",
        "model",
        "alignment",
        "framework",
        "experiment",
        "arxiv",
        "vision",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Targeted Error Correction in Knowledge Distillation: Small Language Models Surpass GPT",
      "url": "https://arxiv.org/abs/2511.03005",
      "description": "arXiv:2511.03005v1 Announce Type: new \nAbstract: We introduce an Analyze-Revise-Finetune (ARF) pipeline that enables smaller open-source language models (LLMs) to surpass substantially larger proprietary models in customer service summarization tasks. The pipeline first analyzes and categorizes comm...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "LLM",
        "fine-tuning",
        "model",
        "summarization",
        "framework",
        "arxiv",
        "GPT",
        "vision"
      ],
      "score": 1.0
    },
    {
      "title": "Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis",
      "url": "https://arxiv.org/abs/2511.03034",
      "description": "arXiv:2511.03034v1 Announce Type: new \nAbstract: Aspect-based Sentiment Analysis (ABSA) is a fine-grained opinion mining approach that identifies and classifies opinions associated with specific entities (aspects) or their categories within a sentence. Despite its rapid growth and broad potential, A...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "arxiv",
        "fine-tuning",
        "model",
        "analysis",
        "example",
        "context",
        "study",
        "API",
        "research",
        "in-context",
        "release"
      ],
      "score": 1.0
    },
    {
      "title": "ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment",
      "url": "https://arxiv.org/abs/2511.03048",
      "description": "arXiv:2511.03048v1 Announce Type: new \nAbstract: We present ROBOTO2, an open-source, web-based platform for large language model (LLM)-assisted risk of bias (ROB) assessment of clinical trials. ROBOTO2 streamlines the traditionally labor-intensive ROB v2 (ROB2) annotation process via an interactive ...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "arxiv",
        "retrieval",
        "platform",
        "prompting",
        "augmented",
        "release",
        "model",
        "ICL",
        "analysis",
        "research",
        "prompt",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech",
      "url": "https://arxiv.org/abs/2511.03080",
      "description": "arXiv:2511.03080v1 Announce Type: new \nAbstract: Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS) systems, converting written forms into their canonical spoken equivalents. Traditional TN systems can exhibit high accuracy, but involve substantial engineering effort, are di...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "arxiv",
        "product",
        "RAG",
        "release",
        "model",
        "few-shot",
        "experiment",
        "research",
        "prompt",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic",
      "url": "https://arxiv.org/abs/2511.03102",
      "description": "arXiv:2511.03102v1 Announce Type: new \nAbstract: Mental health disorders affect millions worldwide, yet early detection remains a major challenge, particularly for Arabic-speaking populations where resources are limited and mental health discourse is often discouraged due to cultural stigma. While s...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "RAG",
        "model",
        "analysis",
        "experiment",
        "arxiv",
        "research",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework",
      "url": "https://arxiv.org/abs/2511.03023",
      "description": "arXiv:2511.03023v1 Announce Type: new \nAbstract: Open data repositories hold potential for evidence-based decision-making, yet are inaccessible to non-experts lacking expertise in dataset discovery, schema mapping, and statistical analysis. Large language models show promise for individual tasks, bu...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "arxiv",
        "model",
        "reasoning",
        "attention",
        "analysis",
        "framework",
        "context",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "No-Human in the Loop: Agentic Evaluation at Scale for Recommendation",
      "url": "https://arxiv.org/abs/2511.03051",
      "description": "arXiv:2511.03051v1 Announce Type: new \nAbstract: Evaluating large language models (LLMs) as judges is increasingly critical for building scalable and trustworthy evaluation pipelines. We present ScalingEval, a large-scale benchmarking study that systematically compares 36 LLMs, including GPT, Gemini...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "product",
        "study",
        "model",
        "analysis",
        "framework",
        "arxiv",
        "GPT",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge",
      "url": "https://arxiv.org/abs/2511.03070",
      "description": "arXiv:2511.03070v1 Announce Type: new \nAbstract: Artificial intelligence (AI) systems hold great promise for advancing various scientific disciplines, and are increasingly used in real-world applications. Despite their remarkable progress, further capabilities are expected in order to achieve more g...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "arxiv",
        "model",
        "paper",
        "context",
        "API",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators",
      "url": "https://arxiv.org/abs/2511.03092",
      "description": "arXiv:2511.03092v1 Announce Type: new \nAbstract: The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+ context length support have resulted in increasing demands for on-chip memory to support large KV caches. Techniques such as StreamingLLM and SnapKV demonstrate how to contro...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "context_management",
      "keywords": [
        "LLM",
        "arxiv",
        "instruction",
        "compression",
        "product",
        "model",
        "reasoning",
        "attention",
        "paper",
        "framework",
        "context",
        "memory",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Large language models require a new form of oversight: capability-based monitoring",
      "url": "https://arxiv.org/abs/2511.03106",
      "description": "arXiv:2511.03106v1 Announce Type: new \nAbstract: The rapid adoption of large language models (LLMs) in healthcare has been accompanied by scrutiny of their oversight. Existing monitoring approaches, inherited from traditional machine learning (ML), are task-based and founded on assumed performance d...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "industry_news",
      "keywords": [
        "LLM",
        "model",
        "reasoning",
        "summarization",
        "arxiv",
        "API",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks",
      "url": "https://arxiv.org/abs/2511.03137",
      "description": "arXiv:2511.03137v1 Announce Type: new \nAbstract: As optimization problems grow increasingly complex and diverse, advancements in optimization techniques and paradigm innovations hold significant importance. The challenges posed by optimization problems are primarily manifested in their non-convexity...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "arxiv",
        "RAG",
        "model",
        "attention",
        "framework",
        "experiment",
        "research",
        "study",
        "API",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "A Proprietary Model-Based Safety Response Framework for AI Agents",
      "url": "https://arxiv.org/abs/2511.03138",
      "description": "arXiv:2511.03138v1 Announce Type: new \nAbstract: With the widespread application of Large Language Models (LLMs), their associated security issues have become increasingly prominent, severely constraining their trustworthy deployment in critical domains. This paper proposes a novel safety response f...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "LLM",
        "arxiv",
        "retrieval",
        "RAG",
        "augmented",
        "fine-tuning",
        "model",
        "attention",
        "paper",
        "framework",
        "experiment",
        "research",
        "large language model",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "Uncovering Bugs in Formal Explainers: A Case Study with PyXAI",
      "url": "https://arxiv.org/abs/2511.03169",
      "description": "arXiv:2511.03169v1 Announce Type: new \nAbstract: Formal explainable artificial intelligence (XAI) offers unique theoretical guarantees of rigor when compared to other non-formal methods of explainability. However, little attention has been given to the validation of practical implementations of form...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "ICL",
        "attention",
        "paper",
        "experiment",
        "arxiv",
        "study"
      ],
      "score": 1.0
    },
    {
      "title": "FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels",
      "url": "https://arxiv.org/abs/2511.02872",
      "description": "arXiv:2511.02872v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) have demonstrated impressive capabilities in formal theorem proving, particularly on contest-based mathematical benchmarks like the IMO. However, these contests do not reflect the depth, breadth, and abs...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "LLM",
        "arxiv",
        "RAG",
        "model",
        "reasoning",
        "library",
        "research",
        "study",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Test-time Adaptation of Tiny Recursive Models",
      "url": "https://arxiv.org/abs/2511.02886",
      "description": "arXiv:2511.02886v1 Announce Type: new \nAbstract: Prior to the close of the 2025 ARC Prize competition, the leading open source approach - known as TRM, or Tiny Recursive Models - involved training a 7M parameter recursive neural network on augmented variants of ARC tasks. That approach scored approx...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "rag_retrieval",
      "keywords": [
        "augmented",
        "fine-tuning",
        "model",
        "paper",
        "arxiv",
        "embedding"
      ],
      "score": 1.0
    },
    {
      "title": "Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models",
      "url": "https://arxiv.org/abs/2511.02894",
      "description": "arXiv:2511.02894v1 Announce Type: new \nAbstract: The widespread integration of wearable sensing devices in Internet of Things (IoT) ecosystems, particularly in healthcare, smart homes, and industrial applications, has required robust human activity recognition (HAR) techniques to improve functionali...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "LLM",
        "few-shot learning",
        "step-by-step",
        "arxiv",
        "prompting",
        "model",
        "few-shot",
        "reasoning",
        "framework",
        "context",
        "zero-shot",
        "prompt",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Zero-shot data citation function classification using transformer-based large language models (LLMs)",
      "url": "https://arxiv.org/abs/2511.02936",
      "description": "arXiv:2511.02936v1 Announce Type: new \nAbstract: Efforts have increased in recent years to identify associations between specific datasets and the scientific literature that incorporates them. Knowing that a given publication cites a given dataset, the next logical step is to explore how or why that...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "LLM",
        "transformer",
        "model",
        "framework",
        "arxiv",
        "zero-shot",
        "prompt",
        "large language model"
      ],
      "score": 1.0
    },
    {
      "title": "Inference-Time Personalized Alignment with a Few User Preference Queries",
      "url": "https://arxiv.org/abs/2511.02966",
      "description": "arXiv:2511.02966v1 Announce Type: new \nAbstract: We study the problem of aligning a generative model's response with a user's preferences. Recent works have proposed several different formulations for personalized alignment; however, they either require a large amount of user preference queries or r...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "paper",
        "alignment",
        "framework",
        "experiment",
        "arxiv",
        "study",
        "image"
      ],
      "score": 1.0
    },
    {
      "title": "Context-Engineering - \"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "url": "https://github.com/davidkimai/Context-Engineering",
      "description": "\"Context engineering is the delicate art and science of filling the context window with just the right information for the next step.\" â€” Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.",
      "published_date": "2025-06-29T00:16:36+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "context window",
        "prompt",
        "prompt engineering",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "ThinkSound - [NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "url": "https://github.com/FunAudioLLM/ThinkSound",
      "description": "[NeurIPS 2025] PyTorch implementation of [ThinkSound], a unified framework for generating audio from any modality, guided by Chain-of-Thought (CoT) reasoning.",
      "published_date": "2025-06-27T02:27:00+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "audio",
        "CoT",
        "chain-of-thought",
        "reasoning",
        "framework"
      ],
      "score": 1.0
    },
    {
      "title": "mcp-context-forge - A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "url": "https://github.com/IBM/mcp-context-forge",
      "description": "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
      "published_date": "2025-05-08T08:16:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "tool",
        "model",
        "context",
        "API",
        "prompt"
      ],
      "score": 1.0
    },
    {
      "title": "Cline-Recursive-Chain-of-Thought-System-CRCT- - A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "url": "https://github.com/RPG-fan/Cline-Recursive-Chain-of-Thought-System-CRCT-",
      "description": "A framework designed to manage context, dependencies, and tasks in large-scale Cline projects within VS Code",
      "published_date": "2025-02-18T15:45:30+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "chain-of-thought",
        "framework",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "airweave - Context retrieval for AI agents across apps and databases",
      "url": "https://github.com/airweave-ai/airweave",
      "description": "Context retrieval for AI agents across apps and databases",
      "published_date": "2024-12-24T10:00:06+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "context"
      ],
      "score": 1.0
    },
    {
      "title": "LightRAG - [EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "url": "https://github.com/HKUDS/LightRAG",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "published_date": "2024-10-02T11:57:54+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "KAG - KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "url": "https://github.com/OpenSPG/KAG",
      "description": "KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.  It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.",
      "published_date": "2024-09-21T13:56:44+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "LLM",
        "retrieval",
        "RAG",
        "model",
        "reasoning",
        "framework",
        "vector",
        "knowledge base"
      ],
      "score": 1.0
    },
    {
      "title": "Kiln - The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "url": "https://github.com/Kiln-AI/Kiln",
      "description": "The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",
      "published_date": "2024-07-23T23:10:13+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "tool",
        "fine-tuning",
        "model"
      ],
      "score": 1.0
    },
    {
      "title": "graphrag - A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "url": "https://github.com/microsoft/graphrag",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "published_date": "2024-03-27T17:57:52+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "RAG",
        "augmented",
        "retrieval"
      ],
      "score": 1.0
    },
    {
      "title": "R2R - SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "url": "https://github.com/SciPhi-AI/R2R",
      "description": "SoTA production-ready AI retrieval system. Agentic Retrieval-Augmented Generation (RAG) with a RESTful API.",
      "published_date": "2024-02-12T03:24:27+00:00",
      "source": "GitHub",
      "category": "rag_retrieval",
      "keywords": [
        "retrieval",
        "RAG",
        "augmented",
        "product",
        "API"
      ],
      "score": 1.0
    },
    {
      "title": "openlit - Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "url": "https://github.com/openlit/openlit",
      "description": "Open source platform for AI Engineering: OpenTelemetry-native LLM Observability, GPU Monitoring, Guardrails, Evaluations, Prompt Management, Vault, Playground. ðŸš€ðŸ’» Integrates with 50+ LLM Providers, VectorDBs, Agent Frameworks and GPUs.",
      "published_date": "2024-01-23T17:40:59+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "LLM",
        "platform",
        "framework",
        "prompt",
        "vector"
      ],
      "score": 1.0
    },
    {
      "title": "Reading Between the Lines: The One-Sided Conversation Problem",
      "url": "https://arxiv.org/abs/2511.03056",
      "description": "arXiv:2511.03056v1 Announce Type: new \nAbstract: Conversational AI is constrained in many real-world settings where only one side of a dialogue can be recorded, such as telemedicine, call centers, and smart glasses. We formalize this as the one-sided conversation problem (1SC): inferring and learnin...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "prompt_engineering",
      "keywords": [
        "LLM",
        "prompting",
        "model",
        "arxiv",
        "study",
        "prompt"
      ],
      "score": 0.8
    },
    {
      "title": "miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward",
      "url": "https://arxiv.org/abs/2511.03108",
      "description": "arXiv:2511.03108v1 Announce Type: new \nAbstract: We perform a thorough analysis of the formal and informal statements in the miniF2F benchmark from the perspective of an AI system that is tasked to participate in a math Olympiad consisting of the problems in miniF2F. In such setting, the model has t...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "reasoning",
        "analysis",
        "alignment",
        "arxiv"
      ],
      "score": 0.8
    },
    {
      "title": "fastapi_mcp - Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "url": "https://github.com/tadata-org/fastapi_mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "published_date": "2025-03-08T11:15:43+00:00",
      "source": "GitHub",
      "category": "tools_frameworks",
      "keywords": [
        "model",
        "API",
        "tool",
        "context"
      ],
      "score": 0.8
    },
    {
      "title": "cosmos-reason1 - Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "url": "https://github.com/nvidia-cosmos/cosmos-reason1",
      "description": "Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.",
      "published_date": "2025-03-02T15:23:55+00:00",
      "source": "GitHub",
      "category": "chain_of_thought",
      "keywords": [
        "reasoning",
        "chain-of-thought",
        "model"
      ],
      "score": 0.8
    },
    {
      "title": "Power Constrained Nonstationary Bandits with Habituation and Recovery Dynamics",
      "url": "https://arxiv.org/abs/2511.02944",
      "description": "arXiv:2511.02944v1 Announce Type: new \nAbstract: A common challenge for decision makers is selecting actions whose rewards are unknown and evolve over time based on prior policies. For instance, repeated use may reduce an action's effectiveness (habituation), while inactivity may restore it (recover...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "paper",
        "framework",
        "arxiv",
        "research"
      ],
      "score": 0.6
    },
    {
      "title": "Value of Information-Enhanced Exploration in Bootstrapped DQN",
      "url": "https://arxiv.org/abs/2511.02969",
      "description": "arXiv:2511.02969v1 Announce Type: new \nAbstract: Efficient exploration in deep reinforcement learning remains a fundamental challenge, especially in environments characterized by high-dimensional states and sparse rewards. Traditional exploration strategies that rely on random local policy noise, su...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "paper",
        "framework",
        "experiment",
        "arxiv"
      ],
      "score": 0.6
    },
    {
      "title": "mcp-agent - Build effective agents using Model Context Protocol and simple workflow patterns",
      "url": "https://github.com/lastmile-ai/mcp-agent",
      "description": "Build effective agents using Model Context Protocol and simple workflow patterns",
      "published_date": "2024-12-18T01:55:10+00:00",
      "source": "GitHub",
      "category": "industry_news",
      "keywords": [
        "model",
        "context"
      ],
      "score": 0.6
    },
    {
      "title": "AlphaCodium - Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "url": "https://github.com/Codium-ai/AlphaCodium",
      "description": "Official implementation for the paper: \"Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\"\"",
      "published_date": "2024-01-14T15:17:18+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "paper",
        "prompt",
        "prompt engineering"
      ],
      "score": 0.6
    },
    {
      "title": "Automatic Machine Translation Detection Using a Surrogate Multilingual Translation Model",
      "url": "https://arxiv.org/abs/2511.02958",
      "description": "arXiv:2511.02958v1 Announce Type: new \nAbstract: Modern machine translation (MT) systems depend on large parallel corpora, often collected from the Internet. However, recent evidence indicates that (i) a substantial portion of these texts are machine-generated translations, and (ii) an overreliance ...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "model",
        "experiment",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "A Computational Approach to Analyzing Disrupted Language in Schizophrenia: Integrating Surprisal and Coherence Measures",
      "url": "https://arxiv.org/abs/2511.03089",
      "description": "arXiv:2511.03089v1 Announce Type: new \nAbstract: Language disruptions are one of the well-known effects of schizophrenia symptoms. They are often manifested as disorganized speech and impaired discourse coherence. These abnormalities in spontaneous language production reflect underlying cognitive di...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "study",
        "model",
        "product",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "Stochastic Deep Graph Clustering for Practical Group Formation",
      "url": "https://arxiv.org/abs/2511.02879",
      "description": "arXiv:2511.02879v1 Announce Type: new \nAbstract: While prior work on group recommender systems (GRSs) has primarily focused on improving recommendation accuracy, most approaches assume static or predefined groups, making them unsuitable for dynamic, real-world scenarios. We reframe group formation a...",
      "published_date": "2025-11-06T05:00:00",
      "source": "arXiv",
      "category": "research_papers",
      "keywords": [
        "framework",
        "experiment",
        "arxiv"
      ],
      "score": 0.4
    },
    {
      "title": "optillm - Optimizing inference proxy for LLMs",
      "url": "https://github.com/algorithmicsuperintelligence/optillm",
      "description": "Optimizing inference proxy for LLMs",
      "published_date": "2024-08-22T19:46:07+00:00",
      "source": "GitHub",
      "category": "prompt_engineering",
      "keywords": [
        "LLM"
      ],
      "score": 0.4
    }
  ]
}